[["index.html", "Tools for Analytics (TFA) Course notes Module 1 Introduction to the course 1.1 Learning outcomes 1.2 Purpose for the course 1.3 R vs Excel/VBA 1.4 How a computer works 1.5 How the notes are organized 1.6 Acknowledgements 1.7 Exercises", " Tools for Analytics (TFA) Course notes Lars Relund Nielsen 2022-10-20 Module 1 Introduction to the course This site contains course notes for the course “Tools for Analytics” held at Aarhus BSS. The notes show the learning path for each week and contain. The course is an introductory course at the Operations and Supply Chain Analytics programme and intended to give knowledge about IT tools for Analytics. Expect the notes to be updated when the course runs. The date listed above is the last time the notes was updated. Learning path diagram Click/hover the nodes to follow links and see details. A detailed description of Business Analytics have been pointed out as an extra supplement in the learning path diagram. You may have a look at it if you like. 1.1 Learning outcomes By the end of this module, you are expected to: Memorize the purpose of the course. Describe what the term Business Analytics mean. Identify pros and cons of using Excel, VBA and R. Describe how a computer works. Describe what an algorithm is. Know how the course is organized. The learning outcomes relate to the overall learning goals number 1, 3 and 5 of the course. 1.2 Purpose for the course Since the amount of available data has increased extensively in many companies, there is a need for analysts with the ability to do tasks within Analytics. For instance, extract relevant data and perform valid quantitative analysis. Clearly, it is also important that the analyst can communicate the results of the analysis to their surroundings. This requires for the analyst to be particularly qualified in handling IT based tools beyond e.g. basic Excel. Business Analytics (BA) (or just Analytics) refers to the scientific process of transforming data into insight for making better decisions in business. BA can both be seen as the complete decision making process for solving a business problem and the creation of business value by integration of concepts, methods and data. As a process, it can be characterized by descriptive, predictive, and prescriptive model building using data sources. For a full definition see the appendix. Within a Business Analytics (BA) framework the course focuses on giving you an introduction to programming, handeling data and doing descriptive analytics. Descriptive analytics categorizes, characterizes, consolidates, and classifies data. Examples are standard reporting and dashboards (key performance indicators (KPIs), what happened or is happening now?) and ad-hoc reporting (how many/often?). Descriptive analytics often serves as a first step in the successful application of predictive or prescriptive analytics. Predictive and prescriptive analytics are covered in other courses of the programme. Analytics may be seen as a data driven process: Figure 1.1: Analytics as a data driven process. For doing data driven analytics you first must import your data. That is, take data from a database, file, web API etc. and transform it into a data frame/table. In general raw data may be messy and need to be structured in a tidy way. Tidying your data means storing it in a structured form suitable for analysis. In brief, when your data is tidy, each column is a variable, and each row is an observation. Tidy data is important because the consistent structure lets you focus your struggle on questions about the data. Once you have tidy data, a common first step is to transform it. Transformation includes narrowing in on observations of interest (e.g. only observations from a specific year or warehouse), creating new variables based on existing variables (e.g. the cost of using the machine that day given idle time). Together, tidying and transforming are called wrangling, because it can be a hard process to get your data in the right form. The next step is to do a simple exploration of you data such as calculating a set of summary statistics (like counts, means or KPIs). A good way to get an overview over your data is by visualization. A good visualisation will show you things that you did not expect, raise new questions about the data or confirm your hypothesis. A good visualization might also hint that you’re asking the wrong question, or you need to collect different data. Exploration and visualization are descriptive analytics and used to answer questions such as: What happened? How many, how often, where? Where exactly is the problem? What actions are needed? Models are complementary tools to visualization. Once you have made your questions sufficiently precise, you can use a model to answer them. A model is a description of a system using mathematical concepts and a simplification of the real system. That is, the results of a model are based on a set of assumptions. Models for statistical analysis, forecasting, system behavior are predictive analytics and answer questions like: Why is this happening? What if these trends continue? What will happen next? Models for prescriptive analytics use optimization and other decision modeling techniques to suggest decision options with the goal of improving business performance and answer questions like: What is the best that can happen? Exploration, visualization and modeling may be seen as different steps which can be used for analyzing the data and answer the overall questions. This course will focus on the two first steps. Given an analysis, communication is an absolutely critical part. It does not matter how well your models and visualization have led you to understand the data unless you can also communicate your results to decision makers. Note that analytics is not a one-way process, it is common that you several times have to tidy and transform your data, explore and visualize based on the results of a model, rerun the model based on feedback from the decision makers etc. Common connections are visualized using directed arrows in Figure 1.1. Surrounding the process is programming. Programming is the Swiss army knife you use during parts of the process. An introduction to programming is given using both VBA in Excel and the programming language and free software environment R. Programming focus on writing algorithms. An algorithm is a finite sequence of well-defined instructions to solve a specific problem or to perform a computation. That is, we use a programming language to program an algorithm that solves a specific task, e.g. find the best route, sort words, make a plot, etc. 1.3 R vs Excel/VBA This course gives you an introduction to programming using both VBA and R. The two programming languages are different and here are some comparisons: Excel Pros: Initial learning curve is quite minimal. Analysis can be done via point-and-click. Useful for fast analysis (you can change a cell and see effects on other cells, plots etc.) It is not exceedingly hard to make basic graphs and charts. Data can be stored inside the sheets. Cons: The mixture of data entries, analysis, and visualization makes it easy to confuse cells that contain raw data from those that are the product of analysis. The analysis directly manipulates the only copy of the raw data. Using mouse clicks means that a mistaken click or drag action can lead to errors or the overwriting of data. Do not handle non-tabular data well. VBA VBA is a compiled language implemented using compilers (translators that generate machine code from source code). That is, code need to be compiled first before running it. Pros: Can be used inside MS Office applications e.g. Excel. Already contained in Excel, i.e. if you have Excel installed you can start coding. The VBA code is stored within the spreadsheet, allowing any user with access to the spreadsheet to easily run the code. VBA is easy to learn. Especially if you are already experienced in Excel. Good for automating tasks in Excel. Still used in many companies. Cons: A programming language, meaning the initial learning curve is steeper. It will take you some time to become familiar with the interface and master the various functions. Since a compiled language, compiling code may take time. Powerful inside Excel but other programming languages are better to learn for general tasks. An old programming language (Microsoft stopped investing in VBA in 2008). R R is an interpreted language with step-by-step execution of source code (no pre-runtime translation takes place) from the command line or using a script file. Pros: There is a clear division between data entry and analysis. You import the data, create an object that is a copy of the raw data and do manipulations on this copy. That is, the original data are never altered in any way and there is no way to mess up the raw data. Manipulating a copy of the data enables you to experiment. A line of code that fails to produce the expected result can be tweaked and rerun. All manipulations can be done in code. The process of analysis are easily reproduced by the code. That is, the use of code for data analysis enables the creation of more reproducible research. With code all analysis is documented instead of being hidden behind mouse clicks. Saving analysis in code has the immediate benefit that it can be easily rerun anytime that new data is added or the code can also be applied to a completely new data set. Free and with a large community that promotes sharing of libraries for data analysis. Can produce complex and advanced data visualizations. Cons: R is a programming language, meaning the initial learning curve is steeper. It will take you some time to become familiar with the interface and master the various functions. 1.4 How a computer works As a prerequisite for this course you need some basic knowledge about what a computer is. Have a look at these slides or this video. 1.5 How the notes are organized Module 1 (this module) gives a short introduction to the course. The course notes consists of different parts each containing teaching modules about specific topics: Part I consider tools for analytics using VBA in Excel (mainly programming). Module 2 gives you an introduction to VBA so you can get started programming. In Module 3 loop and conditional statements are introduced and Module 4 focus on how to make procedures. Next, we consider advanced data types and usage in Module 5. Finally, Module 6 considers generation of random numbers in VBA and how they can be used for simulation. Part II consider tools for analytics using R. The appendix contains different modules that may be helpful for you including hints on how to work in groups, how to get help if you are stuck and how to annotate the course notes. 1.6 Acknowledgements Some of the materials in these notes are taken from various places The bookdown skeleton and some notes are based on the Stat545 course. Some parts in Module 1 are inspired by Chapter 1 in Wickham (2017). The VBA modules are inspired by the book Wøhlk (2010). This also holds for some of the exercises. Module 7 is inspired by Chapter 1 in Bryan (2017). Module 8 is using some text and images from Chapter 1 in Ismay and Kim (2020) and Chapter 2 in Bryan (2017). A few exercises are inspired by Chapter 2 in Irizarry (2020). Notes about git and GitHub in the appendix are based on Bryan, STAT 545 TAs, and Hester (2020). Exercise 13.5.1 is a revision of Chapters 6-7 in Bryan (2017). Exercise 13.5.2 is a revision of Session 3 in the Welcome to the tidyverse course. Exercise 14.6.1 is a revision of Chapter 9 in Irizarry (2020). Exercise 14.6.3 is inspired by the COVID19 application exercise at the data science in a box course. Exercise 14.6.4 is inspired by the Lego homework exercise at the data science in a box course. Exercise 13.5.4 is inspired by the Fisheries application exercise at the data science in a box course. I would like to thank all for their inspiration. Also thanks to Solveig for proofreading the draft. This work is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International CC BY-NC-SA 4.0. 1.7 Exercises 1.7.1 Exercise - How to annotate The online course notes can be annotated using hypothes.is. You can create both private and public annotations. Collaborative annotation helps people connect to each other and what they’re reading, even when they’re keeping their distance. You may also use public notes to help indicate spell errors, unclear content etc. in the notes. Sign-up at hypothes.is. If you are using Chrome you may also install the Chrome extension. Go back to this page and login in the upper right corner (there should be some icons e.g. &lt;). Select some text and try to annotate it using both a private and public annotation (you may delete it again afterwards). Go to the slides for this module and try to annotate the page with a private comment. References "],["mod-vba-intro.html", "Module 2 An introduction to VBA 2.1 Learning outcomes 2.2 What is VBA 2.3 Setup Excel for VBA 2.4 Your first program 2.5 The macro recorder 2.6 VBA - A short overview 2.7 Good coding pratice 2.8 Recap 2.9 Exercises", " Module 2 An introduction to VBA This module gives a short introduction to VBA, so you can get started programming and run your code. A template with VBA code for this module is given in the file 02-vba-intro-template.xlsm (open it and use it while reading the notes). Have a look inside the module TM2_ex in the VBA editor for examples used in the notes and during lectures. Have a look at module TM2_exercises for exercises. The template file for next teaching module will contain guiding answers for the exercises to this teaching module. Learning path diagram Click/hover the nodes to follow links and see details. If you like a different learning style there is a lot for videos about VBA online such as course 14-Hour VBA Course. The videos have been pointed out as extra online supplements in the learning path diagram. However, they are not necessary for the course. Since Excel change as new versions arrive and it work on different operating systems, the look in the screenshots and videos might be a bit different from your version. However, you still should be able to understand it. 2.1 Learning outcomes By the end of this module, you are expected to: Describe what VBA is. Setup Excel for VBA. Know how the macro recorder works. Make your first program. Have an overview over what VBA can do. Describe what a variable is. Name different data types and how they effect memory size. Declare a variable as a data type. Make a simple procedure. Do simple loops and conditional statements. Recorded you first macro using the macro recorder The learning outcomes relate to the overall learning goals number 2 and 4 of the course. 2.2 What is VBA Visual Basic for Applications (VBA) is an implementation of the BASIC programming language intended to control and automate Microsoft Office applications, developed by Microsoft. For instance, you can automatically create sheets, delete objects, create user-defined functions or read/write data to a sheet. It is not a standalone program, it can only run in the host application. In this course we will focus on running VBA from Excel. VBA is widely used in the industry (specially linked to Excel) and easy to learn. Microsoft stopped investing in VBA in 2008. It only update it for small changes. However, VBA is still a vital part of desktop Office applications, and will continue to be so in the future. VBA is a compiled language implemented using compilers (translators that generate machine code from source code). That is, code need to be compiled first before running it. You can only run VBA using the desktop version of Excel. That is, you can’t create, run, or edit VBA in Excel for the web. With VBA you can extend Excel and automate tasks by coding different algorithms that for instance can be run by pressing a button. Since VBA is a programming language, the initial learning curve is steeper compared to Excel. However, you will get started fast because you already know Excel. 2.3 Setup Excel for VBA For running VBA code the Developer tab needs to be visible in Excel. This can be done by check marking the Developer tab under the ‘Ribbon and Toolbar’ options in Excel. You add it by choosing Excel -&gt; Preferences -&gt; Ribbon and toolbar ( ) or right click a tab and choose Customize ribbon … ( ). Figure 2.1: The VBA editor. In the Developer tab you open the VBA editor by pressing the Visual basic button ( Alt + F11, ⌥ + F11). The VBA editor is where you write your VBA code. A screenshot of the VBA editor can be seen in Figure 2.1. You can setup the editor so it consists of a set of different sub-windows. Here we will highlight the ones you will use the most: Code: The code window is where you can see the code of your modules. Process Explorer: Gives you an overview over all your open workbooks (a Excel file) and the VBA modules (a place to write VBA code) inside each workbook. Properties: Each element in the Process Explorer can be seen as an object and each object has a set of properties. For instance a module have a property called Name containing the name of the module. You can edit the name by modifying the field in the Properties window. Similar a worksheet has a set of properties (try selecting one of the sheets in the Process Explorer). Locals: This is a window which can be used for debugging. During debugging you can run your code line by line by inserting breakpoints. You can then observe the values of your variables in the Locals window. If you do not see the sub-windows in the editor. Then you can open them using the icons in the toolbar (hoover over the icons to find them). Finally, let us set the preferences for the VBA editor. Open the preferences/options Excel -&gt; Preferences -&gt; Editor ( ) or Tools -&gt; Options -&gt; Editor ( ). Uncheck mark ‘Auto Syntax Check’ and check mark ‘Require Variable Declaration’. 2.4 Your first program Let us try to make your first piece of code. Download the template file 02-vba-intro-template.xlsm, open the file and open the VBA editor under the Developer tab. Add a new module by clicking the Insert Module icon (upper left corner - note you can hoover over the icons to see what they do). Rename the module (named Module1) to TM2_hello (note you have to use underscores). Open the module by double clicking on the module in the Process Explorer Add the code &#39; Your first program/macro Sub TM2_SayHello() MsgBox (&quot;Say hello world :-)&quot;) End Sub The code is a procedure (sub) and since it does not have any input arguments it is called a macro and can be run directly. Note if a line starts with a ' then the line is considered as a comment and not used by the program. Run the macro by pressing the Play icon or using the shortcut F5. What happend? Go to the worksheet TM2 in Excel. In the Developer tab press the Button icon and click on cell G3. In the popup window select macro name TM2_SayHello and click OK. Rename the button by clicking the text and call it ‘Say Hello’. Click besides the button to finish. Run the button by clicking it. Try right clicking the button and move/resize it. Save the workbook (Excel file). Note the Excel file has extension .xlsm and not .xlsx because it contains VBA code. You have now finished your first program by saying hello to the world using a message box. 2.5 The macro recorder It is possible to use the Macro recorder to turn your actions in Excel into VBA code. This can be particularly useful if you have forgotten the code for a specific color, the name of a function or need to plot a graph. Unfortunately, you cannot record if-statements or loops, so the recorder is not an easy way out of learning to code. But it is a handy tool for getting pieces of code. Let us try to record a macro that make a scatter plot of cells D8:E12 and change the title: Click the Record Macro icon under under the Developer tab. Name the macro TM2_Plot and click OK (the recorder is now running). Go to the worksheet TM2 and select cells D8:E12. Add a scatter plot of the points. Rename the title to ‘A line’. Click the Stop Recording icon under under the Developer tab. You have now finished recording your macro. Let us have a look at the code by going to the TM2_Plot sub in the VBA editor. You should have something similar to: Sub TM2_Plot() &#39; &#39; TM2_Plot Macro &#39; Worksheets(&quot;TM2&quot;).Activate Range(&quot;D8:E12&quot;).Select ActiveSheet.Shapes.AddChart2(240, xlXYScatterSmooth).Select ActiveChart.SetSourceData Source:=Range(&quot;&#39;TM2&#39;!$D$8:$E$12&quot;) ActiveChart.ChartTitle.Select ActiveChart.ChartTitle.Select ActiveChart.ChartTitle.Text = &quot;A line&quot; Selection.Format.TextFrame2.TextRange.Characters.Text = &quot;A line&quot; With Selection.Format.TextFrame2.TextRange.Characters(1, 6).ParagraphFormat .TextDirection = msoTextDirectionLeftToRight .Alignment = msoAlignCenter End With With Selection.Format.TextFrame2.TextRange.Characters(1, 1).Font .BaselineOffset = 0 .Bold = msoFalse .NameComplexScript = &quot;+mn-cs&quot; .NameFarEast = &quot;+mn-ea&quot; .Fill.Visible = msoTrue .Fill.ForeColor.RGB = RGB(89, 89, 89) .Fill.Transparency = 0 .Fill.Solid .Size = 14 .Italic = msoFalse .Kerning = 12 .Name = &quot;+mn-lt&quot; .UnderlineStyle = msoNoUnderline .Spacing = 0 .Strike = msoNoStrike End With With Selection.Format.TextFrame2.TextRange.Characters(2, 5).Font .BaselineOffset = 0 .Bold = msoFalse .NameComplexScript = &quot;+mn-cs&quot; .NameFarEast = &quot;+mn-ea&quot; .Fill.Visible = msoTrue .Fill.ForeColor.RGB = RGB(89, 89, 89) .Fill.Transparency = 0 .Fill.Solid .Size = 14 .Italic = msoFalse .Kerning = 12 .Name = &quot;+mn-lt&quot; .UnderlineStyle = msoNoUnderline .Spacing = 0 .Strike = msoNoStrike End With ActiveChart.ChartArea.Select End Sub In general a recorded macro contains a lot of unnecessary code which can be removed. For instance, here we just want to make a scatter plot of cells D8:E12 and change the title. That is, the code can be reduced to: &#39; Add a scatter plot Sub TM2_Plot() Worksheets(&quot;TM2&quot;).Activate Range(&quot;D8:E12&quot;).Select ActiveSheet.Shapes.AddChart2(240, xlXYScatterSmooth).Select ActiveChart.SetSourceData Source:=Range(&quot;&#39;TM2&#39;!$D$8:$E$12&quot;) ActiveChart.ChartTitle.Text = &quot;A line&quot; End Sub Which code to remove can sometimes be hard to realize. However, you may try to remove small parts of code, run the macro and check if the results still are as wanted. Finally, try to add a button ‘Make plot’ that run the macro. Go to the worksheet TM2 and do steps: In the Developer tab press the Button icon and click on cell G8. In the popup window select macro name TM2_Plot and click OK. Rename the button by clicking the text and call it ‘Make plot’. Click besides the button to finish. Run the button by clicking it. 2.6 VBA - A short overview Let us have a short overview over some VBA features so you can get started coding. Basic building blocks in programming are: Variables store stuff in memory. Procedures (functions and subs) execute a set of instructions. Input and output are needed to read data and output the result. Conditional statements are used to execute different instructions depending on a true/false value. Loops are used to execute code repeatedly. 2.6.1 Variables Variables are used to store information that is saved in memory. You may visualize a variable as a box in memory (see Figure 2.2). The variable name can be seen as the label on the box. Figure 2.2: Visualization of computer memory The box can contain for instance a number, a date or a boolean. That is, any data type defined by VBA. Some of the basic data types used by VBA are: Table 2.1: Basic data types. Name Type Details Byte Numerical Whole number between 0 and 255. Integer Numerical Whole number between -32768 and 32767. Long Numerical Whole number between - 2147483648 and 2147483647. Double Numerical Floating decimal number between -1.79769313486232E308 and 1.79769313486232E308. String Text Text. Date Date Date and time. Boolean Boolean True or False. Variant Any type Any kind of data (default type if the variable is not declared). All basic data types can be seen in the VBA documentation. Note that some data types are numericals, i.e. they represent a number (either an integer or a decimal number), other data types represent a set of characters (a string), a boolean or a date. More advanced data types such as a group of numbers (a numeric array), a range of cells in a worksheet (an object) or a set of numbers (a collection) will be considered in Module 5. Your memory contains a limited amount of storage and it is therefore important to use it wisely. The computer memory can be seen as a group of bits (zero and ones) and we can measure the memory size by counting the number of bits or bytes (8 bits = 1 byte). Different data types take up different amounts of memory. For example, the memory requirements for some of the basic data types are: Table 2.2: Memory requirements for some data types. Data type Storage size Byte 1 byte Boolean 2 bytes Integer 2 bytes Long (long integer) 4 bytes Double (double-precision floating-point) 8 bytes Date 8 bytes String 10 bytes + string length * 2 bytes Variant (a number) 16 bytes Variant (a string) 22 bytes + string length * 2 bytes 8 Bits = 1 Byte, 1024 Bytes = 1 Kilobyte, 1024 Kilobytes = 1 Megabyte, 1024 Megabytes = 1 Gigabyte and 1024 Gigabytes = 1 Terabyte. Always declare your variables explicit in VBA. If you can add Option Explicit in the top of your module, undefined variables will raise an error. You can add it by default by modifying the preferences for the VBA editor (see Section 2.3). Declaring variables is good coding practice since it reduces the memory requirements and avoid type errors such as Option Explicit Dim intCtr as integer intCtr = 10 intCtr = intCtg + 10 This will raise an error because intCtg is not defined (you have made a typo and meant intCtr). Without Option Explicit the code will run and assume that intCtg is another variable (initialized to zero). As can be seen a double takes 4 times the memory compared to an integer. That is, you can save memory by considering what data type you need. Consider an example where you have 10000 customer locations on a map and you want to store the distance between customer \\(i\\) and \\(j\\). That is, you have to store \\(10000 \\cdot 10000 = 100.000.000\\) numbers. The memory requirements given different data types are: Data type Memory requirements Variant \\((10000\\cdot 10000\\cdot 16)/1024/1024 \\approx 1526\\) MB Double \\((10000\\cdot 10000\\cdot 8)/1024/1024 \\approx 763\\) MB Integer \\((10000\\cdot 10000\\cdot 2)/1024/1024 \\approx 191\\) MB If you do not think about memory usage a Variant data type would have been used taking up the double the size compared to using a Double (a decimal number). Moreover, if it is enough to measure the distance using an Integer between 0 and 32767, then we can reduce the memory requirements to only 191 MB. Often the free memory in your computer is around 5 GB, i.e. think about which data type you need! You declare variables using the Dim keyword: &#39;&#39; Declare some variables Sub TM03_DeclareVariables() &#39; Always declare variables in the top of a procedure (memory is allocated) Dim intPersons As Integer Dim dblAmount As Double Dim strText As String &#39; Here we assign values to the variables (modify the memory) intPersons = 10 dblAmount = 27.4 strText = &quot;Number of persons are &quot; MsgBox (strText &amp; intPersons &amp; &quot; which own &quot; &amp; dblAmount &amp; &quot;$&quot;) End Sub Three variables are declared on the first three lines in the sub (good coding practice). Variables can be of different data types (here an integer, a double and a string). We allocate values to the variables on the next lines and finally output the result in a message box. Note VBA code is case-insensitive, i.e. strText and strtext is the same variable. It is good coding practice to be consistent and often the VBA editor will help you by changing strtext to strText automatically. 2.6.2 Procedures In VBA we deal with two kinds of procedures: A Sub which can work as a “macro” in Excel, i.e. we can call it using e.g. a button and a Function which can work like Excel functions, i.e. return a value. We already have declared some subs. Let us try to make a function: &#39;&#39; A function joining two strings Function TM2_StringJoin(strF As String, strL As String) As String Dim strJ As String strJ = strF &amp; &quot; &quot; &amp; strL TM2_StringJoin = strJ End Function First observe that the function have two string input arguments strF and strL. These two strings are joined into one string (saved in the variable strJ) by using the string concatenate symbol &amp;. Finally, the value is returned by assigning the value to same variable as the function name TM2_StringJoin. The function can be called from Excel like any other function by using the function name (have a look at cell D5 in the worksheet TM2). You may also use all the built-in Excel functions in VBA: &#39;&#39; Call an Excel function Sub TM2_ExcelFunction() MsgBox (&quot;The sum of cells D9:D12 are &quot; &amp; WorksheetFunction.Sum(Worksheets(&quot;TM2&quot;).Range(&quot;D9:D12&quot;))) End Sub Note all Excel functions are accessed using the WorksheetFunction object. That is, we write WorksheetFunction.&lt;function name&gt;. VBA also has a set of built-in functions which can be used. For instance the Date and InStr function: &#39;&#39; Call VBA functions (run it using F5) Sub TM2_VBAFunction() MsgBox (&quot;The current date is &quot; &amp; Date) MsgBox (&quot;Jen is found at char number: &quot; &amp; InStr(&quot;Hi Jen how are you&quot;, &quot;Jen&quot;)) End Sub We will have a closer look on procedures in Module 4. 2.6.3 Input and output Input and output are needed to read data and output the result. Examples on input/output are dialog boxes which can be created using MsgBox or InputBox: Sub TM2_Dialog() Dim strName As String strName = InputBox(&quot;Type your name:&quot;) MsgBox &quot;Your name is &quot; &amp; strName End Sub First, a string is declared. Next, a value is read to the string using an input box. Finally, the result is output using a message box. You can also write/read values from a sheet using Range or Cells. Note it is always a good idea to know which sheet you are considering by using the Worksheets function: &#39;&#39; Read and write to sheet Sub TM2_ReadWriteSheet() Dim str1 As String Dim int1 As Integer Worksheets(&quot;TM2&quot;).Activate &#39; We activate a sheet so know use this sheet &#39; Input values from sheet str1 = Range(&quot;D4&quot;) &#39; read cell D4 int1 = Cells(9, 4) &#39; read row 9 and col 4 (cell D9) &#39; Output values Range(&quot;B7&quot;) = str1 &amp; &quot;(&quot; &amp; int1 &amp; &quot;)&quot; Cells(8, 2) = str1 End Sub After declaring variables, the worksheet TM2 is activated and we input/output values using the Range and Cells functions. We will have a closer look on the range object in Module 5. 2.6.4 Conditional statements Conditional statements execute different instructions depending on a true/false value. &#39;&#39; Conditional statements example Sub TM2_CondStatement() Dim strName As String Dim intAnswer As Integer Worksheets(&quot;TM2&quot;).Activate strName = InputBox(&quot;Type your name:&quot;) intAnswer = MsgBox(&quot;Do you want to display your name in a message box?&quot;, vbYesNo) &#39; you can use vbYes and vbNo in your code If intAnswer = vbYes Then &#39; Make the message box: MsgBox (&quot;Your name is &quot; &amp; strName) Else &#39; Write to the sheet: Range(&quot;B10&quot;) = strName MsgBox (&quot;Your name is in cell B10&quot;) End If End Sub After declaring variables and activating the worksheet, a dialog box is used for reading your name. Next, based on your answer we use an If/Else statement to do two different tasks. We will have a closer look on conditional statements in Module 3. 2.6.5 Loops Loops can be used to execute code repeatedly: &#39;&#39; Loops example Sub TM2_Loops() Dim k As Integer Worksheets(&quot;TM2&quot;).Activate For k = 2 To 5 Cells(k, 10) = &quot;Row &quot; &amp; k Next End Sub Here a For loop is used to write out values to cells J2:J5. We will have a closer look on loops in Module ??. 2.7 Good coding pratice It is always a good idea to maintain a consistent coding practice. The main reason for using a consistent set of coding conventions is to standardize the structure and coding style of an application so that you and others can easily read and understand the code. Good coding conventions result in precise, readable, and unambiguous source code that is consistent with other language conventions and as intuitive as possible. As you already have seen the code in this teaching module has been structured in VBA modules (we use the prefix TM2_ for all modules related to this teaching module). Each procedure starts with a capital letter and we use code indention to read the code easier. Different ways of naming variables exists (naming convention). Some use snake case others use camel case. The Leszynski naming convention define variables with a consistent prefix that makes it easy to identify its data type. Some common prefixes used for the Leszynski naming convention are: Table 2.3: Prefixes for some variables. Type Prefix Example Boolean bln blnFound Currency cur curRevenue Date (Time) dtm&lt; dtmStart Double dbl dblTolerance Integer int intQuantity Long lng lngDistance String str strFName Variant vnt vntCheckSum Array ary aryNumbers (optional) Worksheet wst wstDistances Workbook wbk wbkData Many other prefixes can be used also. It is common to use Leszynski convention within the VBA community. A few examples: this_is_snake_case # note you do not use capital letters here (not used) thisIsCamelCase # you start each word with a capital letter intAmount # Lezynski convention naming an integer (int) variable strFullName # Lezynski naming a string (str) variable We adapt the Leszynski naming convention together with camel case. One exception is that we add the suffix TM2_ when we name procedures so that we can easy find procedures related to a given teaching module. When defining variables and functions, it is in general good practice to use nouns for variables and verbs for functions. It is always good practice to comment your code. Such that others can get a fast overview and understand your code easier. We will use roxygen documentation comments which are widely known. For example in the top of a module file you may write: &#39;&#39; Module description. &#39; Can be more than one line. &#39; @author Lars Relund &lt;junk@relund.dk&gt; Before each sub, function etc. write something like: &#39;&#39; Sub description &#39; &#39; @pre Precondition &#39; @post Postcondition &#39; &#39; @param strA Explanation of input parameter strA &#39; @param intB Explanation of input parameter intB &#39; @return Return value (if a function) &#39; @remarks Further remarks Function MyFunc(strA As String, intB As Integer) As Integer { ... } For further details about coding/naming convention see Section D. 2.8 Recap This module gives a short introduction to VBA: A programming language intended to control and automate Microsoft Office applications (we use Excel). VBA (Visual Basic for Applications) is an implementation of BASIC developed by Microsoft. A compiled language. That is, code need to be compiled first before running it. You can only run VBA using the desktop version of Excel (not the web version). With VBA you can extend Excel and automate tasks by coding different algorithms that for instance can be run by pressing a button. For running VBA code the Developer tab needs to be visible in Excel. This can be done by check marking the Developer tab under the ‘Ribbon and Toolbar’ options in Excel. You add it by choosing Excel -&gt; Preferences -&gt; Ribbon and toolbar ( ) or right click a tab and choose Customize ribbon … ( ). In the Developer tab you open the VBA editor by pressing the Visual basic button ( Alt + F11, ⌥ + F11). A few useful shortcuts: Toggle VBA editor and Excel ( Alt + F11, ⌘⇧´). Run current procedure or continues execution after pausing (F5). Auto complete code (Ctrl + Space). On a mac you may have to disable the default shortcut (Ctrl + Space) for switching input sources. You can go to the System Preferences -&gt; Keyboard -&gt; Shortcuts -&gt; Input Sources and disable it. Use the debugger and go to next line of code ( F8, ⇧⌘I). Switch between subs/functions ( Ctrl + Up/Down, ⌘ + Up/Down). Basic building blocks in programming: Variables store stuff in memory. Procedures (functions and subs) execute a set of instructions. Conditional statements are used to execute different instructions depending on a true/false statement. Loops are used to execute code repeatedly. Input/output are needed to read data and output the result. Variables are used to store information in the program. Think of it as a box that can contain e.g. a number, a string or a date. The variable name is the label on the box. In VBA we deal with two kinds of procedures: A Sub which can work as a “macro” in Excel, i.e. we can call it using e.g. a button and a Function which can work like Excel functions, i.e. return a value. Examples on input/output are dialog boxes which can be created using MsgBox or InputBox. You can also write/read values from a sheet using Range or Cells. Note it is always a good idea to know which sheet you are considering by using Worksheets(\"&lt;sheet name&gt;\").Activate. Conditional statements (decisions) execute different instructions depending on a true/false. Loops can be used to execute code repeatedly. Excel functions can be called with the WorksheetFunction e.g. WorksheetFunction.Sum(Range(\"D2:E5\")) Always remember to save workbooks with VBA code using the file has extension .xlsm and not .xlsx otherwise the VBA code will be removed from the file! You may also have a look at the slides for this module . 2.9 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Some of the solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up too early. Put some effort into finding a solution! Practice using shortcuts in RStudio (use Shift+Alt+K to get an overview). Go to the Tools for Analytics workspace and download/export the r project_name_prefix project. Open it on your laptop and have a look at the files in the exercises folder which can be used as a starting point. A template with VBA code for this module is given in the file 02-vba-intro-template.xlsm (open it and use it while reading the notes). Have a look inside the module TM2_ex in the VBA editor for examples used in the notes and during lectures. Have a look at module TM2_exercises for exercises. The template file for next teaching module will contain guiding answers for the exercises to this teaching module. 2.9.1 Exercise - Hello Consider the procedure TM2_SayHello in Section 2.4 and modify it into procedure TM2_SayHelloAdv with features: Use an input box to ask for your name. Output Hello in cell B11 in worksheet TM2. Run it using the shortcut F5. 2.9.2 Exercise - Record a macro Do the following steps: Type ‘My name is:’ in cell B12. Type you name in cell B13 and activate it (click on it). Start the macro recorder and call the macro TM2_ChangeLayout. Change the color to blue and font size to 14. Stop the macro recorder. Activate cell B12 and run the macro. Open the VBA editor and inspect the macro. Cleanup the macro so only stuff about color and size are maintained. Add a button to run the macro. Select cells D15:E17 and run the macro. Modify the macro in the editor so the font size is 10 and test it. 2.9.3 Exercise - User input Write a procedure (sub) TM2_CheckNumber that: Ask for an integer using an input box. Make a message box telling if the number is above or at most 10. Write the number to cell B14. What happens if you do type in a string in the input box? 2.9.4 Exercise - Max and min number The worksheet TM2_Numbers contains a button to a procedure that generate 40 random integers in the interval \\([-1000,1000]\\). × Hint Sub TM2_FindMax() Dim intM As Integer Dim r As Integer Worksheets(&quot;TM2_Numbers&quot;).Activate intM = -1001 For r = 1 To 40 If Cells(r, 1) ___ intM Then intM = ___ End If Next Range(&quot;D1&quot;) = ___ End Sub Close Hint Create a procedure that use loops and conditional statements to find the maximum number and write it to cell D1. Assign the procedure to button Find max. Create a procedure that use loops and conditional statements to find the minimum number and write it to cell D2. Assign the procedure to button Find min. × Hint Sub TM2_FindRange() Dim intM1 As Integer Dim intM2 As Integer Dim r As Integer Worksheets(&quot;TM2_Numbers&quot;).Activate intM1 = 1001 intM2 = -1001 For r = 1 To 40 ___ Next Range(&quot;D3&quot;) = &quot;[&quot; &amp; intM1 &amp; &quot;,&quot; &amp; intM2 &amp; &quot;]&quot; End Sub Close Hint Create a procedure that use loops and conditional statements to find the number range and write it to cell D3. Assign the procedure to button Find range. Given two numbers m1 and m2, you can concatenate them to a string using &amp; e.g. \"[\" &amp; m1 &amp; \",\" &amp; m2 &amp; \"]\". Create a procedure that use loops and conditional statements to count the number of positives and write it to cell D4. Assign the procedure to button Count positives. It may often be nice to know the row number of the minimum and maximum values. Create a procedure that finds the maximum row number and write it to cell D5. Assign the procedure to button Find max row. Create a procedure that finds the minimum row number and write it to cell D6. Assign the procedure to button Find min row. The procedure TM2_RunAll which is already linked to button Run All, runs all the procedures. Have a look at the code and try it out. "],["mod-vba-loops-cond.html", "Module 3 Loops and conditional statements 3.1 Learning outcomes 3.2 Relational and logical operators 3.3 Loops 3.4 Conditional statements 3.5 Example - Find Jen 3.6 Example - A distance matrix 3.7 Recap 3.8 Exercises", " Module 3 Loops and conditional statements This module gives an introduction to loops and conditional statements. Loops are used to repeat code and conditional statements are used to redirect code execution based on the conditions. Both are basic building blocks in programming. A template with VBA code for this module is given in the file 03-vba-loops-cond-template.xlsm (open it and use it while reading the notes). Have a look inside the module TM3_ex in the VBA editor for examples used in the notes and during lectures. Have a look at module TM3_exercises for exercises. The template file for next teaching module will contain guiding answers for the exercises to this teaching module. Learning path diagram Click/hover the nodes to follow links and see details. If you like a different learning style there is a lot for videos about VBA online such as course 14-Hour VBA Course. The videos have been pointed out as online supplements in the learning path diagram. However, they are not necessary for the course. Since Excel change as new versions arrive and it work on different operating systems, the look in the screenshots and videos might be a bit different from your version. However, you still should be able to understand it. 3.1 Learning outcomes By the end of this module, you are expected to be able to: Describe what a conditional statement is. Test a condition built using relational/logical operators. Declare a conditional statement. Describe what a loop is. Declare a loop. Declare nested loops. Exit a loop. The learning outcomes relate to the overall learning goals number 1, 2, 4, 8, 9-12 and 16 of the course. 3.2 Relational and logical operators Often you will need to compare a variable with another one. For this you need the relational operators given in Table 3.1 (also called comparison operators). Table 3.1: Comparison/relational operators. Operator Description Example = Equal to. A = B ’ False &lt;&gt; Not equal to A &lt;&gt; B ’ True &gt; Greater than. A &gt; B ’ False &lt; Less than. A &lt; B ’ True &gt;= Greater than or equal to. A &gt;= B ’ False &lt;= Less than or equal to. A &lt;= B ’ True Assume that A = 2 and B=4. Let us consider an example (try to guess the output before running the procedure): &#39;&#39; Comparison of two variables Sub TM3_Comparison() Dim intA As Integer Dim intB As Integer intA = 10 intB = 20 If intA = intB Then MsgBox (&quot;A = B is True&quot;) Else MsgBox (&quot;A = B is False&quot;) End If If intA &lt;&gt; intB Then MsgBox (&quot;A not equal B is True&quot;) Else MsgBox (&quot;A not equal B is False&quot;) End If If intA &gt; intB Then MsgBox (&quot;A greter then B is True&quot;) Else MsgBox (&quot;A greter then B is False&quot;) End If If intA &lt;= intB Then MsgBox (&quot;A less than or equal to B is True&quot;) Else MsgBox (&quot;A less than or equal to B is False&quot;) End If End Sub Given two boolean expressions we use logical operators to compare them (see Table 3.2) Table 3.2: Logical operators. Operator Description Example AND If both the conditions are True, then the expression is true. A&lt;&gt;0 AND B&lt;&gt;0 ’ False OR If any of the two conditions are True, then the expression is true. A&lt;&gt;0 OR B&lt;&gt;0 ’ True NOT Reverse logical: if the expression is true, then the NOT operator returns false. NOT(A&lt;&gt;0 OR B&lt;&gt;0) ’ False XOR Logical Exclusion. If exactly one condition is True, the result is True. A&lt;&gt;0 XOR B&lt;&gt;0 ’ True Assume that A = 0 and B=4. Let us consider an example (try to guess the output before running the procedure): Sub TM3_Logical() If 5 &gt; 4 And 6 &gt; 2 Then MsgBox (&quot;5 &gt; 4 And 6 &gt; 2 is True&quot;) Else MsgBox (&quot;5 &gt; 4 And 6 &gt; 2 is False&quot;) End If If 1 &gt; 4 Or 1 &gt; 2 Then MsgBox (&quot;1 &gt; 4 Or 1 &gt; 2 is True&quot;) Else MsgBox (&quot;1 &gt; 4 Or 1 &gt; 2 is False&quot;) End If If 6 &gt; 4 Or 1 &gt; 2 Then MsgBox (&quot;6 &gt; 4 Or 1 &gt; 2 is True&quot;) Else MsgBox (&quot;6 &gt; 4 Or 1 &gt; 2 is False&quot;) End If If 5 &gt; 4 And Not 6 &gt; 2 Then MsgBox (&quot;5 &gt; 4 And Not 6 &gt; 2 is True&quot;) Else MsgBox (&quot;5 &gt; 4 And Not 6 &gt; 2 is False&quot;) End If &#39; If more than two boolean expressions remember parenthesis If (5 &gt; 4 Xor 6 &gt; 2) And 7 &gt; 10 Then &#39; Xor (exactly one is true) MsgBox (&quot;(5 &gt; 4 Xor 6 &gt; 2) And 7 &gt; 10 is True&quot;) Else MsgBox (&quot;(5 &gt; 4 Xor 6 &gt; 2) And 7 &gt; 10 is False&quot;) End If If 5 &gt; 4 Xor (6 &gt; 2 And 7 &gt; 10) Then MsgBox (&quot;5 &gt; 4 Xor (6 &gt; 2 And 7 &gt; 10) is True&quot;) Else MsgBox (&quot;5 &gt; 4 Xor (6 &gt; 2 And 7 &gt; 10) is False&quot;) End If End Sub Note parentheses have an impact on the result. Remember to use them correctly. 3.3 Loops Loops are used to repeat pieces of code. There are many types of loops statements but here we will consider For and While loops. The structure of a For loop is: For i = 1 To 10 &lt;code&gt; Next Here i is a counter used to repeat the code inside the loop 10 times. In general we do not use a suffix for counter variables (i should have been named intI according to our naming convention). An example on a simple for loop is: Sub TM3_Loop1() Dim i As Integer For i = 1 To 3 MsgBox (i) &#39; What will the output be? Next End Sub You can use the Step keyword to increment the counter by more than one: Sub TM3_Loop2() Dim i As Integer For i = 2 To 9 Step 2 If i &lt;&gt; 4 Then MsgBox (i) &#39; What will the output be? End If Next End Sub You can use Exit For to end a for loop prematurely (jump to the code after the loop): &#39;&#39; Write the row number in column A and exit after row 10 even though the loop runs to 20 Sub TM3_WriteNumbers1() Dim r As Integer Worksheets(&quot;TM3&quot;).Activate &#39; activate the sheet we want to use For r = 6 To 20 If r &gt; 10 Then Exit For End If Cells(r, 1) = r &#39; write to row r, col 1 (A) Next End Sub Loops may be nested inside each other. For instance if some action needs to be performed for each day and each employee or for each project and each work package of that project. Sub TM3_NestedLoops() Dim i As Integer Dim j As Integer For i = 1 To 2 For j = 1 To 3 MsgBox (&quot;(&quot; &amp; i &amp; &quot;,&quot; &amp; j &amp; &quot;)&quot;) Next Next End Sub The structure of a While loop is: Do While &lt;condition true&gt; &lt;code&gt; Loop Here the loops runs until the condition is not true. While loops are useful when you do not know how many times to do the loop in advance. An example on a simple while loop is: &#39;&#39; Write the row number in column B and exit after row 10 Sub TM3_WriteNumbers2() Dim r As Integer Worksheets(&quot;TM3&quot;).Activate r = 6 Do While r &lt; 11 Cells(r, 2) = r &#39; write to row r, col 2 (B) r = r + 1 Loop End Sub You can use Exit Do to end a while loop prematurely (jump to the code after the loop): &#39;&#39; Write 2, 4, ... in column C and exit after 21 or if equals 12 Sub TM3_WriteNumbers3() Dim i As Integer, r As Integer Worksheets(&quot;TM3&quot;).Activate r = 6 i = 2 Do While i &lt; 21 Cells(r, 3) = i &#39; write to row r, col 3 (C) If i = 12 Then Exit Do End If r = r + 1 i = i + 2 Loop End Sub Beware of endless loops. If the stopping criteria is NOT reached when using a while loop, the computer will keep going: &#39; An endless loop. Do not run if you don&#39;t know how to stop Sub TM3_EndlessLoop() Dim i As Integer While i &gt;= 0 i = i + 1 Wend End Sub An endless loop can be hard to stop depending on the operating system you use. Therefore always “save” before you “run” the code. Make sure the stopping criterion will be reached. You may try to stop the program using a shortcut ( try Ctrl + Break or Ctrl + Alt + Delete. try ⌘., ⌃ + Esc or ⌘⌥ + Esc.) Finally, the For Each loop has to be mentioned: Sub TM3_ForEach() Dim rngC As Range Dim i As Integer Worksheets(&quot;TM3&quot;).Activate i = 1 For Each rngC In Range(&quot;D6:E9&quot;) rngC = i i = i + 1 Next End Sub The loop is used for running trough a set of objects (we will have a closer look at objects in Section 5.3). Here rngC is used to run through all the cells in the range and set values. Note a range is scanned left-down. 3.4 Conditional statements Conditional statements are used to redirect code execution based on the conditions. If the condition is met then the code is executed. The general layout of an if-then-else conditional statement is: If &lt;condition&gt; Then &lt;code&gt; ElseIf &lt;condition&gt; Then &lt;code&gt; ElseIf &lt;condition&gt; Then &lt;code&gt; Else &lt;code&gt; End If If &lt;condition&gt; Then &lt;code&gt; Else &lt;code&gt; &#39; single line form You can drop the ElseIf and Else code chunks. Other conditional statements exists but in general you can formulate them using an if-then-else statement. Let us try to use a conditional statement to separate persons in two groups: &#39;&#39; Seperate persons into two groups (names are written in 2 columns) Sub TM3_SeparatePersons1() Dim r As Integer Worksheets(&quot;TM3_Separate1&quot;).Activate &#39; activate the correct sheet For r = 2 To 12 &#39; scan rows 2-12 If Cells(r, 2) = &quot;Professor&quot; Then Cells(r, 3) = Cells(r, 1) &#39; output in row C Else Cells(r, 4) = Cells(r, 1) &#39; output in row D End If Next End Sub We use variable r to store the row number we want to write to and then an if statement to separate professors from others. The output will be: Figure 3.1: Separate into two groups. If you want to separate both professors and associate professors from others, you may modify the if statement and use an ElseIf: &#39;&#39; Seperate persons into 3 groups (names are written in 3 columns) Sub TM3_SeparatePersons2() Dim r As Integer Worksheets(&quot;TM3_Separate2&quot;).Activate &#39; activate the correct sheet For r = 2 To 12 If Cells(r, 2) = &quot;Professor&quot; Then Cells(r, 3) = Cells(r, 1) ElseIf Cells(r, 2) = &quot;Associate Professor&quot; Then Cells(r, 4) = Cells(r, 1) Else Cells(r, 5) = Cells(r, 1) End If Next End Sub Finally, let us try to separate into five groups: &#39;&#39; Seperate persons into 5 groups (names are written in 5 columns) Sub TM3_SeparatePersons3() Dim r As Integer Worksheets(&quot;TM3_Separate3&quot;).Activate &#39; activate the correct sheet For r = 2 To 12 If Cells(r, 2) = &quot;Professor&quot; Then Cells(r, 3) = Cells(r, 1) ElseIf Sheet1.Cells(r, 2) = &quot;Associate Professor&quot; Then Cells(r, 4) = Cells(r, 1) ElseIf Sheet1.Cells(r, 2) = &quot;Post Doc&quot; Then Cells(r, 5) = Cells(r, 1) ElseIf Sheet1.Cells(r, 2) = &quot;PhD student&quot; Then Cells(r, 6) = Cells(r, 1) Else Cells(r, 7) = Cells(r, 1) End If Next End Sub Here the output will be: Figure 3.2: Separate into five groups. 3.5 Example - Find Jen Consider column A in Figure 3.2. Assume we want to check if Jen is in a name and output her position. We can use a for loop for this: &#39;&#39; Find cell with Jen using a For loop Sub TM3_FindJen1() Dim r As Integer Worksheets(&quot;TM3_Separate1&quot;).Activate &#39; activate the correct sheet For r = 2 To 12 If InStr(Cells(r, 1), &quot;Jen &quot;) &gt; 0 Then &#39; InStr returns first char position at which match is found (0 if no match) MsgBox &quot;Jen is a &quot; &amp; Cells(r, 2) &amp; &quot; (Row &quot; &amp; r &amp; &quot;)&quot; Exit For &#39; exit the loop End If Next End Sub We scan all rows for Jen and return her position. If we found her, then we exit the for loop (no need to search further). What happens if we search for \"Jen\" and not \"Jen \"? Figure 3.3: Search for Jen. The same can be done using a while loop: &#39;&#39; Find cell with Jen using a While loop Sub TM3_FindJen2() Dim r As Integer r = 2 Do While InStr(Cells(r, 1), &quot;Jen &quot;) = 0 r = r + 1 Loop MsgBox &quot;Jen is a &quot; &amp; Cells(r, 2) &amp; &quot; (Row &quot; &amp; r &amp; &quot;)&quot; End Sub Beware of endless looping here. What happens if Jen is not present in column A? A more error safe while loop is: &#39;&#39; Find cell with Jen using a While loop and better stopping criteria Sub TM3_FindJen3() Dim r As Integer r = 2 Do While InStr(Cells(r, 1), &quot;Jen &quot;) = 0 And r &lt; 13 r = r + 1 Loop If (r = 13) Then MsgBox (&quot;Jen not found&quot;) Else MsgBox &quot;Jen is a &quot; &amp; Cells(r, 2) &amp; &quot; (Cell A&quot; &amp; r &amp; &quot;)&quot; End If End Sub 3.6 Example - A distance matrix Assume that you have a set of \\(n=10\\) locations: Table 3.3: A set of locations Location number \\(x\\)-coordinate \\(y\\)-coordinate 1 6 1 2 1 5 3 6 3 4 7 4 5 4 6 6 4 7 7 5 2 8 1 4 9 4 2 10 6 5 The euclidean distance \\(d\\) between location \\(l_1 = (x_1, y_1)\\) and \\(l_2 = (x_2, y_2)\\) are: \\[d(1,2)=\\sqrt{(x_1-x_2)^2 + (y_1-y_2)^2}.\\] In VBA the function becomes: &#39;&#39; Calculate distance between two points &#39; &#39; @param x1 x-coordinate of first point. &#39; @param y1 y-coordinate of first point. &#39; @param x2 x-coordinate of second point. &#39; @param y2 y-coordinate of second point. Private Function TM3_Distance(x1, y1, x2, y2) Dim x As Double Dim y As Double x = x1 - x2 y = y1 - y2 TM3_Distance = Sqr((x * x) + (y * y)) End Function Assume that you want to calculate the distance matrix \\(D\\) where entry \\((i,j)\\) contains the distance between location \\(i\\) and location \\(j\\). Consider the locations in columns B and C: Figure 3.4: Distance matrix worksheet. We want to fill out the cells F1:P11 with the distances. This have been done using procedure: &#39;&#39; Create a distance matrix starting in column 6 &#39; &#39; @pre Assume that coordinates are stored in column B and C starting from row 2 &#39; and that number of points are stored in E1. Public Sub TM3_MakeDistanceMatrix() Dim n As Integer Dim i As Integer Dim j As Integer n = Range(&quot;E1&quot;) For i = 1 To n &#39; add row and column headers Cells(i + 1, 6) = Cells(1 + i, 1) &#39; row equals i+1 Cells(1, 6 + i) = Cells(1 + i, 1) &#39; column equals i+6 Next &#39; add distances For i = 1 To n For j = 1 To n Cells(i + 1, j + 6) = TM3_Distance(Cells(i + 1, 2), Cells(i + 1, 3), Cells(j + 1, 2), Cells(j + 1, 3)) Next Next End Sub First, row and column headers are written to the cells. Next, we use a nested for loop to calculate the distances and output them to the cells. Note we in fact calculate the same distance two times (the distance from \\(i\\) to \\(j\\) equals the distance from \\(j\\) to \\(i\\)). Since we have symmetric distances there is no need to do this and it can be avoided by letting the inner loop in the nested loops be dependent on the outer loop: &#39;&#39; Create a symetric distance matrix with only the upper right part filled starting in column 6. &#39; &#39; @pre Assume that coordinates are stored in column B and C starting from row 2 &#39; and that number of points are stored in E1. Public Sub TM3_MakeSymetricDistanceMatrix() Dim n As Integer Dim i As Integer Dim j As Integer n = Range(&quot;E1&quot;) For i = 1 To n Cells(i + 1, 6) = Cells(1 + i, 1) Cells(1, 6 + i) = Cells(1 + i, 1) Next For i = 1 To n For j = i + 1 To n Cells(i + 1, j + 6) = TM3_Distance(Cells(i + 1, 2), Cells(i + 1, 3), Cells(j + 1, 2), Cells(j + 1, 3)) Next Next End Sub Figure 3.5: Distance matrix worksheet with symmetric distances. 3.7 Recap Loops are used to repeat pieces of code. For loops (repeat a number of times): For i = 1 To 10 &lt;code&gt; Next While loops (repeat until a condition is met): Do While &lt;condition&gt; &#39; repeat while true &lt;code&gt; Loop Use Exit for and Exit Do to break a For and a Do While loop before it ends (jump to the code after the loop). Loops may be nested inside each other: For i = 1 To 2 For j = 1 To 3 MsgBox (&quot;(&quot; &amp; i &amp; &quot;,&quot; &amp; j &amp; &quot;)&quot;) Next Next Conditional Statements are used to make decisions based on the conditions. If the condition is met then the code is executed. An if-then-else statement: If &lt;condition&gt; Then &lt;code&gt; ElseIf &lt;condition&gt; Then &lt;code&gt; Else &lt;code&gt; End If You may drop the ElseIf and Else code chunks. You may also have a look at the slides for this module . 3.8 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Some of the solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up too early. Put some effort into finding a solution! Practice using shortcuts in RStudio (use Shift+Alt+K to get an overview). Go to the Tools for Analytics workspace and download/export the r project_name_prefix project. Open it on your laptop and have a look at the files in the exercises folder which can be used as a starting point. A template with VBA code for this module is given in the file 03-vba-loops-cond-template.xlsm (open it and use it while reading the notes). Have a look inside the module TM3_ex in the VBA editor for examples used in the notes and during lectures. Have a look at module TM3_exercises for exercises. The template file for next teaching module will contain guiding answers for the exercises to this teaching module. 3.8.1 Exercise - Loops Use the sheet TM3 for output. Create a for loop that writes numbers 1 to 4 in rows 25 to 28 in column A. Create a do while loop that writes numbers 1 to 4 in rows 25 to 28 in column B. Create a loop that writes numbers 1 to 4 in rows 27 to 30 in column C. Create a loop that writes numbers -1 to -4 in rows 25 to 28 in column D. Create a loop that writes numbers 1 to 4 in rows 28 to 31 in column E, except if the number is 3 then the output should to a string missing. Create a do while loop that writes numbers i = 1, 2, … in column F (starting in row 25) until i/5 + 3 = 8. Hint: you may use a Exit Do to quit the loop. Create a sub that runs all the loops. 3.8.2 Exercise - Conditional statements Consider worksheet TM3_Numbers, which contains a set of numbers. Create a procedure with the following features Make a copy of the numbers with the upper left cell starting in G1. Scan all the numbers and remove (clear the cell) all the negative numbers (you may use a For Each loop). Highlight all the numbers above 20 (using e.g. rngC.Interior.ColorIndex = 37). Add a button to worksheet TM3_Numbers that run the procedure. Create a procedure with the following features: Scan the numbers and find the sum of all non-negative numbers, the mean of all negative numbers. Use a message box to display the sum and mean calculated. Add a button to worksheet TM3_Numbers that run the procedure. This exercise is a slightly modified version an exam assignment (reexam 2022-A5). "],["mod-vba-procedures.html", "Module 4 Procedures 4.1 Learning outcomes 4.2 Subs and functions - The basics 4.3 Optional arguments 4.4 Public and private procedures 4.5 Passing arguments by reference or by value 4.6 Built-in functions 4.7 Example - Selection of test persons 4.8 Recap 4.9 Exercises", " Module 4 Procedures This module gives a short introduction to procedures. A procedure is a piece of code stored in a module which contains a series of computational steps that will be carried out when the procedure is called. VBA has two kinds of procedures subs (short for subroutine) and functions. Both are basic building blocks in programming. The main differences between a sub and a function is: Subs Can make changes to the worksheet. Can modify its surroundings. Can be executed by a button (a macro - if no arguments). Cannot return anything. Functions Can return something. Can be used in Excel. Cannot be used as a macro. A template with VBA code for this module is given in the file 04-vba-procedures-template.xlsm (open it and use it while reading the notes). Have a look inside the module TM4_ex in the VBA editor for examples used in the notes and during lectures. Have a look at module TM4_exercises for exercises. The template file for next teaching module will contain guiding answers for the exercises to this teaching module. During execution of procedures it may be useful to use the debugger to run the code step by step. A very short introduction to debugging in VBA is given in Section E.1. Read it before continuing this teaching module. Learning path diagram Click/hover the nodes to follow links and see details. 4.1 Learning outcomes By the end of this module, you are expected to be able to: Describe what a procedure is. Explain what kind of procedures there are in VBA and what they can be used for. Declare and call a procedure. Explain what the difference is by using input arguments by reference or by value in a procedure. Set the scope of a procedure using private or public procedures. Set default input arguments. Call built-in functions for VBA and Excel. The learning outcomes relate to the overall learning goals number 1, 2, 4, 8 and 9 of the course. 4.2 Subs and functions - The basics A sub is declared using: Sub SubName(arg1 As &lt;datatype&gt;, arg2 As &lt;datatype&gt;) &lt;code&gt; End Sub The name of the sub is SubName and it takes two arguments arg1 and arg2. A sub can take an arbitrary number of arguments. Until now we have mostly considered subs with no arguments often called a macro. Macros can be called using a button in Excel. A function is declared using: Function FunctionName(arg1 As &lt;datatype&gt;, arg2 As &lt;datatype&gt;) As &lt;return datatype&gt; &lt;code&gt; FunctionName = value &#39; assign a return value to the function End Sub The name of the function is FunctionName and it takes two arguments arg1 and arg2. A function can take an arbitrary number of arguments. A function always return a value of a data type (a sub do not return anything). You return a value by assigning it to the variable FunctionName (same as the function name). Let us consider a simple sub with one argument: Sub TM4_SimpleSub(str As String) MsgBox (str) End Sub and a simple function with two arguments: Function TM4_SimpleFunc(dblA As Double, dblB As Double) As Double TM4_SimpleFunc = dblA + dblB &#39; return variable equals function name End Function You call a sub from another procedure using the Call keyword and a another function by assigning its return value to a variable: &#39; Try running it using the debugger (Ctrl + F8 (win) or cmd + shift + I (mac)) Sub TM4_CallSimpleProc() Dim dblV As Double MsgBox (&quot;Ready&quot;) Call TM4_SimpleSub(&quot;SimpleSub&quot;) &#39; call a sub within a procedure dblV = TM4_SimpleFunc(3, 4) &#39; call a function within a procedure MsgBox (&quot;Value is &quot; &amp; dblV) End Sub It is always good coding practice to document you procedures: &#39;&#39; Product of two numbers &#39; @param i First number &#39; @param j Second number &#39; @return The product i * j &#39; @remarks The numbers are doubles. Function TM4_ProductFunc(i As Double, j As Double) As Double TM4_ProductFunc = i * j End Function &#39;&#39; Product of two numbers which are stored in dblV (since ByRef is the default). &#39; @param i First number &#39; @param j Second number &#39; @param dblV Stores the product &#39; @remarks The numbers are doubles. Private Sub TM4_ProductSub(i As Double, j As Double, dblV As Double) dblV = i * j End Sub Note both procedures above do the same thing. The function returns the product and the procedure stores the product in argument dblV which is modified when the function call is returned: &#39;&#39; Use TM4_ProductSub (TM4_ProductFunc produce the same result) &#39; Try running it using the debugger (Ctrl + F8 (win) or cmd + shift + I (mac)) Sub TM4_RunProductSub() Dim dblV As Double dblV = 4 MsgBox (&quot;Current value is &quot; &amp; dblV) &#39; Current value is 4 Call TM4_ProductSub(7, 3, dblV) &#39; dblV = TM4_ProductFunc(7, 3) (same result) MsgBox (&quot;Current value is &quot; &amp; dblV) &#39; Current value is 21 End Sub The reason is that arguments are per default references pointing to the same place in memory (we will look at the details in Section 4.5). You can use Exit Sub/Exit Function to exit the sub/function early in the code: &#39;&#39; Division of two numbers &#39; @param i First number. &#39; @param j Second number. &#39; @return Divison i / j. &#39; @remarks The numbers are doubles. Sub TM4_DivisionSub(i As Double, j As Double) If j = 0 Then MsgBox (&quot;Error: division with zero!&quot;) Exit Sub End If MsgBox (&quot;Value is &quot; &amp; i / j) End Sub &#39;&#39; Run using F5 Sub TM4_TestDivisionSub() Call TM4_DivisionSub(8, 2) &#39; no error Call TM4_DivisionSub(8, 0) &#39; gives an error message End Sub 4.3 Optional arguments Often you define procedures that have arguments with a default value. You can do this using the Optional keyword: &#39;&#39; Convert kilograms to grams or pounds &#39; @param dblKg Kilograms. &#39; @param blnToGrams Convert to grams (if true) otherwise to pounds. &#39; @return Converted value. Function TM4_ConvertKg(dblKg As Double, Optional blnToGrams As Boolean = True) If blnToGrams Then TM4_ConvertKg = dblKg * 1000 Exit Function End If TM4_ConvertKg = dblKg * 2.20462 End Function &#39;&#39; Run using F5 Sub TM4_TestConvertKg() MsgBox (TM4_ConvertKg(10)) &#39; use default value (to grams) MsgBox (TM4_ConvertKg(10, False)) &#39; to pounds End Sub Here we have one optional argument with default value equal to true. Now the function can be called with one argument (use the default value of the second argument) or with two arguments. Have a look at cells A8:C13 in worksheet TM4 (Figure 4.1) where we use the function to find convert to grams (TM4_ConvertKg(A8)) and pounds (TM4_ConvertKg(A8; FALSE)). Let us try to define a sub that format some cells (the content have been found using the macro recorder and then cleaned): &#39;&#39; Format a range &#39;@param rng Range to format. &#39;@param intInteriorColor Interior color index. &#39;@param intFontColor Font color index. &#39;@param intFontSize Font size. Sub TM4_FormatCell(rng As Range, Optional intInteriorColor As Integer = 0, _ Optional intFontColor As Integer = 44, Optional intFontSize As Integer = 12) rng.Interior.ColorIndex = intInteriorColor rng.Font.ColorIndex = intFontColor rng.Font.Size = intFontSize End Sub &#39;&#39; Run using F5 Sub TM4_TestingFormatCell() Dim rng As Range Worksheets(&quot;TM4&quot;).Activate Call TM4_FormatCell(Range(&quot;A16&quot;)) &#39; use default values Call TM4_FormatCell(Range(&quot;B16&quot;), 46) &#39; use background color index 46 Call TM4_FormatCell(Range(&quot;C16&quot;), , 21) &#39; set font color Call TM4_FormatCell(rng:=Range(&quot;D16&quot;), intFontSize:=16, intFontColor:=23) &#39; call sub using argument names explicit End Sub Observe that there is different ways to call a procedure with optional arguments. If you have may optional arguments it is best to use the last where you explicit state the argument names (here the order of the arguments do not matter either). Note that every argument following an optional argument in the procedure definition must also be optional. Moreover, if lines are to long you may split them using _ (underscore). In the example above we use the color index values in VBA (56 different ones). Let us have a look at them: &#39;&#39; Run using F5 Sub TM4_SeeColorIndex() Dim r As Integer Dim c As Integer Dim i As Integer Worksheets(&quot;TM4&quot;).Activate i = 1 For r = 18 To 40 For c = 2 To 5 Cells(r, c) = i Call TM4_FormatCell(rng:=Cells(r, c), intInteriorColor:=i, intFontColor:=1 + i Mod 4) If i = 56 Then Exit Sub End If i = i + 1 Next Next End Sub The output will be outputted from row 18 (column B-E): Figure 4.1: TM4 worksheet. 4.4 Public and private procedures You may use the keyword Private or Public (default) when you define a procedure. For instance: Private Sub SubName(arg1 As &lt;datatype&gt;, arg2 As &lt;datatype&gt;) &lt;code&gt; End Sub A private procedure can only be used by other procedures in the module. This may be useful if you want to define ‘internal’ procedures that you only want to use in the module. This also imply that a private sub can not be called from a button and a private function can not be called from a cell. Note the default value is Public. That is, if Private or Public is excluded, VBA will always treat the sub as if it were Public: Sub SubName(arg1 As &lt;datatype&gt;, arg2 As &lt;datatype&gt;) &#39; VBA assumes it is public (the default) &lt;code&gt; End Sub Public Sub SubName(arg1 As &lt;datatype&gt;, arg2 As &lt;datatype&gt;) &#39; same result as above &lt;code&gt; End Sub 4.5 Passing arguments by reference or by value There are two ways of passing arguments to procedures: Sub SubName(ByRef arg1 As &lt;datatype&gt;, ByVal arg2 As &lt;datatype&gt;) &lt;code&gt; End Sub Argument arg1 is passed by reference (default). That is, no new memory is allocated when the procedure is called and as a result the procedure can have changed the value of arg1 when the procedure stops. Note since the default, the result is the same if we omitted the keyword ByRef. Argument arg2 is passed by value. That is, a copy of the variable is created in memory. Hence the procedure cannot change the value of arg2 when the procedure stops (the copy is deleted). Using ByRef is faster and saves memory since we do not have to allocate new memory. We may use ByRef to return updated values of the input arguments (sub TM4_ProductSub did that). In fact you may have multiple arguments which when the sub finished have been modified. See it as the arguments have been modified with the result of the sub. Using ByVal is safer if you want be sure that the argument is not modified inside the procedure. Try guessing the result of running sub TM4_TestingBy: Private Function TM4_ByVal(ByVal i As Integer) As Integer i = i * 2 MsgBox (&quot;In ByVal i is &quot; &amp; i) TM4_ByVal = i * 5 End Function &#39;&#39; Note &quot;Function TM4_ByRef(i As Integer) As Integer&quot; gives same result Private Function TM4_ByRef(ByRef i As Integer) As Integer i = i * 2 MsgBox (&quot;In ByRef i is &quot; &amp; i) TM4_ByRef = i * 5 End Function &#39; Try running it using F5 or the debugger (Ctrl + F8 (win) or cmd + shift + I (mac)) Private Sub TM4_TestBy() Dim n As Integer Dim i As Integer i = 5 MsgBox (&quot;In the start i is &quot; &amp; i) n = TM4_ByVal(i) MsgBox (&quot;Try gussing the values of n and i&quot;) MsgBox (&quot;After TM4_ByVal i is &quot; &amp; i &amp; &quot; and &quot; &amp; n &amp; &quot; is returned.&quot;) n = TM4_ByRef(i) MsgBox (&quot;Try gussing the values of n and i&quot;) MsgBox (&quot;After TM4_ByRef i is &quot; &amp; i &amp; &quot; and &quot; &amp; n &amp; &quot; is returned.&quot;) End Sub 4.5.1 Return values from a sub Since ByRef does not create a new copy of the argument in memory. We can return multiple values from a sub by Pass arguments (variables) by reference in the sub. Modify the variables inside the sub. When the sub returns after it has been called the variables used a arguments contain the new updated values. See e.g TM4_ProductSub which returns the product in variable dblV. 4.6 Built-in functions VBA has a set of built-in functions such as Abs, Log and Date. You call them by just writing their name: &#39;&#39; Test VBA functions &#39; You can always get help by putting the crusor in the function name and press F1 Sub TM4_TestVBAfunctions() MsgBox (&quot;Absolute value: &quot; &amp; Abs(-4.2)) MsgBox (&quot;Integer part: &quot; &amp; Fix(-4.2)) MsgBox (&quot;Floor of the number: &quot; &amp; Int(-4.2)) MsgBox (&quot;Natural logarithm: &quot; &amp; Log(16)) MsgBox (&quot;Random number [0,1[: &quot; &amp; Rnd()) MsgBox (&quot;Current date: &quot; &amp; Date) MsgBox (&quot;Days from now: &quot; &amp; DateDiff(&quot;d&quot;, Date, DateValue(&quot;October, 28, 2022&quot;))) End Sub You can also use the worksheet functions in Excel. You call them using the WorksheetFunction object. A few examples: &#39;&#39; Test worksheetfunctions &#39; You can always get help by putting the crusor in the function name and press F1 Sub TM4_TestWorksheetfunctions() Dim r As Integer Dim c As Integer Worksheets(&quot;TM4&quot;).Activate MsgBox (&quot;Numbers above 80: &quot; &amp; WorksheetFunction.CountIf(Range(&quot;B33:E38&quot;), &quot;&gt;80&quot;)) &#39; count numbers above MsgBox (&quot;Sumproduct: &quot; &amp; WorksheetFunction.SumProduct(Range(&quot;B33:E33&quot;), Range(&quot;B34:E34&quot;))) MsgBox (&quot;Max: &quot; &amp; WorksheetFunction.Max(Range(&quot;B33:E38&quot;))) For r = 40 To 45 For c = 2 To 4 Cells(r, c) = WorksheetFunction.RandBetween(0, 9) Next Next End Sub 4.7 Example - Selection of test persons This example is a slightly modified version an exam assignment (exam 2021-A6). A virus has infected a number of persons. A possible cure has been developed, but the effect of it is expected to be dependent on the persons’ height. The cure can be tested on non-infected persons and the findings of this test can be directly transferred to any infected person whose height is within a range of 2 cm from the height of the tested person. For example, if the cure is tested on a non-infected person of height \\(172.2\\), then any infected person whose height is in the interval \\([170.2 ; 174.2]\\) is covered by the test. Figure 4.2: Infected and test persons. Figure 4.2 shows the data in worksheet TM4_Virus: Cell D1 states the number of infected persons. Columns A and B provide the person’s ID and height for each person. Cell D2 states the number of non-infected persons volunteering to be test persons. Columns F and G provide their ID and height. The testing process is extremely resource demanding, and thus it is only possible to test a limited number of test volunteers. This number is stated in cell D3. Given a test person we make a function TM4_TestCover that takes person id as argument and return the number of new infected persons covered. A person is already covered, if that person has a 1 in the Covered column. Function TM4_TestCover(intId As Integer) As Integer Dim intI As Integer &#39; number of infected Dim intC As Integer &#39; number of covered Dim dblHeight As Double &#39; height of test person Dim r As Integer intI = Range(&quot;D1&quot;) dblHeight = Range(&quot;G&quot; &amp; intId + 6) intC = 0 For r = 7 To intI + 6 &#39; loop through all infected If Cells(r, 2) &gt;= dblHeight - 2 And Cells(r, 2) &lt;= dblHeight + 2 And Cells(r, 3) &lt;&gt; 1 Then intC = intC + 1 End If Next TM4_TestCover = intC End Function First, note that given a test person id, the height is found in row id + 6 and column G. Next, we use the counter intC to count new covered persons. This result is returned by the function. To find the right test persons the following greedy strategy is used: Step 1: Select the test person (not already selected) that can cover most new infected persons (not yet covered). If more than one test person have the same cover, select the one with the smallest ID. Step 2: Add ones to the Covered column for all infected persons covered by the test person. Step 3: Go to Step 1 until found the test persons needed. We implement the the greedy strategy: Sub TM4_FindTestPersons() Dim intI As Integer &#39; number of infected Dim intT As Integer &#39; number of test volunteers Dim intS As Integer &#39; number of selected persons Dim intC As Integer &#39; number of covered Dim intBestId As Integer &#39; best id found Dim intBestC As Integer &#39; best cover value found Dim r As Integer Worksheets(&quot;TM4_Virus&quot;).Activate intI = Range(&quot;D1&quot;) intT = Range(&quot;D2&quot;) intS = 0 &#39; no selected yet Do While intS &lt; Range(&quot;D3&quot;) &#39; stop when have found needed test persons intBestId = -1 intBestC = -1 For r = 7 To intT + 6 &#39; loop through all test volunteers If Cells(r, 8) &lt;&gt; 1 Then &#39; not selected already intC = TM4_TestCover(Cells(r, 6)) If intBestC &lt; intC Then &#39; found a better person intBestC = intC intBestId = Cells(r, 6) End If End If Next Cells(intBestId + 6, 8) = 1 &#39; select best For r = 7 To intI + 6 &#39; add ones in covered column If Abs(Cells(r, 2) - Cells(intBestId + 6, 7)) &lt;= 2 Then Cells(r, 3) = 1 End If Next intS = intS + 1 Loop End Sub First, the number of persons are stored in variables. Next, a Do While loop is used to find the test persons. We use two variables to store the best id and cover value. The first inner for loop scan the test persons and for each person (not yet selected) we find the cover (using TM4_TestCover), check if better than current and update. The second inner for loop add ones to the Covered column. The output is given in Figure 4.3. Figure 4.3: Infected and test persons. In total 13 infected persons are covered by 3 test persons. 4.8 Recap A procedure is a piece of code stored in a module. A procedure contains a series of computational steps that will be carried out when the procedure is called. VBA has two kinds of procedures: Subs: Can make changes to the worksheet. Can modify its surroundings. Can be executed by a button (if no arguments). Cannot return anything. Functions: Can return something. Can be used in Excel. Cannot be used as a macro. You declare a procedure using Sub SubName(arg1 As &lt;datatype&gt;, arg2 As &lt;datatype&gt;) &lt;code&gt; End Sub Function FunctionName(arg1 As &lt;datatype&gt;, arg2 As &lt;datatype&gt;) As &lt;return datatype&gt; &lt;code&gt; FunctionName = value &#39; assign a return value to the function End Sub You can use Exit Sub/Exit Function to exit the sub/function early in the code. Procedures can be either public or private: Public (default): Can be used from other modules, from other files and from Excel. Public Sub SubName() ... End Sub Private: Can only be used from within its own module. Private Sub SubName() ... End Sub Use the Call keyword to call a sub: Call SubName(arg1, arg2) Call a function by assigning its return value to a variable result = FunctionName(arg1, arg2) There are two ways of passing arguments to procedures: Sub SubName(ByRef arg1 As &lt;datatype&gt;, ByVal arg2 As &lt;datatype&gt;) &lt;code&gt; End Sub Argument arg1 is passed by reference (default). That is, no new memory is allocated when the procedure is called and hence the procedure can have changed the value of arg1 when the procedure stops. Since the default is ByRef, the result is the same if we omitted the keyword ByRef. Argument arg2 is passed by value. That is, a copy of the variable is created in memory with local scope. Hence the procedure cannot change the value of arg2 when the procedure stops (the local variables is deleted). Using ByRef is faster and saves memory since we do not have to allocate new memory. We may use ByRef to return updated values of the input arguments. Use the Optional keyword to indicate default input arguments: Sub SubName(arg1 As &lt;datatype&gt;, Optional arg2 As &lt;datatype&gt; = &lt;defaultValue&gt;) You can now call the procedure using: Call SubName(arg1) &#39; assume that arg2 = defaultValue Every parameter following an optional parameter in the procedure definition must also be optional. VBA has a set of built-in functions such as Abs, Log and Date. You call them by just writing their name: dtm as Date dtm = Date() You can also use the worksheet functions in Excel. You call them using the WorksheetFunction object: sum = WorksheetFunction.Sum(Range(&quot;A1:D5&quot;)) You may also have a look at the slides for this module . 4.9 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Some of the solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up too early. Put some effort into finding a solution! Practice using shortcuts in RStudio (use Shift+Alt+K to get an overview). Go to the Tools for Analytics workspace and download/export the r project_name_prefix project. Open it on your laptop and have a look at the files in the exercises folder which can be used as a starting point. A template with VBA code for this module is given in the file 04-vba-procedures-template.xlsm (open it and use it while reading the notes). Have a look inside the module TM4_ex in the VBA editor for examples used in the notes and during lectures. Have a look at module TM4_exercises for exercises. The template file for next teaching module will contain guiding answers for the exercises to this teaching module. 4.9.1 Exercise - Subs Create a sub GetMsg that takes a string and a Boolean as input and create a message box with the string content if the Boolean is true. Test the procedure using the TestGetMsg sub. Modify the procedure so the Boolean have a default value equal to true. Create a sub PrintNameAge that takes two arguments as input (name and age) and create a message box with the persons name and age. Write a sub TestPrintNameAge that uses two input boxes to ask for name and age and then call sub PrintNameAge. 4.9.2 Exercise - Temperatures This exercise is a slightly modified version an exam assignment (reexam 2022-A4). Temperatures in Fahrenheit can be converted to Celsius using \\[C = \\frac{5(F-32)}{9}\\] Similar temperatures in Celsius can be converted to Fahrenheit using \\[F = \\frac{9C}{5} + 32\\] Make functions: TM4_CelsiusToFahrenheit that takes a double dblVal in Celsius as input argument and returns the number converted to Fahrenheit. TM4_FahrenheitToCelsius that takes a double dblVal in Fahrenheit as input argument and returns the number converted to Celsius. Make a function TM4_ConvertTemp with the following features: Input arguments are a double dblVal and a string strIUnit. If the input unit strIUnit equals “c” then the returned number is converted to Fahrenheit. If the input unit strIUnit equals “f” then the returned number is converted to Celsius. If the input unit strIUnit does not equals “f” or “c” then a message box is given with an error. Test function TM4_ConvertTemp on worksheet TM4 (row 66). 4.9.3 Exercise - Functions Write a function TM4_Discount which takes a two input arguments (doubles): the discount percentage and the amount. The function returns the discounted value. For instance if the discount is 10 percent and amount 100 then the discounted value is \\(90 = 100\\cdot(1-0.1)\\). Have a look at the unfinished sub TM4_Discount for hints. Note the comments describing the function using the coding convention. Check the test results starting from row 47 in worksheet TM4. Write a function Larger which takes two integer arguments and returns true if the first is larger than the last; otherwise false. Check the test results starting from row 53 in worksheet TM4. Write a function NumbDays that takes a date as argument and return the number of days from today. Hint: Have a look at the DateDiff function. Check the test results starting from row 59 in worksheet TM4. Write a sub that uses an input box to ask for an amount a then returns the discounted amount when the discount is 20%. The sub should use the function in Question 1. Test it using the button in worksheet TM4 (row 49). 4.9.4 Exercise - Worksheet functions The worksheet TM4_Numbers contains a button that runs a procedure which generate a set of numbers. Create a procedure TM4_Summary that uses worksheet functions to: Find the maximum number and write it to cell D1. Find the minimum number and write it to cell D2. Find the sum of the numbers and write it to cell D3. Count the number of positives and write it to cell D4. Find the row number with maximum value and write it to cell D5. Google is a good place to start if you want to find a specific Excel function, e.g. try to search ‘excel row with max value’. Test the procedure using the Summary button in worksheet TM4_Numbers. "],["mod-vba-datatypes.html", "Module 5 Advanced data types and usage 5.1 Learning outcomes 5.2 Strings 5.3 Objects 5.4 The Worksheet object 5.5 The Range object 5.6 Arrays 5.7 Collections 5.8 Example - Job sequencing 5.9 Recap 5.10 Exercises", " Module 5 Advanced data types and usage Recall that variables are used to store information that is saved in memory. A variable may store different data types. Until now we have mostly considered basic data types such as an integer, a double or a string. In this module a short introduction to some of the more advanced data types is given such as a group of integers (an array), a range of cells in a worksheet (a range object) or a set of numbers (a collection). A template with VBA code for this module is given in the file 05-vba-datatypes-template.xlsm (open it and use it while reading the notes). Have a look inside the module TM5_ex in the VBA editor for examples used in the notes and during lectures. Have a look at module TM5_exercises for exercises. The template file for next teaching module will contain guiding answers for the exercises to this teaching module. Learning path diagram Click/hover the nodes to follow links and see details. If you like a different learning style there is a lot for videos about VBA online such as course 14-Hour VBA Course. The videos have been pointed out as extra online supplements in the learning path diagram. However, they are not necessary for the course. Since Excel change as new versions arrive and it work on different operating systems, the look in the screenshots and videos might be a bit different from your version. However, you still should be able to understand it. 5.1 Learning outcomes By the end of this module, you are expected to be able to: Name different data types and how they effect memory size. Declare a variable as a data type. Declare and manipulate strings. Describe what the object is. Declare and set an object. Manipulate worksheets (add, delete, clear). Understand what a range is and extract info about it such as rows, start row, address, start column etc. Use the current region of a range to get information about the size for data. Sort, paste and modify a range. Declare and use an array with both fixed and dynamic dimension. Sort, read and modify an array. Explain why using arrays is often better than ranges. Declare and use a collection. Explain what a collection of objects are. Use a For Each loop to iterate though a collection of objects. The learning outcomes relate to the overall learning goals number 1, 2, 4, 8 and 9 of the course. 5.2 Strings Strings contain a group of characters (an empty string is of length zero). Memory requirements vary with the length of the string (10 bytes + length \\(\\cdot\\) 2 byte). We use the symbol &amp; to concatenate strings (glue strings together): &#39;&#39; Concatenate two strings Sub TM5_StrConcat() Dim strX As String Dim strY As String Dim strRes As String strX = &quot;VBA&quot; strY = &quot;Strings&quot; strRes = strX &amp; &quot; &quot; &amp; strY MsgBox (strRes) MsgBox (strX &amp; vbCr &amp; strY) &#39; use vbCr to insert a new line End Sub Note you can use constant vbCr to add a new line. There are many VBA functions that can be used to manipulate strings. Some examples: &#39;&#39; String functions Sub TM5_StrFunc() Dim str As String str = &quot;VBA Strings&quot; MsgBox (&quot;The length is: &quot; &amp; Len(str)) MsgBox (&quot;In lowercase: &quot; &amp; LCase(str)) MsgBox (&quot;Last 7 char: &quot; &amp; Right(str, 7)) MsgBox (&quot;Replace: &quot; &amp; Replace(str, &quot;Strings&quot;, &quot;Rules&quot;)) MsgBox (&quot;Compare: &quot; &amp; StrComp(str, &quot;VBA Strings&quot;)) &#39; result is 0 (equal) MsgBox (&quot;Compare: &quot; &amp; StrComp(str, &quot;Apple&quot;)) &#39; result is 1 (str alfabetically after) MsgBox (&quot;Compare: &quot; &amp; StrComp(str, &quot;Wait&quot;)) &#39; result is -1 (str alfabetically before) MsgBox (&quot;String is starting at char number: &quot; &amp; InStr(str, &quot;String&quot;)) &#39; result is 0 if not found End Sub 5.3 Objects VBA have a lot of predefined objects you can use. Think of an object as a datatype that holds a group of variables. Examples of some objects are Range, Worksheet, and WorksheetFunction. Objects are grouped, nested and you refer to an object by specifying the path, e.g.: Workbooks(&quot;Jobs.xlsm&quot;).Worksheets(&quot;Data values&quot;).Range(&quot;D4&quot;).value Here we refer to the value in cell D4 in worksheet Data values in the file Jobs.xlsm. You may skip parts of the path (VBA then uses the current active one): Workbooks(&quot;Jobs.xlsm&quot;).Worksheets(&quot;Data values&quot;).Range(&quot;D4&quot;).value &#39; full specification Worksheets(&quot;Data values&quot;).Range(&quot;D4&quot;).value &#39; same result if Excel file &quot;Jobs.xlsm&quot; is active Range(&quot;D4&quot;) &#39; same result if Excel sheet &quot;Data values&quot; is active and &quot;Jobs.xlsm&quot; file Note .value has been dropped in the last line because it is the default, i.e. you do not have to write it explicit. Object variables are declared like any other variables: Dim rng As Range Dim wst As Worksheet Use Set to allocate the Object: Set rng = Range(&quot;F7&quot;) Set wst = Worksheets(&quot;Data values&quot;) Now rng is a reference to cell F7 and wst is a reference to worksheet Data values. Think of a reference as a value that identify where in memory the object is. In the next sections let us have a look at some relevant objects. 5.4 The Worksheet object The Worksheet object refer to a worksheet in the Excel file and you can use it to e.g. modify cells: Sub TM5_TestWorksheet() ThisWorkbook.Activate &#39; activate this workbook Worksheets(&quot;TM5_Test1&quot;).Range(&quot;B2&quot;) = &quot;Testing Worksheet&quot; &#39; write to cell in sheet TM5_Test1 Sheet_TM5_Test1.Range(&quot;B3&quot;) = &quot;Use the sheets code name&quot; &#39; use the code name (also work if sheet renamed) &#39;ThisWorkbook.Worksheets(&quot;Test3&quot;).Range(&quot;B5&quot;) = &quot;Test&quot; &#39; Error since there is no sheet Test3 in this workbook Range(&quot;B4&quot;) = &quot;Do you know which sheet is active?&quot; &#39; Active sheet &#39; Good coding pratice is always to specify the full path (as above) or make the sheet under considration active Worksheets(&quot;TM5_Test1&quot;).Activate &#39; Make sheet active so know where is Range(&quot;B5&quot;) = &quot;I know which sheet is active!&quot; End Sub It is always good practice to make sure that you are working with the correct Excel file. Otherwise you will get errors if another file is active. This can be done using the ThisWorkbook object. Similar you either refer to a worksheet directly using its name or its code name. The code name can be set in the Properties window in the VBA editor. An alternative is to activate the worksheet. You can use Worksheet variables: Sub TM5_TestWorksheetVar() Dim wst1 As Worksheet &#39; define a variable which hold a reference to a Worksheet object Dim wst2 As Worksheet &#39; define a variable which hold a reference to a Worksheet object Dim rng As Range Set wst1 = ThisWorkbook.Worksheets(&quot;TM5_Test1&quot;) &#39; set the reference Set wst2 = ThisWorkbook.Worksheets(&quot;TM5_Test2&quot;) &#39; set the reference wst1.Range(&quot;B6&quot;) = &quot;Writing using wst1&quot; wst2.Range(&quot;B2&quot;) = &quot;Writing using wst2&quot; wst1.Activate &#39; just to have a look End Sub Here by having two worksheet variables we can write directly to cells in different worksheets without activating the worksheet. You may check if a worksheet exists using: &#39;&#39; Check if a worksheet exists &#39; @param strName Name of worksheet. &#39; @return True if exists. Function WstExists(strName As String) As Boolean WstExists = Evaluate(&quot;ISREF(&#39;&quot; &amp; strName &amp; &quot;&#39;!A1)&quot;) End Function The worksheet object has a lot of methods/properties (think of methods as procedures defined inside the object) for instance wst.Add and wst.Delete. Let us try to define a function that delete a worksheet: &#39;&#39; Delete a worksheet if it exists &#39; @param strName Name of worksheet. &#39; @return True if deleted. &#39; @author Lars Relund &lt;lars@relund.dk&gt; Function WstDelete(strName As String) As Boolean Dim wst As Worksheet Dim bln As Boolean bln = Application.DisplayAlerts Application.DisplayAlerts = False &#39; no &quot;really want to delete&quot; alert If WstExists(strName) Then Worksheets(strName).Delete WstDelete = True Else WstDelete = False End If Application.DisplayAlerts = bln &#39; restore value End Function We first use the function WstExists to check if there is a worksheet. If there is, we call the .delete method and delete the worksheet. Note since we do not want an alert stating if we really want to delete the worksheet this is disabled using the Application object. The function returns true if the worksheet has been deleted. Let us try to define a function that create a worksheet: &#39;&#39; Create a worksheet &#39; @param strName Name of worksheet. &#39; @param blnForce Force deletion of worksheet if exists. &#39; @return True if created. Function WstCreate(strName As String, Optional blnForce As Boolean = False) As Boolean Dim wst As Worksheet If blnForce And WstExists(strName) Then Call WstDelete(strName) If Not WstExists(strName) Then Set wst = Worksheets.Add wst.Name = strName WstCreate = True Else WstCreate = False End If End Function We use an optional argument to force deletion of the old worksheet (if a worksheet with the same name). Next, we create the worksheet using the .Add method and rename it using the .Name method. The function returns true if the worksheet has been created. Finally, let us create a function that clear a worksheet: &#39;&#39; Clear a worksheet if it exists &#39; @param strName Name of worksheet. &#39; @param blnCells Delete cell contents, formats, comments, etc. (default). &#39; @param blnContents Delete cell contents. &#39; @param blnFormat Delete cell format. &#39; @param blnObjects Delete cell buttons and charts. &#39; @return True if cleared. Function WstClear(strName As String, _ Optional blnCells As Boolean = True, _ Optional blnContents As Boolean = False, _ Optional blnFormat As Boolean = False, _ Optional blnObjects As Boolean = False) As Boolean Dim wst As Worksheet On Error Resume Next If WstExists(strName) Then Set wst = Worksheets(strName) If blnCells Then wst.UsedRange.Clear If blnContents Then wst.Cells.ClearContents If blnFormat Then wst.Cells.ClearFormats If blnObjects Then wst.ChartObjects.Delete wst.Buttons.Delete End If WstClear = True Else WstClear = False End If End Function First note that we have a lot of optional arguments depending on what we want to clear. Next the On Error Resume Next statement is used to make the program not stop even if an error happens. Finally, depending on the setting of the optional arguments we e.g. clear the format in all cells if blnFormat is true. All the functions above is part of the course procedures that you may use ‘as is’ during the course and at the exam. I will explicitly state if you are not allowed to use them otherwise. All the worksheet procedures start with Wst so you easy can find them using auto complete in the VBA editor. All worksheet procedures are stored in the ModWst module. You may open the module to have a look at the procedures. Let us see them in action: &#39;&#39; Test the worksheet functions Sub TM5_TestWorksheetFunc() If WstCreate(&quot;Test&quot;, blnForce:=True) Then MsgBox (&quot;Created Test&quot;) If WstRename(&quot;Test&quot;, &quot;Test1&quot;) Then MsgBox (&quot;Renamed the Test to Test1&quot;) &#39; only work if no Test1 sheet If WstClear(&quot;Test8&quot;) Then MsgBox (&quot;Cleared Test8&quot;) &#39; no clearing since on sheet with that name If WstDelete(&quot;Test1&quot;) Then MsgBox (&quot;Deleted Test1&quot;) End Sub 5.5 The Range object Ranges are objects that refer to parts of a worksheet e.g. a cell, a row, a column, or a rectangular selection of cells. Ranges can be used to read and write to cells Sub TM5_RangeEx1() Dim rng As Range Dim cell As Range Dim i As Integer Call TM5_ClearTestTM5 &#39; clear test cells so have empty cells ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate &#39; Modify a range to a fixed value Set rng = Range(&quot;G4:I6&quot;) rng = 145 &#39; cell value in rng MsgBox rng.Address &#39; range address &#39; Use for each to scan range (direction left-down) Set rng = Range(&quot;G8:I10&quot;) i = 1 For Each cell In rng cell = &quot;Entry &quot; &amp; i i = i + 1 Next &#39; Use Cells to set a range Set rng = Range(Cells(23, 3), Cells(25, 6)) MsgBox rng.Address End Sub The method .Address is used to return the cell address. Figure 5.1: TM5 worksheet. Similar the number of rows can by found using .rows.Count: &#39;&#39; Rows in range &#39; @param rng A range. Function RngGetRows(rng As Range) As Long RngGetRows = rng.rows.Count End Function We can also find number of columns, address of upper left cell or lower right cell etc. In the course procedures (module ModRng) all these have been defined. Let us try to use them: Sub TM5_RangeEx2() Dim rng As Range Set rng = ThisWorkbook.Worksheets(&quot;TM5&quot;).Range(&quot;C4:E19&quot;) MsgBox (&quot;Number of rows: &quot; &amp; RngGetRows(rng)) MsgBox (&quot;Number of cols: &quot; &amp; RngGetCols(rng)) MsgBox (&quot;First column number: &quot; &amp; RngGetFirstCol(rng)) MsgBox (&quot;First column letter: &quot; &amp; RngGetFirstCol(rng, asLetter:=True)) MsgBox (&quot;Lower right cell: &quot; &amp; RngGetLowerRight(rng, asString:=True)) MsgBox (&quot;Upper right cell: &quot; &amp; RngGetUpperRight(rng, asString:=True)) End Sub 5.5.1 Current region of a range An important method is the current region .CurrentRegion which expands the range until all cells surrounding the range is empty. This is very useful if don’t know the size for data. Let us make a function that return the current region: &#39;&#39; Return the current region of a range. &#39; @param rng The range to get the current region from. Function RngCurRegion(rng As Range) As Range Set RngCurRegion = rng.CurrentRegion End Function Note we have to use the Set keyword since the return value is a range (object). We can now test the course procedures starting with prefix RngGet: Sub TM5_CurrentRegionEx1() Dim rng As Range ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate &#39; Try to guess the output Set rng = RngCurRegion(Range(&quot;D7&quot;)) &#39; rng now is the current region MsgBox (&quot;Address: &quot; &amp; RngGetAddress(rng)) MsgBox (&quot;Rows = &quot; &amp; RngGetRows(rng) &amp; &quot; cols = &quot; &amp; RngGetCols(rng)) MsgBox (&quot;First row number = &quot; &amp; RngGetFirstRow(rng) &amp; &quot;. Last row number = &quot; &amp; RngGetLastRow(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col number = &quot; &amp; RngGetFirstCol(rng) &amp; &quot;. Last col number = &quot; &amp; RngGetLastCol(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col letter = &quot; &amp; RngGetFirstCol(rng, True) &amp; &quot;. Last col letter = &quot; &amp; RngGetLastCol(rng, True) &amp; &quot;.&quot;) &#39; Try to guess the output Set rng = RngCurRegion(Range(&quot;C23&quot;)) &#39; assume we know that data contains cell C23 MsgBox (&quot;Address: &quot; &amp; RngGetAddress(rng)) End Sub The same result can be obtained using the course procedures starting with RngGetCurRegion: Sub TM5_CurrentRegionEx2() Dim rng As Range ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate &#39; Try to guess the output Set rng = Range(&quot;D7&quot;) &#39; assume we know that data contains cell D7 MsgBox (&quot;Address: &quot; &amp; RngGetCurRegionAddress(rng)) MsgBox (&quot;Rows = &quot; &amp; RngGetCurRegionRows(rng) &amp; &quot; cols = &quot; &amp; RngGetCurRegionCols(rng)) MsgBox (&quot;First row number = &quot; &amp; RngGetCurRegionFirstRow(rng) &amp; &quot;. Last row number = &quot; &amp; RngGetCurRegionLastRow(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col number = &quot; &amp; RngGetCurRegionFirstCol(rng) &amp; &quot;. Last col number = &quot; &amp; RngGetCurRegionLastCol(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col letter = &quot; &amp; RngGetCurRegionFirstCol(rng, True) &amp; &quot;. Last col letter = &quot; &amp; RngGetCurRegionLastCol(rng, True) &amp; &quot;.&quot;) Set rng = Range(&quot;C23&quot;) &#39; assume we know that data contains cell C23 MsgBox (&quot;Address: &quot; &amp; RngGetCurRegionAddress(rng)) End Sub Note the difference in how rng is defined. 5.5.2 Input and output You can read/write and copy/paste values to a range using the course procedures: Sub TM5_RangeEx3() Dim rng As Range Dim rngNew As Range Set rng = RngCurRegion(Range(&quot;D7&quot;)) &#39; get current region MsgBox (&quot;Copy to H14 (upper left corner).&quot;) Set rngNew = RngPaste(rng, Range(&quot;H14&quot;)) &#39; rngNew is now the new range MsgBox (&quot;Make yellow.&quot;) Call RngFormat(rngNew, &quot;yellow&quot;) MsgBox (&quot;Remove format.&quot;) Call RngClear(rngNew, blnCells:=False, blnFormat:=True) MsgBox (&quot;Clear range.&quot;) Call RngClear(rngNew) End Sub Here RngPaste is used to copy a range and paste it to another range. Note you may use RngFormat to format cells of a range. Moreover, you can read/write values from/to a csv file. A comma-separated values (csv) file is a delimited text file that uses a delimiter to separate values. Each line of the file is a data record. Each record consists of one or more fields, separated by the delimiter. The file format is not fully standardized, i.e. the delimiter may be a semicolon, a colon or another delimiter. Moreover, a field may be surrounded with quotation marks. Let us have a look at a csv file data1.csv with a header using a semicolon as delimiter: Year;Brand;Model 1997;Ford;E350 2000;Mercury;Cougar and the csv file data2.csv without a header using a semicolon as delimiter: 55,18,34,1,81,26,90,11,46,32,93 49,95,73,82,53,40,99,10,52,38,92 59,90,97,100,59,73,88,33,78,61,24 96,84,32,36,94,82,49,94,48,49,1 59,21,24,57,3,78,54,79,57,42,8 Let us try to read the two files: Sub TM5_RngFromCSVEx() Dim rng As Range ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Call TM5_ClearTestTM5 &#39; clear test cells so have empty cells &#39;&#39; Read data1.csv file (NOTE you must know the separator in the csv file beforehand!) Range(&quot;G3&quot;) = &quot;Content of data1.csv:&quot; Set rng = RngFromCSV(&quot;data1.csv&quot;, Range(&quot;G4&quot;), &quot;;&quot;) &#39; paste file in range with upper left cell G4 MsgBox (RngGetAddress(rng)) &#39;&#39; Read data2.csv file (NOTE you must know the separator in the csv file beforehand!) Range(&quot;G8&quot;) = &quot;Content of data2.csv:&quot; Set rng = RngFromCSV(&quot;data2.csv&quot;, Range(&quot;G9&quot;), &quot;,&quot;) &#39; paste file in range with upper left cell G9 MsgBox (RngGetAddress(rng)) End Sub Here we use the course procedure RngFromCSV to read the file and specify the upper left corner cell of where to paste. Note the function returns the pasted range. You can write the content of a range to a csv file using: Sub TM5_RngToCSVEx() Dim rng As Range ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Call TM5_ClearTestTM5 &#39; clear test cells so have empty cells &#39;&#39; Write to csv file Set rng = Range(&quot;C4:E19&quot;) Call RngToCSV(&quot;test.csv&quot;, rng, &quot;;&quot;) &#39; semicolon (;) separated file &#39;&#39; Read test.csv file to check Range(&quot;G3&quot;) = &quot;Content of test.csv:&quot; Set rng = RngFromCSV(&quot;test.csv&quot;, Range(&quot;G4&quot;), &quot;;&quot;) End Sub Here we use the course procedure RngToCSV to write the range to the file. Note you can specify different delimiters (here we use a semicolon). 5.5.3 Sorting a range Ranges can be sorted using the .Sort method: Sub TM5_SortRangeEx() Dim rng As Range Dim rngCur As Range ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Call TM5_ClearTestTM5 &#39; clear test cells so have empty cells Set rng = RngCurRegion(Range(&quot;C4&quot;)) &#39;&#39; Sort based on second column ascending Set rngCur = RngPaste(rng, Range(&quot;G4&quot;), withFormat:=True) &#39; make a copy to work with Call rngCur.Sort(Key1:=rngCur.Columns(2), Header:=xlYes) rngCur(1).Offset(-1, 0) = &quot;Sort 2. column&quot; &#39; offset first cell in range by -1 row and 0 col &#39;&#39; Sort based on second column and afterwards 3. column (descending) Set rngCur = RngPaste(rng, Range(&quot;K4&quot;), True) Call rngCur.Sort(Key1:=rngCur.Columns(2), Header:=xlYes, Key2:=rngCur.Columns(3), Order2:=xlDescending) rngCur(1).Offset(-1, 0) = &quot;Sort 2. and next 3. column&quot; End Sub We use the Key arguments to identify which columns we want to sort and the Header argument to identify if the first row in the range is a header. Finally the ordering is given using the Order argument (either xlAscending (default) or xlDescending). 5.6 Arrays Arrays are used to store groups of variables of a specific datatype: &#39;&#39; Define an array (run using the debugger - step into) &#39; How to check the content of an array? &#39; Use the Locals window together with debug mode or a message box Sub TM5_ArrayEx1() Dim intAry(4) As Integer &#39; define array with index 0-4 Dim strAry(3 To 5) As String &#39; define array with index 3-5 Dim i As Integer &#39; Set values intAry(0) = 9 intAry(1) = 12 intAry(2) = 222 intAry(3) = 4 intAry(4) = 100 &#39; Information about the array MsgBox (&quot;Lowest index: &quot; &amp; LBound(intAry)) MsgBox (&quot;Largest index: &quot; &amp; UBound(intAry)) MsgBox (&quot;Number of elements: &quot; &amp; UBound(intAry) - LBound(intAry) + 1) MsgBox (&quot;Array as a string: &quot; &amp; AryToStr(intAry)) &#39; Read and assign values For i = 3 To 5 strAry(i) = ThisWorkbook.Worksheets(&quot;TM5&quot;).Cells(23 + i, 3) Next MsgBox (&quot;Array values: &quot; &amp; AryToStr(strAry)) End Sub Array intAry contain 5 elements which can be accessed using index 0, 1, 2, …, 4. In memory this is done by allocating memory for 5 integers (see Figure 5.2) with index 0-4. The lower and upper index bounds can be found using LBound and UBound and we can use the course procedure AryToStr to print it. Figure 5.2: An array in memory. Note the default start index is 0. If you want another start index you can use e.g. Dim strAry(3 To 5) As String which use indices 3-5 (\\(3 = 5-3+1\\) elements). Moreover, if you want to start with index 1 as default then add Option Base 1 to the top of your module. Arrays require 20 bytes of memory plus 4 bytes for each array dimension plus the number of bytes occupied by the data itself. A Variant containing an array requires 12 bytes more than the array alone. 5.6.1 Multi-dimensional arrays Figure 5.3: Arrays with different dimensions. An array can have different dimensions (see Figure 5.3) e.g. and array with three dimensions is declared using: Dim intOrderSize(52, 100, 50) As Integer where indices may be (week, customer, product) number. Let us assume that index start from 1 then we have an array with \\(52 \\cdot 100 \\cdot 50\\) elements which can be accessed using e.g. MsgBox(intOrderSize(2, 10, 20)) &#39; order size week 2, customer 10, product 20 Let us consider an example: Sub TM5_MultiDimArrayEx() Dim intA(20, 10) As Integer Dim i As Integer, j As Integer ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Call TM5_ClearTestTM5 &#39; clear test cells so have empty cells &#39; Assign some values For i = LBound(intA, 1) To UBound(intA, 1) For j = LBound(intA, 2) To UBound(intA, 2) intA(i, j) = WorksheetFunction.RandBetween(1, 1000) Next Next &#39; print results from G4 For i = LBound(intA, 1) To UBound(intA, 1) For j = LBound(intA, 2) To UBound(intA, 2) Cells(i + 4, j + 7) = intA(i, j) Next Next &#39; Call AryPaste(intA, Range(&quot;G4&quot;)) &#39; same result End Sub We first assign random values to intA in the first loop. Note we use LBound and UBound to find the range of the indices (the second argument is the dimension we consider). Next, the results are printed to the sheet with upper left equal to G4. Here you may also have used the course procedure AryPaste instead. 5.6.2 Dynamic arrays Often we do not know the size of the array we need when we start the program. For this we use dynamic arrays: Sub TM5_DynArrayEx() Dim ary() As String &#39; dynamic array, note use empty () Dim i As Integer ThisWorkbook.Worksheets(&quot;TM5_Test3&quot;).Activate ReDim ary(2 To 5) &#39; create entries a(2) to a(5) For i = 2 To 5 ary(i) = Cells(i + 1, 1) &#39; read from Array sheet Next MsgBox (&quot;Values are: &quot; &amp; AryToStr(ary)) MsgBox (&quot;The lowest and higest index are &quot; &amp; LBound(ary) &amp; &quot; and &quot; &amp; UBound(ary)) ReDim ary(3 To 5) &#39; reallocate array, all values are set to default (empty string) MsgBox (&quot;Values are: &quot; &amp; AryToStr(ary)) For i = 3 To 5 ary(i) = Cells(i + 1, 1) Next MsgBox (&quot;Values are: &quot; &amp; AryToStr(ary)) MsgBox (&quot;The lowest and higest index are &quot; &amp; LBound(ary) &amp; &quot; and &quot; &amp; UBound(ary)) End Sub First, the dynamic array is declared using empty parenthesis Dim ary() As String. Next the ReDim keyword is used to set the dimension. 5.6.3 Input and output A set of course procedures (module ModAry) have been defined to read/set the values in an array and output the values of an array: Sub TM5_IOAryEx() Dim ary() As Integer Dim strAry() As String ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Call TM5_ClearTestTM5 &#39;&#39; Set to value single value ReDim ary(2) Call AryToVal(ary, 5) Range(&quot;G4&quot;) = &quot;A fixed value:&quot; Call AryPaste(ary, Range(&quot;G5&quot;)) &#39; the upper left cell is G5 &#39;&#39; Paste vertical Range(&quot;K4&quot;) = &quot;Paste vertical:&quot; Call AryPaste(ary, Range(&quot;K5&quot;), False) &#39;&#39; Set to sequence Call AryToSeq(ary, 1, 6) Range(&quot;G10&quot;) = &quot;A sequence:&quot; Call AryPaste(ary, Range(&quot;G11&quot;)) &#39;&#39; Read strings from a range Call AryRead(strAry, Range(&quot;C31:D33&quot;)) &#39; read a 2D array Range(&quot;G31&quot;) = &quot;Names in the &quot; &amp; AryDim(strAry) &amp; &quot;D array:&quot; Call AryPaste(strAry, Range(&quot;G32&quot;)) End Sub You set all entries in the array to a single value using AryToVal and a sequence using AryToSeq. Moreover, use AryRead to read the values of a range into an array. Finally, AryPaste can be used to paste values of an array to a sheet. You just have to specify the upper left cell where you want to paste. Procedure AryRead can both read values into 1D and 2D arrays: Sub TM5_AryReadEx() Dim ary() As Integer ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Call TM5_ClearTestTM5 &#39;&#39; Read values from a range with only 1 column Call AryRead(ary, Range(&quot;C5:C9&quot;)) Range(&quot;G4&quot;) = AryDim(ary) &amp; &quot;D array:&quot; Call AryPaste(ary, Range(&quot;G5&quot;), False) &#39;&#39; Read values from a range with only 1 row Call AryRead(ary, Range(&quot;C5:E5&quot;)) Range(&quot;I4&quot;) = AryDim(ary) &amp; &quot;D array:&quot; Call AryPaste(ary, Range(&quot;I5&quot;)) &#39;&#39; Read values from a range with only 1 column/row but use 2D array Call AryRead(ary, Range(&quot;C11:C14&quot;), blnReduceDim:=False) Range(&quot;G10&quot;) = AryDim(ary) &amp; &quot;D array:&quot; Call AryPaste(ary, Range(&quot;G11&quot;), False) &#39;&#39; Use other start and end index Call AryRead(ary, Range(&quot;C17:E19&quot;), intStartIdx1:=2, intStartIdx2:=5) Range(&quot;G16&quot;) = AryDim(ary) &amp; &quot;D array with start index &quot; &amp; LBound(ary, 1) &amp; &quot; and &quot; &amp; LBound(ary, 2) &amp; &quot;:&quot; Call AryPaste(ary, Range(&quot;G17&quot;)) End Sub First, note that if the optional argument blnReduceDim is not set to false the array automatically becomes a 1D array if a range with one row or column is read. Next, you can use another start index of the array (default is 1) by specifying the optional arguments intStartIdx1 and intStartIdx2. Procedure AryRead fails if we want to set values for arrays with more than 2 dimensions. For this the AryReadLong can be used which can read arrays until five dimensions: Sub TM5_AryReadLongEx() Dim ary() As Integer ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Call TM5_ClearTestTM5 &#39;&#39; Read 1D array Call AryReadLong(ary, Range(&quot;A36:B38&quot;), 3) &#39; default value = 3 Range(&quot;G35&quot;) = &quot;Values in the &quot; &amp; AryDim(ary) &amp; &quot;D array:&quot; Call AryPaste(ary, Range(&quot;G36&quot;)) &#39;&#39; Read 2D array Call AryReadLong(ary, Range(&quot;A41:C47&quot;), 4) &#39; default value = 4 Range(&quot;G40&quot;) = &quot;Values in the &quot; &amp; AryDim(ary) &amp; &quot;D array:&quot; Call AryPaste(ary, Range(&quot;G41&quot;)) &#39;&#39; Read 3D array (cannot be pasted to the sheet, have a look at it using the debugger) Call AryReadLong(ary, Range(&quot;A50:D56&quot;), 5) &#39; default value = 5 End Sub Procedure AryReadLong assumes that you specify the values in long format, i.e. there is index values in all columns except the last which contains the values (see Figure 5.4). For instance, if we consider row 54, then the specification says that ary(1,3,1) = 49. Note we do not have to specify all combination of indices, e.g. in the specification A41:C47 the index (2,4) is missing and set to the default value 4. It is assumed that indices start from the lowest to highest index in each dimension. Figure 5.4: Reading values to an array using a long format (TM5 worksheet). You can also read a csv file into an array. Let us have a look at a csv file data2.csv using a semicolon as delimiter: 55,18,34,1,81,26,90,11,46,32,93 49,95,73,82,53,40,99,10,52,38,92 59,90,97,100,59,73,88,33,78,61,24 96,84,32,36,94,82,49,94,48,49,1 59,21,24,57,3,78,54,79,57,42,8 You can read the values into an array using AryFromCSV: Sub TM5_AryReadCSVEx() Dim rng As Range Dim ary() As Integer ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Call TM5_ClearTestTM5 &#39;&#39; Read csv file (NOTE you must know the separator in the csv file beforehand!) Range(&quot;G3&quot;) = &quot;Array values:&quot; Call AryFromCSV(ary, &quot;data2.csv&quot;, &quot;,&quot;) &#39; know that it contains integers (otherwise use variant) Call AryPaste(ary, Range(&quot;G4&quot;)) End Sub 5.6.3.1 Example - Reading values from a sheet This example is a slightly modified version an exam assignment (exam 2022-A4). Consider the data in worksheet TM5_AryData. Our goal is to create a procedure that reads the strings in the worksheet into a 2D array with the following features: Indexing must start from 1 in both dimensions. The procedure should work for other datasets with a different number of columns and rows. You may assume that the data starts in cell A1. A message box should be given after the data has been read with the value of array entry (1,3). If the entry does not exists a warning should be given instead. A button in worksheet TM5_AryData should run the procedure. If you are not allowed to read the data into an array using the course procedure AryRead, you must use for loop(s) to assign values to the array: Sub TM5_AryReadValuesPlainVBA() Dim ary() As String Dim rng As Range Dim r As Integer, c As Integer Worksheets(&quot;TM5_AryData&quot;).Activate Set rng = RngCurRegion(Range(&quot;A1&quot;)) &#39; get current region ReDim ary(1 To RngGetLastRow(rng), 1 To RngGetLastCol(rng)) &#39; redim array &#39; allocate values For r = 1 To RngGetLastRow(rng) For c = 1 To RngGetLastCol(rng) ary(r, c) = Cells(r, c) Next Next &#39; print ary(1,3) If (UBound(ary, 2) &lt; 3) Then MsgBox (&quot;Array does not have 3 columns!&quot;) Exit Sub End If MsgBox (&quot;Value entry (1,3) is: &quot; &amp; ary(1, 3)) End Sub If you are allowed to use AryRead then you can skip the for loop: Sub TM5_AryReadValues() Dim ary() As String Dim rng As Range Dim r As Integer, c As Integer Worksheets(&quot;TM5_AryData&quot;).Activate Set rng = RngCurRegion(Range(&quot;A1&quot;)) &#39; get current region Call AryRead(ary, rng) &#39; allocate values &#39; print ary(1,3) If (UBound(ary, 2) &lt; 3) Then MsgBox (&quot;Array does not have 3 columns!&quot;) Exit Sub End If MsgBox (&quot;Value entry (1,3) is: &quot; &amp; ary(1, 3)) End Sub 5.6.4 Sorting arrays Arrays can be sorted using AryQuickSort: Sub TM5_ArySortEx() Dim ary() As Integer ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Call TM5_ClearTestTM5 &#39;&#39; Read from a range and sort Call AryRead(ary, Range(&quot;C5:E19&quot;)) Call AryQuickSort(ary, 2) Range(&quot;G3&quot;) = &quot;Sort w.r.t. 2. column:&quot; Call RngPaste(Range(&quot;C4:E4&quot;), Range(&quot;G4&quot;)) &#39; copy header Call AryPaste(ary, Range(&quot;G5&quot;)) End Sub Here we sort based on the 2. column in the array. 5.6.5 Use arrays instead of ranges Since a range represent a block of cells in a sheet, one may think of a range a some kind of 1D or 2D array. Hence one may use a range directly to read/write values instead of an array (we did that in Section 4.7). However, often arrays are better to use than ranges: You can set indices as you like so they give a meaning to you, e.g. intOrderSize(2, 10, 20) denote the order size of product 20, in week 2 for customer 10. Arrays are much faster to update than ranges, More specific, it is much faster to update the values many times in an array compared to a range. You worksheet and ranges may be seen as a place where you keep your data. Hence, when you run an algorithm, you first read the data into some arrays. Next, do some calculations (update the arrays) and finally output the result to a worksheet again. Consider for example the distance matrix calculations in Section 3.6. Here it would be faster to store the distance matrix in a 2D array: Sub TM5_MakeDistArray() Dim n As Integer Dim aryDist() As Double Dim i As Integer Dim j As Integer ThisWorkbook.Worksheets(&quot;TM3_DistanceMatrix&quot;).Activate n = Range(&quot;E1&quot;) ReDim aryDist(1 To n, 1 To n) For i = 1 To n For j = i + 1 To n aryDist(i, j) = TM3_Distance(Cells(i + 1, 2), Cells(i + 1, 3), Cells(j + 1, 2), Cells(j + 1, 3)) aryDist(j, i) = aryDist(i, j) &#39; set symetric value Next Next End Sub Afterwards aryDist can be used during in an algorithm. 5.7 Collections Collections are a way of storing a group of items together (think of it as a set). Collections and arrays are both used to group variables. They both store a set of items e.g. a list of student marks or country names. If we compare collections against arrays: Collections are similar to arrays but better to use when the number of items is not fixed. With an array you normally set the size once. On the contrary you often add or remove items from a collection. Collections are better when adding and removing items. An item in a collection are read-only whereas an entry in an array are read/write. Collection can be accessed using a key or an index (starting from 1). Items of a collection do not have to share the same data type. Collections are a part of the predefined objects in VBA and hence a collection have to be defined in a special way. Let us consider an example: Sub TM5_ColEx() Dim col As New Collection &#39; declare and create Dim e As Variant ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Call TM5_ClearTestTM5 &#39;&#39; Add items Call col.Add(&quot;Apple&quot;) Call col.Add(&quot;Pear&quot;) Call col.Add(123) Cells(4, 7) = &quot;The collection now contains &quot; &amp; col.Count &amp; &quot; items: &quot; &amp; Col2Str(col) &#39;&#39; Use For Each to scan elements For Each e In col MsgBox (e) Next e &#39;&#39; Access values in the collection using index Cells(5, 7) = &quot;The 1. item is: &quot; &amp; col(1) Cells(6, 7) = &quot;The 3. item is: &quot; &amp; col(3) &#39; Remove items Call col.Remove(2) Cells(7, 7) = &quot;The collection now contains &quot; &amp; col.Count &amp; &quot; items: &quot; &amp; Col2Str(col) &#39;&#39; Note index of items has now changed (the 3. item has become the 2. item) Cells(8, 7) = &quot;The 1. item is: &quot; &amp; col(1) Cells(9, 7) = &quot;The 2. item is: &quot; &amp; col(2) &#39;&#39; Clear collection Set col = Nothing Cells(10, 7) = &quot;The collection now contains &quot; &amp; col.Count &amp; &quot; items.&quot; End Sub First we declare and create a collection: Dim col As New Collection The collection (or set) is now defined with zero items. You can add items using Call col.Add(&quot;Apple&quot;) Call col.Add(&quot;Pear&quot;) Call col.Add(123) Let us create a function that prints the items of a collection as string: Function Col2Str(col As Collection, Optional strSep As String = &quot;, &quot;) As String Dim e As Variant Dim str As String For Each e In col str = str &amp; e &amp; strSep Next e Col2Str = Left(str, Len(str) - Len(strSep)) End Function Then the output of &quot;The collection now contains &quot; &amp; col.Count &amp; &quot; items: &quot; &amp; Col2Str(col) becomes The collection now contains 3 items: Apple, Pear, 123 You can access values in the collection using index: &quot;The 1. item is: &quot; &amp; col(1) &quot;The 3. item is: &quot; &amp; col(3) The 1. item is: Apple The 3. item is: 123 Items are removed using: Call col.Remove (2) &quot;The collection now contains &quot; &amp; col.Count &amp; &quot; items: &quot; &amp; Col2Str(col) The collection now contains 2 items: Apple, 123 Note index of items has now changed (the 3. item has become the 2. item): &quot;The 1. item is: &quot; &amp; col(1) &quot;The 2. item is: &quot; &amp; col(2) The 1. item is: Apple The 2. item is: 123 You clear a collection using: Set col = Nothing &quot;The collection now contains &quot; &amp; col.Count &amp; &quot; items.&quot; The collection now contains 0 items. An item in a collection can be given a key (think af a key as a name tag given to each item): Sub TM5_ColKeyEx() Dim col As New Collection &#39; declare and create Dim k As Variant ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate &#39;&#39; Add using keys Call col.Add(&quot;Hans Jørgensen&quot;, &quot;ID123&quot;) &#39; value, key Call col.Add(&quot;Jens Hansen&quot;, &quot;ID234&quot;) Call col.Add(&quot;Lone Nielsen&quot;, &quot;ID456&quot;) &#39; col.Add &quot;Sine Mikkelsen&quot;, &quot;ID456&quot; &#39; gives an error since already used the key Cells(12, 7) = &quot;The collection now contains &quot; &amp; col.Count &amp; &quot; items: &quot; &amp; Col2Str(col) &#39;&#39; Access values using keys Cells(13, 7) = &quot;The item with key ID123 is: &quot; &amp; col(&quot;ID123&quot;) &#39; Remove items using keys col.Remove &quot;ID123&quot; Cells(14, 7) = &quot;The collection now contains &quot; &amp; col.Count &amp; &quot; items: &quot; &amp; Col2Str(col) End Sub Here we add items using a key: Call col.Add(&quot;Hans Jørgensen&quot;, &quot;ID123&quot;) &#39; value, key Call col.Add(&quot;Jens Hansen&quot;, &quot;ID234&quot;) Call col.Add(&quot;Lone Nielsen&quot;, &quot;ID456&quot;) &quot;The collection now contains &quot; &amp; col.Count &amp; &quot; items: &quot; &amp; Col2Str(col) The collection now contains 3 items: Hans Jørgensen, Jens Hansen, Lone Nielsen You can now access the item using the key: &quot;The item with key ID123 is: &quot; &amp; col(&quot;ID123&quot;) The item with key ID123 is: Hans Jørgensen Similar you can remove an item using a key: Call col.Remove(&quot;ID123&quot;) &quot;The collection now contains &quot; &amp; col.Count &amp; &quot; items: &quot; &amp; Col2Str(col) The collection now contains 2 items: Jens Hansen, Lone Nielsen It is recommended to use keys since using keys has three advantages: If the order changes your code will still access the correct item You can directly access the item without reading through the entire collection It can make you code more readable For more information about collections you may have a look at this webpage. 5.8 Example - Job sequencing Consider \\(i = 1,...,n\\) jobs that has to be done on a machine and let \\(c_{ij}\\) denote the setup cost of switching from job \\(i\\) to job \\(j\\). Moreover, let \\(c_{0i}\\) denote the setup cost of setting up job \\(i\\) when the machine is idle (index 0). Let \\(s = (0, s_1, \\ldots, s_n)\\) denote the sequence of jobs and \\(C\\) the total setup costs, e.g. if \\(s = (0,1,3,2,6,5,4)\\), then \\(C = c_{01} + c_{13} + c_{32} + c_{26} + c_{65} + c_{54}\\). Different algorithms for finding a good strategy minimizing the total setup costs exists. A greedy algorithm is: Step 0: Select the first job as one with minimal idle setup cost. Step 1: Given current job \\(i\\) select the unscheduled with minimal setup cost. Step 2: If no unscheduled jobs then stop and output the found job sequence else go to Step 1. Often a better algorithm is: Step 0: For each column \\(j\\) find \\(\\bar{c}_j = min(c_{0j},\\ldots,c_{j-1,j},c_{j+1,j},\\ldots,c_{nj})\\) and define relative setup costs \\(\\hat{c}_{ij} = c_{ij}-\\bar{c}_{j}\\) (the cost is subtracted the minimum value in that column). Step 1: Call the greedy algorithm using costs \\(\\hat{c}_{ij}\\). Examples on how data could look like can be seen in worksheet TM5_JobSeq that contains the setup costs (Figure 5.5). Columns M-T contain three datasets for which we want to calculate a job sequence. Figure 5.5: Worksheet TM5_JobSeq. Let us try to implement the greedy algorithm which takes the cost array costs as arguments and output the job sequence and cost: &#39;&#39; Job sequeceing using a cost array &#39; &#39; @param costs An array with setup costs &#39; @param strSeq The job sequence found (returned ByRef). &#39; @param dblCosts The total setup costs (returned ByRef). Sub TM5_GreedyAlg(costs() As Double, strSeq As String, dblCosts As Double) Dim intJobs As Integer &#39; number of jobs Dim used() As Integer &#39; an entry equals 1 if already scheduled Dim intCurJob As Integer &#39; current job Dim intNextJob As Integer &#39; best candidate for next job (= intM if not found yet) Dim dblNextCost As Double &#39; setup cost current to next job Dim c As Integer &#39; iterators Dim intM As Integer &#39; big number &#39;&#39; Allocate arrays intJobs = UBound(costs, 1) ReDim used(1 To intJobs) &#39; set size Call AryToVal(used, 0) &#39; set to 0 &#39;&#39; Run greedy strSeq = &quot;0&quot; &#39; start idle intM = 1000 &#39; a number bigger than largest cost intCurJob = 0 &#39; start idle dblCosts = 0 Do While True &#39; find next job given current intNextJob = intM dblNextCost = intM For c = 1 To intJobs &#39; scan row in array to find next unused job with minimal cost If used(c) &lt;&gt; 1 And costs(intCurJob, c) &lt; dblNextCost Then intNextJob = c dblNextCost = costs(intCurJob, c) End If Next If intNextJob = intM Then Exit Do &#39; no new job found (all jobs used) dblCosts = dblCosts + dblNextCost used(intNextJob) = 1 intCurJob = intNextJob strSeq = strSeq &amp; &quot;, &quot; &amp; intNextJob Loop End Sub First observe that the procedure have three arguments costs, strSeq and dblCosts. The array costs contain the setup costs and is an input argument to the algorithm. The last two arguments are output arguments. Since arguments are passed by reference by default (no new memory is allocated), we modify them with the solution. Next, to run the algorithm we need to keep track of which jobs have been used. We use the array used for this and set it to 0 (not used) and 1 (used). Finally, the Do While loop is used to scan a row in the cost array. We want to find the minimum cost and hence use a big number as starting value, then scan all unused jobs and choose the one with minimum cost. If no new job is found we finish; otherwise we update strSeq and dblCosts. Note that the procedure do not have any interaction with a worksheet. It simply takes an array as input argument and store the result in two output arguments. That is, the procedure is independent of where the data is from (could e.g. be an csv file instead of a worksheet). Let us try to link the greedy algorithm to the data in workheet TM5_JobSeq. Columns M-T contain three datasets for which we want to calculate a job sequence. First, let us make a procedure that copies a dataset to A4 (upper left cell): Sub TM5_CopyData() Dim str As String ThisWorkbook.Worksheets(&quot;TM5_JobSeq&quot;).Activate &#39; so use the correct sheet str = InputBox(&quot;Specify cell in data (e.g. N7)&quot;) &#39; get a cell value Call TM5_CleanJobSeq &#39; delete previous data Call RngPaste(RngCurRegion(Range(str)), Range(&quot;A4&quot;), withFormat:=True) &#39; paste the current region End Sub Note we use the current region of the cell value to retrieve the dataset. We can now run the greedy algorithm using the data starting in A4: Sub TM5_RunGreedy() Dim costs() As Double &#39; setup costs Dim strSeq As String &#39; job seq Dim dblCosts As Double &#39; total setup costs Dim rng As Range ThisWorkbook.Worksheets(&quot;TM5_JobSeq&quot;).Activate &#39; Allocate costs to array Set rng = RngCurRegion(Range(&quot;A4&quot;)) &#39; rng now is the whole dataset with headers Set rng = Range(&quot;B5:&quot; &amp; RngGetLastCol(rng, asLetter:=True) &amp; RngGetLastRow(rng)) &#39; rng now is the costs Call AryRead(costs, rng, 0, 1) &#39; start index from 0 (first dim) and 1 (second dim) &#39; Run algorithm Call TM5_GreedyAlg(costs, strSeq, dblCosts) &#39; Write results to sheet Range(&quot;C1&quot;) = UBound(costs, 1) Range(&quot;C2&quot;) = strSeq Range(&quot;F1&quot;) = dblCosts End Sub First, observe how we allocate values to the ‘costs’ array. We use the course procedure AryRead and hence first have to find the range containing the setup costs. This can be done may ways, but we know that the upper left cell is B5 and the lower right is found using the RngGet functions. Next, we call AryRead and set the index to start from 0 (first dimension) and 1 (second dimension). Given setup costs, we call the greedy algorithm which returns updated strSeq and dblCosts. Finally, we output the results to the worksheet. To implement the ‘better’ algorithm we need to modify the costs array and subtract the minimum column value: Sub TM5_RunBetter() Dim minCol() As Double &#39; min value in col c Dim intJobs As Integer &#39; number of jobs Dim costs() As Double &#39; setup costs Dim strSeq As String &#39; job seq Dim dblCosts As Double &#39; total setup costs Dim rng As Range Dim dbl As Double Dim r As Integer, c As Integer ThisWorkbook.Worksheets(&quot;TM5_JobSeq&quot;).Activate &#39; Allocate costs to array Set rng = RngCurRegion(Range(&quot;A4&quot;)) &#39; rng now is the whole dataset with headers Set rng = Range(&quot;B5:&quot; &amp; RngGetLastCol(rng, asLetter:=True) &amp; RngGetLastRow(rng)) &#39; rng now is the costs Call AryRead(costs, rng, 0, 1) &#39; start index from 0 (first dim) and 1 (second dim) &#39; Calc min value in each col intJobs = UBound(costs, 1) ReDim minCol(1 To intJobs) For c = 1 To intJobs dbl = 10000000 &#39; a big number For r = 0 To intJobs If costs(r, c) &lt; dbl And r &lt;&gt; c Then dbl = costs(r, c) Next minCol(c) = dbl Next &#39; Calc relative For c = 1 To intJobs For r = 0 To intJobs costs(r, c) = costs(r, c) - minCol(c) Next Next &#39; Run algorithm Call TM5_GreedyAlg(costs, strSeq, dblCosts) &#39; Write results to sheet Range(&quot;C1&quot;) = intJobs Range(&quot;C2&quot;) = strSeq Range(&quot;F1&quot;) = dblCosts + WorksheetFunction.Sum(minCol) End Sub First, an array minCol is used to store the minimum values for each column. Next, we update the costs array with the relative values and the greedy algorithm is run with the relative setup cost values. Finally, we output the results. Note we have to add the minimum costs back to dblCosts (the sum of the minCol values). 5.9 Recap Variables are used to store information that is saved in memory. A variable may store different data types such an integer, a double, a group of doubles (an array), a range of cells in a worksheet (a range object) or a set of numbers (a collection). Strings are special variables with varying length. Use the &amp; to concatenate strings (glue strings together). An empty string is of length zero. VBA have a lot of predefined objects you can use. Think of an object as a datatype that holds a group of variables. Examples of some objects are Range, Worksheet, and WorksheetFunction. Refer to an object by specifying the path in the hierarchy e.g.  Workbooks(&quot;Jobs.xlsm&quot;).Worksheets(&quot;Data values&quot;).Range(&quot;D4&quot;).value You may skip parts of the path (VBA then uses the current active one). Warning, you must know which sheet is active. Always specify what you want to be active ThisWorkbook.Worksheets(&quot;Data values&quot;).Activate &#39; activate the sheet dbl = Range(&quot;D4&quot;) Declare object variables using: Dim rng As Range Dim wst As Worksheet Set a reference to object variables using the keyword Set: Set rng = Range(&quot;F7&quot;) Set wst = Worksheets(&quot;Data values&quot;) A Worksheet object refer to a worksheet and you can use it to e.g. modify cells: Worksheets(&quot;TM5_Test1&quot;).Range(&quot;B2&quot;) = &quot;Testing Worksheet&quot; &#39; write to cell in sheet TM5_Test1 Set wst1 = ThisWorkbook.Worksheets(&quot;TM5_Test1&quot;) &#39; set a reference to a worksheet wst1.Range(&quot;B6&quot;) = &quot;Writing using wst1&quot; Different functions for worksheets is part of the course procedures. All the worksheet procedures start with Wst so you easy can find them using auto complete in the VBA editor. All worksheet procedures are stored in the ModWst module. You may open the module to have a look at the procedures. Examples: If WstCreate(&quot;Test&quot;, blnForce:=True) Then MsgBox (&quot;Created Test&quot;) If WstRename(&quot;Test&quot;, &quot;Test1&quot;) Then MsgBox (&quot;Renamed the Test to Test1&quot;) &#39; only work if no Test1 sheet If WstClear(&quot;Test8&quot;) Then MsgBox (&quot;Cleared Test8&quot;) &#39; clear sheet Test8 if exists If WstDelete(&quot;Test1&quot;) Then MsgBox (&quot;Deleted Test1&quot;) Ranges are objects that refer to parts of a worksheet e.g. a cell, a row, a column, or a rectangular selection of cells. Ranges can be used to read and write to cells Dim rng As Range Set rng = Range(&quot;A1:D5&quot;) rng = 145 &#39; cell value MsgBox rng.Address &#39; range address ($A$1:$D$5) You can use the course procedures (module ModRng) with prefix RngGet to retrieve info about the range: Set rng = ThisWorkbook.Worksheets(&quot;TM5&quot;).Range(&quot;C4:E19&quot;) MsgBox (&quot;Number of rows: &quot; &amp; RngGetRows(rng)) MsgBox (&quot;Number of cols: &quot; &amp; RngGetCols(rng)) MsgBox (&quot;First column number: &quot; &amp; RngGetFirstCol(rng)) MsgBox (&quot;First column letter: &quot; &amp; RngGetFirstCol(rng, asLetter:=True)) MsgBox (&quot;Lower right cell: &quot; &amp; RngGetLowerRight(rng, asString:=True)) MsgBox (&quot;Upper right cell: &quot; &amp; RngGetUpperRight(rng, asString:=True)) The current region of a range is found by expanding the range until all cells surrounding the range is empty rng = Range(&quot;D23&quot;).CurrentRegion This is useful if don’t know the size for data. You can use the course procedures (module ModRng) with prefix RngGetCurRegion to retrieve info about the current region of a range: Set rng = Range(&quot;D7&quot;) &#39; assume we know that data contains cell D7 MsgBox (&quot;Address: &quot; &amp; RngGetCurRegionAddress(rng)) MsgBox (&quot;Rows = &quot; &amp; RngGetCurRegionRows(rng) &amp; &quot; cols = &quot; &amp; RngGetCurRegionCols(rng)) MsgBox (&quot;First row number = &quot; &amp; RngGetCurRegionFirstRow(rng) &amp; &quot;. Last row number = &quot; &amp; RngGetCurRegionLastRow(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col number = &quot; &amp; RngGetCurRegionFirstCol(rng) &amp; &quot;. Last col number = &quot; &amp; RngGetCurRegionLastCol(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col letter = &quot; &amp; RngGetCurRegionFirstCol(rng, True) &amp; &quot;. Last col letter = &quot; &amp; RngGetCurRegionLastCol(rng, True) &amp; &quot;.&quot;) You copy/paste a range using: Set rng = Range(&quot;D7:E10&quot;) Set rngNew = RngPaste(rng, Range(&quot;H14&quot;)) &#39; paste with upper left = H14, rngNew is now the new range You can read values from a csv file using: Set rng = RngFromCSV(&quot;data1.csv&quot;, Range(&quot;G4&quot;), &quot;;&quot;) &#39; paste file in range with upper left cell G4 You can write values from a range to a csv file using: Call RngToCSV(&quot;test.csv&quot;, rng, &quot;;&quot;) &#39; semicolon (;) separated file The columns in a range can be sorted. For instance sort a range ascending with respect to the second column and next descending with respect to the first column. Call rng.Sort(Key1:=rng.Columns(2), Order1:=xlAscending, _ Key2:=rng.Columns(1), Order2:=xlDescending, Header:=xlYes) An array store groups of variables of a specific data type. For example Dim intValues(8) As Integer The variable intValues is an array with 9 elements which can be accessed using index 0, 1, 2, …, 8. The default start index of an array is 0. If you want to start with index 1 then add Option Base 1 to the top of your module or use: Dim strAry(3 To 5) As String &#39; define array with index 3-5 An array can have different dimensions, e.g. three: Dim intOrderSize(52, 100, 50) As Integer where indices may be (week, customer, product) number. Let us assume that index start from 1 then we have an array with \\(52 \\cdot 100 \\cdot 50\\) elements which can be accessed using e.g. intOrderSize(2,10, 20) &#39; order size week 2, customer 10, product 20 Arrays require 20 bytes of memory plus 4 bytes for each array dimension plus the number of bytes occupied by the data itself. A Variant containing an array requires 12 bytes more than the array alone. Dynamic arrays are arrays where the dimension is unknown when they are declared. Use ReDim to set the dimension later: Dim strPeople() As String ... n = 8 ReDim strPeople(n) You can set values for an array by reading from a range: Dim ary() As Integer Call AryRead(ary, Range(&quot;C5:E9&quot;)) You can paste values of an array to a range: Call AryPaste(ary, Range(&quot;G5&quot;)) &#39; the upper left cell is G5 You can set values for an array with more than 2 dimensions by reading from a range: Dim ary() As Integer Call AryReadLong(ary, Range(&quot;A36:B38&quot;), 3) &#39; default value = 3 The procedure AryReadLong assumes that you specify the values in long format, i.e. there is index values in all columns except the last which contains the values. You can read a csv file into an array using: Dim ary() As Integer Call AryFromCSV(ary, &quot;data2.csv&quot;, &quot;,&quot;) &#39; know that it contains integers (otherwise use variant) Arrays can be sorted using: Dim ary() As Integer Call AryQuickSort(ary, 2) &#39; sort w.r.t. 2. column Often arrays are better to use than ranges: You can set indices as you like so they give a meaning to you, e.g. intOrderSize(2, 10, 20) denote the order size of product 20, in week 2 for customer 10. Arrays are much faster to update that ranges. It is much faster to update the values many times in an array compared to a range. You worksheet and ranges may be seen as a place where you keep your data. Hence, when you run an algorithm, you first read the data into some arrays. Next, do some calculations (update the arrays) and finally output the result to a worksheet again. Collections are used for storing a group of items together (think of it as a set). Collections and arrays are both used to group variables. If we compare collections against arrays: Collections are similar to arrays but better to use when the number of items is not fixed. With an array you normally set the size once. On the contrary you often add or remove items from a collection. Collections are better when adding and removing items. An item in a collection are read-only whereas an entry in an array are read/write. Collection can be accessed using a key or an index (starting from 1). Items of a collection do not have to share the same data type. Declare and create a collection: Dim col As New Collection Add items using: Call col.Add(&quot;Apple&quot;) Call col.Add(&quot;Pear&quot;) Items are removed using: Call col.Remove (2) Clear a collection using: Set col = Nothing An item in a collection can be given a key (think af a key as a name tag given to each item): Call col.Add(&quot;Hans Jørgensen&quot;, &quot;ID123&quot;) &#39; value, key Call col.Add(&quot;Jens Hansen&quot;, &quot;ID234&quot;) You can now access the item using the key: &quot;The item with key ID123 is: &quot; &amp; col(&quot;ID123&quot;) You can remove an item using a key: Call col.Remove(&quot;ID123&quot;) It is recommended to use keys since using keys has three advantages: If the order changes your code will still access the correct item You can directly access the item without reading through the entire collection It can make you code more readable You may also have a look at the slides for this module . 5.10 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Some of the solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up too early. Put some effort into finding a solution! Practice using shortcuts in RStudio (use Shift+Alt+K to get an overview). Go to the Tools for Analytics workspace and download/export the r project_name_prefix project. Open it on your laptop and have a look at the files in the exercises folder which can be used as a starting point. A template with VBA code for this module is given in the file 05-vba-datatypes-template.xlsm (open it and use it while reading the notes). Have a look inside the module TM5_ex in the VBA editor for examples used in the notes and during lectures. Have a look at module TM5_exercises for exercises. The template file for next teaching module will contain guiding answers for the exercises to this teaching module. 5.10.1 Exercise - Equal entries This exercise is a slightly modified version an exam assignment (exam 2021-A4). Consider worksheet TM5_Equal with seven data sets. Each data set consists of a list of integer values and is contained in a single column. Your code should be able to run on any of these data sets, but only on one data set at a time. The value in cell C1 states the column to use, so you can change the data set by changing this value (the values can be 1, 3, 5, …). The data sets vary in size. If you need to know the number of values in the data set, it should be done as part of your vba code. Write a sub TM5_Equal that stores the values of the data set indicated in cell C1 in an array; creates an array equal, where equal(k,j) is 1, if the k’th and j’th values are equal, and 0 otherwise. 5.10.2 Exercise - Product search Consider the worksheet TM5_Products containing a set of products with product code and price. Create a sub TM5_FindProduct that Declare two arrays to store the price and product code. Assign values to the arrays. Use an input box to ask for a product code. Use a for loop to search for the product and output the price in a message box. Hint: the Exit sub may be useful. Add a button to the worksheet that run the procedure. Test you code using different product codes. What happens if you write the product code without capital letters? If your code do not work, have a look at the UCase function. Modify your code so that if the product is not found then “Product not found!” is given in a message box. 5.10.3 Exercise - Read collections Consider worksheet TM5_Col with numbers in column A to be read into a collection. Create a procedure TM5_ColNoKeys that: Create a collection col and add all the numbers. Print the collection in a message box (you may use the function Col2Str here). Create another collection colC and add all the items in col with value below 5. Consider worksheet TM5_Col with some ID numbers and prices for a set of products in columns C-D. Create a procedure TM5_ColKeys that: Create a collection col and add all the prices using ID as key. Print the price of the product with ID92011 in a message box. What happens if you try to print the price of ID92? 5.10.4 Exercise - Read arrays Consider the worksheet TM5_Array containing 3 datasets to be read into an array. The first two are in long format and the last in range format. Write a procedure TM5_ReadArrays that use course procedures AryRead and AryReadLong to read the values into three arrays. Assume that For the first dataset is the default array value 10. For the second dataset is the default array value 5. For the third dataset index must start from 3 (first dimension) and 5 (second dimension). Use the debugger to inspect if the values have been read correctly into the arrays. 5.10.5 Exercise - Process numbers This exercise is a slightly modified version an exam assignment (reexam 2022-A5). Consider worksheet TM5_ProcessData, which contains a set of numbers. Create a procedure TM5_Process with the following features: Copy the numbers to worksheet TM5_Process. Scan all the numbers and remove (clear the cell) all the negative numbers. Highlight all the numbers above 20. Add a button to the worksheet TM5_Process that run the procedure. The procedure should work for other datasets with a different size. You may assume that the data starts in cell A1. Create a procedure TM5_Stat with the following features: Scan the numbers and find the sum of all non-negative numbers, the mean of all negative numbers. Use a message box to display the sum and mean calculated. Add a button to the worksheet TM5_ProcessData that run the procedure. The procedure should work for other datasets with a different size. You may assume that the data starts in cell A1. 5.10.6 Exercise - Search payments This exercise is a slightly modified version an exam assignment (reexam 2022-A6). Consider worksheet TM5_PaymentsData which contains a table with three columns. The table contains data about payments for clients at a set of dates. Create a procedure TM5_SearchPayments that searches the table with the following features: Read the payment boolean in cell B1 (TRUE or FALSE) and the grouping string in cell B2 (None or Year) on worksheet TM5_Payments. Only consider payments where cells in the Payment column equals the payment boolean. If the grouping string equals None then count the number of payments for each client. Next, output the results on worksheet TM5_Payments. See worksheet TM5_PaymentsEx1 for an example. If the grouping string equals Year then count the number of payments for each client and year. Next, output the results on worksheet TM5_Payments. See worksheet TM5_PaymentsEx2_ for an example. Add a button to worksheet TM5_Payments that run the procedure. The procedure should work for other datasets with different number of rows too. 5.10.7 Exercise - Flight search The worksheet TM5_FlightData contains a set of flights between different destinations. You task is to create a procedure TM5_SearchFlights that can search for matching flights given a set of origins and destinations. Have a look at the results in worksheet TM5_FlightData. The origin and destinations to search for are given in columns A and B and the search result in columns D, E and F. Try pressing the Clear Search button and see what happens. Have a look at the code in the VBA editor for this sub and get an overview. × Hint Set the range you want to read and use AryRead Close Hint Try to finish the first part of the TM5_SearchFlights sub and store the flights in arrays. Use the debugger to check if the values are stored correctly. Try to finish the second part of the SearchFlights sub and search for matching origin-destination pairs. Note origins and destinations listed to be searched for are also matching origin-destination pairs if they are not in the same row. 5.10.8 Exercise - Search table This exercise is a slightly modified version an exam assignment (exam 2022-A6). Consider worksheet TM5_Search which contains a table with three columns starting in cell A1. You want to search the this table and output the matching rows to a new sheet. Create a procedure TM5_Search1 that searches the table with the following features: First, a message box is used to ask if a name should be searched. If the answer is yes, then use an input box to type the name. Next, use a message box to ask if an amount should be searched. If the answer is yes, then use an input box to type the amount (search for amounts greater than or equal the typed amount). Scan the table and output all rows that match the specified criteria, and output the resulting table with matching rows in worksheet TM5_SearchOutput. If no criteria are used, then return all rows. Add a button to worksheet TM5_SearchOutput that run the procedure. The procedure should work for other datasets with different number of rows too (such as the dataset starting in cell E1). Create a procedure TM5_Search2 that searches the table with the following features: Copy the whole table to worksheet TM5_SearchOutput. Sort the table non-increasing order of the column Sales Amount, then next based on the Title column. Use an input box to ask for an amount \\(x\\). Highlight the cells in the rows where the Sales Amount is less than \\(x\\). Add a button to worksheet TM5_SearchOutput that run the procedure. "],["mod-vba-random-numbers.html", "Module 6 Generating random numbers 6.1 Learning outcomes 6.2 Generating random numbers 6.3 Simulation 6.4 Recap 6.5 Exercises", " Module 6 Generating random numbers This module gives a short introduction on how to generate random numbers and using them in a simulation. Simulation studies that you do in Excel may be done easier using VBA together with Excel. For more advanced simulation studies you may use dedicated programs (such as Arena) or Excel plugins (such as @Risk). A template with VBA code for this module is given in the file 06-vba-random-numbers-template.xlsm (open it and use it while reading the notes). Have a look inside the module TM6_ex in the VBA editor for examples used in the notes and during lectures. Have a look at module TM6_exercises for exercises. The template file for next teaching module will contain guiding answers for the exercises to this teaching module. Learning path diagram Click/hover the nodes to follow links and see details. 6.1 Learning outcomes By the end of this module, you are expected to be able to: Describe what a random number is. Generate a random number from a distribution. Run a simulation and compare/analyse results. The learning outcomes relate to the overall learning goals number 2-4, 8-14 and 16 of the course. 6.2 Generating random numbers Often we want to model a system where some of the elements are uncertain. To simulate the system we want to generate some random numbers following different distributions. This can be done using the built-in VBA and Excel functions for most distributions. The course procedures (module ModRand) contain a set of procedures for generating random numbers. Let us have a look at how to generate random numbers from a continuous uniform distribution: &#39;&#39; Generate a random number from a continuous uniform distribution &#39; @param dblMin Minimum number. &#39; @param dblMax Maximum number (not included). Function RandInvUniformCont(dblMin As Double, dblMax As Double) As Double RandInvUniformCont = dblMin + (dblMax - dblMin) * Rnd() End Function Here a single random number is returned. The Rnd function is used to generate random numbers in the interval \\([0,1[\\), i.e. a continuous uniform distribution. The Rnd function is a built-in VBA function. To generate random numbers between [dblMin, dblMax[, we use the formula dblMin + (dblMax - dblMin) * Rnd(). If you need more than a single random number, you can use the almost same procedure with Gen in its name instead of Inv: &#39;&#39; Generate random numbers from a continuous uniform distribution &#39; @param intSize Random numbers generated &#39; @param dblMin Minimum number. &#39; @param dblMax Maximum number (not included). &#39; @param ary Array to store the values in. Sub RandGenUniformCont(intSize As Integer, dblMin As Double, dblMax As Double, ary() As Double) Dim i As Integer ReDim ary(intSize) As Double For i = 1 To intSize ary(i) = dblMin + (dblMax - dblMin) * Rnd() Next End Sub The difference is that an array ary of intSize is used to store the random numbers. Let us consider another example, the normal distribution: &#39;&#39; Generate a random number from a normal distribution &#39; @param dblMean Mean. &#39; @param dblSD Standard deviation. Function RandInvNormal(dblMean As Double, dblSD As Double) As Double RandInvNormal = Application.WorksheetFunction.NormInv(Rnd, dblMean, dblSD) End Function The procedure takes the mean and standard deviation as arguments and return a random number. Multiple random numbers are found using: &#39;&#39; Generate random numbers from a normal distribution &#39; @param intSize Random numbers generated &#39; @param dblMean Mean. &#39; @param dblSD Standard deviation. &#39; @param ary Array to store the values in. Sub RandGenNormal(intSize As Integer, dblMean As Double, dblSD As Double, ary() As Double) Dim i As Integer ReDim ary(intSize) As Double For i = 1 To intSize ary(i) = Application.WorksheetFunction.NormInv(Rnd, dblMean, dblSD) Next End Sub Here intSize random numbers in stored in the output array ary. Similar procedures can be found for the uniform (discrete), binomial, poisson and a custom discrete distribution. Let us try some examples: Sub TM6_RandDistEx() Dim aryDens() As Double Randomize &#39; initialize random-number generator MsgBox (&quot;Normal: &quot; &amp; RandInvNormal(100, 20)) &#39; Cont. uniform [10,500[ MsgBox (&quot;Uniform (continuous): &quot; &amp; RandInvUniformCont(10, 500)) &#39; Discrete uniform 10,...,500 MsgBox (&quot;Uniform (discrete): &quot; &amp; RandInvUniformDisc(10, 500)) &#39; Binomial 100 trials, pr = 0.2 MsgBox (&quot;Binomial: &quot; &amp; RandInvBinomial(100, 0.2)) &#39; Poisson lambda = 5 MsgBox (&quot;Poisson: &quot; &amp; RandInvPoisson(5)) &#39; Custom discrete ReDim aryDens(1 To 4, 1 To 2) aryDens(1, 1) = 3 aryDens(2, 1) = 4 aryDens(3, 1) = 5 aryDens(4, 1) = 6 aryDens(1, 2) = 0.1 aryDens(2, 2) = 0.3 aryDens(3, 2) = 0.5 aryDens(4, 2) = 0.1 MsgBox (&quot;Custom (discrete): &quot; &amp; RandInvDiscrete(aryDens)) End Sub First, observe that in the start of the procedure, the Randomize procedure is called. Randomize initialize the random-number generator and it is always a good idea to call it if you want true random numbers. Next we generate a random number from the different distributions. For generating random numbers from a custom discrete distribution we need a 2D array where each row store the outcome and the probability. For instance here the probability of outcome 5 is 50%. Let us try to generate 20 random numbers from each distribution: Sub TM6_RandDistAryEx() Dim ary() As Double Dim aryDens() As Double Dim intSize As Integer ThisWorkbook.Worksheets(&quot;TM6&quot;).Activate Call TM6_ClearTestTM6 Randomize &#39; initialize random-number generator intSize = 20 &#39; generate 20 numbers for each distribution &#39; Normal Call RandGenNormal(intSize, 100, 20, ary) Range(&quot;A1&quot;) = &quot;Normal&quot; Call AryPaste(ary, Range(&quot;A2&quot;), False) &#39; Cont. uniform [10,500[ Call RandGenUniformCont(intSize, 10, 500, ary) Range(&quot;B1&quot;) = &quot;Uniform&quot; Call AryPaste(ary, Range(&quot;B2&quot;), False) &#39; Discrete uniform 10,...,500 Call RandGenUniformDisc(intSize, 10, 500, ary) Range(&quot;B1&quot;) = &quot;Uniform&quot; Call AryPaste(ary, Range(&quot;B2&quot;), False) &#39; Binomial 100 trials, pr = 0.2 Call RandGenBinomial(intSize, 100, 0.2, ary) Range(&quot;C1&quot;) = &quot;Binomial&quot; Call AryPaste(ary, Range(&quot;C2&quot;), False) &#39; Poisson lambda = 5 Call RandGenPoisson(intSize, 5, ary) Range(&quot;D1&quot;) = &quot;Poisson&quot; Call AryPaste(ary, Range(&quot;D2&quot;), False) &#39; Custom discrete ReDim aryDens(1 To 4, 1 To 2) aryDens(1, 1) = 3 aryDens(2, 1) = 4 aryDens(3, 1) = 5 aryDens(4, 1) = 6 aryDens(1, 2) = 0.1 aryDens(2, 2) = 0.3 aryDens(3, 2) = 0.5 aryDens(4, 2) = 0.1 Call RandGenDiscrete(intSize, aryDens, ary) Range(&quot;E1&quot;) = &quot;Custom&quot; Call AryPaste(ary, Range(&quot;E2&quot;), False) Range(&quot;G3&quot;) = &quot;Custom distribution:&quot; Range(&quot;G4&quot;) = &quot;Value&quot; Range(&quot;H4&quot;) = &quot;Prob.&quot; Call AryPaste(aryDens, Range(&quot;G5&quot;)) End Sub 6.3 Simulation Given an uncertain system we simulate the system by: Constructing a deterministic model (that is we assume the random numbers have some specific values) and algorithms for solving it. Generate random numbers and use them to solve the model and store the results. Repeat a number of times and gather statistics such as minimum, mean, standard deviation or maximum value. Let us consider some examples in the next sections. 6.3.1 Example - Traveling salesman problem The travelling salesman problem (TSP) asks the following question: Given a list of cities and the distances between each pair of the cities, what is the shortest possible route that visits each city exactly once and returns to the origin city? The problem is an NP-hard problem (worst case solution time grows exponential with the number of cities) in combinatorial optimization, important in theoretical computer science and operations research. The problem was first formulated in 1930 and is one of the most intensively studied problems in optimization. Even though the problem is computationally difficult, many heuristics and exact algorithms are known. The goal with this example is to test different heuristics on a set of problem instances. To see which one works best. Let us first create a procedure TM6_GenTSPData that generate a TSP instance: &#39;&#39; Generate cities for the TSP (a TSP problem instance) &#39; @param dblCoord A (cities x 3) array to store the generated id and coordinates in (output ByRef). &#39; @param intCities Number of cities to generate. If 0 then ask. &#39; @param blnPrint If true then print out the data in columns A:C in the TM6_TSP sheet. Sub TM6_GenTSPData(dblCoord() As Double, Optional intCities As Integer = 0, _ Optional blnPrint As Boolean = False) Dim dblMin As Double Dim dblMax As Double Dim i As Integer Dim ary1() As Double, ary2() As Double Randomize &#39; Min and max values for uniform distribution dblMin = 0 dblMax = 10 &#39; Reallocate If intCities = 0 Then intCities = InputBox(&quot;How many points should I generate?&quot;) ReDim dblCoord(1 To intCities, 1 To 3) &#39; Generate random numbers Call RandGenUniformCont(intCities, dblMin, dblMax, ary1) Call RandGenUniformCont(intCities, dblMin, dblMax, ary2) For i = 1 To intCities dblCoord(i, 1) = i dblCoord(i, 2) = ary1(i) dblCoord(i, 3) = ary2(i) Next &#39;&#39; Print data If blnPrint Then ThisWorkbook.Worksheets(&quot;TM6_TSP&quot;).Activate Call TM6_ClearTestTSP Cells(1, 1).value = &quot;City&quot; Cells(1, 2).value = &quot;x-coord&quot; Cells(1, 3).value = &quot;y-coord&quot; For i = 1 To intCities Cells(i + 1, 1).value = dblCoord(i, 1) Cells(i + 1, 2).value = dblCoord(i, 2) Cells(i + 1, 3).value = dblCoord(i, 3) Next End If End Sub Note we specify the number of cities as an input argument. Each city has an id number and a \\(x\\) and \\(y\\)-coordinate and the result is stored in array dblCoord with intCities rows and three columns (column 1 store the city id, column 2 the \\(x\\)-coordinate and column 3 the \\(y\\)-coordinate). The \\(x\\) and \\(y\\)-coordinates are random numbers from an uniform distribution between 0 and 10. If blnPrint is true then coordinates are printed to the sheet and if intCities is zero then use an input box to ask for the number of cities. Figure 6.1: TSP algorithms and cost (TM6_TSP worksheet). We now can create a procedure BtnGenTSPData that calls GenTSPData, ask for the number of cities and print the result to the sheet. A button linking to the procedure is made in worksheet TM6_TSP (see Figure 6.1): Sub TM6_BtnGenTSPData() Dim dblCoord() As Double Call TM6_GenTSPData(dblCoord, 0, True) End Sub Given the \\(x\\) and \\(y\\)-coordinates of a problem instance (stored in dblCoord) we need to calculate the distance matrix: &#39;&#39; Calculate distance matrix &#39; @param dblDist The distance matrix to store distances (output ByRef). &#39; @param dblCoord A (cities x 3) array with id and coordinates. &#39; @pre Assume that dblCoord has not been sorted yet! &#39; @post Distances stored in dblDist. Sub TM6_CalcDistArray(ByRef dblDist() As Double, dblCoord() As Double) Dim i As Integer, j As Integer Dim dblDiffX As Double, dblDiffY As Double Dim intCities As Integer intCities = UBound(dblCoord, 1) ReDim dblDist(intCities, intCities) For i = 1 To intCities For j = i + 1 To intCities dblDiffX = dblCoord(i, 2) - dblCoord(j, 2) dblDiffY = dblCoord(i, 3) - dblCoord(j, 3) dblDist(i, j) = Sqr((dblDiffX * dblDiffX) + (dblDiffY * dblDiffY)) dblDist(j, i) = dblDist(i, j) &#39; assume symetric Next Next End Sub The procedure takes the \\(x\\) and \\(y\\)-coordinates (stored in dblCoord) and calculate the distance matrix stored in dblDist, i.e. dblDist(i, j) store the euclidean distance between city i and j. Symmetric distances are assumed, i.e. dblDist(i, j) = dblDist(j, i). We are now ready to consider algorithms for calculating a TSP route. Let us first consider a procedure TM6_SolveTSPIncX that sort the array dblCoord increasing in the x-coordinate and visit the cities in the order of the sorted array and return to the starting city: &#39;&#39; Calculate visiting sequence based on increasing x-coord &#39; @param dblCoord A (cities x 3) array with id and coordinates. &#39; @param dblDist The distance matrix. &#39; @param dblCost Total cost (output ByRef). &#39; @param intSeq The visiting sequence (output ByRef). &#39; @post The total cost and sequence returned. Sub TM6_SolveTSPIncX(dblCoord() As Double, dblDist() As Double, _ dblCost As Double, intSeq() As Integer) Dim j As Integer Dim intCities As Integer &#39; Sort intCities = UBound(dblDist, 1) ReDim intSeq(intCities) Call AryQuickSort(dblCoord, 2) &#39; Store visiting sequence For j = 1 To intCities intSeq(j) = dblCoord(j, 1) Next dblCost = TM6_CalcCost(dblDist, intSeq) End Sub First, observe that we sort the array using course procedure ArySort. Next, the visiting city sequence are stored in intSeq. Finally, the total cost are stored in dblCost which call the function TM6_CalcCost: &#39;&#39; Calculate the cost of a route &#39; @param dblDist The distance matrix. &#39; @param intSeq The visiting sequence (output ByRef). &#39; @return The cost of a route. Function TM6_CalcCost(dblDist() As Double, intSeq() As Integer) As Double Dim dblCost As Double Dim intCities As Integer Dim j As Integer intCities = UBound(intSeq) dblCost = 0 For j = 1 To intCities - 1 dblCost = dblCost + dblDist(intSeq(j), intSeq(j + 1)) Next TM6_CalcCost = dblCost + dblDist(intSeq(intCities), intSeq(1)) &#39; cost + cost of returning to start End Function If we want to use the algorithm on the data in sheet TM6_TSP we first need a procedure reading the data: &#39;&#39; Read the coordinates into an 2D array &#39; @param dblCoord A (cities x 3) array to store the generated id and coordinates in. &#39; @post Generated data stored in dblCoord. Sub TM6_ReadCoord(dblCoord() As Double) Dim rng As Range ThisWorkbook.Worksheets(&quot;TM6_TSP&quot;).Activate Set rng = RngGetCurRegionRange(Range(&quot;A1&quot;), 2) &#39;current region except the header Call AryRead(dblCoord, rng) End Sub and then a procedure TM6_BtnSolveTSPIncX that calls TM6_SolveTSPIncX using the TSP data in the sheet and print out the total cost in cell H4. We include a button linking to the procedure (see Figure 6.1): Sub TM6_BtnSolveTSPIncX() Dim dblCoord() As Double Dim dblDist() As Double Dim intSeq() As Integer Dim dblCost As Double Call TM6_ReadCoord(dblCoord) Call AryQuickSort(dblCoord, 1) &#39; so sure sorted by id Call TM6_CalcDistArray(dblDist, dblCoord) Call TM6_SolveTSPIncX(dblCoord, dblDist, dblCost, intSeq) Range(&quot;H3&quot;) = &quot;Cost:&quot; Range(&quot;H5&quot;) = dblCost End Sub Another algorithm TM6_SolveTSPIncY that sort the array dblCoord increasing in the \\(y\\)-coordinate and visit the cities in the order of the sorted array and return to the starting city can be made similar to above (see Figure 6.1). A possibility is also an algorithm that visit the cities in the order of the dblCoord array and return to the starting city. This may seen as we visit the cities in random order since we generate the \\(x\\) and \\(y\\)-coordinate random. Finally, we will consider a nearest neighbour algorithm. We start in City 1. Given the current city, the next city (not already visited) is the city with the shortest distance: &#39;&#39; Calculate visiting sequence based on nearest neighbour &#39; @param dblCoord A (cities x 3) array with id and coordinates. &#39; @param dblDist The distance matrix. &#39; @param dblCost Total cost. &#39; @param intSeq The visiting sequence. &#39; @post The total cost and sequence returned. Sub TM6_SolveTSPNN(dblCoord() As Double, dblDist() As Double, ByRef dblCost As Double, ByRef intSeq() As Integer) Dim i As Integer, id As Integer Dim intCities As Integer, intCurCity As Integer, intBestCity As Integer Dim dblMinDist As Double Dim intUsed() As Integer &#39; intUsed(id) = 1 if city id have been used in sequence intCities = UBound(dblDist, 1) ReDim intSeq(intCities) ReDim intUsed(intCities) &#39; Find nearst neighbor id = 1 intSeq(1) = id &#39; start in city id = 1 intUsed(id) = 1 For i = 2 To intCities &#39; find next city to add to intSeq(i) dblMinDist = 1000000 &#39; large number intCurCity = intSeq(i - 1) For id = 2 To intCities &#39; scan for next candidate (id = 1 already used) If intUsed(id) = 0 And dblDist(intCurCity, id) &lt; dblMinDist Then &#39; shorter distance found intBestCity = id dblMinDist = dblDist(intCurCity, id) End If Next intSeq(i) = intBestCity intUsed(intBestCity) = 1 Next dblCost = TM6_CalcCost(dblDist, intSeq) End Sub Here we need to have an array intUsed to store if a city already visited (equal 1 if yes). Nested loops is used to scan for the not-visited city nearest to the current one. The results for all the algorithms on an problem instance with 20 cities can be seen in Figure 6.1. We now have a set of algorithms which can be tested on some problem instances that we can generate. On the problem instance we used above the nearest neighbour algorithm seems to find the best route (shortest cost). However, we can not state that this holds in general without testing on many problem instances. Hence we want to do a simulation study with steps: Generate a problem instance with intCities cities which are chosen random between 10 and 500. Calculate the distance matrix. Solve the instance using all of the above algorithms. Store the result in a row in the TM6_TSPSim sheet. Repeat 100 times and calculate min, mean and max values for each solution algorithm. This is done in procedure TM6_TSPSim: Sub TM6_TSPSim() Dim intCities As Integer Dim s As Integer Dim dblCoord() As Double Dim dblDist() As Double Dim intSeq() As Integer Dim dblCost As Double Dim intRow As Integer &#39; Setup sheet ThisWorkbook.Worksheets(&quot;TM6_TSPSim&quot;).Activate Call RngClear(Range(&quot;A:F&quot;)) Cells(1, 1) = &quot;Simulation results&quot; Cells(3, 2) = &quot;Min&quot; Cells(4, 2) = &quot;Mean&quot; Cells(5, 2) = &quot;Max&quot; intRow = 7 Cells(intRow, 1) = &quot;Run&quot; Cells(intRow, 2) = &quot;Cities&quot; Cells(intRow, 3) = &quot;IncX&quot; Cells(intRow, 4) = &quot;IncY&quot; Cells(intRow, 5) = &quot;Random&quot; Cells(intRow, 6) = &quot;NN&quot; &#39; Run simulation For s = 1 To 100 Cells(s + intRow, 1) = s intCities = WorksheetFunction.RandBetween(10, 500) &#39; number of cities Cells(s + intRow, 2) = intCities Call TM6_GenTSPData(dblCoord, intCities, False) Call TM6_CalcDistArray(dblDist, dblCoord) Call TM6_SolveTSPIncX(dblCoord, dblDist, dblCost, intSeq) Cells(s + intRow, 3) = dblCost Call TM6_SolveTSPIncY(dblCoord, dblDist, dblCost, intSeq) Cells(s + intRow, 4) = dblCost Call TM6_SolveTSPRand(dblCoord, dblDist, dblCost, intSeq) Cells(s + intRow, 5) = dblCost Call TM6_SolveTSPNN(dblCoord, dblDist, dblCost, intSeq) Cells(s + intRow, 6) = dblCost Next &#39; Calc statistics For s = 3 To 6 Cells(3, s) = WorksheetFunction.Min(Range(Cells(intRow + 1, s), Cells(intRow + 100, s))) Cells(4, s) = WorksheetFunction.Average(Range(Cells(intRow + 1, s), Cells(intRow + 100, s))) Cells(5, s) = WorksheetFunction.Max(Range(Cells(intRow + 1, s), Cells(intRow + 100, s))) Next &#39; Format cells Call RngFormat(Cells(3, 2).CurrentRegion, &quot;green&quot;) Call RngFormat(Cells(intRow, 1).CurrentRegion, &quot;orange&quot;, True) End Sub First, we setup the worksheet TM6_TSPSim so it is ready for the results. Next, we run the simulation 100 times in a for loop. In each loop we first generate the number of instances, then a problem instance for which we find the distance matrix. The algorithms is then run on the problem instance and results are added to the worksheet. After the loop we calculate statistics for all the runs. Finally, the results are formatted for nice appearance. Figure 6.2: Simulation comparing TSP algorithms (TM6_TSPSim worksheet). The results are given in Figure 6.2. As can be seen the nearest naighbour algorith is best and gives the shortest average distance. 6.4 Recap Often we want to model a system where some of the elements are uncertain. To simulate the system we want to generate some random numbers following different distributions. This can be done using the built-in VBA and Excel functions for most distributions. Initialize generation of random numbers using Randomize() &#39; chooses a random seed Or Randomize(100) &#39; generate the same sequence of random numbers We normally use the first option. When generating random numbers in VBA and writing them to the worksheet, they will NOT be changed when the worksheet is updated! Only when the code is executed! The course procedures (module ModRand) also contain a set of procedures for generating random numbers that are stored in an array. Given an uncertain system we simulate the system by: Constructing a deterministic model (that is we assume the random numbers have some specific values) and algorithms for solving it. Generate random numbers and use them to solve the model and store the results. Repeat a number of times and gather statistics such as minimum, mean, standard deviation or maximum value. You may also have a look at the slides for this module . 6.5 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Some of the solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up too early. Put some effort into finding a solution! Practice using shortcuts in RStudio (use Shift+Alt+K to get an overview). Go to the Tools for Analytics workspace and download/export the r project_name_prefix project. Open it on your laptop and have a look at the files in the exercises folder which can be used as a starting point. A template with VBA code for this module is given in the file 06-vba-random-numbers-template.xlsm (open it and use it while reading the notes). Have a look inside the module TM6_ex in the VBA editor for examples used in the notes and during lectures. Have a look at module TM6_exercises for exercises. The template file for next teaching module will contain guiding answers for the exercises to this teaching module. 6.5.1 Exercise - Two random integers This exercise is a slightly modified version an exam assignment (reexam 2021-A4). Consider worksheet TM6. Write a sub TM6_RandInt1 that reads two integer numbers, \\(a\\) and \\(b\\) (assume that \\(a &lt; b\\)) from cells B24 and B25, and generates two random integer numbers, \\(r_1\\) and \\(r_2\\), uniformly between \\(a\\) and \\(b\\) such that \\(r_1 \\neq r_2\\). The sub should write \\(r_1\\) and \\(r_2\\) in cells D24 and D25 with the smaller of the two numbers in D24. Write a sub TM6_RandInt2 that should take two integer arguments, \\(a\\) and \\(b\\), and generate two random numbers \\(r_1\\) and \\(r_2\\) following the same rules as in Question 1. However, \\(r_1\\) and \\(r_2\\) may not be written to the spreadsheet. Instead, they should be given as output to the sub calling TM6_RandInt2. Write a sub TM6_RandInt2Main that call TM6_RandInt2 using \\(a=2\\) and \\(b=17\\) and output \\(r_1\\) and \\(r_2\\) in a message box. Is your code robust? What happens if \\(a&gt;b\\)? 6.5.2 Exercise - Swap entries This exercise is a slightly modified version an exam assignment (reexam 2021-A5). Consider worksheet TM6_Swap which contains a list of names (from A4) and two numbers between 1 and 20 (in B1 and B2). You may assume that the number in B2 is strictly larger than the one in B1. In the following, let \\(r_1\\) and \\(r_2\\) represent these two numbers. Sometimes, we need to change the order of the items in such lists, and in this assignment, you will be asked to do that in three different ways. Write a sub TM6_Swap1 that, given values of \\(r_1\\) and \\(r_2\\) (to be read from B1 and B2), swaps the \\(r_1\\)‘th and the \\(r_2\\)’th name in the list. Print the result in column D. Write a sub TM6_Swap2 that, given values of \\(r_1\\) and \\(r_2\\) (to be read from B1 and B2), reverses the sequence from the \\(r_1\\)‘th to the \\(r_2\\)’th name in the list. Print the result in column E. Write a sub TM6_Swap3 that changes the order of the names so they appear in random order. Print the result in column F. Figure 6.3 gives an example on the swap operations. Figure 6.3: Swap entries (TM6_Swap worksheet). 6.5.3 Exercise - Dan’s bakery Dan owns a small bakery baking a single cold-rised bread. The demand level \\(l\\) for bread is uncertain and on a given day the demand level equals \\(l=1\\) (low) with probability 0.2, \\(l=2\\) (medium) with probability 0.5 and \\(l=3\\) (high) with probability 0.3. The actual demand (number of customers) depends on the demand level and is Poisson distributed with mean \\(50 + 60l\\). Currently, the sales price per bread is 45 DKK and production cost 7 DKK. If a customer arrives and Dan has no bread left then he estimates the loss of goodwill to be 10 DKK. A customer always buy one bread. Dan can have 20 breads in the oven a time and hence always produce a multiple of 20 breads. Create a function TM6_DanProfit that returns the daily profit given a specific demand and production. The profit given demand \\(d\\) and production \\(p\\) using the current prices and costs is \\[(45-7)\\min(d,p) - 7\\max(0,p-d) - 10\\max(0,d-p).\\] Let the arguments of the function be: &#39; @param dblDemand Demand. &#39; @param dblProd Production. &#39; @param dblPrice Sales price. &#39; @param dblCost Production costs. &#39; @param dblGW Lost goodwill cost. Create a procedure TM6_DanSim that simulate the system for \\(y\\) days given that Dan choose to produce \\(x\\) breads each day. The procedure arguments are: &#39; @param dblProd Production (x). &#39; @param dblPrice Sales price. &#39; @param dblCost Production costs. &#39; @param dblGW Lost goodwill cost. &#39; @param aryDens Demand level density array (needed for RandGenDiscrete). &#39; @param intDays Days to simulate (y). &#39; @param aryStat Array to store the output statistics (output ByRef). The result array aryProfit has entries: number of runs (days), production sales price production cost lost goodwill cost average profit standard deviation min and max profit Create a procedure TM6_DanBtnSim that calls TM6_DanSim for production levels 20, 40, …, 400 and output the results in worksheet TM6_DanSim. The procedure must use the demand level distribution, prices and cost given in the worksheet. What is the best production level? What is the best production level if the demand levels changes to low with probability 0.7, medium with probability 0.2 and high with probability 0.1? 6.5.4 Exercise - Generating random numbers Create a procedure TM6_GenRandNumb that generate 5000 random numbers of A normal distribution with mean 100 and standard deviation 20. An continuous uniform distribution with range 10 to 500. A binomial distribution with 100 trials and a 0.2 probability of success. A poisson distribution with mean 5. Plot the results for each distribution using TM6_PlotFreq (given). "],["mod-r-install.html", "Module 7 Setting up R 7.1 Learning outcomes 7.2 Install R and RStudio 7.3 Setup and test RStudio Cloud", " Module 7 Setting up R R is a programming language and free software environment. The R language is widely used among statisticians and data miners for developing statistical software and data analysis. For a further overview and description of the history of R see Chapter 2 in Peng (2018). R can be run from a terminal but in general you use an IDE (integrated development environment) RStudio for running R and to saving your work. R and RStudio can either be run from your laptop or using RStudio Cloud which run R in the cloud using your browser. During this course it is recommend that you have R and RStudio installed on your laptop and use it to solve your exercises. Moreover, you are going to use the laptop version at the exam. We may use R Cloud during the lectures. Some pros and cons of using R in the cloud vs on the laptop are Cloud (RStudio Cloud) Pros: Log in and you are ready to use R. No need to download anything. Packages easier to install. Everything can be run using a browser. Cons: There is a limit on user time and CPU time. You need to pay if need more time. Often slower than the desktop version. Need an internet connection. Risky to use at the exam if the internet connection is slow or is down. Use the laptop version instead. Laptop (R and RStudio) Pros: Can be used without any internet connection. No limit on user time and CPU usage. Good if computations takes a lot of time. Cons: You need to install R and RStudio to get started. Packages must be installed. Other needed programs may have to be installed. Updates must be installed. Learning path diagram Click/hover the nodes to follow links and see details. If you like a different learning style there is a lot for videos about R online. The videos have been pointed out as extra online supplements in the learning path diagram. However, they are not part of curriculum. 7.1 Learning outcomes By the end of this module, you are expected to have: Installed R and RStudio on your laptop. Tested R and RStudio on your laptop. Installed some packages on your laptop Signed up on RStudio Cloud and tested it. The learning outcomes relate to the overall learning goal number 5 of the course. 7.2 Install R and RStudio R is a programming language and free software environment. The R language is widely used among statisticians and data miners for developing statistical software and data analysis. For a further overview and description of the history of R see Chapter 2 in Peng (2018). To run R you need to install it on your computer. Moreover, you need the IDE (integrated development environment) RStudio to save your work. If you have a pre-existing installation of R and/or RStudio, reinstall both to the latest versions. It can be considerably harder to run old software than new. Install R from CRAN (Comprehensive R Archive Network). Install the latest precompiled binary distribution for your operating system (use the links at the top of the CRAN page). Install the desktop version of RStudio, a powerful user interface for R. Under Windows it is a good idea to always open R with administrator rights: Add a shortcut for RStudio (e.g. to the taskbar or desktop). Ctrl+Shift+Right-Click the shortcut and choose Properties: Choose Properties Under Shortcut click Advanced and set Run as administrator You now always can open RStudio with this shortcut. 7.2.1 Test your installation Do whatever is appropriate for your OS to launch RStudio. You should get a window similar to the screenshot you have here, but yours will be more boring because you have not written any code or made any figures yet. Put your cursor in the pane labeled Console, which is where you interact with the live R process. Create a simple object using code like x &lt;- 2 * 4 (followed by enter or return). Then inspect the x object by typing x followed by enter or return. You should see the value 8 print to screen. If yes, you have succeeded in installing R and RStudio. Try to open a new file File &gt; New File &gt; New RMarkdown…. Use the defaults and press OK. Next save the file and compile it using Knit (Ctrl+Shift+K). You have now compiled a document with R code embedded. 7.2.2 Add-on packages R is an extensible system and many people share useful codes they have developed as a package via CRAN or GitHub. To install a package from CRAN, for example the dplyr package for data manipulation, one way to do it is in the R console. install.packages(&quot;dplyr&quot;, dependencies = TRUE) By including dependencies = TRUE, we are being explicit and extra careful to install any additional packages the target package, dplyr in the example above is dependent on. Install the package tidyverse which is in fact a bundle of packages by running (note this operation may take a long time): install.packages(&quot;tidyverse&quot;, dependencies = TRUE) Check if you have successfully installed tidyverse by loading the package: library(tidyverse) If your install was unsuccessful try to install the packages who fails one by one. You may also see this short video explaining what packages are. 7.3 Setup and test RStudio Cloud RStudio Cloud works as your laptop version except that a workspace with projects for each module already is created. Join the Tools for Analytics workspace on RStudio Cloud (signup if you have not done it yet). Click the Projects link (in the top) and open the project TM7. A personal copy of the project is loaded for you. Put your cursor in the pane labelled Console, which is where you interact with the live R process. Create a simple object using code like x &lt;- 2 * 4 (followed by enter or return). Then inspect the x object by typing x followed by enter or return. You should see the value 8 print to screen. Try to open a new file File &gt; New File &gt; New RMarkdown…. Use the defaults and press OK. Next save the file and compile it using Knit (Ctrl+Shift+K). You have now compiled a document with R code embedded. References "],["mod-r-workflow.html", "Module 8 R basics and workflows 8.1 Learning outcomes 8.2 Working with R at the command line in RStudio 8.3 Your first DataCamp course 8.4 Pipes 8.5 RStudio projects 8.6 Recap 8.7 Exercises", " Module 8 R basics and workflows This module contains an introduction to using R, the syntax, data types etc. Coding in R is, as VBA, best learnt by trying it out and learn by trial and error. Hence the modules often contains links to interactive tutorials. A template project for this module is given on RStudio Cloud (open it and use it while reading the notes). Learning path diagram It is recommended that you follow the green learning path; however, you may like a different learning style. In the learning path diagram, there are links to alternative online content (video or reading). Note this is an alternative to the standard learning path that you may use instead (you should not do both). The learning path may also have extra content, that is NOT a part of syllabus (only look at it if you want more info)! 8.1 Learning outcomes By the end of this module, you are expected to have: Tried R and RStudio. Learned how the RStudio IDE works. Finished your first course on DataCamp. Solved your first exercises. The learning outcomes relate to the overall learning goals number 2, 5, 6, 8, 11, 13 and 15 of the course. 8.2 Working with R at the command line in RStudio R is a programming language and free software environment. The R language is widely used among statisticians and data miners for data analysis. To run R you need to install it on your laptop or use a cloud version. We will use R via RStudio. First time users often confuse the two. At its simplest, R is like a car’s engine while RStudio is like a car’s dashboard as illustrated in Figure 8.1. Figure 8.1: Analogy of difference between R and RStudio. More precisely, R is a programming language that runs computations, while RStudio is an integrated development environment (IDE) that provides an interface by adding many convenient features and tools. So just as the way of having access to a speedometer, rearview mirrors, and a navigation system makes driving much easier, using RStudio’s interface makes using R much easier as well. RStudio can be accessed using both your laptop version or RStudio Cloud. We will assume that you are using R via RStudio Cloud if not stated otherwise. Compared to Excel, the benefit of using Excel is that the initial learning curve is quite minimal, and most analysis can be done via point-and-click on the top panel. Once a user imports their data into the program, it’s not exceedingly hard to make basic graphs and charts. R is a programming language, however, meaning the initial learning curve is steeper. It will take you some time to become familiar with the interface and master the various functions. Luckily, using R can quickly become second-nature with practice. For a detailed comparison you may see Excel vs R: A Brief Introduction to R by Jesse Sadler. Compared to VBA, R is an interpreted language; users typically access it through a command-line or script file. To run VBA you need to compile and execute it. Launch RStudio Cloud (follow this link to get to the correct project). An personal copy of the project is now created for you. Consider the panes: Console (left) Environment/History (tabbed in upper right) Files/Plots/Packages/Help (tabbed in lower right) FYI: you can change the default location of the panes, among many other things: Customizing RStudio. Now that you are set up with R and RStudio, you are probably asking yourself, “OK - now how do I use R?”. The first thing to note is that unlike other software programs like Excel or SPSS that provide point-and-click interfaces, R is an interpreted language. This means you have to type in commands written in R code. In other words, you have to code/program in R. Note that we will use the terms “coding” and “programming” interchangeably. Go into the Console, where we interact with the live R process. Make an assignment and then inspect the object you just created: x &lt;- 3 * 4 x #&gt; [1] 12 All R statements where you create objects – “assignments” – have this form: object_name &lt;- value and in my head I hear, e.g., “x equals 12”. You will make lots of assignments and the operator &lt;- is a pain to type. Do not be lazy and use =, although it would work, because it will just sow confusion later. Instead, utilize RStudio’s keyboard shortcut: Alt+- (the minus sign). Note that RStudio automatically surrounds &lt;- with spaces, which demonstrates a useful code formatting practice. Give your eyes a break and use spaces. RStudio offers many handy keyboard shortcuts. Also, check Tools &gt; Keyboard Shortcuts Help which brings up a keyboard shortcut reference card. Object names cannot start with a digit and cannot contain certain other characters such as a comma or a space. You are advised to adopt a coding convention; some use snake case others use camel case. Choose the naming convention you like best in your study group. But stick only to one of them. this_is_snake_case # note you do not use capital letters here thisIsCamelCase # you start each word with a capital letter Make another assignment: this_is_a_long_name &lt;- 2.5 To inspect this, try out RStudio’s completion facility: type the first few characters, press TAB, add characters until you agree, then press return. In VBA you have procedures and functions. In R we only use functions which always return an object. R has a mind-blowing collection of built-in functions that are accessed like so: function_name(arg1 = val1, arg2 = val2, ...) Let’s try function seq() which makes regular sequences of numbers and at the same time demo more helpful features of RStudio. Type se and hit TAB. A pop-up shows you possible completions. Specify seq() by typing more or use the up/down arrows to select. Note the floating tool-tip-type help that pops up, reminding you of a function’s arguments. If you want even more help, press F1 as directed to get the full documentation in the help tab of the lower right pane. Now open the parentheses and note the automatic addition of the closing parenthesis and the placement of the cursor in the middle. Type the arguments 1, 10 and hit return. seq(1, 10) #&gt; [1] 1 2 3 4 5 6 7 8 9 10 The above also demonstrates something about how R resolves function arguments. Type seq and press F1 or type: ?seq The Help tab of the lower right pane will show the help documentation of function seq with a description of usage, arguments, return value etc. Note all function arguments have names. You can always specify arguments using name = value form. But if you do not, R attempts to resolve by position. So above, it is assumed that we want a sequence from = 1 that goes to = 10. Since we did not specify step size, the default value of by in the function definition is used, which ends up being 1 in this case. Note since the default value for from is 1, the same result is obtained by typing: seq(to = 10) #&gt; [1] 1 2 3 4 5 6 7 8 9 10 Make this assignment and note similar help with quotation marks. yo &lt;- &quot;hello world&quot; If you just create an assignment, you do not see the value. You may see the value by: yo # same as print(yo) #&gt; [1] &quot;hello world&quot; print(yo) #&gt; [1] &quot;hello world&quot; Now look at your Environment tab in the upper right pane where user-defined objects accumulate. You can also get a listing of these objects with commands: objects() #&gt; [1] &quot;add_graph_legend&quot; &quot;addIconOld&quot; &quot;addIconTasks&quot; &quot;addSolution&quot; #&gt; [5] &quot;create_learning_path&quot; &quot;ctrSol&quot; &quot;dat&quot; &quot;exercises_r_text&quot; #&gt; [9] &quot;g&quot; &quot;learning_path_text_r&quot; &quot;link_excel_file&quot; &quot;link_excel_file_text&quot; #&gt; [13] &quot;link_rcloud_text&quot; &quot;link_slide_file_text&quot; &quot;module_name&quot; &quot;module_number&quot; #&gt; [17] &quot;module_number_prefix&quot; &quot;project_name_prefix&quot; &quot;sheet_name_prefix&quot; &quot;strExercises&quot; #&gt; [21] &quot;strLPath&quot; &quot;this_is_a_long_name&quot; &quot;x&quot; &quot;yo&quot; ls() #&gt; [1] &quot;add_graph_legend&quot; &quot;addIconOld&quot; &quot;addIconTasks&quot; &quot;addSolution&quot; #&gt; [5] &quot;create_learning_path&quot; &quot;ctrSol&quot; &quot;dat&quot; &quot;exercises_r_text&quot; #&gt; [9] &quot;g&quot; &quot;learning_path_text_r&quot; &quot;link_excel_file&quot; &quot;link_excel_file_text&quot; #&gt; [13] &quot;link_rcloud_text&quot; &quot;link_slide_file_text&quot; &quot;module_name&quot; &quot;module_number&quot; #&gt; [17] &quot;module_number_prefix&quot; &quot;project_name_prefix&quot; &quot;sheet_name_prefix&quot; &quot;strExercises&quot; #&gt; [21] &quot;strLPath&quot; &quot;this_is_a_long_name&quot; &quot;x&quot; &quot;yo&quot; If you want to remove the object named yo, you can do this: rm(yo) To remove everything: rm(list = ls()) or click the broom in RStudio’s Environment pane. 8.3 Your first DataCamp course DataCamp is an online platform for learning data science. We are going to use the platform for online tutorials. First, sign up to the organization Tools for analytics at DataCamp using your university e-mail here (IMPORTANT do this before running the course/tutorial below!). DataCamp runs all the courses in your browser. That is, R is run on a server and you do not use RStudio here. The first course gives an Introduction to R. You are expected to have completed the course before continuing this module! 8.4 Pipes Most functions support the pipe operator which is a powerful tool for clearly expressing a sequence of multiple operations. The pipe operator %&gt;%, comes from the magrittr package and is loaded automatically when you load tidyverse. You may use the RStudio keyboard shortcut Ctrl+Shift+M. Consider the following code: # calculate x as a sequence of operations x &lt;- 16 x &lt;- sqrt(x) x &lt;- log2(x) x #&gt; [1] 2 # same as y &lt;- log2(sqrt(16)) y #&gt; [1] 2 Note we here calculate x using a sequence of operations: \\[ \\mbox{original data (x)} \\rightarrow \\mbox{ sqrt } \\rightarrow \\mbox{ log2 }. \\] That is, we take what is left of the arrow (the object x) and put it into the function on the right of the arrow. These operations can be done using the pipe operator: library(tidyverse) x &lt;- 16 x &lt;- x %&gt;% sqrt() %&gt;% log2() x #&gt; [1] 2 In general, the pipe sends the result of the left side of the pipe to be the first argument of the function on the right side of the pipe. That is, you may have other arguments in your functions: 16 %&gt;% sqrt() %&gt;% log2() #&gt; [1] 2 16 %&gt;% sqrt() %&gt;% log(base = 2) # equivalent #&gt; [1] 2 The above example is simple but illustrates that you can use pipes to skip intermediate assignment operations. Later you will do more complex pipes when we consider data wrangling. For instance, mtcars %&gt;% select(cyl, gear, hp, mpg) %&gt;% filter(gear == 4, cyl == 4) #&gt; cyl gear hp mpg #&gt; Datsun 710 4 4 93 22.8 #&gt; Merc 240D 4 4 62 24.4 #&gt; Merc 230 4 4 95 22.8 #&gt; Fiat 128 4 4 66 32.4 #&gt; Honda Civic 4 4 52 30.4 #&gt; Toyota Corolla 4 4 65 33.9 #&gt; Fiat X1-9 4 4 66 27.3 #&gt; Volvo 142E 4 4 109 21.4 selects the columns related to cylinders, gears, horse power and miles, and then rows with cars having four cylinders and gears. For a more detailed introduction to pipes see Chapter 18 in Wickham (2017). 8.5 RStudio projects One day you will need to quit R, do something else and return to your analysis later. One day you will have multiple analyses going that use R and you want to keep them separate. One day you will need to bring data from the outside world into R and send numerical results and figures from R back out into the world. To handle these real life situations, you need to store your work in a project that keeps all the files associated with a project organized together (such as input data, R scripts, analytical results and figures). RStudio has built-in support for this via its [projects][rstudio-using-projects]. You may think of a project as a folder where you store all you work. On RStudio Cloud you create a project inside a workspace. Projects have already been made for most modules. However, let us try to create a project in your Your Workspace workspace. Expand the left menu and select your Your Workspace workspace. Press the New Project button and select New RStudio Project. The project is now created and you can rename it in the upper left corner. Go back to the project 01-module-12 in the Tools for Analytics workspace that we will use for the remaining of the module. For RStudio on your laptop you create a project for the rest of this module by doing this: File &gt; New Project… &gt; New Directory &gt; New Project &gt;. The directory name you choose here will be the project name. Call it whatever you want (or follow me for convenience). I used tfa_testing in my tmp directory (that is tfa_testing is now a subfolder of tmp. You now need a way to store R code in your project. We will use 2 ways of storing your code. An R script file or an R Markdown document. Normally you store lines of R code in a script file that you need to run. R Markdown provides an easy way to produce a rich, fully-documented reproducible analysis. Here you combine text, figures and metadata needed to reproduce the analysis from the beginning to the end in a single file. R Markdown compiles to nicely formatted HTML, PDF, or Word. We are going to use R Markdown for larger projects (e.g. the mandatory R report). We will come back to R Markdown later. 8.5.1 Storing your code in a script file R code can be stored in a script file with file suffix .R. A script file contains a line for each R command to run (think of each line as a command added to the console). Create a new script file File &gt; New File &gt; R Script. Let us add some R code to the file: # this is a comment a &lt;- 2 b &lt;- -3 sig_sq &lt;- 0.5 x &lt;- runif(40) y &lt;- a + b * x + rnorm(40, sd = sqrt(sig_sq)) (avg_x &lt;- mean(x)) write(avg_x, &quot;avg_x.txt&quot;) plot(x, y) abline(a, b, col = &quot;purple&quot;) dev.print(pdf, &quot;toy_line_plot.pdf&quot;) Save the file as testing.R Now run each line by setting the cursor at the first line, hit Ctrl+Enter (runs the line in the Console and moves the cursor to the next line). Repeat Ctrl+Enter until you have run all the lines. Alternatively you may select all the code and hit Ctrl+Enter. Change some things in your code. For instance set a sample size n at the top, e.g. n &lt;- 40, and then replace all the hard-wired 40’s with n. Change some other minor, but detectable, stuff, e.g. alter the sample size n, the slope of the line b, the color of the line etc. Practice the different ways to rerun the code: Walk through line by line by keyboard shortcut (Ctrl+Enter) or mouse (click “Run” in the upper right corner of editor pane). Source the entire document by entering source('testing.R') in the Console or use keyboard shortcut (Shift+Ctrl+S) or mouse (click “Source” in the upper right corner of editor pane or select from the mini-menu accessible from the associated down triangle). Source with echo from the Source mini-menu. Try to get an overview of the different planes and tabs. For instance in the Files tab (lower right plane) you can get an overview of your project files. You may also see this video about projects. 8.6 Recap R is a programming language that runs computations, while RStudio is an integrated development environment (IDE) that provides an interface by adding many convenient features and tools. Adopt a naming convention. Either use snake case or use camel case. Choose the naming convention you like best in your study group. But stick only to one of them. Store your work in a project that keeps all the files associated with a project organized together (such as input data, R scripts, analytical results and figures). You may think of a project as a folder where you store all your work. This workflow will serve you well in the future: Create an RStudio project for an analytical project (a project for most modules is already created in RStudio Cloud) Keep inputs there (we will soon talk about importing) Keep scripts there; edit them, run them in bits or as a whole from there Keep outputs there (like the PDF written above) Avoid using the mouse for pieces of your analytical workflow, such as loading a dataset or saving a figure. This is extremely important for the reproducibility and for making it possible to retrospectively determine how a numerical table or PDF was actually produced. Learn and use shortcuts as much as possible. For instance Alt+- for the assignment operator and Ctrl+Shift+M for the pipe operator. A reference card of shortcuts can be seen using Alt+Shift+K. Store your R commands in a script file and R scripts with a .R suffix. Comments start with one or more # symbols. Use them. RStudio helps you (de)comment selected lines with Ctrl+Shift+C (Windows and Linux) or Cmd+Shift+C (Mac). Values saved in R are stored in Objects. The interactive DataCamp course gave an introduction to some basic programming concepts and terminology: Data types: integers, doubles/numerics, logicals, and characters. Integers are values like -1, 0, 2, 4092. Doubles or numerics are a larger set of values containing both the integers but also fractions and decimal values like -24.932 and 0.8. Logicals are either TRUE or FALSE while characters are text such as “Hamilton”, “The Wire is the greatest TV show ever”, and “This ramen is delicious.” Note that characters are often denoted with the quotation marks around them. Vectors: a series of values. These are created using the c() function, where c() stands for “combine” or “concatenate.” For example, c(6, 11, 13, 31, 90, 92) creates a six element series of positive integer values . Factors: categorical data are commonly represented in R as factors. Categorical data can also be represented as strings. Data frames: rectangular spreadsheets. They are representations of datasets in R where the rows correspond to observations and the columns correspond to variables that describe the observations. Lists are general containers that can be used to store a set of different objects under one name (that is, the name of the list) in an ordered way. These objects can be matrices, vectors, data frames, even other lists, etc. It is not even required that these objects are related to each other in any way. Comparison operators known to R are: &lt; for less than, &gt; for greater than, &lt;= for less than or equal to, &gt;= for greater than or equal to, == for equal to each other (and not = which is typically used for assignment!), != not equal to each other. A pipe (%&gt;%) sends the result of the left side of the pipe to be the first argument of the function on the right side of the pipe. Use pipes if you have many intermediate assignment operations. You may also have a look at the slides for this module . 8.7 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Some of the solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up too early. Put some effort into finding a solution! Always practice using shortcuts in RStudio (see Tools &gt; Keyboard Shortcuts Help). Go to the Tools for Analytics workspace and download/export the TM8 project. Open it on your laptop and have a look at the files in the exercises folder which can be used as a starting point. 8.7.1 Exercise (group work) You are not expected to start solving this exercise before you meet in your group. You have all been allocated into groups. During the course, you are expected to solve the R exercises in these groups. Before you start, it is a good idea to agree on a set of group rules: It is a good idea to have a shared place for your code. Have a look at the section Working in groups and decide on a place to share your code. Create a shared folder where you can share your projects. Agree on a coding convention. 8.7.2 Exercise (piping) Solve this exercise using a script file (e.g. exercises/pipe.R which already has been created). Remember that you can run a line in the file using Ctrl+Enter. The pipe %&gt;% can be used to perform operations sequentially without having to define intermediate objects (Ctrl+Shift+M). Have a look at the dataset mtcars: head(mtcars) ?mtcars The pipe library(tidyverse) mtcars %&gt;% select(cyl, gear, hp, mpg) %&gt;% filter(gear == 4 &amp; cyl == 4) #&gt; cyl gear hp mpg #&gt; Datsun 710 4 4 93 22.8 #&gt; Merc 240D 4 4 62 24.4 #&gt; Merc 230 4 4 95 22.8 #&gt; Fiat 128 4 4 66 32.4 #&gt; Honda Civic 4 4 52 30.4 #&gt; Toyota Corolla 4 4 65 33.9 #&gt; Fiat X1-9 4 4 66 27.3 #&gt; Volvo 142E 4 4 109 21.4 selects the columns related to cylinders, gears, horse power and miles, and then rows with cars having four cylinders and (operator &amp;) gears. × Solution mtcars %&gt;% select(mpg, hp, am, gear) #&gt; mpg hp am gear #&gt; Mazda RX4 21.0 110 1 4 #&gt; Mazda RX4 Wag 21.0 110 1 4 #&gt; Datsun 710 22.8 93 1 4 #&gt; Hornet 4 Drive 21.4 110 0 3 #&gt; Hornet Sportabout 18.7 175 0 3 #&gt; Valiant 18.1 105 0 3 #&gt; Duster 360 14.3 245 0 3 #&gt; Merc 240D 24.4 62 0 4 #&gt; Merc 230 22.8 95 0 4 #&gt; Merc 280 19.2 123 0 4 #&gt; Merc 280C 17.8 123 0 4 #&gt; Merc 450SE 16.4 180 0 3 #&gt; Merc 450SL 17.3 180 0 3 #&gt; Merc 450SLC 15.2 180 0 3 #&gt; Cadillac Fleetwood 10.4 205 0 3 #&gt; Lincoln Continental 10.4 215 0 3 #&gt; Chrysler Imperial 14.7 230 0 3 #&gt; Fiat 128 32.4 66 1 4 #&gt; Honda Civic 30.4 52 1 4 #&gt; Toyota Corolla 33.9 65 1 4 #&gt; Toyota Corona 21.5 97 0 3 #&gt; Dodge Challenger 15.5 150 0 3 #&gt; AMC Javelin 15.2 150 0 3 #&gt; Camaro Z28 13.3 245 0 3 #&gt; Pontiac Firebird 19.2 175 0 3 #&gt; Fiat X1-9 27.3 66 1 4 #&gt; Porsche 914-2 26.0 91 1 5 #&gt; Lotus Europa 30.4 113 1 5 #&gt; Ford Pantera L 15.8 264 1 5 #&gt; Ferrari Dino 19.7 175 1 5 #&gt; Maserati Bora 15.0 335 1 5 #&gt; Volvo 142E 21.4 109 1 4 Close Solution × Hint mtcars %&gt;% select(___, ___, ___, ___) Close Hint Create a pipe that selects columns related to miles, horsepower, transmission and gears. × Solution mtcars %&gt;% select(mpg, hp, am, gear) %&gt;% filter(mpg &lt; 20, gear == 4) #&gt; mpg hp am gear #&gt; Merc 280 19.2 123 0 4 #&gt; Merc 280C 17.8 123 0 4 Close Solution × Hint mtcars %&gt;% select(mpg, hp, am, gear) %&gt;% filter(___, ___) Close Hint Given the answer in 1), filter so cars have miles less than 20 and 4 gears. × Solution mtcars %&gt;% select(mpg, hp, am, gear) %&gt;% filter(mpg &lt; 20 | gear == 4) #&gt; mpg hp am gear #&gt; Mazda RX4 21.0 110 1 4 #&gt; Mazda RX4 Wag 21.0 110 1 4 #&gt; Datsun 710 22.8 93 1 4 #&gt; Hornet Sportabout 18.7 175 0 3 #&gt; Valiant 18.1 105 0 3 #&gt; Duster 360 14.3 245 0 3 #&gt; Merc 240D 24.4 62 0 4 #&gt; Merc 230 22.8 95 0 4 #&gt; Merc 280 19.2 123 0 4 #&gt; Merc 280C 17.8 123 0 4 #&gt; Merc 450SE 16.4 180 0 3 #&gt; Merc 450SL 17.3 180 0 3 #&gt; Merc 450SLC 15.2 180 0 3 #&gt; Cadillac Fleetwood 10.4 205 0 3 #&gt; Lincoln Continental 10.4 215 0 3 #&gt; Chrysler Imperial 14.7 230 0 3 #&gt; Fiat 128 32.4 66 1 4 #&gt; Honda Civic 30.4 52 1 4 #&gt; Toyota Corolla 33.9 65 1 4 #&gt; Dodge Challenger 15.5 150 0 3 #&gt; AMC Javelin 15.2 150 0 3 #&gt; Camaro Z28 13.3 245 0 3 #&gt; Pontiac Firebird 19.2 175 0 3 #&gt; Fiat X1-9 27.3 66 1 4 #&gt; Ford Pantera L 15.8 264 1 5 #&gt; Ferrari Dino 19.7 175 1 5 #&gt; Maserati Bora 15.0 335 1 5 #&gt; Volvo 142E 21.4 109 1 4 Close Solution × Hint mtcars %&gt;% select(mpg, hp, am, gear) %&gt;% filter(___ | ___) Close Hint Given the answer in 1), filter so cars have miles less than 20 or 4 gears. The “or” operator in R is |. × Solution mtcars %&gt;% filter(mpg &lt; 20, gear == 4) %&gt;% select(wt, vs) #&gt; wt vs #&gt; Merc 280 3.44 1 #&gt; Merc 280C 3.44 1 Close Solution × Hint mtcars %&gt;% filter(mpg &lt; 20, gear == 4) %&gt;% select(___, ___) Close Hint Create a pipe that filters the cars having miles less than 20 and 4 gears and selects columns related to weight and engine. × Solution dat &lt;- mtcars dat &lt;- filter(dat, mpg &lt; 20, gear == 4) dat &lt;- select(dat, wt, vs) dat #&gt; wt vs #&gt; Merc 280 3.44 1 #&gt; Merc 280C 3.44 1 Close Solution × Hint dat &lt;- mtcars dat &lt;- filter(dat, ___) dat &lt;- select(dat, ___) dat Close Hint Solve Question 4 without the pipe operator. 8.7.3 Exercise (working dir) Do this exercise from the Console in RStudio. When reading and writing to local files, your working directory becomes important. You can get and set the working directory using functions getwd and setwd. Set the working directory to the project directory using the menu: Session &gt; Set Working Directory &gt; To Project Directory. Now let us create some files: library(tidyverse) dir.create(&quot;subfolder&quot;, showWarnings = FALSE) write_file(&quot;Some text in a file&quot;, file = &quot;test1.txt&quot;) write_file(&quot;Some other text in a file&quot;, file = &quot;subfolder/test2.txt&quot;) Which folders and files have been created? You may have a look in the Files tab in RStudio. We can read the file again using: read_file(&quot;test1.txt&quot;) × Solution read_file(&quot;subfolder/test2.txt&quot;) Close Solution × Hint read_file(&quot;subfolder/___&quot;) Close Hint Read the file test2.txt. Set the working directory to subfolder using function setwd. Note that setwd supports relative paths. Check that you are in the right working directory using getwd. You may also have a look at the files in the directory using function list.files. × Solution setwd(&quot;subfolder&quot;) # done in Q3 read_file(&quot;../test1.txt&quot;) read_file(&quot;test2.txt&quot;) Close Solution × Hint setwd(&quot;subfolder&quot;) # done in Q3 read_file(&quot;../___&quot;) read_file(&quot;___&quot;) Close Hint Read files test1.txt and test2.txt. Note that in relative paths ../ means going to the parent folder. What is different compared to Question 2? 8.7.4 Exercise (vectors) Solve this exercise using a script file. × Solution n &lt;- 100 n * (n+1) / 2 #&gt; [1] 5050 Close Solution What is the sum of the first 100 positive integers? The formula for the sum of integers \\(1\\) through \\(n\\) is \\(n(n+1)/2\\). Define \\(n=100\\) and then use R to compute the sum of \\(1\\) through \\(100\\) using the formula. What is the sum? × Solution n &lt;- 1000 n * (n+1) / 2 #&gt; [1] 5e+05 Close Solution Now use the same formula to compute the sum of the integers from 1 through 1000. × Solution The answer is b). Close Solution Look at the result of typing the following code into R: n &lt;- 1000 x &lt;- seq(1, n) sum(x) Based on the result, what do you think the functions seq and sum do? You can use e.g help(\"sum\") or ?sum. sum creates a list of numbers and seq adds them up. seq creates a list of numbers and sum adds them up. seq creates a random list and sum computes the sum of 1 through 1,000. sum always returns the same number. × Solution Sample 30 integers in the range [1, 100]. Close Solution Run code. What does sample.int do (try running ?sample.int)? set.seed(123) v &lt;- sample.int(100,30) v #&gt; [1] 31 79 51 14 67 42 50 43 97 25 90 69 57 9 72 26 7 95 87 36 78 93 76 15 32 84 82 41 23 27 × Solution sum(v) #&gt; [1] 1598 mean(v) #&gt; [1] 53.3 sd(v) #&gt; [1] 28.8 Close Solution What is the sum, mean, and standard deviation of v? × Solution v[c(1, 6, 4, 15)] #&gt; [1] 31 42 14 72 Close Solution × Hint v[c(1, ___, ___, ___)] Close Hint Select elements 1, 6, 4, and 15 of v. × Solution v[v &gt; 50] #&gt; [1] 79 51 67 97 90 69 57 72 95 87 78 93 76 84 82 Close Solution Select elements with value above 50. × Solution v[v &gt; 75 | v &lt; 25] #&gt; [1] 79 14 97 90 9 7 95 87 78 93 76 15 84 82 23 Close Solution × Hint v[___ | ___] Close Hint Select elements with value above 75 or below 25. × Solution v[v == 43] #&gt; [1] 43 Close Solution Select elements with value 43. × Solution v[is.na(v)] #&gt; integer(0) Close Solution × Hint v[is.na(___)] Close Hint Select elements with value NA. × Solution which(v &gt; 75 | v &lt; 25) #&gt; [1] 2 4 9 11 14 17 18 19 21 22 23 24 26 27 29 Close Solution × Hint which(___ | ___) Close Hint Which elements have value above 75 or below 25? Hint: see the documentation of function which (?which). 8.7.5 Exercise (matrices) Solve this exercise using a script file. Consider matrices m1 &lt;- matrix(c(37, 8, 51, NA, 50, 97, 86, NA, 84, 46, 17, 62L), nrow = 3) m2 &lt;- matrix(c(37, 8, 51, NA, 50, 97, 86, NA, 84, 46, 17, 62L), nrow = 3, byrow = TRUE) m3 &lt;- matrix(c(37, 8, 51, NA, 50, 97, 86, NA, 84, 46, 17, 62L), ncol = 3) What is the difference between the three matrices (think/discuss before running the code). × Solution rowSums(m1, na.rm = T) #&gt; [1] 169 75 294 colSums(m2, na.rm = T) #&gt; [1] 171 151 154 62 Close Solution × Hint rowSums(___, na.rm = ___) colSums(___, na.rm = ___) Close Hint Calculate the row sums of m1 and column sums of m2 ignoring NA values. Hint: have a look at the documentation of rowSums. × Solution rbind(m1, c(1, 2, 3, 4)) #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 37 NA 86 46 #&gt; [2,] 8 50 NA 17 #&gt; [3,] 51 97 84 62 #&gt; [4,] 1 2 3 4 Close Solution × Hint rbind(___, ___) Close Hint Add row c(1, 2, 3, 4) as last row to m1. × Solution rbind(c(1, 2, 3, 4), m1) #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 1 2 3 4 #&gt; [2,] 37 NA 86 46 #&gt; [3,] 8 50 NA 17 #&gt; [4,] 51 97 84 62 Close Solution × Hint rbind(___, ___) Close Hint Add row c(1, 2, 3, 4) as first row to m1. × Solution cbind(m3, c(1, 2, 3, 4)) #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 37 50 84 1 #&gt; [2,] 8 97 46 2 #&gt; [3,] 51 86 17 3 #&gt; [4,] NA NA 62 4 Close Solution × Hint cbind(___, ___) Close Hint Add column c(1, 2, 3, 4) as last column to m3. × Solution m1[2,4] #&gt; [1] 17 Close Solution Select the element in row 2 and column 4 of m1. × Solution m1[2:3,1:2] #&gt; [,1] [,2] #&gt; [1,] 8 50 #&gt; [2,] 51 97 Close Solution × Hint m1[2:3,___] Close Hint Select elements in rows 2-3 and columns 1-2 of m1. × Solution m1[3, c(1,3,4)] #&gt; [1] 51 84 62 Close Solution × Hint m1[3,___] Close Hint Select elements in row 3 and columns 1, 3 and 4 of m1. × Solution m1[3,] #&gt; [1] 51 97 84 62 Close Solution Select elements in row 3 of m1. × Solution m2[is.na(m2)] #&gt; [1] NA NA Close Solution × Hint m2[is.na(___)] Close Hint Select all NA elements in m2. × Solution m2[m2 &gt; 50] #&gt; [1] 84 97 51 86 NA NA 62 Close Solution Select all elements greater that 50 in m2. 8.7.6 Exercise (data frames) Solve this exercise using a script file. Data frames may be seen as cell blocks in Excel. They are representations of datasets in R where the rows correspond to observations and the columns correspond to variables that describe the observations. We consider the data frame mtcars: str(mtcars) glimpse(mtcars) ?mtcars Use the head and tail functions to have a look at the data. × Solution mtcars[,4] #&gt; [1] 110 110 93 110 175 105 245 62 95 123 123 180 180 180 205 215 230 66 52 65 97 150 150 245 #&gt; [25] 175 66 91 113 264 175 335 109 mtcars[,&quot;hp&quot;] #&gt; [1] 110 110 93 110 175 105 245 62 95 123 123 180 180 180 205 215 230 66 52 65 97 150 150 245 #&gt; [25] 175 66 91 113 264 175 335 109 mtcars$hp #&gt; [1] 110 110 93 110 175 105 245 62 95 123 123 180 180 180 205 215 230 66 52 65 97 150 150 245 #&gt; [25] 175 66 91 113 264 175 335 109 Close Solution × Hint mtcars[,___] mtcars[,&quot;___&quot;] mtcars$___ Close Hint Select column hp using index (column 4), its name, and the $ operator. × Solution mtcars1 &lt;- rbind(mtcars, c(34, 3, 87, 112, 4.5, 1.515, 167, 1, 1, 5, 3)) rownames(mtcars1)[33] &lt;- &quot;Phantom XE&quot; Close Solution × Hint mtcars1 &lt;- rbind(mtcars, ___) rownames(mtcars1)[___] &lt;- &quot;Phantom XE&quot; Close Hint Update mtcars by adding row c(34, 3, 87, 112, 4.5, 1.515, 167, 1, 1, 5, 3). Name the row ‘Phantom XE’. × Solution col &lt;- c(NA, &quot;green&quot;, &quot;blue&quot;, &quot;red&quot;, NA, &quot;blue&quot;, &quot;green&quot;, &quot;blue&quot;, &quot;red&quot;, &quot;red&quot;, &quot;blue&quot;, &quot;green&quot;, &quot;blue&quot;, &quot;blue&quot;, &quot;green&quot;, &quot;red&quot;, &quot;red&quot;, NA, NA, &quot;red&quot;, &quot;green&quot;, &quot;red&quot;, &quot;red&quot;, NA, &quot;green&quot;, NA, &quot;blue&quot;, &quot;green&quot;, &quot;green&quot;, &quot;red&quot;, &quot;green&quot;, &quot;blue&quot;, NA) mtcars1 &lt;- cbind(mtcars1, col) class(mtcars1$col) #&gt; [1] &quot;character&quot; Close Solution × Hint col &lt;- c(NA, &quot;green&quot;, ......) mtcars1 &lt;- cbind(mtcars1, ___) class(mtcars1$___) Close Hint Update mtcars by adding column: col &lt;- c(NA, &quot;green&quot;, &quot;blue&quot;, &quot;red&quot;, NA, &quot;blue&quot;, &quot;green&quot;, &quot;blue&quot;, &quot;red&quot;, &quot;red&quot;, &quot;blue&quot;, &quot;green&quot;, &quot;blue&quot;, &quot;blue&quot;, &quot;green&quot;, &quot;red&quot;, &quot;red&quot;, NA, NA, &quot;red&quot;, &quot;green&quot;, &quot;red&quot;, &quot;red&quot;, NA, &quot;green&quot;, NA, &quot;blue&quot;, &quot;green&quot;, &quot;green&quot;, &quot;red&quot;, &quot;green&quot;, &quot;blue&quot;, NA) What class is column col? × Solution mtcars1[mtcars1$vs == 0,] #&gt; mpg cyl disp hp drat wt qsec vs am gear carb col #&gt; Mazda RX4 21.0 6 160 110 3.90 2.62 16.5 0 1 4 4 &lt;NA&gt; #&gt; Mazda RX4 Wag 21.0 6 160 110 3.90 2.88 17.0 0 1 4 4 green #&gt; Hornet Sportabout 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 &lt;NA&gt; #&gt; Duster 360 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 green #&gt; Merc 450SE 16.4 8 276 180 3.07 4.07 17.4 0 0 3 3 green #&gt; Merc 450SL 17.3 8 276 180 3.07 3.73 17.6 0 0 3 3 blue #&gt; Merc 450SLC 15.2 8 276 180 3.07 3.78 18.0 0 0 3 3 blue #&gt; Cadillac Fleetwood 10.4 8 472 205 2.93 5.25 18.0 0 0 3 4 green #&gt; Lincoln Continental 10.4 8 460 215 3.00 5.42 17.8 0 0 3 4 red #&gt; Chrysler Imperial 14.7 8 440 230 3.23 5.34 17.4 0 0 3 4 red #&gt; Dodge Challenger 15.5 8 318 150 2.76 3.52 16.9 0 0 3 2 red #&gt; AMC Javelin 15.2 8 304 150 3.15 3.44 17.3 0 0 3 2 red #&gt; Camaro Z28 13.3 8 350 245 3.73 3.84 15.4 0 0 3 4 &lt;NA&gt; #&gt; Pontiac Firebird 19.2 8 400 175 3.08 3.85 17.1 0 0 3 2 green #&gt; Porsche 914-2 26.0 4 120 91 4.43 2.14 16.7 0 1 5 2 blue #&gt; Ford Pantera L 15.8 8 351 264 4.22 3.17 14.5 0 1 5 4 green #&gt; Ferrari Dino 19.7 6 145 175 3.62 2.77 15.5 0 1 5 6 red #&gt; Maserati Bora 15.0 8 301 335 3.54 3.57 14.6 0 1 5 8 green Close Solution × Hint mtcars1[mtcars1$___ == 0,] Close Hint Select cars with a V-shaped engine. 8.7.7 Exercise (lists) Solve this exercise using a script file. Lists are general containers that can be used to store a set of different objects under one name (that is, the name of the list) in an ordered way. These objects can be matrices, vectors, data frames, even other lists, etc. Let us define a list: lst &lt;- list(45, &quot;Lars&quot;, TRUE, 80.5) lst #&gt; [[1]] #&gt; [1] 45 #&gt; #&gt; [[2]] #&gt; [1] &quot;Lars&quot; #&gt; #&gt; [[3]] #&gt; [1] TRUE #&gt; #&gt; [[4]] #&gt; [1] 80.5 Elements can be accessed using brackets: x &lt;- lst[2] x #&gt; [[1]] #&gt; [1] &quot;Lars&quot; y &lt;- lst[[2]] y #&gt; [1] &quot;Lars&quot; × Solution class(x) #&gt; [1] &quot;list&quot; class(y) #&gt; [1] &quot;character&quot; Close Solution × Hint class(___) class(___) Close Hint What is the class of the two objects x and y? What is the difference between using one or two brackets? × Solution names(lst) &lt;- c(&quot;age&quot;, &quot;name&quot;, &quot;male&quot;, &quot;weight&quot;) lst #&gt; $age #&gt; [1] 45 #&gt; #&gt; $name #&gt; [1] &quot;Lars&quot; #&gt; #&gt; $male #&gt; [1] TRUE #&gt; #&gt; $weight #&gt; [1] 80.5 Close Solution × Hint names(lst) &lt;- c(&quot;age&quot;, ___, ___, ___) lst Close Hint Add names age, name, male and weight to the 4 components of the list. × Solution lst$name #&gt; [1] &quot;Lars&quot; Close Solution Extract the name component using the $ operator. You can add/change/remove components using: lst$height &lt;- 173 # add component lst$name &lt;- list(first = &quot;Lars&quot;, last = &quot;Nielsen&quot;) # change the name component lst$male &lt;- NULL # remove male component lst #&gt; $age #&gt; [1] 45 #&gt; #&gt; $name #&gt; $name$first #&gt; [1] &quot;Lars&quot; #&gt; #&gt; $name$last #&gt; [1] &quot;Nielsen&quot; #&gt; #&gt; #&gt; $weight #&gt; [1] 80.5 #&gt; #&gt; $height #&gt; [1] 173 × Solution lst$name$last #&gt; [1] &quot;Nielsen&quot; Close Solution × Hint lst$name$___ Close Hint Extract the last name component using the $ operator. 8.7.8 Exercise (string management) Strings in R can be defined using single or double quotes: str1 &lt;- &quot;Business Analytics (BA) refers to the scientific process of transforming data into insight for making better decisions in business.&quot; str2 &lt;- &#39;BA can both be seen as the complete decision making process for solving a business problem or as a set of methodologies that enable the creation of business value.&#39; str3 &lt;- c(str1, str2) # vector of strings The stringr package in tidyverse provides many useful functions for string manipulation. We will consider a few. str4 &lt;- str_c(str1, str2, &quot;As a process it can be characterized by descriptive, predictive, and prescriptive model building using data sources.&quot;, sep = &quot; &quot;) # join strings str4 #&gt; [1] &quot;Business Analytics (BA) refers to the scientific process of transforming data into insight for making better decisions in business. BA can both be seen as the complete decision making process for solving a business problem or as a set of methodologies that enable the creation of business value. As a process it can be characterized by descriptive, predictive, and prescriptive model building using data sources.&quot; str_c(str3, collapse = &quot; &quot;) # collapse vector to a string #&gt; [1] &quot;Business Analytics (BA) refers to the scientific process of transforming data into insight for making better decisions in business. BA can both be seen as the complete decision making process for solving a business problem or as a set of methodologies that enable the creation of business value.&quot; str_replace(str2, &quot;BA&quot;, &quot;Business Analytics&quot;) # replace first occurrence #&gt; [1] &quot;Business Analytics can both be seen as the complete decision making process for solving a business problem or as a set of methodologies that enable the creation of business value.&quot; str_replace_all(str2, &quot;the&quot;, &quot;a&quot;) # replace all occurrences #&gt; [1] &quot;BA can both be seen as a complete decision making process for solving a business problem or as a set of methodologies that enable a creation of business value.&quot; str_remove(str1, &quot; for making better decisions in business&quot;) #&gt; [1] &quot;Business Analytics (BA) refers to the scientific process of transforming data into insight.&quot; str_detect(str2, &quot;BA&quot;) # detect a pattern #&gt; [1] TRUE × Solution str_detect(str1, &quot;Business&quot;) #&gt; [1] TRUE str_detect(str2, &quot;Business&quot;) #&gt; [1] FALSE Close Solution × Hint str_detect(str1, ___) str_detect(___, ___) Close Hint Is Business (case sensitive) contained in str1 and str2? × Solution str5 &lt;- str_replace(str2, &quot;BA&quot;, &quot;Business Analytics&quot;) str5 #&gt; [1] &quot;Business Analytics can both be seen as the complete decision making process for solving a business problem or as a set of methodologies that enable the creation of business value.&quot; Close Solution × Hint str5 &lt;- str_replace(str2, ___, ___) Close Hint Define a new string that replace BA with Business Analytics in str2 × Solution str5 &lt;- str_remove(str5, &quot; or as a set of methodologies that enable the creation of business value&quot;) str5 #&gt; [1] &quot;Business Analytics can both be seen as the complete decision making process for solving a business problem.&quot; Close Solution × Hint str5 &lt;- str_remove(str5, ___) Close Hint In the string from Question 2, remove or as a set of methodologies that enable the creation of business value. × Solution str5 &lt;- str_c(str5, &quot;This course will focus on programming and descriptive analytics.&quot;, sep= &quot; &quot;) str5 #&gt; [1] &quot;Business Analytics can both be seen as the complete decision making process for solving a business problem. This course will focus on programming and descriptive analytics.&quot; Close Solution × Hint str5 &lt;- str_c(str5, ___, sep= ___) Close Hint In the string from Question 3, add This course will focus on programming and descriptive analytics.. × Solution str5 &lt;- str_replace(str5, &quot;analytics&quot;, &quot;business analytics&quot;) str5 #&gt; [1] &quot;Business Analytics can both be seen as the complete decision making process for solving a business problem. This course will focus on programming and descriptive business analytics.&quot; Close Solution × Hint str5 &lt;- str_replace(str5, ___, ___) Close Hint In the string from Question 4, replace analytics with business analytics. × Solution str_replace(str2, &quot;BA&quot;, &quot;Business Analytics&quot;) %&gt;% str_remove(&quot; or as a set of methodologies that enable the creation of business value&quot;) %&gt;% str_c(&quot;This course will focus on programming and descriptive analytics.&quot;, sep= &quot; &quot;) %&gt;% str_replace(&quot;analytics&quot;, &quot;business analytics&quot;) #&gt; [1] &quot;Business Analytics can both be seen as the complete decision making process for solving a business problem. This course will focus on programming and descriptive business analytics.&quot; Close Solution × Hint str_replace(str2, ___, ___) %&gt;% str_remove(___) %&gt;% str_c(___) %&gt;% str_replace(___) Close Hint Do all calculations in Question 2-5 using pipes. References "],["mod-r-loops-cond.html", "Module 9 Loops and conditionals 9.1 Learning outcomes 9.2 Conditionals and control flow 9.3 Loops 9.4 Recap 9.5 Exercises", " Module 9 Loops and conditionals This module considers programming with loops and conditional statements in R. A template project for this module is given on RStudio Cloud (open it and use it while reading the notes). Learning path diagram It is recommended that you follow the green learning path; however, you may like a different learning style. In the learning path diagram, there are links to alternative online content (video or reading). Note this is an alternative to the standard learning path that you may use instead (you should not do both). The learning path may also have extra content, that is NOT a part of syllabus (only look at it if you want more info)! 9.1 Learning outcomes By the end of this module, you are expected to be able to: Formulate conditional statements. Use functions any and all. Formulate loops in R using for and while statements. Use function if_else. The learning outcomes relate to the overall learning goals number 2, 4 and 10 of the course. 9.2 Conditionals and control flow An excellent introduction to conditionals and if statements is given in Chapter 1 of the interactive DataCamp course Intermediate R. Please complete the chapter before continuing. Some functions are also useful for comparing logical data types. Consider this example: x &lt;- c(1, 3, 5, 10, 2, 17, 11, NA, 4) x &gt; 10 # are the elements greater that 10 #&gt; [1] FALSE FALSE FALSE FALSE FALSE TRUE TRUE NA FALSE any(x &gt; 10) # are any of the elements greater that 10 #&gt; [1] TRUE all(x &gt; 10) # are all of the elements greater that 10 #&gt; [1] FALSE all(x &lt; 20) # are all of the elements greater that 20 #&gt; [1] NA all(x &lt; 20, na.rm = TRUE) # are all of the elements greater that 20 #&gt; [1] TRUE That is, functions any and all can be used to join logical values in vectors. Some if statements can be written alternatively using function if_else: if_else(condition, true, false, missing = NULL) For example: x &lt;- c(-5:5, NA) x #&gt; [1] -5 -4 -3 -2 -1 0 1 2 3 4 5 NA ## using if and for res &lt;- rep(&quot;&quot;, length(x)) for (i in seq_along(x)) { if (is.na(x[i])) res[i] &lt;- &quot;missing&quot; else if (x[i] &lt; 0) res[i] &lt;- &quot;negative&quot; else res[i] &lt;- &quot;positive&quot; } res #&gt; [1] &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;positive&quot; &quot;positive&quot; &quot;positive&quot; #&gt; [9] &quot;positive&quot; &quot;positive&quot; &quot;positive&quot; &quot;missing&quot; ## implicit if statement res &lt;- rep(&quot;&quot;, length(x)) res #&gt; [1] &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; res[x &lt; 0] &lt;- &quot;negative&quot; res[x &gt;= 0] &lt;- &quot;positive&quot; res[is.na(x)] &lt;- &quot;missing&quot; res #&gt; [1] &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;positive&quot; &quot;positive&quot; &quot;positive&quot; #&gt; [9] &quot;positive&quot; &quot;positive&quot; &quot;positive&quot; &quot;missing&quot; ## using if_else res &lt;- if_else(x &lt; 0, &quot;negative&quot;, &quot;positive&quot;, &quot;missing&quot;) res #&gt; [1] &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;positive&quot; &quot;positive&quot; &quot;positive&quot; #&gt; [9] &quot;positive&quot; &quot;positive&quot; &quot;positive&quot; &quot;missing&quot; 9.3 Loops An excellent introduction to conditionals and if statements is given in Chapter 2 of the interactive DataCamp course Intermediate R. Please complete the chapter before continuing (stop when Chapter 2 finishes). Loops in R may be slow. However, not if you follow some golden rules: Do not use a loop when a vectorized alternative exists. Do not grow objects (via c, cbind, etc) during the loop - R has to create a new object and copy across the information just to add a new element or row/column. Instead, allocate an object to hold the results and fill it in during the loop. As an example, consider the for loop with 4 iterations: i_val &lt;- c(1,2,6,9) res &lt;- rep(NA,4) res #&gt; [1] NA NA NA NA for (idx in 1:length(i_val)) { res[idx] &lt;- 6 * i_val[idx] + 9 } res #&gt; [1] 15 21 45 63 Note we allocate memory for the result vector before the loop so we do not have to grow the result object. Next, we calculate results \\(6i+9\\) using a loop. Be careful here! This is not the same: res &lt;- rep(NA,4) for (i in i_val) { res[i] &lt;- 6 * i + 9 } res #&gt; [1] 15 21 NA NA NA 45 NA NA 63 In this example, however, we can use a vectorized alternative: res &lt;- 6 * i_val + 9 res #&gt; [1] 15 21 45 63 where the operation is applied to each element in the vector. Nested for loops is also possible. A simple example of a nested loop: for (i in 1:3) { for (j in 1:2) { cat(str_c(&quot;i =&quot;, i, &quot; j = &quot;,j, &quot;\\n&quot;)) } } #&gt; i =1 j = 1 #&gt; i =1 j = 2 #&gt; i =2 j = 1 #&gt; i =2 j = 2 #&gt; i =3 j = 1 #&gt; i =3 j = 2 We here use the function cat to print out a string (\\n indicates new line). Note how the nested loops are executed: Set i = 1 (outer loop) Set j = 1 (inner loop), i stays 1 Set j = 2 (inner loop), i stays 1 Inner loop finishes, proceed with outer loop. Increase i = 2 (outer loop) Set j = 1 (inner loop), i stays 2 Set j = 2 (inner loop), i stays 2 Inner loop finishes, proceed with outer loop. Increase i = 3 (outer loop) Set j = 1 (inner loop), i stays 3 Set j = 2 (inner loop), i stays 3 Inner loop finishes, proceed with outer loop. Outer loop finishes as well (we looped over i in 1:3). Job done. Nested loops can be used to iterate over matrices or data frames: mat &lt;- matrix(NA, nrow = 2, ncol = 3) mat #&gt; [,1] [,2] [,3] #&gt; [1,] NA NA NA #&gt; [2,] NA NA NA for (i in 1:nrow(mat)) { for (j in 1:ncol(mat)) { mat[i,j] &lt;- (i-1)*ncol(mat) + j cat(str_c(&quot;Entry (&quot;, i, &quot;, &quot;, j, &quot;) = &quot;, mat[i,j], &quot;\\n&quot;)) } } #&gt; Entry (1, 1) = 1 #&gt; Entry (1, 2) = 2 #&gt; Entry (1, 3) = 3 #&gt; Entry (2, 1) = 4 #&gt; Entry (2, 2) = 5 #&gt; Entry (2, 3) = 6 mat #&gt; [,1] [,2] [,3] #&gt; [1,] 1 2 3 #&gt; [2,] 4 5 6 Often you can replace nested loops with a single loop by using expand_grid: library(tidyverse) # load function expand_grid mat &lt;- matrix(NA, nrow = 2, ncol = 3) ite &lt;- expand_grid(i = 1:2, j=1:3) ite #&gt; # A tibble: 6 × 2 #&gt; i j #&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 1 1 #&gt; 2 1 2 #&gt; 3 1 3 #&gt; 4 2 1 #&gt; 5 2 2 #&gt; 6 2 3 for (r in 1:nrow(ite)) { # iterate over rows i &lt;- ite$i[r] j &lt;- ite$j[r] mat[i,j] &lt;- (i-1)*ncol(mat) + j cat(str_c(&quot;Entry (&quot;, i, &quot;, &quot;, j, &quot;) = &quot;, mat[i,j], &quot;\\n&quot;)) } #&gt; Entry (1, 1) = 1 #&gt; Entry (1, 2) = 2 #&gt; Entry (1, 3) = 3 #&gt; Entry (2, 1) = 4 #&gt; Entry (2, 2) = 5 #&gt; Entry (2, 3) = 6 mat #&gt; [,1] [,2] [,3] #&gt; [1,] 1 2 3 #&gt; [2,] 4 5 6 Note expand_grid creates a data frame with all combinations. This way of looping is a more flexible approach since you can nest more loops by adding more columns to ite, add different values in each column. For instance, if you only want to calculate values for row 2 and columns 1 and 3 the code becomes: mat &lt;- matrix(NA, nrow = 2, ncol = 3) ite &lt;- expand_grid(i = 2, j = c(1,3)) ite #&gt; # A tibble: 2 × 2 #&gt; i j #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2 1 #&gt; 2 2 3 for (r in 1:nrow(ite)) { # iterate over rows i &lt;- ite$i[r] j &lt;- ite$j[r] mat[i,j] &lt;- (i-1)*ncol(mat) + j cat(str_c(&quot;Entry (&quot;, i, &quot;, &quot;, j, &quot;) = &quot;, mat[i,j], &quot;\\n&quot;)) } #&gt; Entry (2, 1) = 4 #&gt; Entry (2, 3) = 6 mat #&gt; [,1] [,2] [,3] #&gt; [1,] NA NA NA #&gt; [2,] 4 NA 6 9.4 Recap Comparison/relational operators known to R are: &lt; for less than, &gt; for greater than, &lt;= for less than or equal to, &gt;= for greater than or equal to, == for equal to each other (and not = which is typically used for assignment!), != not equal to each other. Logical operators known to R are: &amp; and, | or, ! not. If you use &amp;&amp; and || only the first element in vectors are compared. In general this is used rarely. Useful functions that return a logical are any and all which can be used to join logical values in vectors. Conditional Statements can be constructed using for instance if and while statements. Moreover, function if_else is a vectorized alternative. Loops can be created using for and while statements. You can break out of a loop using break and jump to the next iteration (skipping the remainder of the code in the loop) using next. Do not use a loop when a vectorized alternative exists. Do not grow objects during the loop. Instead, allocate an object to hold the results and fill it in during the loop. Nested loops are possible in R. However, often they can be converted into a single loop by defining a data frame having the values of the nested loops in each row. Here function expand_grid may be useful to create the data frame. You may also have a look at the slides for this module. 9.5 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Some of the solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up too early. Put some effort into finding a solution! Always practice using shortcuts in RStudio (see Tools &gt; Keyboard Shortcuts Help). Go to the Tools for Analytics workspace and download/export the TM9 project. Open it on your laptop and have a look at the files in the exercises folder which can be used as a starting point. 9.5.1 Exercise (conditional expressions) Solve this exercise using a script file Consider object x: x &lt;- c(1,2,-3,4) What will this conditional expression return? if(all(x&gt;0)){ print(&quot;All Postives&quot;) } else { print(&quot;Not all positives&quot;) } What will the following expressions return? x &lt;- c(TRUE, FALSE, TRUE, TRUE) all(x) any(x) any(!x) all(!x) Which of the expressions above is always FALSE when at least one entry of a logical vector x is TRUE? Consider vector: library(tidyverse) x &lt;- 1:15 x #&gt; [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 × Solution if_else(x &lt; 7, as.integer(0), x) #&gt; [1] 0 0 0 0 0 0 7 8 9 10 11 12 13 14 15 Close Solution × Hint if_else(x &lt; 7, as.integer(___), ___) Close Hint Use the if_else function to set elements with value below 7 to 0. × Solution if_else(x &lt; 7 | x &gt; 10, NA_integer_, x) #&gt; [1] NA NA NA NA NA NA 7 8 9 10 NA NA NA NA NA Close Solution × Hint if_else(___, NA_integer_, ___) Close Hint Use the if_else function to set elements with value below 7 or above 10 to NA_integer_ (which is the NA/missing value of an integer). × Solution x &lt;- sample(c(1:10,NA,5.5), 1) if (is.na(x)) { y &lt;- &quot;missing&quot; } else if (x %% 2 == 0) { y &lt;- &quot;even&quot; } else if (x %% 2 == 1) { y &lt;- &quot;odd&quot; } else if (x %% 1 &gt; 0) { y &lt;- &quot;decimal&quot; } x #&gt; [1] 7 y #&gt; [1] &quot;odd&quot; Close Solution × Hint x &lt;- sample(c(1:10,NA,5.5), 1) if (is.na(x)) { y &lt;- ___ } else if (x %% 2 == 0) { ___ } else if (___) { ___ } else if (___) { y &lt;- &quot;decimal&quot; } x y Close Hint Consider code x &lt;- sample(c(1:10,NA,5.5), 1) x #&gt; [1] 7 which generates a number from the vector c(1:10,NA,5.5). Write code which set object y equal to “even” if x is even, “odd” if x is odd, “decimal” if x has a decimal not zero and “missing” if x is NA. Hint: have a look at ?'%%' (the modulo operator). 9.5.2 Exercise (loops) × Solution x &lt;- rep(NA,4) for (i in 1:4) { x[i] &lt;- 2 * i + 4 } x #&gt; [1] 6 8 10 12 Close Solution × Hint x &lt;- rep(NA,4) for (i in 1:4) { x[i] &lt;- ___ } x Close Hint Using a for loop, create a vector having values \\(2i + 4\\) given \\(i=1\\ldots 4\\). × Solution i_val &lt;- c(2, 5, 6, 12) x &lt;- rep(NA, length(i_val)) for (idx in 1:length(i_val)) { x[idx] &lt;- 2 * i_val[idx] + 4 } Close Solution × Hint i_val &lt;- c(2, 5, 6, 12) x &lt;- rep(NA, length(i_val)) for (idx in 1:length(i_val)) { x[idx] &lt;- ___ } Close Hint Using a for loop, create a vector having values \\(2i + 4\\) given \\(i=2,5,6,12\\). × Solution i_val &lt;- c(2, 5, 6, 12) x &lt;- rep(NA, length(i_val)) idx &lt;- 1 while (idx &lt; 5) { x[idx] &lt;- 2 * i_val[idx] + 4 idx &lt;- idx + 1 } Close Solution × Hint i_val &lt;- c(2, 5, 6, 12) x &lt;- rep(NA, length(i_val)) idx &lt;- 1 while (idx &lt; 5) { x[idx] &lt;- ___ idx &lt;- ___ } Close Hint Solve Question 2 using a while loop. × Solution 2 * 1:4 + 4 # Q1 #&gt; [1] 6 8 10 12 2* c(2, 5, 6, 12) + 4 # Q2 #&gt; [1] 8 14 16 28 Close Solution × Hint 2 * ___ + 4 # Q1 ___ # Q2 Close Hint Solve Questions 1 and 2 using a vectorized alternative. 9.5.3 Exercise (search vector) This exercise is a slightly modified version an exam assignment (reexam 2021-A1). Consider the vector: v &lt;- c(9, 19, 2, 8, NA, 12, 9, 23, NA, 34) v #&gt; [1] 9 19 2 8 NA 12 9 23 NA 34 × Solution any(v &lt;= 2) #&gt; [1] TRUE Yes since the vector contains 2. Close Solution Is any of the entries in v below or equal to 2? × Solution all(v &gt;= 2) #&gt; [1] NA We don't know since we have missing values. Close Solution Is all of the entries in v above or equal to 2? × Solution any(is.na(v)) #&gt; [1] TRUE Yes, since v contains NA values. Close Solution Does v have missing values? × Solution which(v &gt; 10) #&gt; [1] 2 6 8 10 The indicies are show above. Close Solution Which entries in v are above 10? You must return the indices, e.g. the index of v[3] is 3. × Solution res &lt;- if_else(v &lt; 10, v, 0, 0) res #&gt; [1] 9 0 2 8 0 0 9 0 0 0 We use if_else to set values. Close Solution Create a vector res where res[i] is equal to v[i] if v[i] is less than 10 and otherwise zero (also if v[i] is NA). 9.5.4 Exercise (calculating distances) Consider zip codes in Jutland: # remotes::install_github(&quot;bss-osca/tfa-package&quot;, upgrade = FALSE) # run to upgrade library(tidyverse) data(zips, package = &quot;tfa&quot;) # load the zips data from the tfa package zips #&gt; # A tibble: 376 × 2 #&gt; Zip Area #&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 5320 &quot;Agedrup&quot; #&gt; 2 6753 &quot;Agerb\\xe6k&quot; #&gt; 3 6534 &quot;Agerskov&quot; #&gt; 4 8961 &quot;Alling\\xe5bro&quot; #&gt; 5 6051 &quot;Almind&quot; #&gt; 6 8592 &quot;Anholt&quot; #&gt; 7 8643 &quot;Ans By&quot; #&gt; 8 6823 &quot;Ansager&quot; #&gt; 9 9510 &quot;Arden&quot; #&gt; 10 5466 &quot;Asperup&quot; #&gt; # … with 366 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows We want to calculate distances between a subset of zip areas: idx &lt;- 1:5 dat &lt;- zips[idx,] dat #&gt; # A tibble: 5 × 2 #&gt; Zip Area #&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 5320 &quot;Agedrup&quot; #&gt; 2 6753 &quot;Agerb\\xe6k&quot; #&gt; 3 6534 &quot;Agerskov&quot; #&gt; 4 8961 &quot;Alling\\xe5bro&quot; #&gt; 5 6051 &quot;Almind&quot; distanceMat &lt;- matrix(NA, nrow = length(idx), ncol = length(idx)) colnames(distanceMat) &lt;- str_c(dat$Zip[idx], dat$Area[idx], sep = &quot; &quot;) rownames(distanceMat) &lt;- colnames(distanceMat) distanceMat #&gt; 5320 Agedrup 6753 Agerb\\xe6k 6534 Agerskov 8961 Alling\\xe5bro 6051 Almind #&gt; 5320 Agedrup NA NA NA NA NA #&gt; 6753 Agerb\\xe6k NA NA NA NA NA #&gt; 6534 Agerskov NA NA NA NA NA #&gt; 8961 Alling\\xe5bro NA NA NA NA NA #&gt; 6051 Almind NA NA NA NA NA We can find average distances between two zip codes (here rows 1 and 2 in dat) using Bing maps: key &lt;- &quot;AlUJdApmvPe8y2_IMrC4j4x8fzytbD2M0SvlmpemL09ae_CWS6-IuNSgrAtXoyeP&quot; url &lt;- str_c(&quot;http://dev.virtualearth.net/REST/V1/Routes/Driving?wp.0=&quot;, dat$Zip[1], &quot;,Denmark&quot;, &quot;&amp;wp.1=&quot;, dat$Zip[2], &quot;,Denmark&quot;, &quot;&amp;avoid=minimizeTolls&amp;key=&quot;, key) library(jsonlite) lst &lt;- jsonlite::fromJSON(url) dist &lt;- lst$resourceSets$resources[[1]]$travelDistance dist #&gt; [1] 138 lst$statusCode #&gt; [1] 200 lst$statusDescription #&gt; [1] &quot;OK&quot; Note we call the Bing maps API with the two zip codes. A json file is returned and stored in a list. To get the average travel distance we access travelDistance. The status code should be 200 if the calculation returned is okay. × Solution key &lt;- &quot;AlUJdApmvPe8y2_IMrC4j4x8fzytbD2M0SvlmpemL09ae_CWS6-IuNSgrAtXoyeP&quot; for(i in 1:nrow(distanceMat)) { for(j in 1:ncol(distanceMat)) { if (i&gt;j) {distanceMat[i,j] &lt;- distanceMat[j,i]; next} # assume symmetric distances if (!is.na(distanceMat[i,j])) next # value already calculated if (i==j) {distanceMat[i,j] &lt;- 0; next} url &lt;- str_c(&quot;http://dev.virtualearth.net/REST/V1/Routes/Driving?wp.0=&quot;, dat$Zip[i], &quot;,Denmark&quot;, &quot;&amp;wp.1=&quot;, dat$Zip[j], &quot;,Denmark&quot;, &quot;&amp;avoid=minimizeTolls&amp;key=&quot;, key) lst &lt;- jsonlite::fromJSON(url) if (lst$statusCode == 200) { distanceMat[i,j] &lt;- lst$resourceSets$resources[[1]]$travelDistance } } } distanceMat #&gt; 5320 Agedrup 6753 Agerb\\xe6k 6534 Agerskov 8961 Alling\\xe5bro 6051 Almind #&gt; 5320 Agedrup 0.0 137.7 142.2 215 86.2 #&gt; 6753 Agerb\\xe6k 137.7 0.0 107.0 180 61.3 #&gt; 6534 Agerskov 142.2 107.0 0.0 204 65.6 #&gt; 8961 Alling\\xe5bro 215.2 180.4 204.3 0 150.8 #&gt; 6051 Almind 86.2 61.3 65.6 151 0.0 Close Solution × Hint key &lt;- &quot;AlUJdApmvPe8y2_IMrC4j4x8fzytbD2M0SvlmpemL09ae_CWS6-IuNSgrAtXoyeP&quot; for(i in 1:nrow(distanceMat)) { for(j in 1:ncol(___)) { if (i&gt;j) {distanceMat[i,j] &lt;- ___; next} # assume symmetric distances if (!is.na(distanceMat[i,j])) next # value already calculated if (i==j) {distanceMat[i,j] &lt;- ___; next} url &lt;- str_c(&quot;http://dev.virtualearth.net/REST/V1/Routes/Driving?wp.0=&quot;, dat$Zip[i], &quot;,Denmark&quot;, &quot;&amp;wp.1=&quot;, dat$Zip[j], &quot;,Denmark&quot;, &quot;&amp;avoid=minimizeTolls&amp;key=&quot;, key) lst &lt;- jsonlite::fromJSON(url) if (lst$statusCode == ___) { distanceMat[i,j] &lt;- ___ } } } distanceMat Close Hint Use nested for loops to fill distanceMat with distances. Assume that the distance from a to b is the same as from b to a. That is, you only have to call the API once for two zip codes. Use an if statement to check if the status code is okay. 9.5.5 Exercise (expand_grid) × Solution ite &lt;- expand_grid(i = c(1,5), j = 2:3) ite #&gt; # A tibble: 4 × 2 #&gt; i j #&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 1 2 #&gt; 2 1 3 #&gt; 3 5 2 #&gt; 4 5 3 key &lt;- &quot;AlUJdApmvPe8y2_IMrC4j4x8fzytbD2M0SvlmpemL09ae_CWS6-IuNSgrAtXoyeP&quot; for (r in 1:nrow(ite)) { # iterate over rows i &lt;- ite$i[r] j &lt;- ite$j[r] if (i==j) {distanceMat[i,j] &lt;- 0; next} url &lt;- str_c(&quot;http://dev.virtualearth.net/REST/V1/Routes/Driving?wp.0=&quot;, dat$Zip[i], &quot;,Denmark&quot;, &quot;&amp;wp.1=&quot;, dat$Zip[j], &quot;,Denmark&quot;, &quot;&amp;avoid=minimizeTolls&amp;key=&quot;, key) lst &lt;- jsonlite::fromJSON(url) if (lst$statusCode == 200) { distanceMat[i,j] &lt;- lst$resourceSets$resources[[1]]$travelDistance distanceMat[j,i] &lt;- distanceMat[i,j] } } distanceMat #&gt; 5320 Agedrup 6753 Agerb\\xe6k 6534 Agerskov 8961 Alling\\xe5bro 6051 Almind #&gt; 5320 Agedrup 0.0 137.7 142.2 215 86.2 #&gt; 6753 Agerb\\xe6k 137.7 0.0 107.0 180 58.8 #&gt; 6534 Agerskov 142.2 107.0 0.0 204 62.4 #&gt; 8961 Alling\\xe5bro 215.2 180.4 204.3 0 150.8 #&gt; 6051 Almind 86.2 58.8 62.4 151 0.0 Close Solution × Hint ite &lt;- expand_grid(i = ___, j = ___) ite key &lt;- &quot;AlUJdApmvPe8y2_IMrC4j4x8fzytbD2M0SvlmpemL09ae_CWS6-IuNSgrAtXoyeP&quot; for (r in 1:nrow(ite)) { # iterate over rows i &lt;- ite$i[r] j &lt;- ite$j[r] if (i==j) {distanceMat[i,j] &lt;- 0; next} url &lt;- str_c(&quot;http://dev.virtualearth.net/REST/V1/Routes/Driving?wp.0=&quot;, dat$Zip[i], &quot;,Denmark&quot;, &quot;&amp;wp.1=&quot;, dat$Zip[j], &quot;,Denmark&quot;, &quot;&amp;avoid=minimizeTolls&amp;key=&quot;, key) lst &lt;- jsonlite::fromJSON(url) if (lst$statusCode == ___) { distanceMat[i,j] &lt;- lst$resourceSets$resources[[1]]$travelDistance distanceMat[j,i] &lt;- ___ } } distanceMat Close Hint Consider the solution of Exercise 9.5.4 and assume that you only want to calculate the distance from rows 1 and 5 to rows 2 and 3 in dat. Modify the solution using expand_grid so only one loop is used. "],["mod-r-functions.html", "Module 10 Functions 10.1 Learning outcomes 10.2 DataCamp course 10.3 Functions returning multiple objects 10.4 The ... argument 10.5 Documenting your functions 10.6 Example - Job sequencing 10.7 Recap 10.8 Exercises", " Module 10 Functions To understand computations in R, two slogans are helpful: Everything that exists is an object. Everything that happens is a function call. John Chambers Writing functions is a core activity of an R programmer. It represents the key step of the transition from a user to a programmer. Functions have inputs and outputs. Functions (and control structures) are what makes your code more dynamic. Functions are often used to encapsulate a sequence of expressions that needs to be executed numerous times, perhaps under slightly different conditions. In programming, functional programming is a programming paradigm, a style of how code is written. Rather than repeating the code, functions and control structures allow one to build code in blocks. As a result, your code becomes more structured, more readable and much easier to maintain and debug (find errors). A template project for this module is given on RStudio Cloud (open it and use it while reading the notes). Learning path diagram It is recommended that you follow the green learning path; however, you may like a different learning style. In the learning path diagram, there are links to alternative online content (video or reading). Note this is an alternative to the standard learning path that you may use instead (you should not do both). The learning path may also have extra content, that is NOT a part of syllabus (only look at it if you want more info)! 10.1 Learning outcomes By the end of this module, you are expected to be able to: Call a function. Formulate a function with different input arguments. Describe why functions are important in R. Set defaults for input arguments. Return values from functions. Explain how variable scope and precedence works. Document functions. The learning outcomes relate to the overall learning goals number 2, 3, 4 and 10 of the course. 10.2 DataCamp course An excellent introduction to functions is given in Chapter 3 in the DataCamp course Intermediate R. Please complete the chapter before continuing. 10.3 Functions returning multiple objects Functions in R only return a single object. However, note that the object may be a list. That is, if you want to return multiple arguments, store them in a list. A simple example: test &lt;- function() { # the function does some stuff and calculate some results res1 &lt;- 45 res2 &lt;- &quot;Success&quot; res3 &lt;- c(4, 7, 9) res4 &lt;- list(cost = 23, profit = 200) lst &lt;- list(days = res1, run = res2, id = res3, money = res4) return(lst) } test() #&gt; $days #&gt; [1] 45 #&gt; #&gt; $run #&gt; [1] &quot;Success&quot; #&gt; #&gt; $id #&gt; [1] 4 7 9 #&gt; #&gt; $money #&gt; $money$cost #&gt; [1] 23 #&gt; #&gt; $money$profit #&gt; [1] 200 10.4 The ... argument The special argument ... indicates a variable number of arguments and is usually used to pass arguments to nested functions used inside the function. Consider example: my_name &lt;- function(first = &quot;Lars&quot;, last = &quot;Nielsen&quot;) { str_c(first, last, sep = &quot; &quot;) } my_name() #&gt; [1] &quot;Lars Nielsen&quot; cite_text &lt;- function(text, ...) { str_c(text, &#39;, -&#39;, my_name(...)) } cite_text(&quot;Learning by doing is the best way to learn how to program!&quot;) #&gt; [1] &quot;Learning by doing is the best way to learn how to program!, -Lars Nielsen&quot; cite_text(&quot;Learning by doing is the best way to learn how to program!&quot;, last = &quot;Relund&quot;) #&gt; [1] &quot;Learning by doing is the best way to learn how to program!, -Lars Relund&quot; cite_text(&quot;To be or not to be&quot;, first = &quot;Shakespeare&quot;, last = &quot;&quot;) #&gt; [1] &quot;To be or not to be, -Shakespeare &quot; Note in the first function run, we use the defaults in my_name. In the second run, we change the default last name and in the last run, we change both arguments. If you need to retrieve/capture the content of the ... argument, put it in a list: test &lt;- function(...) { return(list(...)) } test(x = 4, y = &quot;hey&quot;, z = 1:5) #&gt; $x #&gt; [1] 4 #&gt; #&gt; $y #&gt; [1] &quot;hey&quot; #&gt; #&gt; $z #&gt; [1] 1 2 3 4 5 10.5 Documenting your functions It is always a good idea to document your functions. This is in fact always done in functions of a package. For instance try ?mutate and see the documentation in the Help tab. Assume that you have written a function subtract &lt;- function(x, y) { return(x-y) } In RStudio you can insert a Roxygen documentation skeleton by having the cursor at the first line of the function and go to Code &gt; Insert Roxygen Skeleton (Ctrl+Alt+Shift+R): #&#39; Title #&#39; #&#39; @param x #&#39; @param y #&#39; @return #&#39; @export #&#39; @examples subtract &lt;- function(x, y) { return(x-y) } You now can modify your documentation to #&#39; Subtract two vectors #&#39; #&#39; @param x First vector. #&#39; @param y Vector to be subtracted. #&#39; @return The difference. #&#39; @export #&#39; @examples #&#39; subtract(x = c(5,5), y = c(2,3)) subtract &lt;- function(x, y) { return(x-y) } Note Parameters/function arguments are documented using the @param tag. Return value is documented using the @return tag. Under the @examples tag you can insert some examples. Ignore the @export tag. This is used if you include your function in your own package. Package development is beyond the scope of this course. If you are interested, have a look at the book Wickham (2015). A list of further tags can be seen in the vignette Rd (documentation) tags. 10.6 Example - Job sequencing Recall the job sequencing problem in Section 5.8 that consider a problem of determining the best sequencing of jobs on a machine. A set of startup costs are given for 5 machines: startup_costs &lt;- c(27, 28, 32, 35, 26) startup_costs #&gt; [1] 27 28 32 35 26 Moreover, when changing from one job to another job, the setup costs are given as: setup_costs &lt;- matrix(c( NA, 35, 22, 44, 12, 49, NA, 46, 38, 17, 46, 12, NA, 29, 41, 23, 37, 31, NA, 26, 17, 23, 28, 34, NA), byrow = T, nrow = 5) setup_costs #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] NA 35 22 44 12 #&gt; [2,] 49 NA 46 38 17 #&gt; [3,] 46 12 NA 29 41 #&gt; [4,] 23 37 31 NA 26 #&gt; [5,] 17 23 28 34 NA For instance, the setup cost from Job 2 to Job 4 is 38. The goal of the problem is to determine a sequence of jobs which minimizes the total setup cost including the startup cost. One possible way to find a sequence is the use a greedy strategy: Greedy Algorithm Step 0: Start with the job which has minimal startup cost. Step 1: Select the next job as the job not already done with minimal setup cost given current job. Step 2: Set next job in Step 1 to current job and go to Step 1 if not all jobs are done. In R the greedy algorithm can be implemented as: #&#39; Calculate a job sequence based on a greedy algorithm #&#39; #&#39; @param startup Startup costs. #&#39; @param setup Setup costs. #&#39; @return A list with the job sequence and total setup costs. greedy &lt;- function(startup, setup) { jobs &lt;- nrow(setup) cur_job &lt;- which.min(startup) cost &lt;- startup[cur_job] # cat(&quot;Start job:&quot;, cur_job, &quot;\\n&quot;) job_seq &lt;- cur_job setup[, cur_job] &lt;- NA for (i in 1:(jobs-1)) { next_job &lt;- which.min(setup[cur_job, ]) # cat(&quot;Next job:&quot;, next_job, &quot;\\n&quot;) cost &lt;- cost + setup[cur_job, next_job] job_seq &lt;- c(job_seq, next_job) cur_job &lt;- next_job setup[, cur_job] &lt;- NA } # print(setup) return(list(seq = job_seq, cost = cost)) } greedy(startup_costs, setup_costs) #&gt; $seq #&gt; [1] 5 1 3 2 4 #&gt; #&gt; $cost #&gt; [1] 115 First, the job with minimum startup cost is found using function which.min and we define cost as the startup cost. We use cat to make some debugging statements and initialize job_seq with the first job. Next, we have to find a way of ignoring jobs already done. We do that here by setting the columns of setup cost equal to NA for jobs already done. Hence, they will not be selected by which.min. The for loop runs 4 times and selects jobs and accumulate the total cost. Finally, the job sequence and the total cost is returned as a list. A well-known better strategy is to: Better Algorithm Step 0: Subtract minimum of startup and setup cost for each job from setup and startup costs (that is columnwise) Step 1: Call the greedy algorithm with the modified costs. Note that the total cost returned has to be modified a bit. The better strategy implemented in R: #&#39; Calculate a job sequence based on a better (greedy) algorithm #&#39; #&#39; @param startup Startup costs. #&#39; @param setup Setup costs. #&#39; @return A list with the job sequence and total setup costs. better &lt;- function(startup, setup) { jobs &lt;- nrow(setup) min_col_val &lt;- apply(rbind(startup, setup), 2, min, na.rm = T) startup &lt;- startup - min_col_val min_mat &lt;- matrix(rep(min_col_val, jobs), ncol = jobs, byrow = T) setup &lt;- setup - min_mat lst &lt;- greedy(startup, setup) lst$cost &lt;- lst$cost + sum(min_col_val) return(lst) } better(startup_costs, setup_costs) #&gt; $seq #&gt; [1] 4 1 3 2 5 #&gt; #&gt; $cost #&gt; [1] 109 First the number of jobs are identified. Next, we need to find the minimum value in each column. Here we use the apply function. The first argument is the setup matrix with the startup costs added as a row. The second argument is 2 indicating that we should apply the third argument to each column (if was equal 1 then to each row). The third argument is the function to apply to each column (here min). The last argument is an optional argument passed to the min function. With the current values min_col_val equals 17, 12, 22, 29, and 12. Afterwards the minimum values are subtracted in each column. Note for subtracting the minimum values from the setup cost, we first need to create a matrix with the minimum values (min_mat). Finally, we call the greedy algorithm with the new costs and correct the returned result with the minimum values. 10.7 Recap Writing functions is a core activity of an R programmer. It represents the key step of the transition from a user to a programmer. Functions have inputs and outputs. Functions (and control structures) are what makes your code more dynamic. Functions are often used to encapsulate a sequence of expressions that need to be executed numerous times, perhaps under slightly different conditions. In programming, functional programming is a programming paradigm, a style of how code is written. Rather than repeating the code, functions and control structures allow one to build code in blocks. As a result, your code becomes more structured, more readable and much easier to maintain and debug (find errors). Functions can be defined using the function() directive. The named arguments (input values) can have default values. Moreover, R passes arguments by value. That is, an R function cannot change the variable that you input to that function. A function can be called using its name and its arguments can be specified by name or by position in the argument list. Functions always return the last expression evaluated in the function body or when you use the return flow control statement (good coding practice). Scoping refers to the rules R use to look up the value of variables. A function will first look inside the body of the function to identify all the variables. If all variables exist, no further search is required. Otherwise, R will look one level up to see if the variable exists. Functions can be assigned to R objects just like any other R object. Document your functions using the Roxygen skeleton! You may also have a look at the slides for this module. 10.8 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Some of the solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up too early. Put some effort into finding a solution! Always practice using shortcuts in RStudio (see Tools &gt; Keyboard Shortcuts Help). Go to the Tools for Analytics workspace and download/export the TM10 project. Open it on your laptop and have a look at the files in the exercises folder which can be used as a starting point. 10.8.1 Exercise (defining functions) Solve this exercise using a script file. × Solution #&#39; Computes the sum of the integers from 1 to n (inclusive). #&#39; #&#39; @param n Max value in the sum. #&#39; #&#39; @return Sum of the integers from 1 to n. #&#39; #&#39; @examples #&#39; sum_n(30) sum_n &lt;- function(n) { return(sum(1:n)) } sum_n(5000) #&gt; [1] 12502500 Close Solution × Hint #&#39; Computes the sum of the integers from 1 to n (inclusive). #&#39; #&#39; @param n Max value in the sum. #&#39; #&#39; @return Sum of the integers from 1 to n. #&#39; #&#39; @examples #&#39; sum_n(30) sum_n &lt;- function(n) { return(___) } sum_n(5000) Close Hint Create a function sum_n that for any given value, say \\(n\\), computes the sum of the integers from 1 to n (inclusive). Use the function to determine the sum of integers from 1 to 5000. Document your function too. × Solution #&#39; Computes the sum S_n = 1^2 + 2^2 + 3^2 + ... + n^2 #&#39; #&#39; @param n Max input in sum. #&#39; #&#39; @return S_n compute_s_n &lt;- function(n) { return(sum((1:n)^2)) } compute_s_n(10) #&gt; [1] 385 Close Solution Write a function compute_s_n that for any given \\(n\\) computes the sum \\(S_n = 1^2 + 2^2 + 3^2 + \\dots + n^2\\). Report the value of the sum when \\(n=10\\). × Solution 1 s_n &lt;- vector(&#39;numeric&#39;, 25) for (n in 1:25) { s_n[n] &lt;- compute_s_n(n) } s_n #&gt; [1] 1 5 14 30 55 91 140 204 285 385 506 650 819 1015 1240 1496 1785 2109 2470 #&gt; [20] 2870 3311 3795 4324 4900 5525 Close Solution 1 × Hint 1 s_n &lt;- vector(&#39;numeric&#39;, 25) for (n in 1:25) { s_n[n] &lt;- ___ } s_n Close Hint 1 × Solution 2 compute_s_n_alt &lt;- function(n) { return(n*(n+1)*(2*n+1)/6) } for (n in 1:25) { if (s_n[n] != compute_s_n_alt(n)) { cat(&#39;Error!&#39;) break } } Close Solution 2 × Hint 2 compute_s_n_alt &lt;- function(n) { return(n*(n+1)*___) } for (n in 1:25) { if (s_n[n] != ___) { cat(&#39;Error!&#39;) break } } Close Hint 2 Define an empty numerical vector s_n of size 25 using s_n &lt;- vector(\"numeric\", 25) and store in the results of \\(S_1, S_2, \\dots S_{25}\\) using a for-loop. Confirm that the formula for the sum is \\(S_n= n(n+1)(2n+1)/6\\) for \\(n = 1, \\ldots, 25\\). × Solution biggest &lt;- function(a, b) { if (a &gt; b) return(1) return(0) } biggest(3,4) #&gt; [1] 0 biggest(3,3) #&gt; [1] 0 biggest(8,2) #&gt; [1] 1 Close Solution × Hint biggest &lt;- function(a, b) { if (a &gt; b) ___ return(0) } Close Hint Write a function biggest which takes two integers as arguments. Let the function return 1 if the first argument is larger than the second and return 0 otherwise. × Solution shipping_cost &lt;- function(total) { return(0.1 * total) } shipping_cost(450) #&gt; [1] 45 Close Solution × Hint shipping_cost &lt;- function(total) { return(___) } Close Hint Write a function that returns the shipping cost as 10% of the total cost of an order (input argument). × Solution shipping_cost &lt;- function(total, pct = 0.1) { return(pct * total) } shipping_cost(450) #&gt; [1] 45 shipping_cost(450, pct = 0.2) #&gt; [1] 90 Close Solution × Hint shipping_cost &lt;- function(total, pct = ___) { ___ } Close Hint Given Question 5, rewrite the function so the percentage is an input argument with a default of 10%. × Solution shipping_cost &lt;- function(total) { return(0.1 * total) } gasoline_cost &lt;- function(total) { return(shipping_cost(total) * 0.5) } gasoline_cost(450) #&gt; [1] 22.5 Close Solution × Hint gasoline_cost &lt;- function(total) { return(shipping_cost(___) * ___) } Close Hint Given Question 5, the shipping cost can be split into parts. One part is gasoline which is 50% of the shipping cost. Write a function that has total cost as input argument and calculate the gasoline cost and use the function defined in Question 5 inside it. × Solution shipping_cost &lt;- function(total, pct = 0.1) { return(pct * total) } gasoline_cost &lt;- function(total, ...) { return(shipping_cost(total, ...) * 0.5) } gasoline_cost(450) #&gt; [1] 22.5 gasoline_cost(450, pct = 0.2) #&gt; [1] 45 Close Solution × Hint gasoline_cost &lt;- function(total, ...) { return(shipping_cost(___) * ___) } Close Hint Given Question 6, the shipping cost can be split into parts. One part is gasoline which is 50% of the shipping cost. Write a function that has total cost a input argument and calculate the gasoline cost and use the function defined in Question 6 inside it. Hint: Use the ... argument to pass arguments to shipping_cost. × Solution shipping_cost &lt;- function(total, pct = 0.1) { return(pct * total) } gasoline_cost &lt;- function(total, ...) { return(shipping_cost(total, ...) * 0.5) } costs &lt;- function(total, ...) { lst &lt;- list(total = total, shipping = shipping_cost(total, ...), gasoline = gasoline_cost(total, ...)) return(lst) } costs(450) #&gt; $total #&gt; [1] 450 #&gt; #&gt; $shipping #&gt; [1] 45 #&gt; #&gt; $gasoline #&gt; [1] 22.5 costs(450, pct = 0.15) #&gt; $total #&gt; [1] 450 #&gt; #&gt; $shipping #&gt; [1] 67.5 #&gt; #&gt; $gasoline #&gt; [1] 33.8 Close Solution × Hint shipping_cost &lt;- function(total, pct = 0.1) { return(pct * total) } gasoline_cost &lt;- function(total, ...) { return(shipping_cost(total, ...) * 0.5) } costs &lt;- function(total, ...) { lst &lt;- list(total = ___, shipping = ___, gasoline = ___) return(lst) } Close Hint Given Question 8, write a function costs that, given total cost, returns the total cost, shipping cost and gasoline cost. 10.8.2 Exercise (euclidean distances) This exercise is a slightly modified version an exam assignment (exam 2021-A1). The euclidean distance between two points \\(p = (p_1,p_2)\\) and \\(q = (q_1,q_2)\\) can be calculated using formula \\[ d(p,q) = \\sqrt{(p_1-q_1)^2 + (p_2-q_2)^2}.\\] × Solution p &lt;- c(10,10) q &lt;- c(4,3) sqrt((p[1] - q[1])^2 + (p[2] - q[2])^2) #&gt; [1] 9.22 The distance is 9.22. Close Solution Calculate the distance between points \\(p = (10,10)\\) and \\(q = (4,3)\\) using the formula. × Solution d_mat = matrix(NA, nrow = nrow(p_mat), ncol = nrow(p_mat)) for (i in 1:nrow(d_mat)) { for (j in 1:ncol(d_mat)) { # if (i&gt;j) {d_mat[i,j] &lt;- d_mat[j,i]; next} # assume symmetric distances # if (!is.na(d_mat[i,j])) next # value already calculated if (i==j) {d_mat[i,j] &lt;- 0; next} d_mat[i,j] &lt;- sqrt((p_mat[i,1] - p_mat[j,1])^2 + (p_mat[i,2] - p_mat[j,2])^2) } } d_mat #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 0.00 9.22 8.25 2.83 #&gt; [2,] 9.22 0.00 8.06 6.40 #&gt; [3,] 8.25 8.06 0.00 7.21 #&gt; [4,] 2.83 6.40 7.21 0.00 The distance matrix is given above. Close Solution Consider 4 points in a matrix (one in each row): p_mat &lt;- matrix(c(0, 7, 8, 2, 10, 16, 8, 12), nrow = 4) p_mat #&gt; [,1] [,2] #&gt; [1,] 0 10 #&gt; [2,] 7 16 #&gt; [3,] 8 8 #&gt; [4,] 2 12 The distance matrix of p_mat is a 4 times 4 matrix where entry (i,j) contains the distance from the point in row i to the point in row j. Calculate the distance matrix of p_mat. × Solution calc_distances &lt;- function(p_mat, from = 1:nrow(p_mat), to = 1:nrow(p_mat)) { d_mat &lt;- matrix(NA, nrow = nrow(p_mat), ncol = nrow(p_mat)) ite &lt;- expand_grid(from = from, to = to) for (r in 1:nrow(ite)) { i &lt;- ite$from[r] j &lt;- ite$to[r] if (!is.na(d_mat[i,j])) next # value already calculated if (i==j) {d_mat[i,j] &lt;- 0; next} d_mat[i,j] &lt;- sqrt((p_mat[i,1] - p_mat[j,1])^2 + (p_mat[i,2] - p_mat[j,2])^2) } return(d_mat) } p_mat &lt;- matrix(c(10, 9, 15, 15, 11, 19, 12, 11, 7, 15), nrow = 5) calc_distances(p_mat) #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] 0.00 7.07 9.43 13.00 4.12 #&gt; [2,] 7.07 0.00 6.08 7.81 3.61 #&gt; [3,] 9.43 6.08 0.00 4.00 5.66 #&gt; [4,] 13.00 7.81 4.00 0.00 8.94 #&gt; [5,] 4.12 3.61 5.66 8.94 0.00 calc_distances(p_mat, to = 3:4) #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] NA NA 9.43 13.00 NA #&gt; [2,] NA NA 6.08 7.81 NA #&gt; [3,] NA NA 0.00 4.00 NA #&gt; [4,] NA NA 4.00 0.00 NA #&gt; [5,] NA NA 5.66 8.94 NA calc_distances(p_mat, from = c(1, nrow(p_mat)), to = 3:4) #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] NA NA 9.43 13.00 NA #&gt; [2,] NA NA NA NA NA #&gt; [3,] NA NA NA NA NA #&gt; [4,] NA NA NA NA NA #&gt; [5,] NA NA 5.66 8.94 NA The function with test are given above. Close Solution × Hint calc_distances &lt;- function(p_mat, from = 1:nrow(p_mat), to = 1:nrow(p_mat)) { d_mat &lt;- matrix(NA, nrow = ___, ncol = ___) ite &lt;- expand_grid(___) for (r in 1:nrow(ite)) { i &lt;- ___ j &lt;- ___ if (!is.na(d_mat[i,j])) next # value already calculated if (i==j) {d_mat[i,j] &lt;- 0; next} d_mat[i,j] &lt;- ___ } return(d_mat) } Close Hint Create a function calc_distances with the following features (implement as many as you can): Takes a matrix p_mat with a point in each row as input argument. Takes two additional input arguments from and to with default values 1:nrow(p_mat) Return the distance matrix with values calculated for rows in the from input argument and columns in the to input argument. The other entries equals NA. The function should work for different p_mat (you may assume that the matrix always have two columns). You may test your code using: p_mat &lt;- matrix(c(10, 9, 15, 15, 11, 19, 12, 11, 7, 15), nrow = 5) calc_distances(p_mat) calc_distances(p_mat, to = 3:4) calc_distances(p_mat, from = c(1, nrow(p_mat)), to = 3:4) 10.8.3 Exercise (scope) × Solution That value is still 3 since x defined inside the function is a local variable. Close Solution After running the code below, what is the value of variable x? x &lt;- 3 my_func &lt;- function(y){ x &lt;- 5 return(y + 5) } my_func(7) × Solution The code runs. But it is not good coding practice to call global variables inside a function (x). Instead x should have been an argument to the function. Close Solution Is there any problems with the following code? x &lt;- 3 my_func &lt;- function(y){ return(y + x) } my_func(7) × Solution That value is still 3 since my_func has not been called yet. Close Solution Have a look at the documentation for operator &lt;&lt;- (run ?'&lt;&lt;-'). After running the code below, what is the value of variable x? x &lt;- 3 my_func &lt;- function(y){ x &lt;- 4 x &lt;&lt;- 5 return(y + 5) } × Solution That value of x is 5 since &lt;&lt;- is used to look at the parent environment. The function call returns 11 since the x used is the local variable. In general avoid using &lt;&lt;- and give local variables different names compared to global ones. Close Solution After running the code below, what is the value of variable x and output of the function call? x &lt;- 3 my_func &lt;- function(y){ x &lt;- 4 x &lt;&lt;- 5 return(y + x) } my_func(7) References "],["mod-r-tidyverse-intro.html", "Module 11 Introduction to tidyverse and RMarkdown 11.1 Learning outcomes 11.2 The tidyverse package 11.3 Writing reproducible reports 11.4 Tibbles 11.5 Recap 11.6 Exercises", " Module 11 Introduction to tidyverse and RMarkdown The tidyverse is a collection of R packages designed for data science. RMarkdown documents support the concept of literate programming where you weave R code together with text (written in Markdown) to produce elegantly formatted documents. A template project for this module is given on RStudio Cloud (open it and use it while reading the notes). Learning path diagram It is recommended that you follow the green learning path; however, you may like a different learning style. In the learning path diagram, there are links to alternative online content (video or reading). Note this is an alternative to the standard learning path that you may use instead (you should not do both). The learning path may also have extra content, that is NOT a part of syllabus (only look at it if you want more info)! 11.1 Learning outcomes By the end of this module, you are expected to be able to: Describe what the tidyverse package is. Explain the ideas behind reproducible reports and literal programming. Create your first RMarkdown document and add some code and text. The learning outcomes relate to the overall learning goals number 7, 17 and 18 of the course. 11.2 The tidyverse package The tidyverse is a collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. The core tidyverse includes the packages that you are likely to use in everyday data analyses. In tidyverse 1.3.0, the following packages are included in the core tidyverse: dplyr provides a grammar of data manipulation, providing a consistent set of verbs that solve the most common data manipulation challenges. We are going to use dplyr in Module 13. ggplot2 is a system for declaratively creating graphics, based on The Grammar of Graphics. You provide the data, tell ggplot2 how to map variables to aesthetics, what graphical primitives to use, and it takes care of the details. We are going to use ggplot in Module 14. tidyr provides a set of functions that help you get to tidy data. Tidy data is data with a consistent form: in brief, every variable goes in a column, and every column is a variable. readr provides a fast and friendly way to read rectangular data (like csv, tsv, and fwf). It is designed to flexibly parse many types of data found in the wild, while still cleanly failing when data unexpectedly changes. We are going to use dplyr in Module 12. purrr enhances R’s functional programming (FP) toolkit by providing a complete and consistent set of tools for working with functions and vectors. Once you master the basic concepts, purrr allows you to replace many for loops with code that is easier to write and more expressive. This package is not covered in this course. tibble is a modern re-imagining of the data frame, keeping what time has proven to be effective, and throwing out what has not. Tibbles are data frames that are lazy and surly: they do less and complain more forcing you to confront problems earlier, typically leading to cleaner, more expressive code. We are going to use tibbles in Module 13. stringr provides a cohesive set of functions designed to make working with strings as easy as possible. You have already worked a bit with stringr in Exercise 8.7.8 forcats provides a suite of useful tools that solve common problems with factors. R uses factors to handle categorical variables, variables that have a fixed and known set of possible values. This package is not covered in this course. Small introductions (with examples) to the packages are given on their documentation pages (follow the links above). The tidyverse also includes many other packages with more specialized usage. They are not loaded automatically with library(tidyverse), so you will need to load each one with its own call to library(). 11.3 Writing reproducible reports The concept of literate programming was originally introduced by Donald Knuth in 1984. In a nutshell, Knuth envisioned a new programming paradigm where computer scientists focus on weaving code together with text as documentation. That is, when we do an Analytics project, we are interested in writing reports containing both R code for importing data, wrangling and analysis. Moreover, at the same time, the document should contain our comments about the code, plots, analysis, results, etc. The document is then rendered to an output format such as html, pdf or Word which is presented to the decision maker. Note the document can be seen as the “the source code” for the report communicated to the decision maker. Some developers have created tools to enable others to write better literate programs. They use a markup language made for authoring. We are going to focus on RMarkdown. In RMarkdown documents you can weave R code together with text (written in Markdown) to produce elegantly formatted output. In fact this book is written in RMarkdown by using a set of RMarkdown documents bound together as a collection using the bookdown package, rendered to a web page using RStudio, shared on GitHub, built by GitHub Actions, and published on GitHub Pages. This may seem complicated at first. However, after setup, it makes life much easier, since we can update the book easier, share and collaborate on the book easier, update the web page automatically, keep history of the book source, keep the book source at a single location. RMarkdown documents are reproducible. Anybody who works with data has at some point heard a colleague say ‘Well, it works on my computer’, expressing dismay at the fact that you cannot reproduce their results. Ultimately, reproducible means that the results can be reproduced given access to the original data, software, and code. In practice it may be hard to make your project totally reproducible. For instance, people may be using a different operating system, other versions of the software, etc. That is, there are different levels of reproducibility. In this course, we will focus on RMarkdown only. See Module 11 for more info about levels of reproducibility. An introduction to RMarkdown is given in Chapters 3 and 4 of the DataCamp course Communicating with Data in the Tidyverse. Note that you may skip Chapters 1 and 2 and still understand most of the questions in Chapters 3 and 4 (otherwise just see the solution). You are expected to have completed the chapters before continuing this module! The RMarkdown cheatsheet may be useful. Find the newest version in RStudio Help &gt; Cheatsheets. All chunk options for R code can be seen here. 11.4 Tibbles Tibbles are a modern data frame, keeping what time has proven to be effective, and throwing out what is not. Tibbles are more strict compared to data frames e.g. they do not change variable names or types, do not do partial matching and complain more e.g. when a variable does not exist. This forces you to confront problems earlier, typically leading to cleaner, more expressive code. Moreover, tibbles have an enhanced print method and can have columns that are lists. Let us see a few examples: tbl1 &lt;- tibble(name = c(&quot;Lars&quot;, &quot;Susan&quot;, &quot;Hans&quot;), age = c(23, 56, 45)) tbl1 #&gt; # A tibble: 3 × 2 #&gt; name age #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Lars 23 #&gt; 2 Susan 56 #&gt; 3 Hans 45 tbl2 &lt;- tibble(x = 1:3, y = list(1:5, 1:10, 1:20)) tbl2 #&gt; # A tibble: 3 × 2 #&gt; x y #&gt; &lt;int&gt; &lt;list&gt; #&gt; 1 1 &lt;int [5]&gt; #&gt; 2 2 &lt;int [10]&gt; #&gt; 3 3 &lt;int [20]&gt; tbl3 &lt;- as_tibble(mtcars) tbl3 #&gt; # A tibble: 32 × 11 #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 #&gt; 2 21 6 160 110 3.9 2.88 17.0 0 1 4 4 #&gt; 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 #&gt; 4 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 #&gt; 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 #&gt; 6 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 #&gt; 7 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 #&gt; 8 24.4 4 147. 62 3.69 3.19 20 1 0 4 2 #&gt; 9 22.8 4 141. 95 3.92 3.15 22.9 1 0 4 2 #&gt; 10 19.2 6 168. 123 3.92 3.44 18.3 1 0 4 4 #&gt; # … with 22 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows tbl4 &lt;- tribble( ~x, ~y, ~z, #--|--|---- &quot;a&quot;, 2, 3.6, &quot;b&quot;, 1, 8.5 ) tbl4 #&gt; # A tibble: 2 × 3 #&gt; x y z #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 a 2 3.6 #&gt; 2 b 1 8.5 Note that we can always coerce a data frame to a tibble (tbl3) or create it directly using tibble. Another way to create a tibble is with tribble. Here column headings are defined by formulas (i.e. they start with ~), and entries are separated by commas. This makes it possible to lay out small amounts of data in easy to read form. Tibbles have a refined print method that shows only the first 10 rows along with the number of columns that will fit on your screen. This makes it much easier to work with large data. In addition to its name, each column reports its type. Hence, your console is not overwhelmed with data. To see a full view of the data, you can use RStudio’s built-in data viewer: View(tbl3) 11.5 Recap tidyverse is a collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. RMarkdown is an example of literate programming. The core tidyverse includes the packages that you are likely to use in everyday data analyses. The concept of literate programming is a programming paradigm which focuses on weaving code together with text as documentation. That is, we are interested in writing reports containing both text and R code for importing data, wrangling and analysis. Reproducibility means that the results can be reproduced given access to the original data, software, and code. In practice it may be hard to make your project totally reproducible. That is, there are different levels of reproducibility. RMarkdown documents are an attempt to make reproducible documents and combine R code and markdown text. All chunk options for R code in RMarkdown documents can be seen here. The RMarkdown cheatsheet may be useful. Find the newest version in RStudio Help &gt; Cheatsheets. For Markdown syntax see Help &gt; Markdown Quick Reference. Tibbles are a modern data frame, keeping what time has proven to be effective, and throwing out what is not. Tibbles are more strict compared to data frames e.g. they do not change variable names or types, do not do partial matching and complain more e.g. when a variable does not exist. Tibbles have an enhanced print method and can have columns that are lists. You may also have a look at the slides for this module. 11.6 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Some of the solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up too early. Put some effort into finding a solution! Always practice using shortcuts in RStudio (see Tools &gt; Keyboard Shortcuts Help). Go to the Tools for Analytics workspace and download/export the TM11 project. Open it on your laptop and have a look at the files in the exercises folder which can be used as a starting point. 11.6.1 Exercise (your first RMarkdown exercise) Load the tfa package: # remotes::install_github(&quot;bss-osca/tfa-package&quot;, upgrade = FALSE) # run to upgrade library(tfa) The package contains templates for exercises etc. Go to File &gt; New File &gt; R Markdown…. In the pop-up box select From template in the left column and then TFA Exercise. Press Ok and a new RMarkdown document will be opened. Change the meta text (e.g. the title and add your name) in the yaml. Render/compile the document by pressing the Knit button (or Ctrl+Shift+K). × Solution All the code is now hidden. But not the output. Close Solution Change echo = TRUE to echo = FALSE in the first chunk setup and render the document. What has happened? You can easily go to a chunk using the navigation in the bottom left of the source window. Try to change fig.asp = 0.25 to e.g. 0.5 in Chunk 10. What happens? Create a new section ## Question 4 and add text in italic: What is the sum of all setup costs? × Solution total &lt;- sum(setup_costs) Close Solution Add a code chunk solving Question 5 above. × Solution The sum of all setup costs are ̀r total ̀. Close Solution Add a line of text with the result. 11.6.2 Exercise (tibbles) Solve this exercise using an R script file. × Solution airquality %&gt;% as_tibble() #&gt; # A tibble: 153 × 6 #&gt; Ozone Solar.R Wind Temp Month Day #&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 41 190 7.4 67 5 1 #&gt; 2 36 118 8 72 5 2 #&gt; 3 12 149 12.6 74 5 3 #&gt; 4 18 313 11.5 62 5 4 #&gt; 5 NA NA 14.3 56 5 5 #&gt; 6 28 NA 14.9 66 5 6 #&gt; 7 23 299 8.6 65 5 7 #&gt; 8 19 99 13.8 59 5 8 #&gt; 9 8 19 20.1 61 5 9 #&gt; 10 NA 194 8.6 69 5 10 #&gt; # … with 143 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Close Solution Convert the dataset airquality to a tibble. × Solution airquality %&gt;% as_tibble() #&gt; # A tibble: 153 × 6 #&gt; Ozone Solar.R Wind Temp Month Day #&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 41 190 7.4 67 5 1 #&gt; 2 36 118 8 72 5 2 #&gt; 3 12 149 12.6 74 5 3 #&gt; 4 18 313 11.5 62 5 4 #&gt; 5 NA NA 14.3 56 5 5 #&gt; 6 28 NA 14.9 66 5 6 #&gt; 7 23 299 8.6 65 5 7 #&gt; 8 19 99 13.8 59 5 8 #&gt; 9 8 19 20.1 61 5 9 #&gt; 10 NA 194 8.6 69 5 10 #&gt; # … with 143 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows airquality #&gt; Ozone Solar.R Wind Temp Month Day #&gt; 1 41 190 7.4 67 5 1 #&gt; 2 36 118 8.0 72 5 2 #&gt; 3 12 149 12.6 74 5 3 #&gt; 4 18 313 11.5 62 5 4 #&gt; 5 NA NA 14.3 56 5 5 #&gt; 6 28 NA 14.9 66 5 6 #&gt; 7 23 299 8.6 65 5 7 #&gt; 8 19 99 13.8 59 5 8 #&gt; 9 8 19 20.1 61 5 9 #&gt; 10 NA 194 8.6 69 5 10 #&gt; 11 7 NA 6.9 74 5 11 #&gt; 12 16 256 9.7 69 5 12 #&gt; 13 11 290 9.2 66 5 13 #&gt; 14 14 274 10.9 68 5 14 #&gt; 15 18 65 13.2 58 5 15 #&gt; 16 14 334 11.5 64 5 16 #&gt; 17 34 307 12.0 66 5 17 #&gt; 18 6 78 18.4 57 5 18 #&gt; 19 30 322 11.5 68 5 19 #&gt; 20 11 44 9.7 62 5 20 #&gt; 21 1 8 9.7 59 5 21 #&gt; 22 11 320 16.6 73 5 22 #&gt; 23 4 25 9.7 61 5 23 #&gt; 24 32 92 12.0 61 5 24 #&gt; 25 NA 66 16.6 57 5 25 #&gt; 26 NA 266 14.9 58 5 26 #&gt; 27 NA NA 8.0 57 5 27 #&gt; 28 23 13 12.0 67 5 28 #&gt; 29 45 252 14.9 81 5 29 #&gt; 30 115 223 5.7 79 5 30 #&gt; 31 37 279 7.4 76 5 31 #&gt; 32 NA 286 8.6 78 6 1 #&gt; 33 NA 287 9.7 74 6 2 #&gt; 34 NA 242 16.1 67 6 3 #&gt; 35 NA 186 9.2 84 6 4 #&gt; 36 NA 220 8.6 85 6 5 #&gt; 37 NA 264 14.3 79 6 6 #&gt; 38 29 127 9.7 82 6 7 #&gt; 39 NA 273 6.9 87 6 8 #&gt; 40 71 291 13.8 90 6 9 #&gt; 41 39 323 11.5 87 6 10 #&gt; 42 NA 259 10.9 93 6 11 #&gt; 43 NA 250 9.2 92 6 12 #&gt; 44 23 148 8.0 82 6 13 #&gt; 45 NA 332 13.8 80 6 14 #&gt; 46 NA 322 11.5 79 6 15 #&gt; 47 21 191 14.9 77 6 16 #&gt; 48 37 284 20.7 72 6 17 #&gt; 49 20 37 9.2 65 6 18 #&gt; 50 12 120 11.5 73 6 19 #&gt; 51 13 137 10.3 76 6 20 #&gt; 52 NA 150 6.3 77 6 21 #&gt; 53 NA 59 1.7 76 6 22 #&gt; 54 NA 91 4.6 76 6 23 #&gt; 55 NA 250 6.3 76 6 24 #&gt; 56 NA 135 8.0 75 6 25 #&gt; 57 NA 127 8.0 78 6 26 #&gt; 58 NA 47 10.3 73 6 27 #&gt; 59 NA 98 11.5 80 6 28 #&gt; 60 NA 31 14.9 77 6 29 #&gt; 61 NA 138 8.0 83 6 30 #&gt; 62 135 269 4.1 84 7 1 #&gt; 63 49 248 9.2 85 7 2 #&gt; 64 32 236 9.2 81 7 3 #&gt; 65 NA 101 10.9 84 7 4 #&gt; 66 64 175 4.6 83 7 5 #&gt; 67 40 314 10.9 83 7 6 #&gt; 68 77 276 5.1 88 7 7 #&gt; 69 97 267 6.3 92 7 8 #&gt; 70 97 272 5.7 92 7 9 #&gt; 71 85 175 7.4 89 7 10 #&gt; 72 NA 139 8.6 82 7 11 #&gt; 73 10 264 14.3 73 7 12 #&gt; 74 27 175 14.9 81 7 13 #&gt; 75 NA 291 14.9 91 7 14 #&gt; 76 7 48 14.3 80 7 15 #&gt; 77 48 260 6.9 81 7 16 #&gt; 78 35 274 10.3 82 7 17 #&gt; 79 61 285 6.3 84 7 18 #&gt; 80 79 187 5.1 87 7 19 #&gt; 81 63 220 11.5 85 7 20 #&gt; 82 16 7 6.9 74 7 21 #&gt; 83 NA 258 9.7 81 7 22 #&gt; 84 NA 295 11.5 82 7 23 #&gt; 85 80 294 8.6 86 7 24 #&gt; 86 108 223 8.0 85 7 25 #&gt; 87 20 81 8.6 82 7 26 #&gt; 88 52 82 12.0 86 7 27 #&gt; 89 82 213 7.4 88 7 28 #&gt; 90 50 275 7.4 86 7 29 #&gt; 91 64 253 7.4 83 7 30 #&gt; 92 59 254 9.2 81 7 31 #&gt; 93 39 83 6.9 81 8 1 #&gt; 94 9 24 13.8 81 8 2 #&gt; 95 16 77 7.4 82 8 3 #&gt; 96 78 NA 6.9 86 8 4 #&gt; 97 35 NA 7.4 85 8 5 #&gt; 98 66 NA 4.6 87 8 6 #&gt; 99 122 255 4.0 89 8 7 #&gt; 100 89 229 10.3 90 8 8 #&gt; 101 110 207 8.0 90 8 9 #&gt; 102 NA 222 8.6 92 8 10 #&gt; 103 NA 137 11.5 86 8 11 #&gt; 104 44 192 11.5 86 8 12 #&gt; 105 28 273 11.5 82 8 13 #&gt; 106 65 157 9.7 80 8 14 #&gt; 107 NA 64 11.5 79 8 15 #&gt; 108 22 71 10.3 77 8 16 #&gt; 109 59 51 6.3 79 8 17 #&gt; 110 23 115 7.4 76 8 18 #&gt; 111 31 244 10.9 78 8 19 #&gt; 112 44 190 10.3 78 8 20 #&gt; 113 21 259 15.5 77 8 21 #&gt; 114 9 36 14.3 72 8 22 #&gt; 115 NA 255 12.6 75 8 23 #&gt; 116 45 212 9.7 79 8 24 #&gt; 117 168 238 3.4 81 8 25 #&gt; 118 73 215 8.0 86 8 26 #&gt; 119 NA 153 5.7 88 8 27 #&gt; 120 76 203 9.7 97 8 28 #&gt; 121 118 225 2.3 94 8 29 #&gt; 122 84 237 6.3 96 8 30 #&gt; 123 85 188 6.3 94 8 31 #&gt; 124 96 167 6.9 91 9 1 #&gt; 125 78 197 5.1 92 9 2 #&gt; 126 73 183 2.8 93 9 3 #&gt; 127 91 189 4.6 93 9 4 #&gt; 128 47 95 7.4 87 9 5 #&gt; 129 32 92 15.5 84 9 6 #&gt; 130 20 252 10.9 80 9 7 #&gt; 131 23 220 10.3 78 9 8 #&gt; 132 21 230 10.9 75 9 9 #&gt; 133 24 259 9.7 73 9 10 #&gt; 134 44 236 14.9 81 9 11 #&gt; 135 21 259 15.5 76 9 12 #&gt; 136 28 238 6.3 77 9 13 #&gt; 137 9 24 10.9 71 9 14 #&gt; 138 13 112 11.5 71 9 15 #&gt; 139 46 237 6.9 78 9 16 #&gt; 140 18 224 13.8 67 9 17 #&gt; 141 13 27 10.3 76 9 18 #&gt; 142 24 238 10.3 68 9 19 #&gt; 143 16 201 8.0 82 9 20 #&gt; 144 13 238 12.6 64 9 21 #&gt; 145 23 14 9.2 71 9 22 #&gt; 146 36 139 10.3 81 9 23 #&gt; 147 7 49 10.3 69 9 24 #&gt; 148 14 20 16.6 63 9 25 #&gt; 149 30 193 6.9 70 9 26 #&gt; 150 NA 145 13.2 77 9 27 #&gt; 151 14 191 14.3 75 9 28 #&gt; 152 18 131 8.0 76 9 29 #&gt; 153 20 223 11.5 68 9 30 Close Solution Print the tibble and the original data frame and compare the difference. × Solution # here misc is a list with lists dat &lt;- tibble(name = c(&quot;Hans&quot;, &quot;Ole&quot;), age = c(23, 45), misc = list( list(status = 1, comment = &quot;To young&quot;), list(comment = &quot;Potential candidate&quot;))) dat #&gt; # A tibble: 2 × 3 #&gt; name age misc #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;list&gt; #&gt; 1 Hans 23 &lt;named list [2]&gt; #&gt; 2 Ole 45 &lt;named list [1]&gt; dat$misc[[1]] #&gt; $status #&gt; [1] 1 #&gt; #&gt; $comment #&gt; [1] &quot;To young&quot; Close Solution Create a tibble with 3 columns of data type string/character, double and list. "],["mod-r-io.html", "Module 12 Importing and exporting data 12.1 Learning outcomes 12.2 CSV files 12.3 Excel 12.4 Google Sheets 12.5 Text files 12.6 R’s native binary format 12.7 Json 12.8 Recap 12.9 Exercises", " Module 12 Importing and exporting data For doing data driven analytics, you first must import some data. That is, take data from a database, file, web API etc. and transform it into a data frame/table. Moreover, after processing data, you often want to export or store some of the results. This module introduces you to different ways of importing and exporting data. A template project for this module is given on RStudio Cloud (open it and use it while reading the notes). Learning path diagram It is recommended that you follow the green learning path; however, you may like a different learning style. In the learning path diagram, there are links to alternative online content (video or reading). Note this is an alternative to the standard learning path that you may use instead (you should not do both). The learning path may also have extra content, that is NOT a part of syllabus (only look at it if you want more info)! 12.1 Learning outcomes By the end of this module, you are expected to be able to: Import and export csv files in different formats. Import and export data from Excel. Import and export data from Google Sheets. Write to a text file. Save data using R’s native format. Read and write to a json file. The learning outcomes relate to the overall learning goals number 7 and 13 of the course. 12.2 CSV files CSV files contain comma separated values (csv) in plain text and are often named using the file suffix .csv. Each line of the file is a data record. Each record consists of one or more fields, separated by a common delimiter (e.g. ,, ; or _). The CSV file format is not fully standardized. Different delimiters may be used, fields may be surrounded by quotation marks, text may contain escape characters and the encoding of the file may not be known. Despite these problems, CSV files are commonly used since they are easy to exchange and read. We will use the readr package for reading and writing. An overview over the functions can be seen in the cheatsheet. 12.2.1 Reading a CSV file In general use the following functions read_csv: Read a file with delimiter ,. read_csv2: Read a file with delimiter ;. read_delim: Read a file with a delimiter set by you. 12.2.1.1 Reading an unknown CSV file For importing a CSV file properly, you need to know the delimiter, if the files has headers and the encoding. If you are not sure, you may have a look on the file by opening it in a text editor or try to read some lines: csv_file &lt;- readr_example(&quot;mtcars.csv&quot;) # csv file lines &lt;- read_lines(csv_file, n_max = 3) lines #&gt; [1] &quot;\\&quot;mpg\\&quot;,\\&quot;cyl\\&quot;,\\&quot;disp\\&quot;,\\&quot;hp\\&quot;,\\&quot;drat\\&quot;,\\&quot;wt\\&quot;,\\&quot;qsec\\&quot;,\\&quot;vs\\&quot;,\\&quot;am\\&quot;,\\&quot;gear\\&quot;,\\&quot;carb\\&quot;&quot; #&gt; [2] &quot;21,6,160,110,3.9,2.62,16.46,0,1,4,4&quot; #&gt; [3] &quot;21,6,160,110,3.9,2.875,17.02,0,1,4,4&quot; cat(lines, sep = &quot;\\n&quot;) #&gt; &quot;mpg&quot;,&quot;cyl&quot;,&quot;disp&quot;,&quot;hp&quot;,&quot;drat&quot;,&quot;wt&quot;,&quot;qsec&quot;,&quot;vs&quot;,&quot;am&quot;,&quot;gear&quot;,&quot;carb&quot; #&gt; 21,6,160,110,3.9,2.62,16.46,0,1,4,4 #&gt; 21,6,160,110,3.9,2.875,17.02,0,1,4,4 It seems that the delimiter is a , and we may try to read the file using read_csv: dat &lt;- read_csv(csv_file) head(dat) #&gt; # A tibble: 6 × 11 #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 #&gt; 2 21 6 160 110 3.9 2.88 17.0 0 1 4 4 #&gt; 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 #&gt; 4 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 #&gt; 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 #&gt; 6 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 CSV files should always be saved using encoding UTF-8. However, sometimes you may have encoding problems when you read a file: csv_file &lt;- system.file(&quot;extdata/persons.csv&quot;, package = &quot;tfa&quot;) read_csv(csv_file) #&gt; # A tibble: 3 × 2 #&gt; first last #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 &quot;Hans&quot; &quot;S\\xf8gaard&quot; #&gt; 2 &quot;\\xc5ge&quot; &quot;\\xd8kse&quot; #&gt; 3 &quot;Yvette&quot; &quot;L\\xe6ske&quot; Note that some of the characters are not converted correctly. This is usually because the file encoding is not UTF-8. In this case, try to guess the encoding using: guess_encoding(csv_file) #&gt; # A tibble: 1 × 2 #&gt; encoding confidence #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 ISO-8859-1 0.27 dat &lt;- read_csv(csv_file, locale = locale(encoding = &quot;ISO-8859-1&quot;)) dat #&gt; # A tibble: 3 × 2 #&gt; first last #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Hans Søgaard #&gt; 2 Åge Økse #&gt; 3 Yvette Læske 12.2.2 Writing to CSV files Given a tibble/data frame export it using write_csv: csv_file &lt;- &quot;testing.csv&quot; write_csv(dat, file = csv_file) write_csv2(dat, file = &quot;testing_semicolon.csv&quot;) # use a semicolon as delimitor You can now always import the data again using read_csv: read_csv(csv_file) #&gt; # A tibble: 3 × 2 #&gt; first last #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Hans Søgaard #&gt; 2 Åge Økse #&gt; 3 Yvette Læske guess_encoding(csv_file) #&gt; # A tibble: 3 × 2 #&gt; encoding confidence #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 UTF-8 1 #&gt; 2 windows-1252 0.31 #&gt; 3 windows-1250 0.25 Note that write_csv always saves the file using encoding UTF-8. In a few cases, you may need to save a CSV file that can be read by Excel. For this purpose use: write_excel_csv2(dat, csv_file) The CSV file can now be opened correctly in Excel. 12.3 Excel There are different packages in R for reading and writing to Excel. We will use the readxl package for reading Excel files which is a part of tidyverse. The package supports both the legacy .xls format and the modern xml-based .xlsx format. Let us use one of the example files provided by the package: xlsx_file &lt;- system.file(&quot;extdata/datasets.xlsx&quot;, package = &quot;readxl&quot;) It is always a good idea to have a look at the file before you import from it. You can open it from R by using: browseURL(xlsx_file) Data can be read using: library(readxl) xlsx &lt;- read_excel(xlsx_file) # reads the first sheet xlsx #&gt; # A tibble: 150 × 5 #&gt; Sepal.Length Sepal.Width Petal.Length Petal.Width Species #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 5.1 3.5 1.4 0.2 setosa #&gt; 2 4.9 3 1.4 0.2 setosa #&gt; 3 4.7 3.2 1.3 0.2 setosa #&gt; 4 4.6 3.1 1.5 0.2 setosa #&gt; 5 5 3.6 1.4 0.2 setosa #&gt; 6 5.4 3.9 1.7 0.4 setosa #&gt; 7 4.6 3.4 1.4 0.3 setosa #&gt; 8 5 3.4 1.5 0.2 setosa #&gt; 9 4.4 2.9 1.4 0.2 setosa #&gt; 10 4.9 3.1 1.5 0.1 setosa #&gt; # … with 140 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows xlsx &lt;- read_excel(xlsx_file, sheet = 2) # reads the second sheet xlsx #&gt; # A tibble: 32 × 11 #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 #&gt; 2 21 6 160 110 3.9 2.88 17.0 0 1 4 4 #&gt; 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 #&gt; 4 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 #&gt; 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 #&gt; 6 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 #&gt; 7 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 #&gt; 8 24.4 4 147. 62 3.69 3.19 20 1 0 4 2 #&gt; 9 22.8 4 141. 95 3.92 3.15 22.9 1 0 4 2 #&gt; 10 19.2 6 168. 123 3.92 3.44 18.3 1 0 4 4 #&gt; # … with 22 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows xlsx &lt;- read_excel(xlsx_file, sheet = &quot;quakes&quot;) # reads a named sheet xlsx #&gt; # A tibble: 1,000 × 5 #&gt; lat long depth mag stations #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 -20.4 182. 562 4.8 41 #&gt; 2 -20.6 181. 650 4.2 15 #&gt; 3 -26 184. 42 5.4 43 #&gt; 4 -18.0 182. 626 4.1 19 #&gt; 5 -20.4 182. 649 4 11 #&gt; 6 -19.7 184. 195 4 12 #&gt; 7 -11.7 166. 82 4.8 43 #&gt; 8 -28.1 182. 194 4.4 15 #&gt; 9 -28.7 182. 211 4.7 35 #&gt; 10 -17.5 180. 622 4.3 19 #&gt; # … with 990 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows xlsx &lt;- read_excel(xlsx_file, sheet = &quot;mtcars&quot;, range = &quot;A5:G11&quot;, col_names = F) # reads a range colnames(xlsx) &lt;- read_excel(xlsx_file, sheet = &quot;mtcars&quot;, range = &quot;A1:G1&quot;, col_names = F) # reads the column names xlsx #&gt; # A tibble: 7 × 7 #&gt; mpg cyl disp hp drat wt qsec #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 21.4 6 258 110 3.08 3.22 19.4 #&gt; 2 18.7 8 360 175 3.15 3.44 17.0 #&gt; 3 18.1 6 225 105 2.76 3.46 20.2 #&gt; 4 14.3 8 360 245 3.21 3.57 15.8 #&gt; 5 24.4 4 147. 62 3.69 3.19 20 #&gt; 6 22.8 4 141. 95 3.92 3.15 22.9 #&gt; 7 19.2 6 168. 123 3.92 3.44 18.3 Writing to an Excel file can be done using the openxlsx package. To write to a new file use: library(openxlsx) dat &lt;- trees # test dataset head(dat) #&gt; Girth Height Volume #&gt; 1 8.3 70 10.3 #&gt; 2 8.6 65 10.3 #&gt; 3 8.8 63 10.2 #&gt; 4 10.5 72 16.4 #&gt; 5 10.7 81 18.8 #&gt; 6 10.8 83 19.7 write.xlsx(dat, &quot;test1.xlsx&quot;, sheetName = &quot;trees&quot;) # start at cell A1 write.xlsx(dat, &quot;test2.xlsx&quot;, sheetName = &quot;trees&quot;, startCol = &quot;C&quot;, startRow = 3) If you want to append a sheet to a file use: xlsx_file &lt;- system.file(&quot;extdata/datasets.xlsx&quot;, package = &quot;tfa&quot;) file.copy(xlsx_file, &quot;test.xlsx&quot;) # copy the file so can make some tests #&gt; [1] TRUE wb &lt;- loadWorkbook(file = &quot;test.xlsx&quot;) # read the workbook addWorksheet(wb = wb, sheetName = &quot;trees&quot;) writeData(wb, sheet = &quot;trees&quot;, x = dat) saveWorkbook(wb, file = &quot;test.xlsx&quot;, overwrite = TRUE) 12.4 Google Sheets You can import and export to Google sheets using the googlesheets4 package in tidyverse. To read and write data, in general, you need to be logged in as a Google user. The package will ask you when needed. However, if you only want to read data from a public sheet, you can use gs4_deauth to skip this: library(googlesheets4) gs4_deauth() To read data use: url &lt;- &quot;https://docs.google.com/spreadsheets/d/1U6Cf_qEOhiR9AZqTqS3mbMF3zt2db48ZP5v3rkrAEJY/edit#gid=780868077&quot; read_sheet(url) read_sheet(url, sheet = 3) range_read(url, sheet = 2, n_max = 3) range_read(url, range = &quot;Africa!A5:C15&quot;) To write data to a new file use: gs4_auth() gs &lt;- gs4_create(&quot;test&quot;, sheets = c(&quot;Sheet 1&quot;, &quot;Sheet 2&quot;)) write_sheet(dat, ss = gs) range_write(gs, dat, sheet = &quot;Sheet 1&quot;, range = &quot;C4&quot;) gs4_browse(gs) # have a look at the file in a browser To see the results, have a look at your Google sheet test in your browser. 12.5 Text files You can read and write to plain text files using the readr package. However, mostly you want to write to a text file because you want to save some kind of log file when you run your script. Here sink is an excellent function to use, since it redirects your R output. To see the output without messages, errors and warnings use: sink(file = &quot;ex1.log&quot;, split = TRUE) # open the file for output cat(&quot;This is a string\\n... and on a new line\\n\\n&quot;) print(&quot;This is another string&quot;) head(mtcars) rep(1, 4) message(&quot;A message.&quot;) warning(&quot;A warning.&quot;) rep(3, f) # a error cat(&quot;\\nLast line\\n&quot;) sink() # close the file again # file.show(&quot;ex1.log&quot;) # to view in external viewer Let us have a look at the content of the file (run cat(read_file(\"ex1.log\"))): This is a string ... and on a new line [1] &quot;This is another string&quot; mpg cyl disp hp drat wt qsec vs am gear carb Mazda RX4 21.0 6 160 110 3.90 2.62 16.5 0 1 4 4 Mazda RX4 Wag 21.0 6 160 110 3.90 2.88 17.0 0 1 4 4 Datsun 710 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 Hornet 4 Drive 21.4 6 258 110 3.08 3.21 19.4 1 0 3 1 Hornet Sportabout 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 Valiant 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 [1] 1 1 1 1 Last line Note that messages, errors and warnings are not included in the output. If you want to include it use: zz &lt;- file(&quot;ex2.log&quot;, open = &quot;wt&quot;) sink(zz, type = &quot;output&quot;) # open the file for output sink(zz, type = &quot;message&quot;) # open the same file for messages, errors and warnings cat(&quot;This is a string\\n... and on a new line\\n\\n&quot;) print(&quot;This is another string&quot;) head(mtcars) rep(1, 4) message(&quot;A message.&quot;) warning(&quot;A warning.&quot;) rep(3, f) # a error cat(&quot;\\nLast line\\n&quot;) sink() # close the file for output sink() # close the file for messages, errors and warnings That is, we call sink two times. Let us have a look at the content of the file: This is a string ... and on a new line [1] &quot;This is another string&quot; mpg cyl disp hp drat wt qsec vs am gear carb Mazda RX4 21.0 6 160 110 3.90 2.62 16.5 0 1 4 4 Mazda RX4 Wag 21.0 6 160 110 3.90 2.88 17.0 0 1 4 4 Datsun 710 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 Hornet 4 Drive 21.4 6 258 110 3.08 3.21 19.4 1 0 3 1 Hornet Sportabout 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 Valiant 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 [1] 1 1 1 1 A message. Warning message: A warning. Error: object &#39;f&#39; not found Last line Warning message: In sink() : no sink to remove ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. Error: unexpected symbol in &quot;By the&quot; Error: unexpected &#39;*&#39; in &quot;*&quot; Error: unexpected &#39;*&#39; in &quot;*&quot; Error: unexpected &#39;*&#39; in &quot;*&quot; Error: unexpected &#39;*&#39; in &quot;*&quot; Error: unexpected &#39;*&#39; in &quot;*&quot; Error: unexpected symbol in &quot;The learning&quot; Error: unexpected &#39;&lt;&#39; in &quot;&lt;&quot; Error: unexpected &#39;&lt;&#39; in &quot;&lt;&quot; Error: unexpected &#39;&lt;&#39; in &quot;&lt;&quot; Error: unexpected &#39;&lt;&#39; in &quot;&lt;&quot; Error: unexpected symbol in &quot;An excellent&quot; Error: unexpected &#39;&lt;&#39; in &quot;&lt;&quot; Error: unexpected &#39;&lt;&#39; in &quot;&lt;&quot; Error: unexpected &#39;&lt;&#39; in &quot;&lt;&quot; Error: unexpected &#39;&lt;&#39; in &quot;&lt;&quot; Error: unexpected &#39;&lt;&#39; in &quot;&lt;&quot; Error: unexpected symbol in &quot;Mutating joins&quot; Error: attempt to use zero-length variable name Error in curl::curl_fetch_memory(url, handle = handle) : Error in the HTTP2 framing layer ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. x Request failed [429]. Retry 1 happens in 3.5 seconds ... x Request failed [429]. Retry 2 happens in 3.5 seconds ... x Request failed [429]. Retry 3 happens in 8.2 seconds ... x Request failed [429]. Retry 1 happens in 2.5 seconds ... x Request failed [429]. Retry 2 happens in 1.9 seconds ... x Request failed [429]. Retry 3 happens in 26 seconds ... x Request failed [429]. Retry 1 happens in 4.2 seconds ... ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. 12.6 R’s native binary format In general, we can differ between two main types of data/files. Information is either binary encoded (basically just 0’s and 1’s) or stored as text files. What we have considered so far is storing data in text files. Text files can be read by humans and computers alike. The great thing about plain text is their simplicity and their ease of use: any programming language can read a plain text file. Text files are good for storing tabular data but lacks type-safety, and has limited precision for numeric values. Binary file formats cannot be read by humans but allow space-efficient data compression. Furthermore, binary formats may be difficult to read and write using other programs. As most other programming languages, R comes with its own binary format. We will focus on the Rds data format which is optimized for speed and compression ratios. To save and read an R object use: dat &lt;- list(x = c(2, 5, 6), y = &quot;A string&quot;, z = mtcars) saveRDS(dat, file = &quot;test.rds&quot;) readRDS(&quot;test.rds&quot;) #&gt; $x #&gt; [1] 2 5 6 #&gt; #&gt; $y #&gt; [1] &quot;A string&quot; #&gt; #&gt; $z #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; Mazda RX4 21.0 6 160.0 110 3.90 2.62 16.5 0 1 4 4 #&gt; Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.88 17.0 0 1 4 4 #&gt; Datsun 710 22.8 4 108.0 93 3.85 2.32 18.6 1 1 4 1 #&gt; Hornet 4 Drive 21.4 6 258.0 110 3.08 3.21 19.4 1 0 3 1 #&gt; Hornet Sportabout 18.7 8 360.0 175 3.15 3.44 17.0 0 0 3 2 #&gt; Valiant 18.1 6 225.0 105 2.76 3.46 20.2 1 0 3 1 #&gt; Duster 360 14.3 8 360.0 245 3.21 3.57 15.8 0 0 3 4 #&gt; Merc 240D 24.4 4 146.7 62 3.69 3.19 20.0 1 0 4 2 #&gt; Merc 230 22.8 4 140.8 95 3.92 3.15 22.9 1 0 4 2 #&gt; Merc 280 19.2 6 167.6 123 3.92 3.44 18.3 1 0 4 4 #&gt; Merc 280C 17.8 6 167.6 123 3.92 3.44 18.9 1 0 4 4 #&gt; Merc 450SE 16.4 8 275.8 180 3.07 4.07 17.4 0 0 3 3 #&gt; Merc 450SL 17.3 8 275.8 180 3.07 3.73 17.6 0 0 3 3 #&gt; Merc 450SLC 15.2 8 275.8 180 3.07 3.78 18.0 0 0 3 3 #&gt; Cadillac Fleetwood 10.4 8 472.0 205 2.93 5.25 18.0 0 0 3 4 #&gt; Lincoln Continental 10.4 8 460.0 215 3.00 5.42 17.8 0 0 3 4 #&gt; Chrysler Imperial 14.7 8 440.0 230 3.23 5.34 17.4 0 0 3 4 #&gt; Fiat 128 32.4 4 78.7 66 4.08 2.20 19.5 1 1 4 1 #&gt; Honda Civic 30.4 4 75.7 52 4.93 1.61 18.5 1 1 4 2 #&gt; Toyota Corolla 33.9 4 71.1 65 4.22 1.83 19.9 1 1 4 1 #&gt; Toyota Corona 21.5 4 120.1 97 3.70 2.46 20.0 1 0 3 1 #&gt; Dodge Challenger 15.5 8 318.0 150 2.76 3.52 16.9 0 0 3 2 #&gt; AMC Javelin 15.2 8 304.0 150 3.15 3.44 17.3 0 0 3 2 #&gt; Camaro Z28 13.3 8 350.0 245 3.73 3.84 15.4 0 0 3 4 #&gt; Pontiac Firebird 19.2 8 400.0 175 3.08 3.85 17.1 0 0 3 2 #&gt; Fiat X1-9 27.3 4 79.0 66 4.08 1.94 18.9 1 1 4 1 #&gt; Porsche 914-2 26.0 4 120.3 91 4.43 2.14 16.7 0 1 5 2 #&gt; Lotus Europa 30.4 4 95.1 113 3.77 1.51 16.9 1 1 5 2 #&gt; Ford Pantera L 15.8 8 351.0 264 4.22 3.17 14.5 0 1 5 4 #&gt; Ferrari Dino 19.7 6 145.0 175 3.62 2.77 15.5 0 1 5 6 #&gt; Maserati Bora 15.0 8 301.0 335 3.54 3.57 14.6 0 1 5 8 #&gt; Volvo 142E 21.4 4 121.0 109 4.11 2.78 18.6 1 1 4 2 Note we here have saved a non tabular R object (a list). 12.7 Json JavaScript Object Notation (json) is an open standard text file format, and data interchange format, that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and array data types. It can be used to store non tabular data in text format. It is often used for data-exchange in web-apis. Let us try to read and write to a json file using the jsonlite package. library(jsonlite) dat &lt;- list(x = c(2, 5, 6), y = &quot;A string&quot;, z = head(mtcars)) write_json(dat, &quot;test.json&quot;, pretty = T) lst &lt;- read_json(&quot;test.json&quot;, simplifyDataFrame = T, simplifyVector = T) lst #&gt; $x #&gt; [1] 2 5 6 #&gt; #&gt; $y #&gt; [1] &quot;A string&quot; #&gt; #&gt; $z #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; Mazda RX4 21.0 6 160 110 3.90 2.62 16.5 0 1 4 4 #&gt; Mazda RX4 Wag 21.0 6 160 110 3.90 2.88 17.0 0 1 4 4 #&gt; Datsun 710 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 #&gt; Hornet 4 Drive 21.4 6 258 110 3.08 3.21 19.4 1 0 3 1 #&gt; Hornet Sportabout 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 #&gt; Valiant 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 The content of the json file look likes: { &quot;x&quot;: [2, 5, 6], &quot;y&quot;: [&quot;A string&quot;], &quot;z&quot;: [ { &quot;mpg&quot;: 21, &quot;cyl&quot;: 6, &quot;disp&quot;: 160, &quot;hp&quot;: 110, &quot;drat&quot;: 3.9, &quot;wt&quot;: 2.62, &quot;qsec&quot;: 16.46, &quot;vs&quot;: 0, &quot;am&quot;: 1, &quot;gear&quot;: 4, &quot;carb&quot;: 4, &quot;_row&quot;: &quot;Mazda RX4&quot; }, { &quot;mpg&quot;: 21, &quot;cyl&quot;: 6, &quot;disp&quot;: 160, &quot;hp&quot;: 110, &quot;drat&quot;: 3.9, &quot;wt&quot;: 2.875, &quot;qsec&quot;: 17.02, &quot;vs&quot;: 0, &quot;am&quot;: 1, &quot;gear&quot;: 4, &quot;carb&quot;: 4, &quot;_row&quot;: &quot;Mazda RX4 Wag&quot; }, { &quot;mpg&quot;: 22.8, &quot;cyl&quot;: 4, &quot;disp&quot;: 108, &quot;hp&quot;: 93, &quot;drat&quot;: 3.85, &quot;wt&quot;: 2.32, &quot;qsec&quot;: 18.61, &quot;vs&quot;: 1, &quot;am&quot;: 1, &quot;gear&quot;: 4, &quot;carb&quot;: 1, &quot;_row&quot;: &quot;Datsun 710&quot; }, { &quot;mpg&quot;: 21.4, &quot;cyl&quot;: 6, &quot;disp&quot;: 258, &quot;hp&quot;: 110, &quot;drat&quot;: 3.08, &quot;wt&quot;: 3.215, &quot;qsec&quot;: 19.44, &quot;vs&quot;: 1, &quot;am&quot;: 0, &quot;gear&quot;: 3, &quot;carb&quot;: 1, &quot;_row&quot;: &quot;Hornet 4 Drive&quot; }, { &quot;mpg&quot;: 18.7, &quot;cyl&quot;: 8, &quot;disp&quot;: 360, &quot;hp&quot;: 175, &quot;drat&quot;: 3.15, &quot;wt&quot;: 3.44, &quot;qsec&quot;: 17.02, &quot;vs&quot;: 0, &quot;am&quot;: 0, &quot;gear&quot;: 3, &quot;carb&quot;: 2, &quot;_row&quot;: &quot;Hornet Sportabout&quot; }, { &quot;mpg&quot;: 18.1, &quot;cyl&quot;: 6, &quot;disp&quot;: 225, &quot;hp&quot;: 105, &quot;drat&quot;: 2.76, &quot;wt&quot;: 3.46, &quot;qsec&quot;: 20.22, &quot;vs&quot;: 1, &quot;am&quot;: 0, &quot;gear&quot;: 3, &quot;carb&quot;: 1, &quot;_row&quot;: &quot;Valiant&quot; } ] } 12.8 Recap For doing data driven analytics you first must import some data. That is, take data from a database, file, web API etc. and transform it into a data frame/table. CSV files contain delimiter separated values in plain text and are often named using the file suffix .csv. Each line of a csv file is a data record. Each record consists of one or more fields, separated by a common delimiter (e.g. ,, ; or _). The readxl package can be used to read Excel files. Writing to an Excel file can be done using the openxlsx package. You can import and export to Google sheets using the googlesheets4 package in tidyverse. Use sink to save output of you R script. There are two main types of data files. Information is either binary encoded or stored as text files. Text files can be read by humans and computers alike. The great thing about plain text is their simplicity and their ease of use: any programming language can read a plain text file. Text files are good for storing tabular data but lacks type-safety, and has limited precision for numeric values. Binary file formats cannot be read by humans but allow space-efficient data compression. Moreover they can be used to save non tabular data. As most other programming languages, R comes with its own binary format. We will focus on the Rds data format which are optimized for speed and compression ratios. Json is an open standard text file format, and data interchange format. It can be used to store non tabular data in text format. It is often used for data-exchange in web-api’s. You may also have a look at the slides for this module. 12.9 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Some of the solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up too early. Put some effort into finding a solution! Always practice using shortcuts in RStudio (see Tools &gt; Keyboard Shortcuts Help). Go to the Tools for Analytics workspace and download/export the TM12 project. Open it on your laptop and have a look at the files in the exercises folder which can be used as a starting point. 12.9.1 Exercise (Statistikbanken) Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). You can use the API from Statistikbanken to download a lot of data sets. Let us consider airports in Denmark (data set with table id FLYV41): url &lt;- &quot;https://api.statbank.dk/v1/data/FLYV41/CSV?lang=en&amp;LUFTHAVN=*&amp;Tid=*&amp;Transport=*&quot; Use cat(read_lines(url, n_max = 3), sep = \"\\n\") to have a look at the delimiter used. × Solution url &lt;- &#39;https://api.statbank.dk/v1/data/FLYV41/CSV?lang=en&amp;LUFTHAVN=*&amp;Tid=*&amp;Transport=*&#39; dat &lt;- read_csv2(url) dat Close Solution Import the csv file. Try to retrieve information and get an overview over the data by running: library(jsonlite) url &lt;- &quot;https://api.statbank.dk/v1/tableinfo/FLYV41?lang=en&quot; lst &lt;- read_json(url, simplifyVector = T) View(lst) Note the data returned is in json format, so we use read_json to read the data into a list. × Solution info &lt;- function(tab_id) { url &lt;- str_c(&quot;https://api.statbank.dk/v1/tableinfo/&quot;, tab_id, &quot;?lang=en&quot;) lst &lt;- read_json(url, simplifyVector = T) return(list(description = lst$description, unit = lst$unit, variables = lst$variables[,1:2])) } info(&quot;FLYV41&quot;) Close Solution × Hint 2 info &lt;- function(tab_id) { url &lt;- str_c(___) lst &lt;- read_json(___) return(list(description = lst$___, unit = ___, ___)) } info(&quot;FLYV41&quot;) Close Hint 2 × Hint 1 You can modify the code in Question 3 to return only parts of the list. Close Hint 1 Create a function info(tab_id) that returns a list with components description, unit and variables from the information for a data set with table id tab_id. Information about all the data sets can be retrieved using: url &lt;- &quot;https://api.statbank.dk/v1/tables?lang=en&quot; lst &lt;- jsonlite::read_json(url, simplifyVector = T) View(lst) Have a look at the row for FLYV41. × Solution get_data &lt;- function(tab_id, col_id = NULL) { url &lt;- str_c(&quot;https://api.statbank.dk/v1/tableinfo/&quot;, tab_id, &quot;?lang=en&quot;) lst &lt;- read_json(url, simplifyVector = T) cols &lt;- lst$variables$id if (!is.null(col_id)) cols &lt;- cols[col_id] url &lt;- str_c(&quot;https://api.statbank.dk/v1/data/&quot;, tab_id, &quot;/CSV?lang=en&amp;&quot;, str_c(cols, collapse = &quot;=*&amp;&quot;), &quot;=*&quot;) %&gt;% URLencode() dat &lt;- read_csv2(url) return(dat) } get_data(&quot;FLYV41&quot;, 3) get_data(&quot;FLYV41&quot;, 1:2) get_data(&quot;FLYV41&quot;) Close Solution × Hint get_data &lt;- function(tab_id, col_id = NULL) { url &lt;- ___ lst &lt;- ___ cols &lt;- lst$variables$id if (!is.null(col_id)) cols &lt;- cols[___] url &lt;- ___ dat &lt;- ___ return(dat) } get_data(&quot;FLYV41&quot;, 3) get_data(&quot;FLYV41&quot;, 1:2) get_data(&quot;FLYV41&quot;) Close Hint Given the information about variables in a data set we can construct the url to retrieve the data in csv format: tab_id &lt;- &quot;FLYV41&quot; url &lt;- str_c(&quot;https://api.statbank.dk/v1/tableinfo/&quot;, tab_id, &quot;?lang=en&quot;) lst &lt;- read_json(url, simplifyVector = T) col_id &lt;- c(1,3) # column ids in lst$variables$id cols &lt;- lst$variables$id[col_id] url &lt;- str_c(&quot;https://api.statbank.dk/v1/data/&quot;, tab_id, &quot;/CSV?lang=en&amp;&quot;, str_c(cols, collapse = &quot;=*&amp;&quot;), &quot;=*&quot;) %&gt;% URLencode() url #&gt; [1] &quot;https://api.statbank.dk/v1/data/FLYV41/CSV?lang=en&amp;LUFTHAVN=*&amp;Tid=*&quot; Create a function get_data(tab_id, col_id) that retrieve a data set. × Solution dat &lt;- get_data(&quot;FOLK1A&quot;, c(2, 3, 5)) dat write_csv(dat, &quot;test.csv&quot;) Close Solution Use the function get_data to retrieve data for tab_id = \"FOLK1A\" and col_id = c(2, 3, 5) and save it as a csv file with a comma as delimiter. × Solution library(openxlsx) write.xlsx(dat, &quot;test.xlsx&quot;, sheetName = &quot;FOLK1A&quot;) library(googlesheets4) gs &lt;- gs4_create(&quot;test&quot;) write_sheet(dat, ss = gs, sheet = &quot;FOLK1A&quot;) gs4_browse(gs) Close Solution × Hint library(openxlsx) write.xlsx(___) library(googlesheets4) gs &lt;- gs4_create(&quot;test&quot;) write_sheet(___, ss = ___, sheet = &quot;FOLK1A&quot;) gs4_browse(gs) Close Hint Save the data in an Excel file and a Google sheet. 12.9.2 Exercise (tuples in OPL) In the algebraic modeling language OPL (Optimization Programming Language) used by IBM ILOG CPLEX Optimization Studio, you can define tuples to contain various information. For example consider tuples defined as: tuple nurse { string name; int experience; // higest best } tuple shift { string departmentName; string day; int startTime; int endTime; } A nurse tuple is then defined as &lt;\"Anne\", 11&gt; and a shift tuple as `&lt;“Consultation”, “Monday” 12, 18&gt;. A set of tuples can be defined using: {nurse} nurses = ...; {shift} shifts = ...; where the ... operator means that the sets are read from a data text file: nurses = { &lt;&quot;Anne&quot;, 11&gt;, &lt;&quot;Bethanie&quot;, 4&gt;, &lt;&quot;Betsy&quot;, 2&gt; }; shifts = { &lt;&quot;Emergency&quot;, &quot;Monday&quot;, 2, 8&gt;, &lt;&quot;Emergency&quot;, Monday 8 12 4 7&gt;, &lt;&quot;Emergency&quot;, &quot;Monday&quot; 12 18 2 5&gt; }; You can now use the sets to define decision variables \\(x_{ns}\\) equal one if nurse \\(n\\) is assigned to shift \\(s\\). In this exercise we will try to generate the data text file given tibbles with data. × Solution file = &quot;test.dat&quot; write_lines(&quot;nurses = {&quot;, file) write_lines(&#39; &lt;&quot;Anne&quot;, 11&gt;&#39;, file, append = TRUE) write_lines(&#39;};&#39;, file, append = TRUE) cat(read_file(&quot;test.dat&quot;)) #&gt; nurses = { #&gt; &lt;&quot;Anne&quot;, 11&gt; #&gt; }; Close Solution × Hint file = &quot;test.dat&quot; write_lines(&quot;nurses = {&quot;, file) write_lines(___, ___, append = TRUE) write_lines(___, ___, append = TRUE) cat(read_file(&quot;test.dat&quot;)) # to have a look Close Hint Try to generate a text file named test.dat using function write_lines with content nurses = { &lt;&quot;Anne&quot;, 11&gt; }; Load datasets # remotes::install_github(&quot;bss-osca/tfa-package&quot;, dependencies = FALSE) # if tfa not installed library(tfa) library(tidyverse) nurses &lt;- read_csv(system.file(&quot;extdata/nurses.csv&quot;, package = &quot;tfa&quot;)) shifts &lt;- read_csv(system.file(&quot;extdata/shifts.csv&quot;, package = &quot;tfa&quot;)) × Solution nurses %&gt;% mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) #&gt; # A tibble: 32 × 2 #&gt; name experience #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 &quot;\\&quot;Anne\\&quot;&quot; 11 #&gt; 2 &quot;\\&quot;Bethanie\\&quot;&quot; 4 #&gt; 3 &quot;\\&quot;Betsy\\&quot;&quot; 2 #&gt; 4 &quot;\\&quot;Cathy\\&quot;&quot; 2 #&gt; 5 &quot;\\&quot;Cecilia\\&quot;&quot; 9 #&gt; 6 &quot;\\&quot;Chris\\&quot;&quot; 11 #&gt; 7 &quot;\\&quot;Cindy\\&quot;&quot; 5 #&gt; 8 &quot;\\&quot;David\\&quot;&quot; 1 #&gt; 9 &quot;\\&quot;Debbie\\&quot;&quot; 7 #&gt; 10 &quot;\\&quot;Dee\\&quot;&quot; 3 #&gt; # … with 22 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Close Solution × Hint 2 nurses %&gt;% mutate(across(where(___), ~str_c(&#39;___&#39;, .x, &#39;___&#39;))) Close Hint 2 × Hint 1 v &lt;- c(&quot;foo&quot;, &quot;bar&quot;) str_c(&#39;&quot;&#39;, v, &#39;&quot;&#39;) # use of str_c to add &quot; #&gt; [1] &quot;\\&quot;foo\\&quot;&quot; &quot;\\&quot;bar\\&quot;&quot; str_c(v, collapse = &quot;, &quot;) # collapsing a vector #&gt; [1] &quot;foo, bar&quot; tbl &lt;- tribble( ~name, ~experience, &quot;Anne&quot;, 11, &quot;Bethanie&quot;, 4 ) tbl #&gt; # A tibble: 2 × 2 #&gt; name experience #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Anne 11 #&gt; 2 Bethanie 4 tbl %&gt;% mutate(across(where(is.character), # use across to find all character columns ~str_c(&#39;(&#39;, .x, &#39;)&#39;))) # str_c is applied to each column where .x is the column values #&gt; # A tibble: 2 × 2 #&gt; name experience #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 (Anne) 11 #&gt; 2 (Bethanie) 4 Close Hint 1 Transform all character columns in nurses so they start and end with \". Some hints are given in Hint 1. × Solution nurses %&gt;% mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) %&gt;% unite(&quot;tuple&quot;, everything(), sep = &quot;, &quot;, remove = FALSE) #&gt; # A tibble: 32 × 3 #&gt; tuple name experience #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 &quot;\\&quot;Anne\\&quot;, 11&quot; &quot;\\&quot;Anne\\&quot;&quot; 11 #&gt; 2 &quot;\\&quot;Bethanie\\&quot;, 4&quot; &quot;\\&quot;Bethanie\\&quot;&quot; 4 #&gt; 3 &quot;\\&quot;Betsy\\&quot;, 2&quot; &quot;\\&quot;Betsy\\&quot;&quot; 2 #&gt; 4 &quot;\\&quot;Cathy\\&quot;, 2&quot; &quot;\\&quot;Cathy\\&quot;&quot; 2 #&gt; 5 &quot;\\&quot;Cecilia\\&quot;, 9&quot; &quot;\\&quot;Cecilia\\&quot;&quot; 9 #&gt; 6 &quot;\\&quot;Chris\\&quot;, 11&quot; &quot;\\&quot;Chris\\&quot;&quot; 11 #&gt; 7 &quot;\\&quot;Cindy\\&quot;, 5&quot; &quot;\\&quot;Cindy\\&quot;&quot; 5 #&gt; 8 &quot;\\&quot;David\\&quot;, 1&quot; &quot;\\&quot;David\\&quot;&quot; 1 #&gt; 9 &quot;\\&quot;Debbie\\&quot;, 7&quot; &quot;\\&quot;Debbie\\&quot;&quot; 7 #&gt; 10 &quot;\\&quot;Dee\\&quot;, 3&quot; &quot;\\&quot;Dee\\&quot;&quot; 3 #&gt; # … with 22 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Close Solution × Hint nurses %&gt;% mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) %&gt;% unite(&quot;tuple&quot;, everything(), sep = ___, remove = ___) Close Hint Unite all columns into a new column named tuple where each column is separated with ,. Hint: have a look at the unite function. All columns can be selected using everything(). × Solution nurses %&gt;% mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) %&gt;% unite(&quot;tuple&quot;, everything(), sep = &quot;, &quot;, remove = FALSE) %&gt;% mutate(tuple = str_c(&quot;&lt;&quot;, tuple, &quot;&gt;&quot;)) #&gt; # A tibble: 32 × 3 #&gt; tuple name experience #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 &quot;&lt;\\&quot;Anne\\&quot;, 11&gt;&quot; &quot;\\&quot;Anne\\&quot;&quot; 11 #&gt; 2 &quot;&lt;\\&quot;Bethanie\\&quot;, 4&gt;&quot; &quot;\\&quot;Bethanie\\&quot;&quot; 4 #&gt; 3 &quot;&lt;\\&quot;Betsy\\&quot;, 2&gt;&quot; &quot;\\&quot;Betsy\\&quot;&quot; 2 #&gt; 4 &quot;&lt;\\&quot;Cathy\\&quot;, 2&gt;&quot; &quot;\\&quot;Cathy\\&quot;&quot; 2 #&gt; 5 &quot;&lt;\\&quot;Cecilia\\&quot;, 9&gt;&quot; &quot;\\&quot;Cecilia\\&quot;&quot; 9 #&gt; 6 &quot;&lt;\\&quot;Chris\\&quot;, 11&gt;&quot; &quot;\\&quot;Chris\\&quot;&quot; 11 #&gt; 7 &quot;&lt;\\&quot;Cindy\\&quot;, 5&gt;&quot; &quot;\\&quot;Cindy\\&quot;&quot; 5 #&gt; 8 &quot;&lt;\\&quot;David\\&quot;, 1&gt;&quot; &quot;\\&quot;David\\&quot;&quot; 1 #&gt; 9 &quot;&lt;\\&quot;Debbie\\&quot;, 7&gt;&quot; &quot;\\&quot;Debbie\\&quot;&quot; 7 #&gt; 10 &quot;&lt;\\&quot;Dee\\&quot;, 3&gt;&quot; &quot;\\&quot;Dee\\&quot;&quot; 3 #&gt; # … with 22 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Close Solution × Hint nurses %&gt;% mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) %&gt;% unite(&quot;tuple&quot;, everything(), sep = &quot;, &quot;, remove = FALSE) %&gt;% mutate(tuple = str_c(___, tuple, ___)) Close Hint Add &lt; and &gt; the start and end of the tuple column. × Solution nurses %&gt;% mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) %&gt;% unite(&quot;tuple&quot;, everything(), sep = &quot;, &quot;, remove = FALSE) %&gt;% mutate(tuple = str_c(&quot;&lt;&quot;, tuple, &quot;&gt;&quot;)) %&gt;% pull(tuple) %&gt;% str_c(collapse = &quot;,\\n&quot;) #&gt; [1] &quot;&lt;\\&quot;Anne\\&quot;, 11&gt;,\\n&lt;\\&quot;Bethanie\\&quot;, 4&gt;,\\n&lt;\\&quot;Betsy\\&quot;, 2&gt;,\\n&lt;\\&quot;Cathy\\&quot;, 2&gt;,\\n&lt;\\&quot;Cecilia\\&quot;, 9&gt;,\\n&lt;\\&quot;Chris\\&quot;, 11&gt;,\\n&lt;\\&quot;Cindy\\&quot;, 5&gt;,\\n&lt;\\&quot;David\\&quot;, 1&gt;,\\n&lt;\\&quot;Debbie\\&quot;, 7&gt;,\\n&lt;\\&quot;Dee\\&quot;, 3&gt;,\\n&lt;\\&quot;Gloria\\&quot;, 8&gt;,\\n&lt;\\&quot;Isabelle\\&quot;, 3&gt;,\\n&lt;\\&quot;Jane\\&quot;, 3&gt;,\\n&lt;\\&quot;Janelle\\&quot;, 4&gt;,\\n&lt;\\&quot;Janice\\&quot;, 2&gt;,\\n&lt;\\&quot;Jemma\\&quot;, 2&gt;,\\n&lt;\\&quot;Joan\\&quot;, 5&gt;,\\n&lt;\\&quot;Joyce\\&quot;, 8&gt;,\\n&lt;\\&quot;Jude\\&quot;, 4&gt;,\\n&lt;\\&quot;Julie\\&quot;, 6&gt;,\\n&lt;\\&quot;Juliet\\&quot;, 7&gt;,\\n&lt;\\&quot;Kate\\&quot;, 5&gt;,\\n&lt;\\&quot;Nancy\\&quot;, 8&gt;,\\n&lt;\\&quot;Nathalie\\&quot;, 9&gt;,\\n&lt;\\&quot;Nicole\\&quot;, 0&gt;,\\n&lt;\\&quot;Patricia\\&quot;, 1&gt;,\\n&lt;\\&quot;Patrick\\&quot;, 6&gt;,\\n&lt;\\&quot;Roberta\\&quot;, 3&gt;,\\n&lt;\\&quot;Suzanne\\&quot;, 5&gt;,\\n&lt;\\&quot;Vickie\\&quot;, 7&gt;,\\n&lt;\\&quot;Wendie\\&quot;, 5&gt;,\\n&lt;\\&quot;Zoe\\&quot;, 8&gt;&quot; Close Solution × Hint nurses %&gt;% mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) %&gt;% unite(&quot;tuple&quot;, everything(), sep = &quot;, &quot;, remove = FALSE) %&gt;% mutate(tuple = str_c(&quot;&lt;&quot;, tuple, &quot;&gt;&quot;)) %&gt;% pull(___) %&gt;% str_c(___) Close Hint Extract the tuple column and transform it into a string with collapse = \",\\n\". × Solution write_tuple &lt;- function(dat, file) { write_lines(&quot;nurses = {&quot;, file, sep = &quot;\\n &quot;) tuples &lt;- dat %&gt;% mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) %&gt;% unite(&quot;tuple&quot;, everything(), sep = &quot;, &quot;, remove = FALSE) %&gt;% mutate(tuple = str_c(&quot;&lt;&quot;, tuple, &quot;&gt;&quot;)) %&gt;% pull(tuple) %&gt;% str_c(collapse = &quot;,\\n &quot;) write_lines(tuples, file, append = TRUE) write_lines(&quot;};&quot;, file, append = TRUE) } file &lt;- &quot;test.dat&quot; write_tuple(nurses, file) cat(read_file(&quot;test.dat&quot;)) # to have a look #&gt; nurses = { #&gt; &lt;&quot;Anne&quot;, 11&gt;, #&gt; &lt;&quot;Bethanie&quot;, 4&gt;, #&gt; &lt;&quot;Betsy&quot;, 2&gt;, #&gt; &lt;&quot;Cathy&quot;, 2&gt;, #&gt; &lt;&quot;Cecilia&quot;, 9&gt;, #&gt; &lt;&quot;Chris&quot;, 11&gt;, #&gt; &lt;&quot;Cindy&quot;, 5&gt;, #&gt; &lt;&quot;David&quot;, 1&gt;, #&gt; &lt;&quot;Debbie&quot;, 7&gt;, #&gt; &lt;&quot;Dee&quot;, 3&gt;, #&gt; &lt;&quot;Gloria&quot;, 8&gt;, #&gt; &lt;&quot;Isabelle&quot;, 3&gt;, #&gt; &lt;&quot;Jane&quot;, 3&gt;, #&gt; &lt;&quot;Janelle&quot;, 4&gt;, #&gt; &lt;&quot;Janice&quot;, 2&gt;, #&gt; &lt;&quot;Jemma&quot;, 2&gt;, #&gt; &lt;&quot;Joan&quot;, 5&gt;, #&gt; &lt;&quot;Joyce&quot;, 8&gt;, #&gt; &lt;&quot;Jude&quot;, 4&gt;, #&gt; &lt;&quot;Julie&quot;, 6&gt;, #&gt; &lt;&quot;Juliet&quot;, 7&gt;, #&gt; &lt;&quot;Kate&quot;, 5&gt;, #&gt; &lt;&quot;Nancy&quot;, 8&gt;, #&gt; &lt;&quot;Nathalie&quot;, 9&gt;, #&gt; &lt;&quot;Nicole&quot;, 0&gt;, #&gt; &lt;&quot;Patricia&quot;, 1&gt;, #&gt; &lt;&quot;Patrick&quot;, 6&gt;, #&gt; &lt;&quot;Roberta&quot;, 3&gt;, #&gt; &lt;&quot;Suzanne&quot;, 5&gt;, #&gt; &lt;&quot;Vickie&quot;, 7&gt;, #&gt; &lt;&quot;Wendie&quot;, 5&gt;, #&gt; &lt;&quot;Zoe&quot;, 8&gt; #&gt; }; Close Solution × Hint 2 write_tuple &lt;- function(dat, file) { write_lines(&quot;nurses = {&quot;, file, sep = &quot;\\n &quot;) tuples &lt;- dat %&gt;% ___ write_lines(tuples, file, append = TRUE) write_lines(&quot;};&quot;, file, append = TRUE) } file &lt;- &quot;test.dat&quot; write_tuple(nurses, file) cat(read_file(&quot;test.dat&quot;)) # to have a look Close Hint 2 × Hint 1 write_tuple &lt;- function(dat, file) { write_lines(___) ___ write_lines(&quot;};&quot;, ___, ___) } file &lt;- &quot;test.dat&quot; write_tuple(nurses, file) cat(read_file(&quot;test.dat&quot;)) # to have a look Close Hint 1 Create a function write_tuple that takes nurses as input and write the tuples to a file. The name of an object can be extracted as a string using deparse(substitute(nurses)) #&gt; [1] &quot;nurses&quot; × Solution write_tuple &lt;- function(dat, file) { name &lt;- deparse(substitute(dat)) write_lines(str_c(name, &quot; = {&quot;), file, sep = &quot;\\n &quot;) tuples &lt;- dat %&gt;% mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) %&gt;% unite(&quot;tuple&quot;, everything(), sep = &quot;, &quot;, remove = FALSE) %&gt;% mutate(tuple = str_c(&quot;&lt;&quot;, tuple, &quot;&gt;&quot;)) %&gt;% pull(tuple) %&gt;% str_c(collapse = &quot;,\\n &quot;) write_lines(tuples, file, append = TRUE) write_lines(&quot;};&quot;, file, append = TRUE) } file &lt;- &quot;test.dat&quot; write_tuple(shifts, file) cat(read_file(&quot;test.dat&quot;)) # to have a look #&gt; shifts = { #&gt; &lt;&quot;Emergency&quot;, &quot;Monday&quot;, 2, 8&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Monday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Monday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Monday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Monday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Monday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Tuesday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Tuesday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Tuesday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Tuesday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Tuesday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Wednesday&quot;, 2, 8&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Wednesday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Wednesday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Wednesday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Wednesday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Wednesday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Thursday&quot;, 2, 8&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Thursday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Thursday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Thursday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Thursday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Thursday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Friday&quot;, 2, 8&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Friday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Friday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Friday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Friday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Friday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Saturday&quot;, 2, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Saturday&quot;, 12, 20&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Saturday&quot;, 20, 2&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Sunday&quot;, 2, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Sunday&quot;, 12, 20&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Sunday&quot;, 20, 2&gt; #&gt; }; Close Solution Modify write_tuple so it works if shifts are given as input instead of nurses. × Solution write_tuple &lt;- function(dat, file, append = FALSE) { name &lt;- deparse(substitute(dat)) write_lines(str_c(&quot;\\n&quot;, name, &quot; = {&quot;), file, sep = &quot;\\n &quot;, append = append) tuples &lt;- dat %&gt;% mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) %&gt;% unite(&quot;tuple&quot;, everything(), sep = &quot;, &quot;, remove = FALSE) %&gt;% mutate(tuple = str_c(&quot;&lt;&quot;, tuple, &quot;&gt;&quot;)) %&gt;% pull(tuple) %&gt;% str_c(collapse = &quot;,\\n &quot;) write_lines(tuples, file, append = TRUE) write_lines(&quot;};&quot;, file, append = TRUE) } Close Solution Modify write_tuple with a new input argument append which is false by default. If true, then then the file is not overwritten. × Solution file &lt;- &quot;test.dat&quot; write_tuple(nurses, file) write_tuple(shifts, file, append = TRUE) cat(read_file(&quot;test.dat&quot;)) # to have a look #&gt; #&gt; nurses = { #&gt; &lt;&quot;Anne&quot;, 11&gt;, #&gt; &lt;&quot;Bethanie&quot;, 4&gt;, #&gt; &lt;&quot;Betsy&quot;, 2&gt;, #&gt; &lt;&quot;Cathy&quot;, 2&gt;, #&gt; &lt;&quot;Cecilia&quot;, 9&gt;, #&gt; &lt;&quot;Chris&quot;, 11&gt;, #&gt; &lt;&quot;Cindy&quot;, 5&gt;, #&gt; &lt;&quot;David&quot;, 1&gt;, #&gt; &lt;&quot;Debbie&quot;, 7&gt;, #&gt; &lt;&quot;Dee&quot;, 3&gt;, #&gt; &lt;&quot;Gloria&quot;, 8&gt;, #&gt; &lt;&quot;Isabelle&quot;, 3&gt;, #&gt; &lt;&quot;Jane&quot;, 3&gt;, #&gt; &lt;&quot;Janelle&quot;, 4&gt;, #&gt; &lt;&quot;Janice&quot;, 2&gt;, #&gt; &lt;&quot;Jemma&quot;, 2&gt;, #&gt; &lt;&quot;Joan&quot;, 5&gt;, #&gt; &lt;&quot;Joyce&quot;, 8&gt;, #&gt; &lt;&quot;Jude&quot;, 4&gt;, #&gt; &lt;&quot;Julie&quot;, 6&gt;, #&gt; &lt;&quot;Juliet&quot;, 7&gt;, #&gt; &lt;&quot;Kate&quot;, 5&gt;, #&gt; &lt;&quot;Nancy&quot;, 8&gt;, #&gt; &lt;&quot;Nathalie&quot;, 9&gt;, #&gt; &lt;&quot;Nicole&quot;, 0&gt;, #&gt; &lt;&quot;Patricia&quot;, 1&gt;, #&gt; &lt;&quot;Patrick&quot;, 6&gt;, #&gt; &lt;&quot;Roberta&quot;, 3&gt;, #&gt; &lt;&quot;Suzanne&quot;, 5&gt;, #&gt; &lt;&quot;Vickie&quot;, 7&gt;, #&gt; &lt;&quot;Wendie&quot;, 5&gt;, #&gt; &lt;&quot;Zoe&quot;, 8&gt; #&gt; }; #&gt; #&gt; shifts = { #&gt; &lt;&quot;Emergency&quot;, &quot;Monday&quot;, 2, 8&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Monday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Monday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Monday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Monday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Monday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Tuesday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Tuesday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Tuesday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Tuesday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Tuesday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Wednesday&quot;, 2, 8&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Wednesday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Wednesday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Wednesday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Wednesday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Wednesday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Thursday&quot;, 2, 8&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Thursday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Thursday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Thursday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Thursday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Thursday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Friday&quot;, 2, 8&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Friday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Friday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Friday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Friday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Friday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Saturday&quot;, 2, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Saturday&quot;, 12, 20&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Saturday&quot;, 20, 2&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Sunday&quot;, 2, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Sunday&quot;, 12, 20&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Sunday&quot;, 20, 2&gt; #&gt; }; Close Solution Write nurses and shifts to a single data file. "],["mod-r-transform.html", "Module 13 Transforming data 13.1 Learning outcomes 13.2 Working with data in the tidyverse 13.3 Mutating joins 13.4 Recap 13.5 Exercises", " Module 13 Transforming data In this module, we consider transformation of data. In general raw data may be messy and need to be structured in a tidy way. Tidying your data means storing it in a structured form suitable for analysis. This is done using a tibble (data frame) where each column is a variable, and each row is an observation. Tidy data is important because the consistent structure lets you focus your struggle on questions about the data. Given a raw dataset the first step is to clean it and and transform it to a tidy format. Given tidy data, you next often need to transform it. Transformation includes narrowing in on observations of interest (e.g. only observations from a specific year or warehouse), creating new variables based on existing variables (like the cost of using the machine that day given idle time). Together, tidying and transforming are called wrangling, because it can be a hard process to get your data in the right form. In this chapter, you will learn how to work with tibbles using the dplyr package which is a part of the tidyverse. A template project for this module is given on RStudio Cloud (open it and use it while reading the notes). Learning path diagram It is recommended that you follow the green learning path; however, you may like a different learning style. In the learning path diagram, there are links to alternative online content (video or reading). Note this is an alternative to the standard learning path that you may use instead (you should not do both). The learning path may also have extra content, that is NOT a part of syllabus (only look at it if you want more info)! 13.1 Learning outcomes By the end of this module, you are expected to be able to: Describe what tidy and wangling is. Apply the most common string functions. Apply tidy operations to data. Transform data. Clean data. The learning outcomes relate to the overall learning goals number 7, 11-14 and 18 of the course. 13.2 Working with data in the tidyverse An excellent introduction on how to transform data using the tidyverse is given in the interactive DataCamp course Data Manipulation with dplyr. Please complete the course before continuing. 13.3 Mutating joins Mutating joins allow you to combine variables from multiple tables. There are four types of mutating join, which differ in their behavior when a match is not found. We’ll illustrate each with a simple example: df1 &lt;- tibble(x = c(1, 2), y = 2:1) df2 &lt;- tibble(x = c(3, 1), a = 10, b = &quot;a&quot;) df1 #&gt; # A tibble: 2 × 2 #&gt; x y #&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 1 2 #&gt; 2 2 1 df2 #&gt; # A tibble: 2 × 3 #&gt; x a b #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 3 10 a #&gt; 2 1 10 a Note that column x is present in both tables and used when joining them. inner_join(df1, df2) only includes observations that match in both df1 and df2. df1 %&gt;% inner_join(df2) #&gt; # A tibble: 1 × 4 #&gt; x y a b #&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 1 2 10 a left_join(df1, df2) includes all observations in df1, regardless of whether they match or not. This is the most commonly used join because it ensures that you don’t lose observations from your primary table. df1 %&gt;% left_join(df2) #&gt; # A tibble: 2 × 4 #&gt; x y a b #&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 1 2 10 a #&gt; 2 2 1 NA &lt;NA&gt; right_join(df1, df2) includes all observations in df2. It’s equivalent to left_join(df2, df1), but the columns and rows will be ordered differently. df1 %&gt;% right_join(df2) #&gt; # A tibble: 2 × 4 #&gt; x y a b #&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 1 2 10 a #&gt; 2 3 NA 10 a df2 %&gt;% left_join(df1) #&gt; # A tibble: 2 × 4 #&gt; x a b y #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 3 10 a NA #&gt; 2 1 10 a 2 full_join() includes all observations from df1 and df2. df1 %&gt;% full_join(df2) #&gt; # A tibble: 3 × 4 #&gt; x y a b #&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 1 2 10 a #&gt; 2 2 1 NA &lt;NA&gt; #&gt; 3 3 NA 10 a The left, right and full joins are collectively know as outer joins. When a row doesn’t match in an outer join, the new variables are filled in with missing values. While mutating joins are primarily used to add new variables, they can also generate new observations. If a match is not unique, a join will add all possible combinations (the Cartesian product) of the matching observations: df1 &lt;- tibble(x = c(1, 1, 2), y = 1:3) df2 &lt;- tibble(x = c(1, 1, 2), z = c(&quot;a&quot;, &quot;b&quot;, &quot;a&quot;)) df1 %&gt;% left_join(df2) #&gt; # A tibble: 5 × 3 #&gt; x y z #&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; #&gt; 1 1 1 a #&gt; 2 1 1 b #&gt; 3 1 2 a #&gt; 4 1 2 b #&gt; 5 2 3 a Filtering joins match observations in the same way as mutating joins, but affect the observations, not the variables. There are two types: semi_join(df1, df2) keeps all observations in df1 that have a match in df2. anti_join(df1, df2) drops all observations in df1 that have a match in df2. These are most useful for diagnosing join mismatches. If you’re worried about what observations your joins will match, start with a semi_join() or anti_join(). semi_join() and anti_join() never duplicate; they only remove observations. df1 &lt;- tibble(x = c(1, 1, 3, 4), y = 1:4) df2 &lt;- tibble(x = c(1, 1, 2), z = c(&quot;a&quot;, &quot;b&quot;, &quot;a&quot;)) # Four rows to start with: df1 %&gt;% nrow() #&gt; [1] 4 # And we get four rows after the join df1 %&gt;% inner_join(df2, by = &quot;x&quot;) %&gt;% nrow() #&gt; [1] 4 # But only two rows actually match df1 %&gt;% semi_join(df2, by = &quot;x&quot;) %&gt;% nrow() #&gt; [1] 2 13.4 Recap We consider transformation of tidy data where data are stored using a tibble (data frame) where each column is a variable, and each row is an observation/case. Tidy data is important because the consistent structure lets you focus your struggle on questions about the data. Transformation includes narrowing in on observations of interest (e.g. only observations from a specific year or warehouse), creating new variables based on existing variables (like the cost of using the machine that day given idle time). Tidying and transforming are called wrangling, because it can be a hard process to get your data in the right form. The package dplyr provides a consistent set of verbs that helps you solve the most common data manipulation challenges: The filter function chooses rows (cases/observations) that meet a specific criteria. The select function chooses columns (variables) based on their names. The arrange function reorders the rows. The transmute function adds/modifies columns (variables) and drops existing ones. The mutate function adds/modifies columns (variables). The group_by function groups variables for groupwise operations. The ungroup function removes the current grouping. The count function counts rows based on a grouping. The summarise function reduces multiple values down to a single summary. The distinct function selects unique/distinct rows. The pull function can be used to extract columns as vectors (it is similar to $). Some nice to know functions to use inside e.g. summarise or mutate are The n() function counts the number of rows in a group. The n_distinct counts the number of unique rows in a group. The first function considers the first row in a group (remember to order it as needed). The slice_min and slice_max functions select rows with highest or lowest values of a variable. The across function makes it easy to apply the same transformation to multiple columns. Use print(n = Inf) in a pipe to print all rows. Use the pipe operator %&gt;% to connect operations. Use functions glimpse, tail, head, View to have a look at the data. The skim function in the skimr package provides an approach to summary statistics. Use as.character, as.numeric, etc. to convert data to a different type. Use nrow and ncol functions to get the number of rows and columns of the data. The ‘Data transformation with dplyr’ cheatsheet is very useful. Find the newest version in RStudio Help &gt; Cheatsheets. You may also have a look at the slides for this module. 13.5 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Some of the solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up too early. Put some effort into finding a solution! Always practice using shortcuts in RStudio (see Tools &gt; Keyboard Shortcuts Help). Go to the Tools for Analytics workspace and download/export the TM13 project. Open it on your laptop and have a look at the files in the exercises folder which can be used as a starting point. 13.5.1 Exercise (gapminder) Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). The gapminder data set provides values for life expectancy, GDP per capita, and population, every five years, from 1952 to 2007 for 142 countries. The data can be loaded using the gapminder package: library(gapminder) data(gapminder, package = &quot;gapminder&quot;) gapminder #&gt; # A tibble: 1,704 × 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. #&gt; 2 Afghanistan Asia 1957 30.3 9240934 821. #&gt; 3 Afghanistan Asia 1962 32.0 10267083 853. #&gt; 4 Afghanistan Asia 1967 34.0 11537966 836. #&gt; 5 Afghanistan Asia 1972 36.1 13079460 740. #&gt; 6 Afghanistan Asia 1977 38.4 14880372 786. #&gt; 7 Afghanistan Asia 1982 39.9 12881816 978. #&gt; 8 Afghanistan Asia 1987 40.8 13867957 852. #&gt; 9 Afghanistan Asia 1992 41.7 16317921 649. #&gt; 10 Afghanistan Asia 1997 41.8 22227415 635. #&gt; # … with 1,694 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Let us try to examine the dataset (use pipes %&gt;% as much as possible). × Solution gapminder %&gt;% glimpse() #&gt; Rows: 1,704 #&gt; Columns: 6 #&gt; $ country &lt;fct&gt; &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afgh… #&gt; $ continent &lt;fct&gt; Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Europe, … #&gt; $ year &lt;int&gt; 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 2007, 1952, 19… #&gt; $ lifeExp &lt;dbl&gt; 28.8, 30.3, 32.0, 34.0, 36.1, 38.4, 39.9, 40.8, 41.7, 41.8, 42.1, 43.8, 55.2, 59… #&gt; $ pop &lt;int&gt; 8425333, 9240934, 10267083, 11537966, 13079460, 14880372, 12881816, 13867957, 16… #&gt; $ gdpPercap &lt;dbl&gt; 779, 821, 853, 836, 740, 786, 978, 852, 649, 635, 727, 975, 1601, 1942, 2313, 27… gapminder %&gt;% summary() #&gt; country continent year lifeExp pop #&gt; Afghanistan: 12 Africa :624 Min. :1952 Min. :23.6 Min. :6.00e+04 #&gt; Albania : 12 Americas:300 1st Qu.:1966 1st Qu.:48.2 1st Qu.:2.79e+06 #&gt; Algeria : 12 Asia :396 Median :1980 Median :60.7 Median :7.02e+06 #&gt; Angola : 12 Europe :360 Mean :1980 Mean :59.5 Mean :2.96e+07 #&gt; Argentina : 12 Oceania : 24 3rd Qu.:1993 3rd Qu.:70.8 3rd Qu.:1.96e+07 #&gt; Australia : 12 Max. :2007 Max. :82.6 Max. :1.32e+09 #&gt; (Other) :1632 #&gt; gdpPercap #&gt; Min. : 241 #&gt; 1st Qu.: 1202 #&gt; Median : 3532 #&gt; Mean : 7215 #&gt; 3rd Qu.: 9325 #&gt; Max. :113523 #&gt; gapminder %&gt;% tail() #&gt; # A tibble: 6 × 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Zimbabwe Africa 1982 60.4 7636524 789. #&gt; 2 Zimbabwe Africa 1987 62.4 9216418 706. #&gt; 3 Zimbabwe Africa 1992 60.4 10704340 693. #&gt; 4 Zimbabwe Africa 1997 46.8 11404948 792. #&gt; 5 Zimbabwe Africa 2002 40.0 11926563 672. #&gt; 6 Zimbabwe Africa 2007 43.5 12311143 470. Close Solution Use glimpse, summary and tail to examine the data. Use count to count the number of × Solution gapminder %&gt;% count(country) %&gt;% nrow() #&gt; [1] 142 Close Solution         a) countries, × Solution gapminder %&gt;% count(continent) %&gt;% nrow() #&gt; [1] 5 Close Solution         b) continents, × Solution gapminder %&gt;% count(continent, country) %&gt;% count(continent) # or #&gt; # A tibble: 5 × 2 #&gt; continent n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Africa 52 #&gt; 2 Americas 25 #&gt; 3 Asia 33 #&gt; 4 Europe 30 #&gt; 5 Oceania 2 gapminder %&gt;% distinct(continent, country) %&gt;% count(continent) #&gt; # A tibble: 5 × 2 #&gt; continent n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Africa 52 #&gt; 2 Americas 25 #&gt; 3 Asia 33 #&gt; 4 Europe 30 #&gt; 5 Oceania 2 Close Solution         c) countries per continent. × Solution gapminder %&gt;% distinct(continent) %&gt;% pull(continent) %&gt;% as.character() #&gt; [1] &quot;Asia&quot; &quot;Europe&quot; &quot;Africa&quot; &quot;Americas&quot; &quot;Oceania&quot; Close Solution × Hint gapminder %&gt;% distinct(___) %&gt;% pull(___) %&gt;% as.character() Close Hint Retrieve a vector with all distinct continent values. Subset rows to find: × Solution gapminder %&gt;% filter(lifeExp &lt; 29) #&gt; # A tibble: 2 × 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. #&gt; 2 Rwanda Africa 1992 23.6 7290203 737. Close Solution         a) all rows with life expectancy less that 29 years, × Solution gapminder %&gt;% filter(country == &quot;Rwanda&quot;, year &gt; 1979) #&gt; # A tibble: 6 × 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Rwanda Africa 1982 46.2 5507565 882. #&gt; 2 Rwanda Africa 1987 44.0 6349365 848. #&gt; 3 Rwanda Africa 1992 23.6 7290203 737. #&gt; 4 Rwanda Africa 1997 36.1 7212583 590. #&gt; 5 Rwanda Africa 2002 43.4 7852401 786. #&gt; 6 Rwanda Africa 2007 46.2 8860588 863. Close Solution         b) all rows for Rwanda after year 1979, × Solution gapminder %&gt;% filter(country %in% c(&quot;Rwanda&quot;, &quot;Afghanistan&quot;, &quot;France&quot;)) #&gt; # A tibble: 36 × 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. #&gt; 2 Afghanistan Asia 1957 30.3 9240934 821. #&gt; 3 Afghanistan Asia 1962 32.0 10267083 853. #&gt; 4 Afghanistan Asia 1967 34.0 11537966 836. #&gt; 5 Afghanistan Asia 1972 36.1 13079460 740. #&gt; 6 Afghanistan Asia 1977 38.4 14880372 786. #&gt; 7 Afghanistan Asia 1982 39.9 12881816 978. #&gt; 8 Afghanistan Asia 1987 40.8 13867957 852. #&gt; 9 Afghanistan Asia 1992 41.7 16317921 649. #&gt; 10 Afghanistan Asia 1997 41.8 22227415 635. #&gt; # … with 26 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Close Solution         c) all rows for Rwanda, Afghanistan or France. Select columns × Solution gapminder %&gt;% select(year, lifeExp) #&gt; # A tibble: 1,704 × 2 #&gt; year lifeExp #&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1952 28.8 #&gt; 2 1957 30.3 #&gt; 3 1962 32.0 #&gt; 4 1967 34.0 #&gt; 5 1972 36.1 #&gt; 6 1977 38.4 #&gt; 7 1982 39.9 #&gt; 8 1987 40.8 #&gt; 9 1992 41.7 #&gt; 10 1997 41.8 #&gt; # … with 1,694 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Close Solution         a) year and life expectancy, × Solution gapminder %&gt;% select(country, gdpPercap) #&gt; # A tibble: 1,704 × 2 #&gt; country gdpPercap #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 Afghanistan 779. #&gt; 2 Afghanistan 821. #&gt; 3 Afghanistan 853. #&gt; 4 Afghanistan 836. #&gt; 5 Afghanistan 740. #&gt; 6 Afghanistan 786. #&gt; 7 Afghanistan 978. #&gt; 8 Afghanistan 852. #&gt; 9 Afghanistan 649. #&gt; 10 Afghanistan 635. #&gt; # … with 1,694 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Close Solution         b) country and GDP per capita. × Solution gapminder %&gt;% filter((gdpPercap &gt; 40000 &amp; continent == &quot;Europe&quot;) | (gdpPercap &lt; 400 &amp; continent == &quot;Africa&quot;)) %&gt;% # print(n=Inf) %&gt;% # if want to see the intermediate results select(continent, country, gdpPercap) # %&gt;% print(n=Inf) #&gt; # A tibble: 21 × 3 #&gt; continent country gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 Africa Burundi 339. #&gt; 2 Africa Burundi 380. #&gt; 3 Africa Burundi 355. #&gt; 4 Africa Congo, Dem. Rep. 312. #&gt; 5 Africa Congo, Dem. Rep. 241. #&gt; 6 Africa Congo, Dem. Rep. 278. #&gt; 7 Africa Equatorial Guinea 376. #&gt; 8 Africa Eritrea 329. #&gt; 9 Africa Eritrea 344. #&gt; 10 Africa Eritrea 381. #&gt; # … with 11 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Close Solution × Hint gapminder %&gt;% filter((gdpPercap &gt; ___ &amp; continent == ___) | (___)) %&gt;% # print(n=Inf) %&gt;% # if want to see the intermediate results select(continent, ___, ___) # %&gt;% print(n=Inf) Close Hint Subset your data set to find all rows with GDP per capita greater than 40000 in Europe or with GDP per capita less than 500 in Africa. × Solution gapminder %&gt;% mutate(gdp = pop * gdpPercap) #&gt; # A tibble: 1,704 × 7 #&gt; country continent year lifeExp pop gdpPercap gdp #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. 6567086330. #&gt; 2 Afghanistan Asia 1957 30.3 9240934 821. 7585448670. #&gt; 3 Afghanistan Asia 1962 32.0 10267083 853. 8758855797. #&gt; 4 Afghanistan Asia 1967 34.0 11537966 836. 9648014150. #&gt; 5 Afghanistan Asia 1972 36.1 13079460 740. 9678553274. #&gt; 6 Afghanistan Asia 1977 38.4 14880372 786. 11697659231. #&gt; 7 Afghanistan Asia 1982 39.9 12881816 978. 12598563401. #&gt; 8 Afghanistan Asia 1987 40.8 13867957 852. 11820990309. #&gt; 9 Afghanistan Asia 1992 41.7 16317921 649. 10595901589. #&gt; 10 Afghanistan Asia 1997 41.8 22227415 635. 14121995875. #&gt; # … with 1,694 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Close Solution Use mutate to calculate each country’s GDP (population times GDP per capita). In general GDP numbers are large and abstract. Let us try to calculate relative numbers. × Solution mean_dk &lt;- gapminder %&gt;% filter(country == &quot;Denmark&quot;) %&gt;% pull(gdpPercap) %&gt;% mean() dat &lt;- gapminder %&gt;% mutate(gdpPercapRel = gdpPercap/mean_dk) The relative GDP per capita numbers are, in general, well below 1. We see that most of the countries covered by this dataset have substantially lower GDP per capita, relative to Denmark, across the entire time period. Close Solution × Hint 2 dat &lt;- gapminder %&gt;% mutate(gdpPercapRel = ___) Close Hint 2 × Hint 1 mean_dk &lt;- gapminder %&gt;% filter(country == &quot;Denmark&quot;) %&gt;% pull(___) %&gt;% mean() First you must calculate the mean of Danish gdpPercap and next use that to add a new column gdpPercapRel. Close Hint 1 Use mutate to calculate GDP per capita relative to mean GDP per capita in Denmark over the whole period (gdpPercap divided by the mean of Danish gdpPercap). Have a look at the calculated data. Does the numbers seem reasonable? I perceive Denmark to be a “high GDP” country, so I predict that the distribution of gdpPercapRel is located below 1, possibly even well below. Use arrange to order × Solution gapminder %&gt;% arrange(year, country) #&gt; # A tibble: 1,704 × 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. #&gt; 2 Albania Europe 1952 55.2 1282697 1601. #&gt; 3 Algeria Africa 1952 43.1 9279525 2449. #&gt; 4 Angola Africa 1952 30.0 4232095 3521. #&gt; 5 Argentina Americas 1952 62.5 17876956 5911. #&gt; 6 Australia Oceania 1952 69.1 8691212 10040. #&gt; 7 Austria Europe 1952 66.8 6927772 6137. #&gt; 8 Bahrain Asia 1952 50.9 120447 9867. #&gt; 9 Bangladesh Asia 1952 37.5 46886859 684. #&gt; 10 Belgium Europe 1952 68 8730405 8343. #&gt; # … with 1,694 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Close Solution         a) data by year then country, as opposed to current by country then year, × Solution gapminder %&gt;% filter(year == 2007) %&gt;% arrange(lifeExp) #&gt; # A tibble: 142 × 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Swaziland Africa 2007 39.6 1133066 4513. #&gt; 2 Mozambique Africa 2007 42.1 19951656 824. #&gt; 3 Zambia Africa 2007 42.4 11746035 1271. #&gt; 4 Sierra Leone Africa 2007 42.6 6144562 863. #&gt; 5 Lesotho Africa 2007 42.6 2012649 1569. #&gt; 6 Angola Africa 2007 42.7 12420476 4797. #&gt; 7 Zimbabwe Africa 2007 43.5 12311143 470. #&gt; 8 Afghanistan Asia 2007 43.8 31889923 975. #&gt; 9 Central African Republic Africa 2007 44.7 4369038 706. #&gt; 10 Liberia Africa 2007 45.7 3193942 415. #&gt; # … with 132 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Close Solution         b) data from 2007, sorted on life expectancy, × Solution gapminder %&gt;% filter(year == 2007) %&gt;% arrange(desc(lifeExp)) #&gt; # A tibble: 142 × 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Japan Asia 2007 82.6 127467972 31656. #&gt; 2 Hong Kong, China Asia 2007 82.2 6980412 39725. #&gt; 3 Iceland Europe 2007 81.8 301931 36181. #&gt; 4 Switzerland Europe 2007 81.7 7554661 37506. #&gt; 5 Australia Oceania 2007 81.2 20434176 34435. #&gt; 6 Spain Europe 2007 80.9 40448191 28821. #&gt; 7 Sweden Europe 2007 80.9 9031088 33860. #&gt; 8 Israel Asia 2007 80.7 6426679 25523. #&gt; 9 France Europe 2007 80.7 61083916 30470. #&gt; 10 Canada Americas 2007 80.7 33390141 36319. #&gt; # … with 132 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Close Solution         c) data from 2007, sorted on life expectancy in descending order. Hint: use desc() inside arrange. Use select to × Solution gapminder %&gt;% select(yr = year, everything()) #&gt; # A tibble: 1,704 × 6 #&gt; yr country continent lifeExp pop gdpPercap #&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1952 Afghanistan Asia 28.8 8425333 779. #&gt; 2 1957 Afghanistan Asia 30.3 9240934 821. #&gt; 3 1962 Afghanistan Asia 32.0 10267083 853. #&gt; 4 1967 Afghanistan Asia 34.0 11537966 836. #&gt; 5 1972 Afghanistan Asia 36.1 13079460 740. #&gt; 6 1977 Afghanistan Asia 38.4 14880372 786. #&gt; 7 1982 Afghanistan Asia 39.9 12881816 978. #&gt; 8 1987 Afghanistan Asia 40.8 13867957 852. #&gt; 9 1992 Afghanistan Asia 41.7 16317921 649. #&gt; 10 1997 Afghanistan Asia 41.8 22227415 635. #&gt; # … with 1,694 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Close Solution         a) rename year to yr and keep all other columns (the select helper everything may be used), × Solution gapminder %&gt;% select(-pop) #&gt; # A tibble: 1,704 × 5 #&gt; country continent year lifeExp gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 779. #&gt; 2 Afghanistan Asia 1957 30.3 821. #&gt; 3 Afghanistan Asia 1962 32.0 853. #&gt; 4 Afghanistan Asia 1967 34.0 836. #&gt; 5 Afghanistan Asia 1972 36.1 740. #&gt; 6 Afghanistan Asia 1977 38.4 786. #&gt; 7 Afghanistan Asia 1982 39.9 978. #&gt; 8 Afghanistan Asia 1987 40.8 852. #&gt; 9 Afghanistan Asia 1992 41.7 649. #&gt; 10 Afghanistan Asia 1997 41.8 635. #&gt; # … with 1,694 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Close Solution         b) remove pop, × Solution gapminder %&gt;% select(year, pop, everything()) #&gt; # A tibble: 1,704 × 6 #&gt; year pop country continent lifeExp gdpPercap #&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1952 8425333 Afghanistan Asia 28.8 779. #&gt; 2 1957 9240934 Afghanistan Asia 30.3 821. #&gt; 3 1962 10267083 Afghanistan Asia 32.0 853. #&gt; 4 1967 11537966 Afghanistan Asia 34.0 836. #&gt; 5 1972 13079460 Afghanistan Asia 36.1 740. #&gt; 6 1977 14880372 Afghanistan Asia 38.4 786. #&gt; 7 1982 12881816 Afghanistan Asia 39.9 978. #&gt; 8 1987 13867957 Afghanistan Asia 40.8 852. #&gt; 9 1992 16317921 Afghanistan Asia 41.7 649. #&gt; 10 1997 22227415 Afghanistan Asia 41.8 635. #&gt; # … with 1,694 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Close Solution         c) reorder columns in order year, pop, … (remaining). Use group_by and summarize to find the × Solution gapminder %&gt;% group_by(continent) %&gt;% summarize(n = n()) #&gt; # A tibble: 5 × 2 #&gt; continent n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Africa 624 #&gt; 2 Americas 300 #&gt; 3 Asia 396 #&gt; 4 Europe 360 #&gt; 5 Oceania 24 Close Solution         a) number of observations per continent, × Solution gapminder %&gt;% group_by(continent) %&gt;% summarize(n = n(), n_countries = n_distinct(country)) #&gt; # A tibble: 5 × 3 #&gt; continent n n_countries #&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Africa 624 52 #&gt; 2 Americas 300 25 #&gt; 3 Asia 396 33 #&gt; 4 Europe 360 30 #&gt; 5 Oceania 24 2 Close Solution         b) number of countries per continent (use n_distinct inside summarize to count the number of distinct observations), × Solution gapminder %&gt;% group_by(continent) %&gt;% summarize(avg_lifeExp = mean(lifeExp)) #&gt; # A tibble: 5 × 2 #&gt; continent avg_lifeExp #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 Africa 48.9 #&gt; 2 Americas 64.7 #&gt; 3 Asia 60.1 #&gt; 4 Europe 71.9 #&gt; 5 Oceania 74.3 Close Solution         c) average life expectancy by continent, × Solution gapminder %&gt;% filter(continent == &quot;Asia&quot;) %&gt;% group_by(year) %&gt;% summarize(min_lifeExp = min(lifeExp), max_lifeExp = max(lifeExp)) #&gt; # A tibble: 12 × 3 #&gt; year min_lifeExp max_lifeExp #&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1952 28.8 65.4 #&gt; 2 1957 30.3 67.8 #&gt; 3 1962 32.0 69.4 #&gt; 4 1967 34.0 71.4 #&gt; 5 1972 36.1 73.4 #&gt; 6 1977 31.2 75.4 #&gt; 7 1982 39.9 77.1 #&gt; 8 1987 40.8 78.7 #&gt; 9 1992 41.7 79.4 #&gt; 10 1997 41.8 80.7 #&gt; 11 2002 42.1 82 #&gt; 12 2007 43.8 82.6 Close Solution         d) minimum and maximum life expectancies seen by year in Asia. × Solution gapminder %&gt;% group_by(country) %&gt;% # group by country select(country, year, lifeExp) %&gt;% # select relevant columns arrange(year, .by_group = TRUE) %&gt;% # make sure that data is sorted correct mutate(lifeExp_gain = lifeExp - first(lifeExp)) %&gt;% filter(year &lt; 1963) # just for nice printing #&gt; # A tibble: 426 × 4 #&gt; # Groups: country [142] #&gt; country year lifeExp lifeExp_gain #&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Afghanistan 1952 28.8 0 #&gt; 2 Afghanistan 1957 30.3 1.53 #&gt; 3 Afghanistan 1962 32.0 3.20 #&gt; 4 Albania 1952 55.2 0 #&gt; 5 Albania 1957 59.3 4.05 #&gt; 6 Albania 1962 64.8 9.59 #&gt; 7 Algeria 1952 43.1 0 #&gt; 8 Algeria 1957 45.7 2.61 #&gt; 9 Algeria 1962 48.3 5.23 #&gt; 10 Angola 1952 30.0 0 #&gt; # … with 416 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Close Solution × Hint gapminder %&gt;% group_by(country) %&gt;% # group by country select(country, year, lifeExp) %&gt;% # select relevant columns arrange(year, .by_group = TRUE) %&gt;% # make sure that data is sorted correct mutate(lifeExp_gain = ___) %&gt;% # define new variable filter(year &lt; 1963) # just for nice printing The first function may be helpful to extract the first value from a vector in each group. Close Hint Sometimes you do not want to collapse the \\(n\\) rows for each group into one row. That is, you do not want to use summarize but mutate within your groups. Try to make a new variable that is the years of life expectancy gained (lost) relative to 1952, for each individual country. × Solution gapminder %&gt;% select(country, year, continent, lifeExp) %&gt;% group_by(continent, country) %&gt;% mutate(le_delta = lifeExp - lag(lifeExp)) %&gt;% summarize(worst_le_delta = min(le_delta, na.rm = TRUE)) %&gt;% slice_min(worst_le_delta) %&gt;% arrange(worst_le_delta) #&gt; # A tibble: 5 × 3 #&gt; # Groups: continent [5] #&gt; continent country worst_le_delta #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 Africa Rwanda -20.4 #&gt; 2 Asia Cambodia -9.10 #&gt; 3 Americas El Salvador -1.51 #&gt; 4 Europe Montenegro -1.46 #&gt; 5 Oceania Australia 0.170 Mostly you are seeing what genocide looks like in dry statistics on average life expectancy. Close Solution × Hint gapminder %&gt;% select(country, year, continent, lifeExp) %&gt;% # select relevant columns group_by(continent, country) %&gt;% # group mutate(le_delta = ___) %&gt;% # within country, take (lifeExp in year i) - (lifeExp in year i - 1) summarize(worst_le_delta = min(___, na.rm = TRUE)) %&gt;% # find lowest value slice_min(worst_le_delta) %&gt;% # find min in each continent arrange(worst_le_delta) # arrange The lag function is useful to select the value in the previous row. Positive values of le_delta means lifeExp went up, negative means it went down. Break the code into pieces, starting at the top, and inspect the intermediate results. These commands are built up gradually, with lots of errors and refinements along the way. Close Hint Which country experienced the sharpest 5-year drop in life expectancy in each continent? Recall that the Gapminder data only has data every five years, e.g. for 1952, 1957, etc. So this really means looking at life expectancy changes between adjacent timepoints. 13.5.2 Exercise (babynames) Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). The package babynames contains the dataset babynames provided by the U.S. Social Security Administration. For each year from 1880 to 2017, the number of children of each sex given each name. All names with more than 5 uses are given (source: http://www.ssa.gov/oact/babynames/limits.html). Install it using install.packages(&quot;babynames&quot;) We will use the skimr package to get an overview over babynames: library(babynames) library(skimr) skim(babynames) Table 13.1: Data summary Name babynames Number of rows 1924665 Number of columns 5 _______________________ Column type frequency: character 2 numeric 3 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace sex 0 1 1 1 0 2 0 name 0 1 2 15 0 97310 0 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist year 0 1 1975 34 1880 1951 1985 2003 2017.00 ▁▂▃▅▇ n 0 1 181 1533 5 7 12 32 99686.00 ▇▁▁▁▁ prop 0 1 0 0 0 0 0 0 0.08 ▇▁▁▁▁ × Solution The last line only selects the n column. Close Solution Which of these is NOT a way to select the name and n columns together? select(babynames, -c(year, sex, prop)) select(babynames, name:n) select(babynames, starts_with(&quot;n&quot;)) select(babynames, ends_with(&quot;n&quot;)) Use filter and the logical operators to find: × Solution babynames %&gt;% filter(prop &gt;= 0.08) #&gt; # A tibble: 3 × 5 #&gt; year sex name n prop #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1880 M John 9655 0.0815 #&gt; 2 1880 M William 9532 0.0805 #&gt; 3 1881 M John 8769 0.0810 Close Solution         a) all of the names where prop is greater than or equal to 0.08, × Solution babynames %&gt;% filter(name == &quot;Sea&quot;) #&gt; # A tibble: 4 × 5 #&gt; year sex name n prop #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1982 F Sea 5 0.00000276 #&gt; 2 1985 M Sea 6 0.00000312 #&gt; 3 1986 M Sea 5 0.0000026 #&gt; 4 1998 F Sea 5 0.00000258 Close Solution         b) all of the children named “Sea”. Use Boolean operators to return only the rows that contain: × Solution babynames %&gt;% filter(name == &quot;Sue&quot;, sex == &quot;M&quot;) #&gt; # A tibble: 52 × 5 #&gt; year sex name n prop #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1917 M Sue 7 0.0000073 #&gt; 2 1927 M Sue 5 0.0000043 #&gt; 3 1928 M Sue 5 0.00000438 #&gt; 4 1930 M Sue 5 0.00000443 #&gt; 5 1931 M Sue 6 0.00000561 #&gt; 6 1932 M Sue 7 0.00000652 #&gt; 7 1933 M Sue 7 0.00000686 #&gt; 8 1934 M Sue 14 0.0000132 #&gt; 9 1935 M Sue 13 0.0000122 #&gt; 10 1936 M Sue 9 0.00000846 #&gt; # … with 42 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Close Solution         a) boys named Sue, × Solution babynames %&gt;% filter(year == 1880, n == 5 | n == 6) #&gt; # A tibble: 455 × 5 #&gt; year sex name n prop #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1880 F Abby 6 0.0000615 #&gt; 2 1880 F Aileen 6 0.0000615 #&gt; 3 1880 F Alba 6 0.0000615 #&gt; 4 1880 F Alda 6 0.0000615 #&gt; 5 1880 F Alla 6 0.0000615 #&gt; 6 1880 F Alverta 6 0.0000615 #&gt; 7 1880 F Ara 6 0.0000615 #&gt; 8 1880 F Ardelia 6 0.0000615 #&gt; 9 1880 F Ardella 6 0.0000615 #&gt; 10 1880 F Arrie 6 0.0000615 #&gt; # … with 445 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Close Solution         b) names that were used by exactly 5 or 6 children in 1880, × Solution babynames %&gt;% filter(name %in% c(&quot;Acura&quot;, &quot;Lexus&quot;, &quot;Yugo&quot;)) #&gt; # A tibble: 57 × 5 #&gt; year sex name n prop #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1990 F Lexus 36 0.0000175 #&gt; 2 1990 M Lexus 12 0.00000558 #&gt; 3 1991 F Lexus 102 0.0000502 #&gt; 4 1991 M Lexus 16 0.00000755 #&gt; 5 1992 F Lexus 193 0.0000963 #&gt; 6 1992 M Lexus 25 0.0000119 #&gt; 7 1993 F Lexus 285 0.000145 #&gt; 8 1993 M Lexus 30 0.0000145 #&gt; 9 1994 F Lexus 381 0.000195 #&gt; 10 1994 F Acura 6 0.00000308 #&gt; # … with 47 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Close Solution         c) names that are one of Acura, Lexus, or Yugo. × Solution min(babynames$n) #&gt; [1] 5 max(babynames$n) #&gt; [1] 99686 Close Solution What is the smallest value of n? What is the largest? × Solution babynames %&gt;% filter(sex == &quot;F&quot;, year == 2017) %&gt;% select(name, n) %&gt;% arrange(desc(n)) #&gt; # A tibble: 18,309 × 2 #&gt; name n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Emma 19738 #&gt; 2 Olivia 18632 #&gt; 3 Ava 15902 #&gt; 4 Isabella 15100 #&gt; 5 Sophia 14831 #&gt; 6 Mia 13437 #&gt; 7 Charlotte 12893 #&gt; 8 Amelia 11800 #&gt; 9 Evelyn 10675 #&gt; 10 Abigail 10551 #&gt; # … with 18,299 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Close Solution × Hint babynames %&gt;% filter(___) %&gt;% select(name, n) %&gt;% arrange(desc(___)) Close Hint Write a sequence of functions that filters babynames to just the girls that were born in 2017, then select the name and n columns, then arrange the results so that the most popular names are near the top. × Solution # for instance babynames %&gt;% filter(sex == &quot;M&quot;, name == &quot;Lars&quot;) #&gt; # A tibble: 112 × 5 #&gt; year sex name n prop #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1883 M Lars 7 0.0000622 #&gt; 2 1884 M Lars 5 0.0000407 #&gt; 3 1886 M Lars 5 0.000042 #&gt; 4 1887 M Lars 5 0.0000457 #&gt; 5 1897 M Lars 5 0.000041 #&gt; 6 1901 M Lars 8 0.0000692 #&gt; 7 1912 M Lars 6 0.0000133 #&gt; 8 1913 M Lars 6 0.0000112 #&gt; 9 1914 M Lars 16 0.0000234 #&gt; 10 1915 M Lars 17 0.0000193 #&gt; # … with 102 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Close Solution Trim babynames to just the rows that contain your name and your sex. × Solution babynames %&gt;% filter(name == &quot;Khaleesi&quot;) %&gt;% summarise(total = sum(n), first = min(year)) #&gt; # A tibble: 1 × 2 #&gt; total first #&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1964 2011 Close Solution × Hint babynames ___ filter(____) ___ ____(total = ___, first = ___) Close Hint Extract the rows where name == \"Khaleesi\". Then use summarise() to find the total number of children named Khaleesi and the first year Khaleesi appeared in the data. × Solution babynames %&gt;% group_by(name, sex) %&gt;% summarize(total = sum(n)) %&gt;% arrange(desc(total)) #&gt; # A tibble: 107,973 × 3 #&gt; # Groups: name [97,310] #&gt; name sex total #&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 James M 5150472 #&gt; 2 John M 5115466 #&gt; 3 Robert M 4814815 #&gt; 4 Michael M 4350824 #&gt; 5 Mary F 4123200 #&gt; 6 William M 4102604 #&gt; 7 David M 3611329 #&gt; 8 Joseph M 2603445 #&gt; 9 Richard M 2563082 #&gt; 10 Charles M 2386048 #&gt; # … with 107,963 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Close Solution × Hint babynames %&gt;% _______(name, sex) %&gt;% _______(total = _____(n)) %&gt;% _______(desc(_____)) Close Hint Use group_by(), summarise(), and arrange() to display the ten most popular names. Compute popularity as the total number of children of a single gender given a name. × Solution babynames %&gt;% group_by(year) %&gt;% summarise(total = sum(n)) #&gt; # A tibble: 138 × 2 #&gt; year total #&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 1880 201484 #&gt; 2 1881 192696 #&gt; 3 1882 221533 #&gt; 4 1883 216946 #&gt; 5 1884 243462 #&gt; 6 1885 240854 #&gt; 7 1886 255317 #&gt; 8 1887 247394 #&gt; 9 1888 299473 #&gt; 10 1889 288946 #&gt; # … with 128 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Close Solution Use group_by() to calculate the total number of children born each year over time. × Solution babynames %&gt;% group_by(year, sex) %&gt;% mutate(rank = min_rank(desc(n))) %&gt;% arrange(year, sex, desc(prop)) #&gt; # A tibble: 1,924,665 × 6 #&gt; # Groups: year, sex [276] #&gt; year sex name n prop rank #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 1880 F Mary 7065 0.0724 1 #&gt; 2 1880 F Anna 2604 0.0267 2 #&gt; 3 1880 F Emma 2003 0.0205 3 #&gt; 4 1880 F Elizabeth 1939 0.0199 4 #&gt; 5 1880 F Minnie 1746 0.0179 5 #&gt; 6 1880 F Margaret 1578 0.0162 6 #&gt; 7 1880 F Ida 1472 0.0151 7 #&gt; 8 1880 F Alice 1414 0.0145 8 #&gt; 9 1880 F Bertha 1320 0.0135 9 #&gt; 10 1880 F Sarah 1288 0.0132 10 #&gt; # … with 1,924,655 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows The same results if you use n since in the same order. Close Solution × Hint babynames %&gt;% group_by(___, ___) %&gt;% ___(rank = ___(desc(___))) %&gt;% arrange(year, sex, desc(prop)) Close Hint Column prop denotes the proportion given year and sex. Use mutate() and min_rank() to rank each row in babynames from largest prop to lowest prop given year and sex. What happens if you do the same using the n column? × Solution babynames %&gt;% group_by(year, sex) %&gt;% mutate(rank = min_rank(desc(n))) %&gt;% filter(rank == 1, year &gt; 2009) #&gt; # A tibble: 16 × 6 #&gt; # Groups: year, sex [16] #&gt; year sex name n prop rank #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 2010 F Isabella 22905 0.0117 1 #&gt; 2 2010 M Jacob 22117 0.0108 1 #&gt; 3 2011 F Sophia 21837 0.0113 1 #&gt; 4 2011 M Jacob 20365 0.0100 1 #&gt; 5 2012 F Sophia 22304 0.0115 1 #&gt; 6 2012 M Jacob 19069 0.00941 1 #&gt; 7 2013 F Sophia 21213 0.0110 1 #&gt; 8 2013 M Noah 18241 0.00904 1 #&gt; 9 2014 F Emma 20924 0.0107 1 #&gt; 10 2014 M Noah 19286 0.00943 1 #&gt; 11 2015 F Emma 20435 0.0105 1 #&gt; 12 2015 M Noah 19613 0.00962 1 #&gt; 13 2016 F Emma 19471 0.0101 1 #&gt; 14 2016 M Noah 19082 0.00946 1 #&gt; 15 2017 F Emma 19738 0.0105 1 #&gt; 16 2017 M Liam 18728 0.00954 1 Close Solution Filter the results to find all names with rank == 1 after 2009. 13.5.3 Exercise (profit) Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). Consider the dataset profit containing quarterly financial records for each costumer, product, etc.: library(skimr) path &lt;- system.file(&quot;extdata/profit_raw.csv&quot;, package = &quot;tfa&quot;) profit &lt;- read_csv(path) skim(profit) Table 13.2: Data summary Name profit Number of rows 24546 Number of columns 9 _______________________ Column type frequency: character 9 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace Quarter 0 1 1 2 0 12 0 Channel 0 1 3 3 0 10 0 Customer ID 0 1 3 3 0 18 0 Country 0 1 3 14 0 47 0 Product Line 0 1 14 25 0 6 0 Revenue 63 1 1 7 0 1210 0 Product Cost 61 1 3 6 0 1139 0 Customer Service Cost 10 1 1 6 0 464 0 Profit 0 1 3 7 0 966 0 Note that it seems that the dataset need to be cleaned. All columns are strings (some should be numbers) and there seems to be missing values. You may start by having a view of the dataset using: View(profit) First focus on column Quarter which currently has 12 distinct values: profit %&gt;% distinct(Quarter) #&gt; # A tibble: 12 × 1 #&gt; Quarter #&gt; &lt;chr&gt; #&gt; 1 Q3 #&gt; 2 1 #&gt; 3 Q4 #&gt; 4 Q1 #&gt; 5 Q2 #&gt; 6 2 #&gt; 7 4 #&gt; 8 q1 #&gt; 9 q4 #&gt; 10 q3 #&gt; 11 q2 #&gt; 12 3 You would like it to be a numeric with values 1-4. × Solution profit &lt;- profit %&gt;% mutate(Quarter = str_remove(Quarter, &quot;q&quot;) %&gt;% str_remove(&quot;Q&quot;) %&gt;% as.numeric()) profit %&gt;% distinct(Quarter) #&gt; # A tibble: 4 × 1 #&gt; Quarter #&gt; &lt;dbl&gt; #&gt; 1 3 #&gt; 2 1 #&gt; 3 4 #&gt; 4 2 Close Solution × Hint profit &lt;- profit %&gt;% mutate(Quarter = str_remove(___, &quot;q&quot;) %&gt;% str_remove(___) %&gt;% as.numeric()) profit %&gt;% distinct(Quarter) Close Hint Use mutate, str_remove and as.numeric to convert the column to a numeric by removing all ‘q’ and ‘Q’ values. Let us look at the next columns: profit %&gt;% distinct(Channel) %&gt;% pull() #&gt; [1] &quot;ATM&quot; &quot;BRH&quot; &quot;INT&quot; &quot;MAL&quot; &quot;EML&quot; &quot;CCT&quot; &quot;TEL&quot; &quot;MOP&quot; &quot;DSA&quot; &quot;EVE&quot; profit %&gt;% distinct(`Customer ID`) %&gt;% pull() #&gt; [1] &quot;FRT&quot; &quot;MRT&quot; &quot;PBI&quot; &quot;MAM&quot; &quot;EBP&quot; &quot;RPB&quot; &quot;WEB&quot; &quot;WEM&quot; &quot;HEC&quot; &quot;STF&quot; &quot;IAS&quot; &quot;CRE&quot; &quot;INB&quot; &quot;CAM&quot; &quot;AGR&quot; &quot;SBE&quot; #&gt; [17] &quot;AFF&quot; &quot;MFN&quot; profit %&gt;% distinct(Country) %&gt;% pull() #&gt; [1] &quot;USA&quot; &quot;Canada&quot; &quot;Great Britain&quot; &quot;Finland&quot; &quot;New Zealand&quot; #&gt; [6] &quot;Brazil&quot; &quot;Mexico&quot; &quot;Germany&quot; &quot;Puerto Rico&quot; &quot;Hong Kong&quot; #&gt; [11] &quot;Japan&quot; &quot;Columbia&quot; &quot;Switzerland&quot; &quot;Uruguay&quot; &quot;Netherlands&quot; #&gt; [16] &quot;Korea&quot; &quot;Venezuela&quot; &quot;Panama&quot; &quot;Sweden&quot; &quot;China&quot; #&gt; [21] &quot;Guatemala&quot; &quot;South Africa&quot; &quot;Malaysia&quot; &quot;Nigeria&quot; &quot;Denmark&quot; #&gt; [26] &quot;France&quot; &quot;India&quot; &quot;Taiwan&quot; &quot;Norway&quot; &quot;Chile&quot; #&gt; [31] &quot;Indonesia&quot; &quot;Ireland&quot; &quot;Thailand&quot; &quot;Peru&quot; &quot;Spain&quot; #&gt; [36] &quot;Belgium&quot; &quot;Poland&quot; &quot;Ecuador&quot; &quot;Costa Rica&quot; &quot;Australia&quot; #&gt; [41] &quot;Israel&quot; &quot;Guam&quot; &quot;Oman&quot; &quot;Singapore&quot; &quot;Argentina&quot; #&gt; [46] &quot;Czechoslovakia&quot; &quot;Philippines&quot; profit %&gt;% distinct(`Product Line`) %&gt;% pull() #&gt; [1] &quot;Credit Products&quot; &quot;Deposit Products&quot; &quot;Revolving Credit Products&quot; #&gt; [4] &quot;Other Products&quot; &quot;Third Party Products&quot; &quot;Fee Based Products&quot; These seem to be okay. The last columns should be numbers. Let us consider Revenue. profit %&gt;% distinct(Revenue) %&gt;% pull() %&gt;% head(n = 100) #&gt; [1] &quot;$ 6044&quot; &quot;$ 4686&quot; &quot;$ 6063&quot; &quot;$ 4682&quot; &quot;$ 6320&quot; &quot;$ 2993&quot; &quot;$ 3355&quot; &quot;$ 5716&quot; &quot;$ 3347&quot; #&gt; [10] &quot;$ 2624&quot; &quot;$ 3629&quot; &quot;$ 5612&quot; &quot;$ 4618&quot; &quot;$ 2080&quot; &quot;$ 2788&quot; &quot;$ 2829&quot; &quot;$ 2898&quot; &quot;$ 5232&quot; #&gt; [19] &quot;$ 2949&quot; &quot;$ 5565&quot; &quot;$ 2153&quot; &quot;$ 3097&quot; &quot;$ 1920&quot; &quot;$ 4041&quot; &quot;$ 5931&quot; &quot;$ 1605&quot; &quot;$ 2026&quot; #&gt; [28] &quot;$ 1687&quot; &quot;$ 5075&quot; &quot;$ 4223&quot; &quot;$ 2456&quot; &quot;$ 1924&quot; &quot;$ 1578&quot; &quot;$ 3235&quot; &quot;$ 5123&quot; &quot;$ 1560&quot; #&gt; [37] &quot;$ 1945&quot; &quot;$ 6060&quot; &quot;$ 1222&quot; &quot;$ 1660&quot; &quot;$ 3000&quot; &quot;$ 2970&quot; &quot;$ 1631&quot; &quot;$ 1215&quot; &quot;$ 1759&quot; #&gt; [46] &quot;$ 3285&quot; &quot;$ 2048&quot; &quot;$ 2173&quot; &quot;$ 3353&quot; &quot;$ 1162&quot; &quot;$ 1232&quot; &quot;$ 1561&quot; &quot;$ 1123&quot; &quot;$ 1794&quot; #&gt; [55] &quot;$ 1202&quot; &quot;$ 1510&quot; &quot;$ 4472&quot; &quot;$ 2370&quot; &quot;$ 2581&quot; &quot;$ 2761&quot; &quot;$ 6371&quot; &quot;$ 1972&quot; &quot;$ 1562&quot; #&gt; [64] &quot;$ 2742&quot; &quot;$ 4598&quot; &quot;$ 5322&quot; &quot;$ 3411&quot; NA &quot;$ 1569&quot; &quot;$ 2852&quot; &quot;$ 1622&quot; &quot;$ 2505&quot; #&gt; [73] &quot;$ 1596&quot; &quot;$ 1447&quot; &quot;$ 1690&quot; &quot;$ 2448&quot; &quot;$ 1593&quot; &quot;$ 1876&quot; &quot;$ 6591&quot; &quot;$ 1611&quot; &quot;$ 1254&quot; #&gt; [82] &quot;Unknown&quot; &quot;$ 842&quot; &quot;$ 1529&quot; &quot;$ 1439&quot; &quot;$ 762&quot; &quot;$ 1959&quot; &quot;$ 4382&quot; &quot;$ 1407&quot; &quot;$ 909&quot; #&gt; [91] &quot;$ 1549&quot; &quot;$ 2161&quot; &quot;$ 1331&quot; &quot;$ 727&quot; &quot;$ 1462&quot; &quot;$ 1067&quot; &quot;$ 833&quot; &quot;$ 1675&quot; &quot;$ 1524&quot; #&gt; [100] &quot;$ 1285&quot; Most values start with a dollar sign. Let us have a look at the other ones: profit %&gt;% filter(!str_starts(Revenue, fixed(&quot;$&quot;))) #&gt; # A tibble: 95 × 9 #&gt; Quarter Channel `Customer ID` Country `Product Line` Revenue Produ…¹ Custo…² Profit #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 3 INT MAM USA Deposit Products Unknown $ 1008 $ 246 $ 418 #&gt; 2 3 MAL RPB USA Credit Products ? $ 1420 $ 347 $ 30 #&gt; 3 1 MAL WEM Great Britain Other Products ? $ 87 $ 19 $ -34 #&gt; 4 3 ATM MFN Germany Fee Based Products unknown $ 47 $ 6 $ 9 #&gt; 5 3 ATM PBI Costa Rica Third Party Products Unknown $ 51 $ 9 $ 6 #&gt; 6 1 ATM PBI Chile Deposit Products Unknown $ 58 $ 7 $ -9 #&gt; 7 4 CCT MRT Great Britain Revolving Credit Prod… ? $ 27 $ 5 $ 16 #&gt; 8 4 ATM MAM Taiwan Third Party Products unknown $ 55 $ 9 $ 75 #&gt; 9 4 MAL WEB Japan Other Products unknown $ 40 $ 7 $ 17 #&gt; 10 2 CCT MAM Netherlands Credit Products unknown $ 14 $ 3 $ 20 #&gt; # … with 85 more rows, and abbreviated variable names ¹​`Product Cost`, ²​`Customer Service Cost` #&gt; # ℹ Use `print(n = ...)` to see more rows na_values &lt;- profit %&gt;% filter(!str_starts(Revenue, fixed(&quot;$&quot;))) %&gt;% distinct(Revenue) %&gt;% pull(Revenue) na_values #&gt; [1] &quot;Unknown&quot; &quot;?&quot; &quot;unknown&quot; The expression is a bit complex. Let us break it up. Function fixed just returns the fixed string ‘$’. This is necessary since the dollar sign has a special meaning in regular expressions (beyond the scope here). Function str_starts checks if the string starts with a dollar sign. We use the logical negation (NOT) to find the complementary set. Note that different strings have been used to indicate NA values (Unknown, ?, unknown). Let us first use a single value to indicate NA (a question mark): profit &lt;- profit %&gt;% mutate(Revenue = str_replace_all(Revenue, c(&quot;unknown&quot; = &quot;?&quot;, &quot;Unknown&quot; = &quot;?&quot;))) Next, we replace all ? with NA: profit &lt;- profit %&gt;% mutate(Revenue = na_if(Revenue, &quot;?&quot;)) profit %&gt;% # check filter(!str_starts(Revenue, fixed(&quot;$&quot;))) #&gt; # A tibble: 0 × 9 #&gt; # … with 9 variables: Quarter &lt;dbl&gt;, Channel &lt;chr&gt;, Customer ID &lt;chr&gt;, Country &lt;chr&gt;, #&gt; # Product Line &lt;chr&gt;, Revenue &lt;chr&gt;, Product Cost &lt;chr&gt;, Customer Service Cost &lt;chr&gt;, #&gt; # Profit &lt;chr&gt; #&gt; # ℹ Use `colnames()` to see all variable names Finally, we remove all dollar signs: profit &lt;- profit %&gt;% mutate(Revenue = str_remove(Revenue, fixed(&quot;$ &quot;)) %&gt;% as.numeric()) profit #&gt; # A tibble: 24,546 × 9 #&gt; Quarter Channel `Customer ID` Country `Product Line` Revenue Product …¹ Custo…² Profit #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 3 ATM FRT USA Credit Products 6044 $ 3998 $ 413 $ 1633 #&gt; 2 1 ATM MRT USA Credit Products 4686 $ 3229 $ 643 $ 815 #&gt; 3 4 ATM PBI USA Deposit Products 6063 $ 7440 $ 1842 $ -32… #&gt; 4 1 ATM PBI USA Deposit Products 4682 $ 6127 $ 1118 $ -25… #&gt; 5 4 ATM MRT USA Deposit Products 6320 $ 7913 $ 1854 $ -34… #&gt; 6 3 BRH MAM USA Deposit Products 2993 $ 1034 $ 242 $ 1718 #&gt; 7 4 BRH PBI USA Revolving Credit Products 3355 $ 4355 $ 1027 $ -20… #&gt; 8 3 ATM FRT USA Revolving Credit Products 5716 $ 5617 $ 876 $ -777 #&gt; 9 4 BRH PBI USA Deposit Products 3347 $ 4229 $ 425 $ -13… #&gt; 10 1 BRH PBI USA Credit Products 2624 $ 1960 $ 264 $ 401 #&gt; # … with 24,536 more rows, and abbreviated variable names ¹​`Product Cost`, ²​`Customer Service Cost` #&gt; # ℹ Use `print(n = ...)` to see more rows As one pipe: profit &lt;- profit %&gt;% mutate(Revenue = str_replace_all(Revenue, c(&quot;unknown&quot; = &quot;?&quot;, &quot;Unknown&quot; = &quot;?&quot;))) %&gt;% mutate(Revenue = na_if(Revenue, &quot;?&quot;)) %&gt;% mutate(Revenue = str_remove(Revenue, fixed(&quot;$ &quot;)) %&gt;% as.numeric()) Convert the remaining columns to numeric like shown for Revenue above. × Solution profit &lt;- read_csv(path) profit &lt;- profit %&gt;% mutate(across(Revenue:Profit, ~str_replace_all(.x, c(&quot;unknown&quot; = &quot;?&quot;, &quot;Unknown&quot; = &quot;?&quot;)) )) %&gt;% mutate(across(Revenue:Profit, ~na_if(.x, &quot;?&quot;) )) %&gt;% mutate(across(Revenue:Profit, ~str_remove(.x, fixed(&quot;$ &quot;)) %&gt;% as.numeric() )) profit #&gt; # A tibble: 24,546 × 9 #&gt; Quarter Channel `Customer ID` Country `Product Line` Revenue Product …¹ Custo…² Profit #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Q3 ATM FRT USA Credit Products 6044 3998 413 1633 #&gt; 2 1 ATM MRT USA Credit Products 4686 3229 643 815 #&gt; 3 Q4 ATM PBI USA Deposit Products 6063 7440 1842 -3219 #&gt; 4 Q1 ATM PBI USA Deposit Products 4682 6127 1118 -2563 #&gt; 5 Q4 ATM MRT USA Deposit Products 6320 7913 1854 -3447 #&gt; 6 Q3 BRH MAM USA Deposit Products 2993 1034 242 1718 #&gt; 7 Q4 BRH PBI USA Revolving Credit Products 3355 4355 1027 -2027 #&gt; 8 Q3 ATM FRT USA Revolving Credit Products 5716 5617 876 -777 #&gt; 9 Q4 BRH PBI USA Deposit Products 3347 4229 425 -1307 #&gt; 10 Q1 BRH PBI USA Credit Products 2624 1960 264 401 #&gt; # … with 24,536 more rows, and abbreviated variable names ¹​`Product Cost`, ²​`Customer Service Cost` #&gt; # ℹ Use `print(n = ...)` to see more rows Close Solution × Hint profit &lt;- read_csv(path) %&gt;% mutate(across(___:___, ~str_replace_all(.x, c(&quot;unknown&quot; = &quot;?&quot;, &quot;Unknown&quot; = &quot;?&quot;)) )) %&gt;% mutate(across(___:___, ~na_if(.x, &quot;?&quot;) )) %&gt;% mutate(across(___:___, ~str_remove(.x, fixed(&quot;$ &quot;)) %&gt;% as.numeric() )) profit Close Hint Use the across function to apply the operations in Question 2 for a set of columns. Hint: see the examples on the help page of across. × Solution profit &lt;- read_csv(path) %&gt;% mutate(Quarter = str_remove(Quarter, &quot;q&quot;) %&gt;% str_remove(&quot;Q&quot;) %&gt;% as.numeric()) %&gt;% mutate(across(Revenue:Profit, ~str_replace_all(.x, c(&quot;unknown&quot; = &quot;?&quot;, &quot;Unknown&quot; = &quot;?&quot;)) )) %&gt;% mutate(across(Revenue:Profit, ~na_if(.x, &quot;?&quot;) )) %&gt;% mutate(across(Revenue:Profit, ~str_remove(.x, fixed(&quot;$ &quot;)) %&gt;% as.numeric() )) skim(profit) Table 13.3: Data summary Name profit Number of rows 24546 Number of columns 9 _______________________ Column type frequency: character 4 numeric 5 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace Channel 0 1 3 3 0 10 0 Customer ID 0 1 3 3 0 18 0 Country 0 1 3 14 0 47 0 Product Line 0 1 14 25 0 6 0 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist Quarter 0 1.00 2.50 1.12 1 2 2 3 4 ▇▇▁▇▇ Revenue 158 0.99 120.31 421.79 1 12 41 74 7540 ▇▁▁▁▁ Product Cost 61 1.00 100.04 375.58 0 9 29 68 9256 ▇▁▁▁▁ Customer Service Cost 96 1.00 17.41 67.50 0 1 5 12 1865 ▇▁▁▁▁ Profit 0 1.00 2.71 154.89 -4139 -7 0 9 3664 ▁▁▇▁▁ Close Solution Write one pipe that does all the cleaning. × Solution profit &lt;- profit %&gt;% mutate(Profit_calc = Revenue - `Product Cost` - `Customer Service Cost`, Diff = abs(Profit - Profit_calc)) %&gt;% mutate(Profit = if_else(Diff &gt; 0 &amp; Diff &lt;= 1, Profit_calc, Profit, missing = Profit) ) profit %&gt;% filter(Diff == 1, is.na(Profit_calc)) # check #&gt; # A tibble: 0 × 11 #&gt; # … with 11 variables: Quarter &lt;dbl&gt;, Channel &lt;chr&gt;, Customer ID &lt;chr&gt;, Country &lt;chr&gt;, #&gt; # Product Line &lt;chr&gt;, Revenue &lt;dbl&gt;, Product Cost &lt;dbl&gt;, Customer Service Cost &lt;dbl&gt;, #&gt; # Profit &lt;dbl&gt;, Profit_calc &lt;dbl&gt;, Diff &lt;dbl&gt; #&gt; # ℹ Use `colnames()` to see all variable names Close Solution × Hint profit &lt;- profit %&gt;% mutate(Profit_calc = Revenue - `Product Cost` - `Customer Service Cost`, Diff = abs(___)) %&gt;% mutate(Profit = if_else(Diff &gt; 0 &amp; Diff &lt;= 1, ___, Profit, Profit) ) profit %&gt;% filter(Diff == 1, is.na(Profit_calc)) # check Close Hint Validate that revenue - product costs - customer service cost equals profit. If you see small rounding errors (less than or equal one) then recalculate the profit. × Solution profit &lt;- profit %&gt;% rowwise() %&gt;% mutate(c_na = sum(is.na(c_across(Revenue:Profit)))) %&gt;% mutate(Revenue = if_else(is.na(Revenue) &amp; c_na == 1, Profit + `Product Cost` + `Customer Service Cost`, Revenue, Revenue), `Product Cost` = if_else(is.na(`Product Cost`) &amp; c_na == 1, - Profit + Revenue - `Customer Service Cost`, `Product Cost`), `Customer Service Cost` = if_else(is.na(`Customer Service Cost`) &amp; c_na == 1, - Profit + Revenue - `Product Cost`, `Customer Service Cost`)) %&gt;% select(Quarter:Profit) # check - do numbers match profit %&gt;% mutate(Profit_calc = Revenue - `Product Cost` - `Customer Service Cost`, Diff = abs(Profit - Profit_calc)) %&gt;% filter(Diff &gt; 0) #&gt; # A tibble: 0 × 11 #&gt; # Rowwise: #&gt; # … with 11 variables: Quarter &lt;dbl&gt;, Channel &lt;chr&gt;, Customer ID &lt;chr&gt;, Country &lt;chr&gt;, #&gt; # Product Line &lt;chr&gt;, Revenue &lt;dbl&gt;, Product Cost &lt;dbl&gt;, Customer Service Cost &lt;dbl&gt;, #&gt; # Profit &lt;dbl&gt;, Profit_calc &lt;dbl&gt;, Diff &lt;dbl&gt; #&gt; # ℹ Use `colnames()` to see all variable names # check - find NA values profit %&gt;% rowwise() %&gt;% mutate(c_na = sum(is.na(c_across(Revenue:Profit)))) %&gt;% filter(c_na &gt; 0) #&gt; # A tibble: 3 × 10 #&gt; # Rowwise: #&gt; Quarter Channel `Customer ID` Country `Product Line` Revenue Produ…¹ Custo…² Profit c_na #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 1 EML FRT France Revolving Credit Produ… 3 NA NA -1 2 #&gt; 2 2 BRH EBP Guam Fee Based Products NA NA 0 1 2 #&gt; 3 1 MAL MFN Japan Fee Based Products NA NA 5 21 2 #&gt; # … with abbreviated variable names ¹​`Product Cost`, ²​`Customer Service Cost` Close Solution × Hint 2 profit &lt;- profit %&gt;% rowwise() %&gt;% mutate(c_na = sum(is.na(c_across(Revenue:Profit)))) %&gt;% mutate(Revenue = if_else(is.na(___) &amp; c_na == 1, ___, Revenue, Revenue), `Product Cost` = if_else(is.na(___) &amp; c_na == 1, ___, `Product Cost`), `Customer Service Cost` = if_else(is.na(___) &amp; c_na == 1, ___, `Customer Service Cost`)) %&gt;% select(Quarter:Profit) You can check you calculations using your code from Question 5. Close Hint 2 × Hint 1 # To find the number of missing values (`NA`) you can create a new column # counting the number of missing values: profit &lt;- profit %&gt;% rowwise() %&gt;% mutate(ct_na = sum(is.na(c_across(Revenue:Profit)))) %&gt;% ungroup() profit %&gt;% filter(ct_na &gt;= 1) Recall that profit = revenue - product costs - customer service cost; that is, if a single value of these are missing then the value can be calculated using the other ones. Close Hint 1 Recalculate values in columns Revenue to Profit if possible. × Solution profit %&gt;% group_by(Quarter) %&gt;% slice_max(Profit, n = 2) #&gt; # A tibble: 8 × 9 #&gt; # Groups: Quarter [4] #&gt; Quarter Channel `Customer ID` Country `Product Line` Revenue Product C…¹ Custo…² Profit #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 ATM PBI USA Credit Products 4821 1808 233 2780 #&gt; 2 1 ATM PBI USA Revolving Credit Products 4268 1638 363 2267 #&gt; 3 2 ATM FRT USA Credit Products 5931 3137 406 2388 #&gt; 4 2 ATM RPB USA Deposit Products 4864 2156 533 2175 #&gt; 5 3 ATM WEM USA Credit Products 5682 2112 454 3116 #&gt; 6 3 ATM WEM USA Deposit Products 4850 2493 253 2104 #&gt; 7 4 ATM MAM USA Revolving Credit Products 6699 2506 530 3663 #&gt; 8 4 ATM WEM USA Revolving Credit Products 5836 2114 265 3457 #&gt; # … with abbreviated variable names ¹​`Product Cost`, ²​`Customer Service Cost` Close Solution Find the two best rows with highest profit in each quarter. × Solution profit %&gt;% group_by(Quarter, `Customer ID`) %&gt;% summarise(Profit = sum(Profit)) %&gt;% slice_max(Profit, n = 2) #&gt; # A tibble: 8 × 3 #&gt; # Groups: Quarter [4] #&gt; Quarter `Customer ID` Profit #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 1 MRT 3925 #&gt; 2 1 WEB 3776 #&gt; 3 2 FRT 7272 #&gt; 4 2 MAM 6992 #&gt; 5 3 WEM 6616 #&gt; 6 3 RPB 3245 #&gt; 7 4 EBP 10093 #&gt; 8 4 WEM 8262 The results are not the same since use another group by. Close Solution × Hint profit %&gt;% group_by(___, `Customer ID`) %&gt;% summarise(Profit = ___) %&gt;% slice_max(Profit, n = 2) Close Hint Find the two best customers with highest profit in each quarter. Is the result the same as in Question 7? × Solution profit %&gt;% group_by(`Product Line`) %&gt;% summarise(Profit = sum(Profit)) %&gt;% slice_max(Profit) #&gt; # A tibble: 1 × 2 #&gt; `Product Line` Profit #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Credit Products 31022 # ... repeat # Using a function summarise_profit &lt;- function(data, group_var, summarise_var) { data %&gt;% group_by(across({{ group_var }})) %&gt;% summarise(across({{ summarise_var }}, sum)) %&gt;% slice_max(Profit) } summarise_profit(profit, `Product Line`, Profit) #&gt; # A tibble: 1 × 2 #&gt; `Product Line` Profit #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Credit Products 31022 summarise_profit(profit, `Customer ID`, Profit) #&gt; # A tibble: 1 × 2 #&gt; `Customer ID` Profit #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 WEM 18942 # ... repeat # Using purrr package to get a single tibble (if interested in the purrr package) val &lt;- names(profit)[1:5] max_profit &lt;- map_df( val, ~{ tmp &lt;- profit %&gt;% group_by(.data[[.x]]) %&gt;% summarise(Profit = sum(Profit), .groups = &quot;drop&quot;) %&gt;% slice_max(Profit) tibble(by = .x, best = as.character(tmp[[1,1]]), profit = tmp[[1,2]] ) } ) max_profit #&gt; # A tibble: 5 × 3 #&gt; by best profit #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Quarter 4 35268 #&gt; 2 Channel ATM 30433 #&gt; 3 Customer ID WEM 18942 #&gt; 4 Country USA 39693 #&gt; 5 Product Line Credit Products 31022 Close Solution × Hint profit %&gt;% group_by(___) %&gt;% summarise(Profit = ___) %&gt;% slice_max(Profit) # ... repeat Close Hint Find the product line, customer, channel, country and quarter with the highest profit. × Solution profit %&gt;% group_by(`Customer ID`) %&gt;% distinct(Country) %&gt;% count(`Customer ID`) #&gt; # A tibble: 18 × 2 #&gt; # Groups: Customer ID [18] #&gt; `Customer ID` n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 AFF 1 #&gt; 2 AGR 16 #&gt; 3 CAM 1 #&gt; 4 CRE 1 #&gt; 5 EBP 47 #&gt; 6 FRT 47 #&gt; 7 HEC 1 #&gt; 8 IAS 1 #&gt; 9 INB 1 #&gt; 10 MAM 47 #&gt; 11 MFN 30 #&gt; 12 MRT 47 #&gt; 13 PBI 47 #&gt; 14 RPB 47 #&gt; 15 SBE 1 #&gt; 16 STF 2 #&gt; 17 WEB 47 #&gt; 18 WEM 47 Close Solution Are there rows with the same customer in different countries? × Solution profit %&gt;% arrange(desc(Profit), desc(Revenue)) #&gt; # A tibble: 24,546 × 9 #&gt; # Rowwise: #&gt; Quarter Channel `Customer ID` Country `Product Line` Revenue Product …¹ Custo…² Profit #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 4 ATM MAM USA Revolving Credit Products 6699 2506 530 3663 #&gt; 2 4 ATM WEM USA Revolving Credit Products 5836 2114 265 3457 #&gt; 3 4 ATM MAM USA Credit Products 7540 3374 728 3438 #&gt; 4 4 ATM MRT USA Credit Products 6419 2669 618 3132 #&gt; 5 3 ATM WEM USA Credit Products 5682 2112 454 3116 #&gt; 6 4 ATM WEB USA Deposit Products 5145 1907 191 3047 #&gt; 7 1 ATM PBI USA Credit Products 4821 1808 233 2780 #&gt; 8 4 ATM RPB USA Credit Products 5828 2727 559 2542 #&gt; 9 2 ATM FRT USA Credit Products 5931 3137 406 2388 #&gt; 10 1 ATM PBI USA Revolving Credit Products 4268 1638 363 2267 #&gt; # … with 24,536 more rows, and abbreviated variable names ¹​`Product Cost`, ²​`Customer Service Cost` #&gt; # ℹ Use `print(n = ...)` to see more rows Close Solution Sort the data decreasing with respect to profit and next revenue. × Solution profit %&gt;% group_by(`Product Line`) %&gt;% summarise(cost = sum(`Product Cost` + `Customer Service Cost`)) %&gt;% # print() %&gt;% # if want a peek before slicing slice_max(cost) #&gt; # A tibble: 1 × 2 #&gt; `Product Line` cost #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Credit Products 820665 profit %&gt;% group_by(`Product Line`) %&gt;% summarise(cost = sum(`Product Cost`)) %&gt;% slice_min(cost) #&gt; # A tibble: 1 × 2 #&gt; `Product Line` cost #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Third Party Products 91796 Close Solution × Hint profit %&gt;% group_by(`Product Line`) %&gt;% summarise(cost = sum(___)) %&gt;% # print() %&gt;% # if want a peek before slicing slice_max(___) profit %&gt;% ___% slice_min(cost) Close Hint Which product line has the highest and lowest total cost? × Solution profit %&gt;% mutate(cust_cost_new = `Customer Service Cost` * 1.05, profit_new = Revenue - cust_cost_new - `Product Cost`) %&gt;% group_by(`Product Line`) %&gt;% summarise(cust_cost = sum(`Customer Service Cost`), profit = sum(Profit), cust_cost_new = sum(cust_cost_new), profit_new = sum(profit_new), profit_decrease = profit_new - profit) #&gt; # A tibble: 6 × 6 #&gt; `Product Line` cust_cost profit cust_cost_new profit_new profit_decrease #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Credit Products 119612 31022 125593. 25041. -5981. #&gt; 2 Deposit Products 114526 5408 120252. -318. -5726. #&gt; 3 Fee Based Products 22900 4953 24045 NA NA #&gt; 4 Other Products 33282 7438 34946. 5774. -1664. #&gt; 5 Revolving Credit Products NA 15905 NA NA NA #&gt; 6 Third Party Products 15970 2264 16768. 1465. -799. Close Solution × Hint profit %&gt;% mutate(cust_cost_new = ___ * 1.05, profit_new = ___) %&gt;% group_by(`Product Line`) %&gt;% summarise(cust_cost = sum(___), profit = sum(Profit), cust_cost_new = ___, profit_new = ___, profit_decrease = ___) Close Hint Assume that customer service cost increases with 5%. How will that affect the profit for each product line? rm(profit) 13.5.4 Exercise (fisheries) Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). The dataset called fisheries contains world fisheries harvest for 2005. The tonnage from capture and aquaculture is listed by country. You need the tidyverse package as usual: library(tidyverse) # install tfa package using remotes::install_github(&quot;bss-osca/tfa-package&quot;, upgrade = FALSE) We load the needed datasets: fisheries &lt;- read_csv(system.file(&quot;extdata/fisheries.csv&quot;, package = &quot;tfa&quot;)) fisheries #&gt; # A tibble: 216 × 4 #&gt; country capture aquaculture total #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Afghanistan 1000 1200 2200 #&gt; 2 Albania 7886 950 8836 #&gt; 3 Algeria 95000 1361 96361 #&gt; 4 American Samoa 3047 20 3067 #&gt; 5 Andorra 0 0 0 #&gt; 6 Angola 486490 655 487145 #&gt; 7 Antigua and Barbuda 3000 10 3010 #&gt; 8 Argentina 755226 3673 758899 #&gt; 9 Armenia 3758 16381 20139 #&gt; 10 Aruba 142 0 142 #&gt; # … with 206 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows continents &lt;- read_csv(system.file(&quot;extdata/continents.csv&quot;, package = &quot;tfa&quot;)) continents #&gt; # A tibble: 247 × 2 #&gt; country continent #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Afghanistan Asia #&gt; 2 Åland Islands Europe #&gt; 3 Albania Europe #&gt; 4 Algeria Africa #&gt; 5 American Samoa Oceania #&gt; 6 Andorra Europe #&gt; 7 Angola Africa #&gt; 8 Anguilla Americas #&gt; 9 Antigua &amp; Barbuda Americas #&gt; 10 Argentina Americas #&gt; # … with 237 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Some mean statistics: fisheries %&gt;% summarise(across(where(is.numeric), mean, na.rm = TRUE)) #&gt; # A tibble: 1 × 3 #&gt; capture aquaculture total #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 421916. 508368. 930284. × Solution fisheries %&gt;% anti_join(continents) # countries not belonging to a continent #&gt; # A tibble: 20 × 4 #&gt; country capture aquaculture total #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Antigua and Barbuda 3000 10 3010 #&gt; 2 Bosnia and Herzegovina 305 4564 4869 #&gt; 3 Czech Republic 3507 20952 24459 #&gt; 4 Democratic Republic of the Congo 237372 3161 240533 #&gt; 5 Eswatini 65 100 165 #&gt; 6 Federated States of Micronesia 88397 0 88397 #&gt; 7 Ivory Coast 67500 4701 72201 #&gt; 8 Jersey and Guernsey 2985 1499 4484 #&gt; 9 Macao 1500 0 1500 #&gt; 10 Myanmar 2072390 1017644 3090034 #&gt; 11 North Macedonia 306 986 1292 #&gt; 12 Palestine 3306 280 3586 #&gt; 13 Republic of the Congo 86748 177 86925 #&gt; 14 Saint Kitts and Nevis 65734 1 65735 #&gt; 15 Saint Lucia 2097 32 2129 #&gt; 16 Saint Vincent and the Grenadines 23077 0 23077 #&gt; 17 São Tomé and Príncipe 11750 0 11750 #&gt; 18 Trinidad and Tobago 13027 11 13038 #&gt; 19 Turks and Caicos Islands 2780 0 2780 #&gt; 20 US Virgin Islands 551 8 559 fisheries &lt;- fisheries %&gt;% print() %&gt;% left_join(continents) %&gt;% print() #&gt; # A tibble: 216 × 4 #&gt; country capture aquaculture total #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Afghanistan 1000 1200 2200 #&gt; 2 Albania 7886 950 8836 #&gt; 3 Algeria 95000 1361 96361 #&gt; 4 American Samoa 3047 20 3067 #&gt; 5 Andorra 0 0 0 #&gt; 6 Angola 486490 655 487145 #&gt; 7 Antigua and Barbuda 3000 10 3010 #&gt; 8 Argentina 755226 3673 758899 #&gt; 9 Armenia 3758 16381 20139 #&gt; 10 Aruba 142 0 142 #&gt; # … with 206 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows #&gt; # A tibble: 216 × 5 #&gt; country capture aquaculture total continent #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 Afghanistan 1000 1200 2200 Asia #&gt; 2 Albania 7886 950 8836 Europe #&gt; 3 Algeria 95000 1361 96361 Africa #&gt; 4 American Samoa 3047 20 3067 Oceania #&gt; 5 Andorra 0 0 0 Europe #&gt; 6 Angola 486490 655 487145 Africa #&gt; 7 Antigua and Barbuda 3000 10 3010 &lt;NA&gt; #&gt; 8 Argentina 755226 3673 758899 Americas #&gt; 9 Armenia 3758 16381 20139 Asia #&gt; 10 Aruba 142 0 142 Americas #&gt; # … with 206 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows fisheries %&gt;% filter(is.na(continent)) # same result - countries not belonging to a continent #&gt; # A tibble: 20 × 5 #&gt; country capture aquaculture total continent #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 Antigua and Barbuda 3000 10 3010 &lt;NA&gt; #&gt; 2 Bosnia and Herzegovina 305 4564 4869 &lt;NA&gt; #&gt; 3 Czech Republic 3507 20952 24459 &lt;NA&gt; #&gt; 4 Democratic Republic of the Congo 237372 3161 240533 &lt;NA&gt; #&gt; 5 Eswatini 65 100 165 &lt;NA&gt; #&gt; 6 Federated States of Micronesia 88397 0 88397 &lt;NA&gt; #&gt; 7 Ivory Coast 67500 4701 72201 &lt;NA&gt; #&gt; 8 Jersey and Guernsey 2985 1499 4484 &lt;NA&gt; #&gt; 9 Macao 1500 0 1500 &lt;NA&gt; #&gt; 10 Myanmar 2072390 1017644 3090034 &lt;NA&gt; #&gt; 11 North Macedonia 306 986 1292 &lt;NA&gt; #&gt; 12 Palestine 3306 280 3586 &lt;NA&gt; #&gt; 13 Republic of the Congo 86748 177 86925 &lt;NA&gt; #&gt; 14 Saint Kitts and Nevis 65734 1 65735 &lt;NA&gt; #&gt; 15 Saint Lucia 2097 32 2129 &lt;NA&gt; #&gt; 16 Saint Vincent and the Grenadines 23077 0 23077 &lt;NA&gt; #&gt; 17 São Tomé and Príncipe 11750 0 11750 &lt;NA&gt; #&gt; 18 Trinidad and Tobago 13027 11 13038 &lt;NA&gt; #&gt; 19 Turks and Caicos Islands 2780 0 2780 &lt;NA&gt; #&gt; 20 US Virgin Islands 551 8 559 &lt;NA&gt; Close Solution × Hint 2 fisheries %&gt;% anti_join(___) # countries not belonging to a continent fisheries &lt;- fisheries %&gt;% print() %&gt;% left_join(___) %&gt;% print() fisheries %&gt;% filter(is.na(___)) # same result - countries not belonging to a continent Close Hint 2 × Hint 1 You could use anti_join to find missing values. Use left_join to join the datasets. Close Hint 1 Use a mutating join to add a continent column to the fisheries dataset. Are there some countries which do not belong to a continent? × Solution fisheries &lt;- fisheries %&gt;% filter(total &gt; 100000) Close Solution × Hint fisheries &lt;- ___ %&gt;% filter(___) Close Hint Filter out countries whose total harvest was less than 100,000 tons. × Solution fisheries %&gt;% filter(is.na(continent)) #&gt; # A tibble: 2 × 5 #&gt; country capture aquaculture total continent #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 Democratic Republic of the Congo 237372 3161 240533 &lt;NA&gt; #&gt; 2 Myanmar 2072390 1017644 3090034 &lt;NA&gt; fisheries &lt;- fisheries %&gt;% mutate(continent = case_when( country == &quot;Democratic Republic of the Congo&quot; ~ &quot;Africa&quot;, country == &quot;Hong Kong&quot; ~ &quot;Asia&quot;, country == &quot;Myanmar&quot; ~ &quot;Asia&quot;, TRUE ~ continent ) ) fisheries %&gt;% filter(is.na(continent)) #&gt; # A tibble: 0 × 5 #&gt; # … with 5 variables: country &lt;chr&gt;, capture &lt;dbl&gt;, aquaculture &lt;dbl&gt;, total &lt;dbl&gt;, continent &lt;chr&gt; #&gt; # ℹ Use `colnames()` to see all variable names Close Solution × Hint fisheries %&gt;% filter(is.na(continent)) fisheries &lt;- ___ %&gt;% mutate(continent = case_when( country == ___ ~ &quot;Africa&quot;, country == ___ ~ &quot;Asia&quot;, country == ___ ~ &quot;Asia&quot;, TRUE ~ continent ) ) fisheries %&gt;% filter(is.na(continent)) Close Hint If still any countries not belonging to a continent then add them to the closest continent. × Solution fisheries &lt;- fisheries %&gt;% mutate(aquaculture_perc = aquaculture / total) The percentage of fish harvest done using aquaculture. Close Solution × Hint fisheries &lt;- ___ %&gt;% mutate(___) Close Hint Add column aquaculture_perc = aquaculture / total and explain the variable. × Solution fisheries %&gt;% group_by(continent) %&gt;% summarize(mean_ap = mean(aquaculture_perc)) #&gt; # A tibble: 5 × 2 #&gt; continent mean_ap #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Africa 0.0943 #&gt; 2 Americas 0.192 #&gt; 3 Asia 0.367 #&gt; 4 Europe 0.165 #&gt; 5 Oceania 0.150 Close Solution × Hint fisheries %&gt;% # start with the fisheries data frame ___ %&gt;% # group by continent ___(mean_ap = ___) # calculate mean aquaculture Close Hint Calculate the mean aquaculture percentage (we’ll call it mean_ap for short) for continents in the fisheries data. × Solution fisheries_summary_continent &lt;- fisheries %&gt;% group_by(continent) %&gt;% summarize(mean_ap = mean(aquaculture_perc), min_ap = min(aquaculture_perc), max_ap = max(aquaculture_perc)) %&gt;% print() #&gt; # A tibble: 5 × 4 #&gt; continent mean_ap min_ap max_ap #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Africa 0.0943 0 0.803 #&gt; 2 Americas 0.192 0 0.529 #&gt; 3 Asia 0.367 0 0.782 #&gt; 4 Europe 0.165 0.00682 0.618 #&gt; 5 Oceania 0.150 0.0197 0.357 Close Solution × Hint fisheries_summary_continent &lt;- fisheries %&gt;% # start with the fisheries data frame ___ %&gt;% # group by continent ___(mean_ap = ___, min_ap = ___, ___) # calculate mean aquaculture Close Hint Now expand your calculations to also calculate the minimum and maximum aquaculture percentage for continents in the fisheries data and store the summary table in a data frame called fisheries_summary_continent. × Solution fisheries_summary_continent %&gt;% arrange(desc(mean_ap)) #&gt; # A tibble: 5 × 4 #&gt; continent mean_ap min_ap max_ap #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Asia 0.367 0 0.782 #&gt; 2 Americas 0.192 0 0.529 #&gt; 3 Europe 0.165 0.00682 0.618 #&gt; 4 Oceania 0.150 0.0197 0.357 #&gt; 5 Africa 0.0943 0 0.803 Close Solution × Hint fisheries_summary_continent %&gt;% # start with the fisheries_summary_continent data frame ___ # order in descending order of mean_ap Close Hint Take the fisheries_summary_continent data frame and order the results in descending order of mean aquaculture percentage. × Solution ggplot(fisheries_summary_continent, aes(y = reorder(continent, mean_ap), x = mean_ap)) + geom_col() + labs( x = &quot;&quot;, y = &quot;&quot;, title = &quot;Average share of aquaculture by continent&quot;, subtitle = &quot;out of total fisheries harvest&quot;, caption = &quot;Source: bit.ly/2VrawTt&quot; ) An example plot Close Solution If you already have read the module about visualizations, then try to make some relevant plots. 13.5.5 Exercise (company ranking) This exercise is a slightly modified version an exam assignment (exam 2021-A2). Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). The dataset companies, in the tfa package, lists approx. 1000 of the world’s biggest companies, measured by sales, profits, assets and market value. The column/variables are: name: the name of the company. country: the country the company is situated in. category: the products the company produces. sales: the amount of sales of the company in billion USD. profits: the profit of the company in billion USD. assets: the assets of the company in billion USD. marketvalue: the market value of the company in billion USD. You can load the dataset using: # remotes::install_github(&quot;bss-osca/tfa-package&quot;, build = FALSE) # run if tfa not installed library(tidyverse) companies &lt;- read_csv(system.file(&quot;extdata/companies.csv&quot;, package = &quot;tfa&quot;)) Use the dplyr package in tidyverse to calculate relevant summary tables (data frames) and answer the following questions. × Solution companies #&gt; # A tibble: 1,002 × 7 #&gt; name country category sales profits assets marketvalue #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 General Electric United States Conglomerates 134. 15.6 627. 329. #&gt; 2 Microsoft United States Software &amp; services 34.3 8.88 85.9 287. #&gt; 3 Pfizer United States Drugs &amp; biotechnology 40.4 6.2 120. 285. #&gt; 4 ExxonMobil United States Oil &amp; gas operations 223. 21.0 167. 277. #&gt; 5 Citigroup United States Banking 94.7 17.8 1264. 255. #&gt; 6 Wal-Mart Stores United States Retailing 256. 9.05 105. 244. #&gt; 7 Intel United States Semiconductors 30.1 5.64 47.1 197. #&gt; 8 American Intl Group United States Insurance 76.7 6.46 648. 195. #&gt; 9 HSBC Group United Kingdom Banking 44.3 6.66 758. 178. #&gt; 10 Vodafone United Kingdom Telecommunications services 48.0 -15.5 256. 175. #&gt; # … with 992 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows 1002 rows and 7 columns. Close Solution How many rows and columns do the dataset have? × Solution library(skimr) skim(companies) Table 13.4: Data summary Name companies Number of rows 1002 Number of columns 7 _______________________ Column type frequency: character 3 numeric 4 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace name 0 1 1 26 0 1002 0 country 0 1 5 14 0 42 0 category 0 1 5 32 0 27 0 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist sales 0 1 15.24 23.67 0.27 3.47 7.96 17.09 256 ▇▁▁▁▁ profits 2 1 0.71 2.41 -25.83 0.20 0.42 0.88 21 ▁▁▇▁▁ assets 0 1 57.34 136.14 0.75 6.74 15.03 39.63 1264 ▇▁▁▁▁ marketvalue 0 1 21.04 32.01 5.15 7.02 10.55 20.19 329 ▇▁▁▁▁ From the output we can see that there are 1002 different companies (one for each row) 27 different product categories and 42 different countries. Close Solution × Hint library(skimr) skim(___) Close Hint How many different companies are we considering, how many different product categories and how many different countries? Hint: the skimr package might be useful. × Solution dat &lt;- companies %&gt;% arrange(desc(marketvalue)) %&gt;% head(n = 3) %&gt;% print() #&gt; # A tibble: 3 × 7 #&gt; name country category sales profits assets marketvalue #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 General Electric United States Conglomerates 134. 15.6 627. 329. #&gt; 2 Microsoft United States Software &amp; services 34.3 8.88 85.9 287. #&gt; 3 Pfizer United States Drugs &amp; biotechnology 40.4 6.2 120. 285. # or # companies %&gt;% # slice_max(marketvalue, n = 3) The 3 biggest companies are listed in the name column. Close Solution × Hint companies %&gt;% slice_max(___) Close Hint What are the 3 biggest companies with respect to market value? × Solution dat &lt;- companies %&gt;% group_by(country) %&gt;% slice_max(profits, n = 1) %&gt;% print() #&gt; # A tibble: 42 × 7 #&gt; # Groups: country [42] #&gt; name country category sales profits assets marke…¹ #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Natl Australia Bank Australia Banking 15.3 2.69 270. 36.5 #&gt; 2 Erste Bank Austria Banking 7.5 0.27 127. 8.12 #&gt; 3 Dexia Belgium Banking 19.6 1.36 368. 21.6 #&gt; 4 ACE Bermuda Insurance 10.7 1.39 49.5 12.6 #&gt; 5 Petrobras-Petrsleo Brasil Brazil Oil &amp; gas operations 22.6 2.29 27.1 35.5 #&gt; 6 Royal Bank of Canada Canada Banking 18.8 2.28 305. 31.8 #&gt; 7 Garmin Cayman Islands Technology hardware &amp; equi… 0.57 0.18 0.86 5.19 #&gt; 8 PetroChina China Oil &amp; gas operations 29.5 5.67 58.4 90.5 #&gt; 9 Den Danske Bank Denmark Banking 12.6 1.57 309. 16.4 #&gt; 10 Nokia Finland Technology hardware &amp; equi… 37.0 4.52 29.2 104. #&gt; # … with 32 more rows, and abbreviated variable name ¹​marketvalue #&gt; # ℹ Use `print(n = ...)` to see more rows The company with highest profit for each country is listed above. In Denmark the company is Den Danske Bank. Close Solution × Hint dat &lt;- companies %&gt;% group_by(___) %&gt;% slice_max(___) %&gt;% print() Close Hint For each country find the company with highest profit. What company has the highest profit in Denmark? × Solution dat &lt;- companies %&gt;% group_by(category) %&gt;% summarise(marketvalue = sum(marketvalue)) %&gt;% slice_max(marketvalue, n = 4) %&gt;% print() #&gt; # A tibble: 4 × 2 #&gt; category marketvalue #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Banking 2858. #&gt; 2 Oil &amp; gas operations 1748. #&gt; 3 Drugs &amp; biotechnology 1732. #&gt; 4 Telecommunications services 1415. The 4 product categories that have the highest total market value are given in the category column. Close Solution × Hint dat &lt;- companies %&gt;% group_by(___) %&gt;% summarise(__) %&gt;% slice_max(___) %&gt;% print() Close Hint Which 4 product categories have the highest total market value? × Solution dat &lt;- companies %&gt;% filter(country == &quot;Denmark&quot;) %&gt;% mutate(value = profits + assets + marketvalue) %&gt;% select(name, category, value) %&gt;% print() #&gt; # A tibble: 4 × 3 #&gt; name category value #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Moller-Maersk Transportation 63.3 #&gt; 2 Den Danske Bank Banking 327. #&gt; 3 Novo-Nordisk Drugs &amp; biotechnology 22.4 #&gt; 4 TDC Group Telecommunications services 22.4 The companies can be seen above. The company with lowest value is Novo-Nordisk (or TDC Group). Close Solution × Hint dat &lt;- companies %&gt;% filter(___) %&gt;% mutate(___) %&gt;% select(___) %&gt;% print() Close Hint Create a new data frame only containing rows from Denmark and with columns name, category and a column value which equals the sum of columns profits, assets and marketvalue. Which company have the lowest value? 13.5.6 Exercise (Titanic) This exercise is a slightly modified version an exam assignment (reexam 2021-A2). Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). The dataset titanic, given in the appendix, lists approx. 1300 passengers on Titanic. The column/variables are: pclass: Passenger class (1 = 1st; 2 = 2nd; 3 = 3rd). survived: Survival (0 = No; 1 = Yes). name: Name. sex: Sex. age: Age. fare: Passenger Fare. cabin: Cabin number. embarked: Port of embarkation (C = Cherbourg; Q = Queenstown; S = Southampton). boat: Lifeboat number. You can read the dataset file titanic.csv into the dataset dat using # remotes::install_github(&quot;bss-osca/tfa-package&quot;, build = FALSE) # run if tfa not installed library(tidyverse) dat &lt;- read_csv(system.file(&quot;extdata/titanic.csv&quot;, package = &quot;tfa&quot;)) Use the dplyr package in tidyverse to calculate relevant summary tables (data frames) and answer the following questions. × Solution dat &lt;- dat %&gt;% mutate(male = if_else(sex == &quot;male&quot;, TRUE, FALSE)) dat #&gt; # A tibble: 1,309 × 10 #&gt; pclass survived name sex age fare cabin embar…¹ boat male #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt; #&gt; 1 1 1 Allen, Miss. Elisabeth Walton fema… 29 211. B5 S 2 FALSE #&gt; 2 1 1 Allison, Master. Hudson Trevor male 0.92 152. C22 … S 11 TRUE #&gt; 3 1 0 Allison, Miss. Helen Loraine fema… 2 152. C22 … S &lt;NA&gt; FALSE #&gt; 4 1 0 Allison, Mr. Hudson Joshua Creighton male 30 152. C22 … S &lt;NA&gt; TRUE #&gt; 5 1 0 Allison, Mrs. Hudson J C (Bessie Wal… fema… 25 152. C22 … S &lt;NA&gt; FALSE #&gt; 6 1 1 Anderson, Mr. Harry male 48 26.6 E12 S 3 TRUE #&gt; 7 1 1 Andrews, Miss. Kornelia Theodosia fema… 63 78.0 D7 S 10 FALSE #&gt; 8 1 0 Andrews, Mr. Thomas Jr male 39 0 A36 S &lt;NA&gt; TRUE #&gt; 9 1 1 Appleton, Mrs. Edward Dale (Charlott… fema… 53 51.5 C101 S D FALSE #&gt; 10 1 0 Artagaveytia, Mr. Ramon male 71 49.5 &lt;NA&gt; C &lt;NA&gt; TRUE #&gt; # … with 1,299 more rows, and abbreviated variable name ¹​embarked #&gt; # ℹ Use `print(n = ...)` to see more rows We use if_else to set the new column. Close Solution × Hint dat &lt;- dat %&gt;% mutate(male = if_else(___)) dat Close Hint Create a new column named male which is true if the person is a male. × Solution library(skimr) skim(dat) Table 13.5: Data summary Name dat Number of rows 1309 Number of columns 10 _______________________ Column type frequency: character 5 logical 1 numeric 4 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace name 0 1.00 12 82 0 1307 0 sex 0 1.00 4 6 0 2 0 cabin 1014 0.23 1 15 0 186 0 embarked 2 1.00 1 1 0 3 0 boat 823 0.37 1 7 0 27 0 Variable type: logical skim_variable n_missing complete_rate mean count male 0 1 0.64 TRU: 843, FAL: 466 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist pclass 0 1.0 2.29 0.84 1.00 2.0 3.0 3.0 3 ▃▁▃▁▇ survived 0 1.0 0.38 0.49 0.00 0.0 0.0 1.0 1 ▇▁▁▁▅ age 263 0.8 29.88 14.41 0.17 21.0 28.0 39.0 80 ▂▇▅▂▁ fare 1 1.0 33.30 51.76 0.00 7.9 14.4 31.3 512 ▇▁▁▁▁ From the output we can consider 1309 persons of which approx 64% are males. Approx. 38% of the passangers survived. Close Solution × Hint library(skimr) ___ Close Hint How many persons are we considering, how many men (in percentage) and how many survived? × Solution dat %&gt;% group_by(sex, survived) %&gt;% count() %&gt;% group_by(sex) %&gt;% mutate(rate = n/sum(n)) #&gt; # A tibble: 4 × 4 #&gt; # Groups: sex [2] #&gt; sex survived n rate #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 female 0 127 0.273 #&gt; 2 female 1 339 0.727 #&gt; 3 male 0 682 0.809 #&gt; 4 male 1 161 0.191 # Alternatively res &lt;- dat %&gt;% group_by(male) %&gt;% summarise(survived = sum(survived)/n()) %&gt;% print() #&gt; # A tibble: 2 × 2 #&gt; male survived #&gt; &lt;lgl&gt; &lt;dbl&gt; #&gt; 1 FALSE 0.727 #&gt; 2 TRUE 0.191 The survival rate for women and men are 73 and 19 percent, respectively. Close Solution × Hint dat %&gt;% group_by(___) %&gt;% count() %&gt;% group_by(___) %&gt;% mutate(rate = ___) Close Hint How many of the females survived in percent (and how many males)? × Solution res &lt;- dat %&gt;% filter(age &lt; 19, survived == TRUE) %&gt;% nrow() %&gt;% print() #&gt; [1] 95 95 childern survived. Close Solution × Hint res &lt;- dat %&gt;% filter(___) %&gt;% nrow() %&gt;% print() Close Hint Define children as people with age below 19. How many children survived? × Solution res &lt;- dat %&gt;% group_by(pclass) %&gt;% summarise(rate = sum(survived)/n()) %&gt;% print() #&gt; # A tibble: 3 × 2 #&gt; pclass rate #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 0.619 #&gt; 2 2 0.430 #&gt; 3 3 0.255 There seems to be a big difference in survival rate between first class (62%) and third class (26%). Close Solution × Hint res &lt;- dat %&gt;% group_by(___) %&gt;% summarise(rate = ___) %&gt;% print() Close Hint Did relatively more people survive at first class compared to third class? × Solution res &lt;- dat %&gt;% filter(!is.na(boat)) %&gt;% summarise(rate = 1-sum(survived)/n()) %&gt;% print() #&gt; # A tibble: 1 × 1 #&gt; rate #&gt; &lt;dbl&gt; #&gt; 1 0.0185 The survival rate when entered the lifeboat was high. Only 1.85% died. Close Solution × Hint res &lt;- dat %&gt;% filter(___) %&gt;% summarise(rate = ___) %&gt;% print() Close Hint How many persons that entered a lifeboat did die in percent? × Solution dat %&gt;% filter(str_detect(name, &quot;Hansen&quot;)) #&gt; # A tibble: 6 × 10 #&gt; pclass survived name sex age fare cabin embar…¹ boat male #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt; #&gt; 1 3 0 Hansen, Mr. Claus Peter male 41 14.1 &lt;NA&gt; S &lt;NA&gt; TRUE #&gt; 2 3 0 Hansen, Mr. Henrik Juul male 26 7.85 &lt;NA&gt; S &lt;NA&gt; TRUE #&gt; 3 3 0 Hansen, Mr. Henry Damsgaard male 21 7.85 &lt;NA&gt; S &lt;NA&gt; TRUE #&gt; 4 3 1 Hansen, Mrs. Claus Peter (Jennie L Ho… fema… 45 14.1 &lt;NA&gt; S 11 FALSE #&gt; 5 3 0 Moen, Mr. Sigurd Hansen male 25 7.65 F G73 S &lt;NA&gt; TRUE #&gt; 6 3 0 Nysveen, Mr. Johan Hansen male 61 6.24 &lt;NA&gt; S &lt;NA&gt; TRUE #&gt; # … with abbreviated variable name ¹​embarked Only a single person survived. Close Solution × Hint dat %&gt;% filter(str_detect(___)) Close Hint How many persons with Hansen in their name survived? 13.5.7 Exercise (covid) This exercise is a slightly modified version an exam assignment (reexam 2022-A2). Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). Consider COVID-19 data obtained from Our World in Data in the file covid.csv. The dataset contains data from different countries. Some of the columns/variables are: cases: New confirmed cases of COVID-19. deaths: New deaths attributed to COVID-19. icu_patients: Number of COVID-19 patients in intensive care units (ICUs) on a given day. hosp_patients: Number of COVID-19 patients in hospital on a given day. tests: Total tests for COVID-19. positive_rate: The share of COVID-19 tests that are positive, given as a rolling 7-day average. vac: Total number of people who received at least one vaccine dose. fully_vac: Total number of people who received all doses prescribed by the vaccination protocol. population: Country population. Other columns are date, country, month and year. You can read the dataset file using # remotes::install_github(&quot;bss-osca/tfa-package&quot;, build = FALSE) # run if tfa not installed library(tidyverse) dat &lt;- read_csv(system.file(&quot;extdata/covid.csv&quot;, package = &quot;tfa&quot;)) Use the dplyr package in tidyverse to calculate relevant summary tables (tibbles/data frames) and answer the following questions. × Solution res1 &lt;- dat %&gt;% distinct(country) %&gt;% print() #&gt; # A tibble: 4 × 1 #&gt; country #&gt; &lt;chr&gt; #&gt; 1 Denmark #&gt; 2 Germany #&gt; 3 Norway #&gt; 4 United Kingdom res2 &lt;- dat %&gt;% ungroup() %&gt;% summarise(start = min(date), end = max(date)) %&gt;% print() #&gt; # A tibble: 1 × 2 #&gt; start end #&gt; &lt;date&gt; &lt;date&gt; #&gt; 1 2020-01-27 2021-11-24 We have a total of 4 countries with data from 2020-01-27 to 2021-11-24. Close Solution × Hint res1 &lt;- dat %&gt;% distinct(___) %&gt;% print() res2 &lt;- dat %&gt;% ungroup() %&gt;% summarise(start = ___, end = ___) %&gt;% print() Close Hint Which countries are considered and what is the timespan of the data? × Solution res &lt;- dat %&gt;% filter(country == &quot;Denmark&quot;, date == &quot;2021-11-22&quot;) %&gt;% print() #&gt; # A tibble: 1 × 13 #&gt; date country cases deaths icu_pat…¹ hosp_…² tests posit…³ vac fully…⁴ popul…⁵ month year #&gt; &lt;date&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2021-11-22 Denmark 3810 6 NA NA NA NA 4.54e6 4441376 5813302 11 2021 #&gt; # … with abbreviated variable names ¹​icu_patients, ²​hosp_patients, ³​positive_rate, ⁴​fully_vac, #&gt; # ⁵​population The number of confirmed cases was 3810. Close Solution × Hint res &lt;- dat %&gt;% filter(___) %&gt;% print() Close Hint What is the number of new confirmed cases November 22nd, 2021 in Denmark? × Solution res1 &lt;- dat %&gt;% group_by(country) %&gt;% mutate(total_cases = cumsum(replace_na(cases, 0)), total_deaths = cumsum(replace_na(deaths, 0))) %&gt;% print() #&gt; # A tibble: 2,628 × 15 #&gt; # Groups: country [4] #&gt; date country cases deaths icu_pat…¹ hosp_…² tests posit…³ vac fully…⁴ popul…⁵ month year #&gt; &lt;date&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2020-02-02 Denmark NA NA NA NA 1 NA NA NA 5813302 2 2020 #&gt; 2 2020-02-03 Denmark NA NA NA NA NA NA NA NA 5813302 2 2020 #&gt; 3 2020-02-04 Denmark NA NA NA NA NA NA NA NA 5813302 2 2020 #&gt; 4 2020-02-05 Denmark NA NA NA NA NA NA NA NA 5813302 2 2020 #&gt; 5 2020-02-06 Denmark NA NA NA NA NA NA NA NA 5813302 2 2020 #&gt; 6 2020-02-07 Denmark NA NA NA NA NA NA NA NA 5813302 2 2020 #&gt; 7 2020-02-08 Denmark NA NA NA NA NA NA NA NA 5813302 2 2020 #&gt; 8 2020-02-09 Denmark NA NA NA NA NA NA NA NA 5813302 2 2020 #&gt; 9 2020-02-10 Denmark NA NA NA NA NA NA NA NA 5813302 2 2020 #&gt; 10 2020-02-11 Denmark NA NA NA NA NA NA NA NA 5813302 2 2020 #&gt; # … with 2,618 more rows, 2 more variables: total_cases &lt;dbl&gt;, total_deaths &lt;dbl&gt;, and abbreviated #&gt; # variable names ¹​icu_patients, ²​hosp_patients, ³​positive_rate, ⁴​fully_vac, ⁵​population #&gt; # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names res2 &lt;- res1 %&gt;% filter(country == &quot;Norway&quot;, date == &quot;2021-10-10&quot;) %&gt;% select(contains(&quot;total&quot;)) %&gt;% print() #&gt; # A tibble: 1 × 3 #&gt; # Groups: country [1] #&gt; country total_cases total_deaths #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Norway 193562 871 The total number of deaths in Norway up to 10th October 2021 is 871. Close Solution × Hint res1 &lt;- dat %&gt;% group_by(___) %&gt;% mutate(total_cases = cumsum(replace_na(cases, 0)), total_deaths = ___) %&gt;% print() res2 &lt;- res1 %&gt;% filter(___) %&gt;% select(contains(___)) %&gt;% print() Close Hint Calculate the total number of confirmed cases and deaths. Hint: you may use the cumsum function to add all cases up until a given date. You may here consider NA values in the cases and deaths columns as equal to zero (e.g. using replace_na(cases, 0)). What is the total number of deaths in Norway up to October 10th, 2021? × Solution res1 &lt;- dat %&gt;% group_by(country, month, year, population) %&gt;% summarize(tests = max(tests, na.rm = TRUE) - min(tests, na.rm = TRUE)) %&gt;% ungroup() %&gt;% mutate(testsCap = tests/population) %&gt;% arrange(desc(year), month) %&gt;% print() #&gt; # A tibble: 90 × 6 #&gt; country month year population tests testsCap #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Denmark 1 2021 5813302 2863482 0.493 #&gt; 2 Germany 1 2021 83900471 4684292 0.0558 #&gt; 3 Norway 1 2021 5465629 581599 0.106 #&gt; 4 United Kingdom 1 2021 68207114 16382170 0.240 #&gt; 5 Denmark 2 2021 5813302 3357579 0.578 #&gt; 6 Germany 2 2021 83900471 3335631 0.0398 #&gt; 7 Norway 2 2021 5465629 429646 0.0786 #&gt; 8 United Kingdom 2 2021 68207114 15305191 0.224 #&gt; 9 Denmark 3 2021 5813302 4881781 0.840 #&gt; 10 Germany 3 2021 83900471 4068985 0.0485 #&gt; # … with 80 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows res2 &lt;- res1 %&gt;% filter(year == 2021, month == 3) %&gt;% arrange(desc(testsCap)) %&gt;% print() #&gt; # A tibble: 4 × 6 #&gt; country month year population tests testsCap #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Denmark 3 2021 5813302 4881781 0.840 #&gt; 2 United Kingdom 3 2021 68207114 33279694 0.488 #&gt; 3 Norway 3 2021 5465629 791345 0.145 #&gt; 4 Germany 3 2021 83900471 4068985 0.0485 The highest number of tests per capita in March 2021 was in Denmark. Close Solution × Hint res1 &lt;- dat %&gt;% group_by(___) %&gt;% summarize(tests = max(___, na.rm = TRUE) - min(___, na.rm = TRUE)) %&gt;% ungroup() %&gt;% mutate(testsCap = ___) %&gt;% arrange(desc(___), month) %&gt;% print() res2 &lt;- res1 %&gt;% filter(___) %&gt;% arrange(desc(___)) %&gt;% print() Close Hint For each country calculate the number of tests done in each month in a given year. Which country had the highest number of tests per capita in March 2021? × Solution res &lt;- dat %&gt;% filter(country == &quot;United Kingdom&quot;) %&gt;% group_by(country, year, month) %&gt;% summarize(icu = max(icu_patients, na.rm = TRUE)) %&gt;% arrange(desc(icu)) %&gt;% print() #&gt; # A tibble: 23 × 4 #&gt; # Groups: country, year [2] #&gt; country year month icu #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 United Kingdom 2021 1 4077 #&gt; 2 United Kingdom 2021 2 3726 #&gt; 3 United Kingdom 2020 4 3301 #&gt; 4 United Kingdom 2020 5 2178 #&gt; 5 United Kingdom 2020 12 2122 #&gt; 6 United Kingdom 2021 3 1806 #&gt; 7 United Kingdom 2020 11 1489 #&gt; 8 United Kingdom 2021 9 1081 #&gt; 9 United Kingdom 2021 11 1034 #&gt; 10 United Kingdom 2021 8 1014 #&gt; # … with 13 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows The highest number of ICU patients on a given day was in January (4077 patients). Close Solution × Hint res &lt;- dat %&gt;% filter(___) %&gt;% group_by(___) %&gt;% summarize(icu = max(___, na.rm = TRUE)) %&gt;% arrange(desc(___)) %&gt;% print() Close Hint Consider United Kingdom. Which month had the highest number of ICU patients on a given day? "],["mod-r-plot.html", "Module 14 Data visualization using ggplot 14.1 Learning outcomes 14.2 Introduction to data visualization 14.3 Combining plots into one using patchwork 14.4 Saving graphics 14.5 Recap 14.6 Exercises", " Module 14 Data visualization using ggplot This module considers visualization of your data using the ggplot2 package which is a part of tidyverse. R has several systems for making plots, but ggplot2 is one of the most elegant and most versatile. Using ggplot2 you can make plots faster by learning one system and applying it in many different plot types. A template project for this module is given on RStudio Cloud (open it and use it while reading the notes). Learning path diagram It is recommended that you follow the green learning path; however, you may like a different learning style. In the learning path diagram, there are links to alternative online content (video or reading). Note this is an alternative to the standard learning path that you may use instead (you should not do both). The learning path may also have extra content, that is NOT a part of syllabus (only look at it if you want more info)! 14.1 Learning outcomes By the end of this module, you are expected to: Know how to create basic plots using ggplot. Formulate the ideas behind the grammar of graphics. Explain the idea behind aesthetics such as color, fill, and line type. Add geometries to a plot such as a histogram, a boxplot, a barplot, a scatter plot, and a line. Understand how themes can be used to modify the overall look of a plot. Combine multiple plots into a single graphic. Save plots as variables and different image files. The learning outcomes relate to the overall learning goals number 7, 11-14 and 18 of the course. 14.2 Introduction to data visualization The package ggplot2 is a plotting package that makes it simple to create complex plots from data in a data frame. It provides an interface for specifying which variables to plot, how they are displayed, and general visual properties. Hence, only minimal changes are needed, if the underlying data change or if we decide to change from a bar plot to a scatterplot. The package implements the grammar of graphics, a coherent system for describing and building layered plots. A plot is built step by step by adding new layers. Adding layers in this fashion allows for extensive flexibility and customization of plots. An excellent introduction to data visualization using ggplot2 is given in the interactive DataCamp course Introduction to data visualization with ggplot2. Please complete the course before continuing. Note that there is a difference between using the pipe %&gt;% operator which passes the output of the previous line of code as the first input of the next line of code and the + operator used between ggplot2 functions for “layering”. That is, you create the plot in layers, separated by +. 14.3 Combining plots into one using patchwork You can combine separate ggplots into the same graphic using the patchwork package. You can install patchwork from CRAN using install.packages('patchwork'). The usage is simple. Plots in two rows: library(ggplot2) library(patchwork) p1 &lt;- ggplot(mtcars) + geom_point(aes(mpg, disp)) p2 &lt;- ggplot(mtcars) + geom_boxplot(aes(gear, disp, group = gear)) p1 + p2 The package provides rich support for arbitrarily complex layouts. Code for nesting three plots on top of a third: p3 &lt;- ggplot(mtcars) + geom_smooth(aes(disp, qsec)) p4 &lt;- ggplot(mtcars) + geom_bar(aes(carb)) (p1 | p2 | p3) / p4 For further examples see the documentation pages. 14.4 Saving graphics In general, when you do analytics using R Markdown, there is no need to save your graphics. This is done automatically. However, in a few cases you may need to save you graphics in different formats. Let us consider a simple plot: library(tidyverse) p &lt;- ggplot(mpg, aes(displ, hwy, colour = class)) + geom_point() p # print it out To save the plot as a bitmap image (png, jpeg etc) have a look at the documentation (?png). Let us try to save the plot as a png file. png(&quot;test1.png&quot;) # open png device for writing p dev.off() # close device #&gt; png #&gt; 2 png(&quot;test2.png&quot;, width = 1200, height = 600) # use other output width and height in px p dev.off() #&gt; png #&gt; 2 png(&quot;test3.png&quot;, width = 1200, height = 900) # save a patchwork plot (p1 | p2 | p3) / p4 dev.off() #&gt; png #&gt; 2 # browseURL(&quot;test1.png&quot;) # to have a look at the file # browseURL(&quot;test3.png&quot;) # to have a look at the file To save the plot as a pdf use pdf(&quot;test1.pdf&quot;) # open pdf device for writing p dev.off() # close device #&gt; png #&gt; 2 # browseURL(&quot;test1.pdf&quot;) # to have a look at the file If you use LaTeX you may use the tikzDevice package to save plots as TikZ. 14.5 Recap The tidyverse package ggplot2 is an R package for producing data visualizations. It is based on the Grammar of Graphics by Wilkinson (2005). The grammar of graphics is a coherent system for describing and building layered plots. Graphics are made by grammatical elements such as data, aesthetics, geometries, scales, facets, and themes. Plots are made though aesthetic mappings. That is, variables are mapped to x or y position using aesthetics attributes such as color, shape, or size. A plot is built step by step by adding new layers. Adding layers in this fashion allows for extensive flexibility and customization of plots. Together, the data, aesthetic mappings, and geometric object form a layer. A plot may have multiple layers, for example, when we overlay a scatterplot with a smoothed line. Aesthetics are add in ggplot using the aes function or alternatively in geom_ functions. Geometries (e.g. a boxplot or line) are added to a plot using the geom_ functions. Themes can be applied to the plot using the theme_ functions and control all the non-data ink used to modify the overall look of a plot. Separate ggplots can be combined into the same graphic using the patchwork package. Save plots as variables and different image files using the device functions such as png and pdf. The pipe %&gt;% operator is used to “pipe” the output of the previous line of code as the first input of the next line of code. The + operator in ggplot2 functions is used for “layering”. This means you create the plot in layers, separated by +. The ‘Data visualization with ggplot2’ cheatsheet is very useful. Find the newest version in RStudio Help &gt; Cheatsheets. A good place to see examples are on the main reference page. Follow the link to the function of interest and have a look at the examples. You may also have a look at the slides for this module. 14.6 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Some of the solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up too early. Put some effort into finding a solution! Always practice using shortcuts in RStudio (see Tools &gt; Keyboard Shortcuts Help). Go to the Tools for Analytics workspace and download/export the TM14 project. Open it on your laptop and have a look at the files in the exercises folder which can be used as a starting point. 14.6.1 Exercise (gapminder) Use the exercise R Markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). In this exercise, we will demonstrate how relatively simple ggplot2 code can create insightful and aesthetically pleasing plots. As motivation we will create plots that help us better understand trends in world health and economics. Hans Rosling was the co-founder of the Gapminder Foundation, an organization dedicated to educating the public by using data to dispel common myths about the so-called developing world. Hans Rosling conveyed actual data-based trends in a dramatic way of his own, using effective data visualization. Here we will try to answer two questions: Is it a fair characterization of today’s world to say it is divided into Western rich nations and the developing world in Africa, Asia, and Latin America? Has income inequality across countries worsened during the last 40 years? To answer these questions, we will be using the gapminder dataset provided in the dslabs package. This dataset was created using a number of spreadsheets available from the Gapminder Foundation. You can access the table like this: library(tidyverse) library(dslabs) data(gapminder) gapminder %&gt;% as_tibble() #&gt; # A tibble: 10,545 × 9 #&gt; country year infant_mortality life_expecta…¹ ferti…² popul…³ gdp conti…⁴ region #&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; #&gt; 1 Albania 1960 115. 62.9 6.19 1.64e6 NA Europe South… #&gt; 2 Algeria 1960 148. 47.5 7.65 1.11e7 1.38e10 Africa North… #&gt; 3 Angola 1960 208 36.0 7.32 5.27e6 NA Africa Middl… #&gt; 4 Antigua and Barbuda 1960 NA 63.0 4.43 5.47e4 NA Americ… Carib… #&gt; 5 Argentina 1960 59.9 65.4 3.11 2.06e7 1.08e11 Americ… South… #&gt; 6 Armenia 1960 NA 66.9 4.55 1.87e6 NA Asia Weste… #&gt; 7 Aruba 1960 NA 65.7 4.82 5.42e4 NA Americ… Carib… #&gt; 8 Australia 1960 20.3 70.9 3.45 1.03e7 9.67e10 Oceania Austr… #&gt; 9 Austria 1960 37.3 68.8 2.7 7.07e6 5.24e10 Europe Weste… #&gt; 10 Azerbaijan 1960 NA 61.3 5.57 3.90e6 NA Asia Weste… #&gt; # … with 10,535 more rows, and abbreviated variable names ¹​life_expectancy, ²​fertility, #&gt; # ³​population, ⁴​continent #&gt; # ℹ Use `print(n = ...)` to see more rows We start by testing our knowledge regarding differences in child mortality across different countries. For each of the six pairs of countries below, which country do you think had the highest child mortality rates in 2015? Which pairs do you think are most similar? Sri Lanka or Turkey Poland or South Korea Malaysia or Russia Pakistan or Vietnam Thailand or South Africa When answering these questions without data, the non-European countries are typically picked as having higher child mortality rates: Sri Lanka over Turkey, South Korea over Poland, and Malaysia over Russia. It is also common to assume that countries considered to be part of the developing world: Pakistan, Vietnam, Thailand, and South Africa, have similarly high mortality rates. To answer these questions with data, we can use dplyr. For example, for the first comparison we see that: gapminder %&gt;% filter(year == 2015 &amp; country %in% c(&quot;Sri Lanka&quot;,&quot;Turkey&quot;)) %&gt;% select(country, infant_mortality) #&gt; country infant_mortality #&gt; 1 Sri Lanka 8.4 #&gt; 2 Turkey 11.6 Turkey has the higher infant mortality rate. We can use this code on all comparisons and find the following: country infant mortality country infant mortality Sri Lanka 8.4 Turkey 11.6 Poland 4.5 South Korea 2.9 Malaysia 6.0 Russia 8.2 Pakistan 65.8 Vietnam 17.3 Thailand 10.5 South Africa 33.6 We see that the European countries on this list have higher child mortality rates: Poland has a higher rate than South Korea, and Russia has a higher rate than Malaysia. We also see that Pakistan has a much higher rate than Vietnam, and South Africa has a much higher rate than Thailand. It turns out that when Hans Rosling gave this quiz to educated groups of people, the average score was less than 2.5 out of 5, worse than what they would have obtained had they guessed randomly. This implies that we are misinformed. We will try to use visualization to help us being more informed. The west vs. the developing world There is a preconceived notion that the world is divided into two groups: the Western world (Western Europe and North America), characterized by long life spans and small families, versus the developing world (Africa, Asia, and Latin America) characterized by short life spans and large families. But do the data support this dichotomous view? × Solution filter(gapminder, year == 1962) %&gt;% ggplot( aes(fertility, life_expectancy, color = continent)) + geom_point() Most points fall into two distinct categories: Life expectancy around 70 years and 3 or fewer children per family. Life expectancy lower than 65 years and more than 5 children per family. Countries are from the regions we expect. Close Solution × Hint filter(gapminder, year == ___) %&gt;% ggplot( aes(___, ___, color = ___)) + geom_point() Close Hint Make a scatterplot of life expectancy versus fertility rates (average number of children per woman) in 1962. Use continent as color aesthetic. × Solution filter(gapminder, year %in% c(1962, 2012)) %&gt;% ggplot(aes(fertility, life_expectancy, col = continent)) + geom_point() + facet_grid(cols = vars(year)) This plot clearly shows that the majority of countries have moved from the developing world cluster to the western world one. In 2012, the western versus developing world view no longer makes sense. This is particularly clear when comparing Europe to Asia, the latter of which includes several countries that have made great improvements. Close Solution × Hint filter(gapminder, ___ %in% c(1962, 2012)) %&gt;% ggplot(aes(___, ___, col = ___)) + geom_point() + facet_grid(cols = vars(___)) Close Hint In 1962, “the West versus developing world” view was grounded in some reality. Is this still the case 50 years later? We could easily plot the 2012 data in the same way we did for 1962. To make comparisons, side by side plots are preferable. In ggplot2, we can achieve this by faceting variables and making a plot for each year. That is, you must filter by years 1962 and 2012 and add the layer facet_grid, which automatically separates the plots. × Solution years &lt;- c(1962, 1970, 1980, 1990, 2000, 2012) continents &lt;- c(&quot;Europe&quot;, &quot;Asia&quot;) gapminder %&gt;% filter(year %in% years &amp; continent %in% continents) %&gt;% ggplot( aes(fertility, life_expectancy, col = continent)) + geom_point() + facet_wrap(vars(year)) The plot clearly shows how most Asian countries have improved at a much faster rate than European ones. Close Solution × Hint gapminder %&gt;% filter(year %in% ___ &amp; continent %in% ___) %&gt;% ggplot(aes(___)) + geom_point() + facet_wrap(___) Close Hint To explore the transformation through the years, make a plot for the years 1962, 1970, 1980, 1990, 2000, and 2012 considering Europe and Asia. How has Asia transformed through the years compared to Europe? Since we consider many years, we will not want all the plots on the same row. Instead, we will want to use multiple rows and columns. The function facet_wrap permits us to do this by automatically wrapping the series of plots. Infobox - Scales The default choice of the range of the axes is important. When not using facet, this range is determined by the data shown in the plot. When using facet, this range is determined by the data shown in all plots and therefore kept fixed across plots. This makes comparisons across plots much easier. For example, in the above plot, we can see that life expectancy has increased and the fertility has decreased across most countries. We see this because the cloud of points moves. This is not the case if we adjust the scales: In the plot above, we have to pay special attention to the range to notice that the plot on the right has a larger life expectancy. × Solution gapminder %&gt;% filter(continent == &quot;Asia&quot;) %&gt;% ggplot(aes(fertility, life_expectancy, col = year)) + geom_point() Close Solution × Hint gapminder %&gt;% filter(___) %&gt;% ggplot(aes(___)) + geom_point() Close Hint Illustrate the transformation for Asia using a single plot where year is used as color aesthetic. Time series plots The visualizations above effectively illustrate that data no longer supports the Western versus developing world view. Once we see these plots, new questions emerge. For example, which countries are improving more and which ones less? Was the improvement constant during the last 50 years or was it more accelerated during certain periods? For a closer look that may help answer these questions, we introduce time series plots. Time series plots have time in the x-axis and an outcome or measurement of interest on the y-axis. For example, here is a trend plot of United States fertility rates: gapminder %&gt;% filter(country == &quot;United States&quot;) %&gt;% ggplot(aes(year, fertility)) + geom_point() We see that the trend is not linear at all. Instead there is sharp drop during the 1960s and 1970s to below 2. Then the trend comes back to 2 and stabilizes during the 1990s. When the points are regularly and densely spaced, as they are here, we create curves by joining the points with lines, to convey that these data are from a single series, here a country. To do this, we use the geom_line function instead of geom_point. × Solution gapminder %&gt;% filter(country == &quot;United States&quot;) %&gt;% ggplot(aes(year, fertility)) + geom_line() Close Solution Make a lineplot showing the time series of fertility versus year for United States. × Solution countries &lt;- c(&quot;South Korea&quot;, &quot;Germany&quot;) gapminder %&gt;% filter(country %in% countries) %&gt;% ggplot(aes(year, fertility, col = country)) + geom_line() The plot clearly shows how South Korea's fertility rate dropped drastically during the 1960s and 1970s, and by 1990 had a similar rate to that of Germany. Close Solution × Hint gapminder %&gt;% filter(country %in% ___) %&gt;% ggplot(aes(year, fertility, col = ___)) + geom_line() Close Hint Lineplots is particularly helpful when we look at more countries. Make a lineplot showing the time series of fertility versus year for South Korea and Germany. Use country as color aesthetic. × Solution gapminder %&gt;% filter(country %in% countries) %&gt;% ggplot(aes(year, life_expectancy, col = country)) + geom_line() The plot clearly shows how an improvement in life expectancy followed the drops in fertility rates. In 1960, Germans lived 15 years longer than South Koreans, although by 2010 the gap is completely closed. It exemplifies the improvement that many non-western countries have achieved in the last 40 years. Close Solution Make a lineplot showing the time series of life expectancy versus year for South Korea and Germany. Use country as color aesthetic. Data transformations We now shift our attention to the second question related to the commonly held notion that wealth distribution across the world has become worse during the last decades. When general audiences are asked if poor countries have become poorer and rich countries become richer, the majority answers yes. By using stratification, histograms, smooth densities, and boxplots, we will be able to understand if this is in fact the case. First we learn how transformations can sometimes help provide more informative summaries and plots. The gapminder data table includes a column with the countries’ gross domestic product (GDP). GDP measures the market value of goods and services produced by a country in a year. The GDP per person is often used as a rough summary of a country’s wealth. Here we divide this quantity by 365 to obtain the more interpretable measure dollars per day. Using current U.S. dollars as a unit, a person surviving on an income of less than $2 a day, is defined to be living in absolute poverty. We add this variable to the data table: gapminder &lt;- gapminder %&gt;% mutate(dollars_per_day = gdp/population/365) The GDP values are adjusted for inflation and represent current U.S. dollar, so these values are meant to be comparable across the years. Of course, these are country averages and within each country there is much variability. All the graphs and insights described below relate to country averages and not to individuals. Here is a histogram of per day incomes from 1970: past_year &lt;- 1970 gapminder %&gt;% filter(year == past_year &amp; !is.na(gdp)) %&gt;% ggplot(aes(dollars_per_day)) + geom_histogram(binwidth = 1, color = &quot;black&quot;) We use the color = \"black\" argument to draw a boundary and clearly distinguish the bins. In this plot, we see that for the majority of countries, averages are below $10 a day. However, the majority of the x-axis is dedicated to the 35 countries with averages above $10. So the plot is not very informative about countries with values below $10 a day. It might be more informative to quickly be able to see how many countries have average daily incomes of about $1 (extremely poor), $2 (very poor), $4 (poor), $8 (middle), $16 (well off), $32 (rich), $64 (very rich) per day. These changes are multiplicative and log transformations convert multiplicative changes into additive ones: when using base 2, a doubling of a value turns into an increase by 1. × Solution gapminder %&gt;% filter(year == past_year &amp; !is.na(gdp)) %&gt;% ggplot(aes(log2(dollars_per_day))) + geom_histogram(binwidth = 1, color = &quot;black&quot;) This provides a close-up of the mid to lower income countries. Close Solution Make a histogram of log2(dollars_per_day) from 1970. Infobox - Which base? In the case above, we used base 2 in the log transformations. Other common choices are base \\(\\mathrm{e}\\) (the natural log) and base 10. In general, we do not recommend using the natural log for data exploration and visualization. This is because while \\(2^2, 2^3, 2^4, \\dots\\) or \\(10^2, 10^3, \\dots\\) are easy to compute in our heads, the same is not true for \\(\\mathrm{e}^2, \\mathrm{e}^3, \\dots\\), so the scale is not intuitive or easy to interpret. In the dollars per day example, we used base 2 instead of base 10 because the resulting range is easier to interpret. The range of the values being plotted is 0.327, 48.885. In base 10, this turns into a range that includes very few integers: just 0 and 1. With base two, our range includes -2, -1, 0, 1, 2, 3, 4, and 5. It is easier to compute \\(2^x\\) and \\(10^x\\) when \\(x\\) is an integer and between -10 and 10, so we prefer to have smaller integers in the scale. Another consequence of a limited range is that choosing the binwidth is more challenging. With log base 2, we know that a binwidth of 1 will translate to a bin with range \\(x\\) to \\(2x\\). For an example in which base 10 makes more sense, consider population sizes. A log base 10 is preferable since the range for these is: filter(gapminder, year == past_year) %&gt;% summarize(min = min(population), max = max(population)) #&gt; min max #&gt; 1 46075 8.09e+08 Here is the histogram of the transformed values: gapminder %&gt;% filter(year == past_year) %&gt;% ggplot(aes(log10(population))) + geom_histogram(binwidth = 0.5, color = &quot;black&quot;) In the above, we quickly see that country populations range between ten thousand and ten billion. There are two ways we can use log transformations in plots. We can log the values before plotting them or use log scales on the axes. Both approaches are useful and have different strengths. If we log the data, we can more easily interpret intermediate values in the scale. For example, if we see: ----1----x----2--------3---- for log transformed data, we know that the value of \\(x\\) is about 1.5. If the scales are logged: ----1----x----10------100--- then, to determine x, we need to compute \\(10^{1.5}\\), which is not easy to do in our heads. The advantage of using logged scales is that we see the original values on the axes. However, the advantage of showing logged scales is that the original values are displayed in the plot, which are easier to interpret. For example, we would see “32 dollars a day” instead of “5 log base 2 dollars a day”. × Solution gapminder %&gt;% filter(year == past_year &amp; !is.na(gdp)) %&gt;% ggplot(aes(dollars_per_day)) + geom_histogram(binwidth = 1, color = &quot;black&quot;) + scale_x_continuous(trans = &quot;log2&quot;) The plot from Q8 is the same except the values on the x-axis. Close Solution Make a histogram of dollars_per_day from 1970 using a log2 scale on the x-axis. Compare it to the plot from Question 8. Hint: you can use the scale_x_continuous function with trans = \"log2\". The histograms in Questions 8 and 9 have two bumps: one at about 4 and another at about 32. In statistics these bumps are sometimes referred to as modes. The mode of a distribution is the value with the highest frequency. The mode of the normal distribution is the average. When a distribution, like the one above, does not monotonically decrease from the mode, we call the locations where it goes up and down again local modes and say that the distribution has multiple modes indicating different distributions for different groups. The histogram above suggests that the 1970 country income distribution has two modes: one at about 2 dollars per day (1 in the log 2 scale) and another at about 32 dollars per day (5 in the log 2 scale). However, the histogram does not show us if the two groups of countries are west versus the rest. Let us create the group column: gapminder &lt;- gapminder %&gt;% mutate(group = case_when( region %in% c(&quot;Western Europe&quot;, &quot;Northern Europe&quot;,&quot;Southern Europe&quot;, &quot;Northern America&quot;, &quot;Australia and New Zealand&quot;) ~ &quot;West&quot;, TRUE ~ &quot;Rest&quot;)) %&gt;% as_tibble() × Solution gapminder %&gt;% filter(year == past_year &amp; !is.na(gdp)) %&gt;% ggplot(aes(dollars_per_day)) + geom_histogram(binwidth = 1, color = &quot;black&quot;) + facet_grid(cols = vars(group)) + scale_x_continuous(trans = &quot;log2&quot;) The plot confirms the west vs the rest dichotomy. Close Solution × Hint gapminder %&gt;% filter(year == past_year &amp; !is.na(gdp)) %&gt;% ggplot(aes(dollars_per_day)) + geom_histogram(binwidth = 1, color = &quot;black&quot;) + facet_grid(cols = ___) + scale_x_continuous(trans = &quot;log2&quot;) Close Hint Make a histogram of dollars_per_day from 1970 using a log2 scale and facet it by group. Is there a west versus the rest dichotomy? The exploratory data analysis above has revealed two characteristics about average income distribution in 1970. Using a histogram, we found a bimodal distribution with the modes relating to poor and rich countries. We will try to visualize these summaries in one plot. × Solution gapminder %&gt;% filter(year == past_year &amp; !is.na(gdp)) %&gt;% ggplot(aes(group, dollars_per_day)) + geom_boxplot() + scale_y_continuous(trans = &quot;log2&quot;) + geom_point() Close Solution × Hint gapminder %&gt;% filter(year == past_year &amp; !is.na(gdp)) %&gt;% ggplot(aes(group, dollars_per_day)) + geom____() + scale_y_continuous(trans = &quot;log2&quot;) + geom____() Close Hint Make a boxplot (geom_boxplot) of dollars_per_day (y-axis) versus group (x-axis) from 1970 using a log2 scale. Also add a the data using geom_point(). Data exploration clearly shows that in 1970 there was a “west versus the rest” dichotomy. But does this dichotomy persist? We first have to be a little careful here since there are more countries represented in 2010 than in 1970: the total counts are larger. One reason for this is that several countries were founded after 1970. For example, the Soviet Union divided into several countries during the 1990s. Another reason is that data was available for more countries in 2010. Hence we only have to consider the countries with data available for both years: past_year &lt;- 1970 present_year &lt;- 2010 years &lt;- c(past_year, present_year) country_list_1 &lt;- gapminder %&gt;% filter(year == past_year &amp; !is.na(dollars_per_day)) %&gt;% pull(country) country_list_2 &lt;- gapminder %&gt;% filter(year == present_year &amp; !is.na(dollars_per_day)) %&gt;% pull(country) country_list &lt;- intersect(country_list_1, country_list_2) We can now filter the rows by years and country_list. × Solution gapminder %&gt;% filter(year %in% years &amp; country %in% country_list) %&gt;% ggplot(aes(dollars_per_day)) + geom_histogram(binwidth = 1, color = &quot;black&quot;) + scale_x_continuous(trans = &quot;log2&quot;) + facet_grid(year ~ group) The income gap between rich and poor countries has narrowed considerably during the last 40 years Close Solution × Hint gapminder %&gt;% filter(year %in% ___ &amp; country %in% ___) %&gt;% ggplot(aes(dollars_per_day)) + geom_histogram(binwidth = 1, color = &quot;black&quot;) + scale_x_continuous(trans = &quot;log2&quot;) + facet_grid(___) Close Hint Make a histogram of dollars_per_day from 1970 and 2010 using a log2 scale and facet it by group and year. Does the dichotomy persist? × Solution gapminder %&gt;% filter(year %in% years &amp; country %in% country_list) %&gt;% mutate(year = factor(year)) %&gt;% ggplot(aes(group, dollars_per_day, fill = year)) + geom_boxplot() + scale_y_continuous(trans = &quot;log2&quot;) We now see that the rich countries have become a bit richer, but percentage-wise, the poor countries appear to have improved more. In particular, we see that the proportion of developing countries earning more than $16 a day increased substantially. Close Solution × Hint gapminder %&gt;% filter(year %in% years &amp; country %in% country_list) %&gt;% mutate(year = factor(___)) %&gt;% ggplot(aes(group, dollars_per_day, fill = ___)) + geom_boxplot() + scale_y_continuous(trans = &quot;log2&quot;) Close Hint Make a boxplot of dollars_per_day versus group from 1970 and 2010 using a log2 scale. Use year as fill aesthetic. Hint: you must convert year to a factor using mutate(year = factor(year)). The previous data exploration suggested that the income gap between rich and poor countries has narrowed considerably during the last 40 years. We used a series of histograms and boxplots to see this. Let us now shift to density plots. Let us start by noting that density plots for income distribution in 1970 and 2010 deliver the message that the gap is closing: gapminder %&gt;% filter(year %in% years &amp; country %in% country_list) %&gt;% ggplot(aes(dollars_per_day)) + geom_density(fill = &quot;grey&quot;) + scale_x_continuous(trans = &quot;log2&quot;) + facet_grid(cols = vars(year)) In the 1970 plot, we see two clear modes: poor and rich countries. In 2010, it appears that some of the poor countries have shifted towards the right, closing the gap. The next message we need to convey is that the reason for this change in distribution is that several poor countries became richer, rather than some rich countries becoming poorer. To do this, we can assign a color to the groups we identified during data exploration. gapminder %&gt;% filter(year %in% years &amp; country %in% country_list) %&gt;% ggplot(aes(dollars_per_day, fill = group)) + scale_x_continuous(trans = &quot;log2&quot;) + geom_density(alpha = 0.2) + facet_grid(cols = vars(year)) Note the default is to have the area represented by each distribution add up to 1, regardless of the size of each group: the number of countries in the ‘west’ group is 21 and in the ‘rest’ group is 87. We may use count on the y-axis instead: p &lt;- gapminder %&gt;% filter(year %in% years &amp; country %in% country_list) %&gt;% ggplot(aes(dollars_per_day, y = ..count.., fill = group)) + scale_x_continuous(trans = &quot;log2&quot;, limit = c(0.125, 300)) + facet_grid(cols = vars(year)) p + geom_density(alpha = 0.2) × Solution p + geom_density(alpha = 0.2, bw = 0.75) This plot now shows that the developing world distribution is changing. Close Solution To get densities smoother, use bw = 0.75 argument so that the same bandwidth is used in each density. Comment on the plot. As a final point, we note that in these distributions the weight of every country is the same. So if most of the population is improving, but living in a very large country, such as China, we might not appreciate this. We can actually weight the smooth densities using the weight mapping argument. We modify the dataset: gapminder &lt;- gapminder %&gt;% filter(year %in% years &amp; country %in% country_list) %&gt;% group_by(year) %&gt;% mutate(weight = population/sum(population)*2) %&gt;% ungroup() × Solution gapminder %&gt;% ggplot(aes(dollars_per_day, fill = group, weight = weight)) + scale_x_continuous(trans = &quot;log2&quot;, limit = c(0.125, 300)) + geom_density(alpha = 0.2, bw = 0.75) + facet_grid(cols = vars(year)) We now see that the rich countries have become a bit richer, but percentage-wise, the poor countries appear to have improved more. In particular, we see that the proportion of developing countries earning more than $16 a day increased substantially. Close Solution × Hint gapminder %&gt;% ggplot(aes(dollars_per_day, fill = group, weight = ___)) + scale_x_continuous(trans = &quot;log2&quot;, limit = c(0.125, 300)) + geom_density(alpha = 0.2, bw = 0.75) + facet_grid(cols = vars(year)) Close Hint Modify the ggplot function with a weight argument and plot the density (with area equal 1). 14.6.2 Exercise (profit) Use the exercise R Markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). Consider the dataset profit (provided by the tfa package) containing quarterly financial records for each costumer, product, etc.: # remotes::install_github(&quot;bss-osca/tfa-package&quot;, upgrade = FALSE) # upgrade first library(tfa) library(skimr) glimpse(profit) #&gt; Rows: 24,546 #&gt; Columns: 9 #&gt; $ Quarter &lt;dbl&gt; 3, 1, 4, 1, 4, 3, 4, 3, 4, 1, 1, 3, 3, 3, 2, 2, 1, 2, 3, 2, 2, 2, … #&gt; $ Channel &lt;chr&gt; &quot;ATM&quot;, &quot;ATM&quot;, &quot;ATM&quot;, &quot;ATM&quot;, &quot;ATM&quot;, &quot;BRH&quot;, &quot;BRH&quot;, &quot;ATM&quot;, &quot;BRH&quot;, &quot;BR… #&gt; $ `Customer ID` &lt;chr&gt; &quot;FRT&quot;, &quot;MRT&quot;, &quot;PBI&quot;, &quot;PBI&quot;, &quot;MRT&quot;, &quot;MAM&quot;, &quot;PBI&quot;, &quot;FRT&quot;, &quot;PBI&quot;, &quot;PB… #&gt; $ Country &lt;chr&gt; &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;US… #&gt; $ `Product Line` &lt;chr&gt; &quot;Credit Products&quot;, &quot;Credit Products&quot;, &quot;Deposit Products&quot;, &quot;Deposit… #&gt; $ Revenue &lt;dbl&gt; 6044, 4686, 6063, 4682, 6320, 2993, 3355, 5716, 3347, 2624, 3629, … #&gt; $ `Product Cost` &lt;dbl&gt; 3998, 3229, 7440, 6127, 7913, 1034, 4355, 5617, 4229, 1960, 4650, … #&gt; $ `Customer Service Cost` &lt;dbl&gt; 413, 643, 1842, 1118, 1854, 242, 1027, 876, 425, 264, 700, 1482, 4… #&gt; $ Profit &lt;dbl&gt; 1633, 815, -3219, -2563, -3447, 1718, -2027, -777, -1307, 401, -17… skim(profit) Table 14.1: Data summary Name profit Number of rows 24546 Number of columns 9 _______________________ Column type frequency: character 4 numeric 5 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace Channel 0 1 3 3 0 10 0 Customer ID 0 1 3 3 0 18 0 Country 0 1 3 14 0 47 0 Product Line 0 1 14 25 0 6 0 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist Quarter 0 1 2.50 1.12 1 2 2 3 4 ▇▇▁▇▇ Revenue 0 1 120.22 420.96 1 12 41 74 7540 ▇▁▁▁▁ Product Cost 0 1 100.07 375.51 0 9 29 68 9256 ▇▁▁▁▁ Customer Service Cost 0 1 17.42 67.43 0 1 5 12 1865 ▇▁▁▁▁ Profit 0 1 2.71 154.89 -4139 -7 0 9 3664 ▁▁▇▁▁ Make a barplot that shows the total profitability of the product lines. Use the following steps: × Solution profit &lt;- profit %&gt;% mutate(across(where(is.character), as.factor)) Close Solution × Hint profit &lt;- profit %&gt;% mutate(across(where(is.___), as.___)) Close Hint        a) Convert all character columns to factor columns. × Solution profit %&gt;% group_by(`Product Line`) %&gt;% summarise(Profit = sum(Profit)) %&gt;% ggplot(aes(x = `Product Line`, y = Profit)) + geom_col() Close Solution × Hint profit %&gt;% group_by(___) %&gt;% summarise(Profit = sum(___)) %&gt;% ggplot(aes(x = ___, y = ___)) + geom_col() Close Hint        b) Group by product line, calculate the total profit and plot profit for each product line. × Solution profit %&gt;% group_by(`Product Line`) %&gt;% summarise(Profit = sum(Profit)) %&gt;% ggplot(aes(x = reorder(`Product Line`, Profit), y = Profit)) + geom_col() # Alternatively you can reorder the data frame before calling ggplot profit %&gt;% group_by(`Product Line`) %&gt;% summarise(Profit = sum(Profit)) %&gt;% arrange(Profit) %&gt;% mutate(`Product Line` = factor(`Product Line`, levels = `Product Line`, ordered = TRUE)) %&gt;% ggplot(aes(x = reorder(`Product Line`, Profit), y = Profit)) + geom_col() + labs(title = &quot;Total profit for each product line&quot;) Close Solution × Hint 2 profit %&gt;% group_by(`Product Line`) %&gt;% summarise(Profit = sum(Profit)) %&gt;% ggplot(aes(x = reorder(___), y = Profit)) + geom_col() Close Hint 2 × Hint 1 See the last section on this webpage. Close Hint 1        c) Plot profit for each product line where product line is reordered based on total profit. × Solution profit %&gt;% group_by(`Product Line`) %&gt;% summarise(Profit = sum(Profit)) %&gt;% ggplot(aes(x = reorder(`Product Line`, Profit), y = Profit)) + geom_col() + labs(title = &quot;Total profit for each product line&quot;) Close Solution × Hint Try to google ‘ggplot add title’. Close Hint        d) Add a title to the plot using labs. × Solution profit %&gt;% group_by(`Product Line`) %&gt;% summarise(Profit = sum(Profit)) %&gt;% ggplot(aes(x = reorder(`Product Line`, Profit), y = Profit)) + geom_col() + labs(title = &quot;Total profit for each product line&quot;) + xlab(&quot;Product line&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Solution × Hint Try to google ‘ggplot2 rotate axis labels’. Close Hint        e) Rotate the x-axis labels 90 degrees. × Solution dat &lt;- profit %&gt;% group_by(`Product Line`) %&gt;% summarise(Profit = sum(Profit)) dat %&gt;% slice_min(Profit) #&gt; # A tibble: 1 × 2 #&gt; `Product Line` Profit #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 Third Party Products 2209 dat %&gt;% slice_max(Profit) #&gt; # A tibble: 1 × 2 #&gt; `Product Line` Profit #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 Credit Products 31016 Close Solution × Hint dat &lt;- profit %&gt;% group_by(`Product Line`) %&gt;% summarise(Profit = sum(Profit)) dat %&gt;% slice_min(___) dat %&gt;% ___ Close Hint        f) Which product line is best and worst? × Solution profit %&gt;% group_by(`Product Line`, Quarter) %&gt;% summarise(Profit = sum(Profit)) %&gt;% ggplot(aes(x = reorder(`Product Line`, Profit), y = Profit)) + geom_col() + facet_grid(cols = vars(Quarter)) + labs(title = &quot;Total profit for each product line&quot;) + xlab(&quot;Product Line&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Some product lines have quite different earnings in different quarters. Close Solution × Hint profit %&gt;% group_by(`Product Line`, ___) %&gt;% summarise(Profit = sum(Profit)) %&gt;% ggplot(aes(x = reorder(`Product Line`, Profit), y = Profit)) + geom_col() + facet_grid(cols = vars(___)) + labs(title = &quot;Total profit for each product line&quot;) + xlab(&quot;Product Line&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Hint Make a barplot that shows the total profitability of the product lines in each quarter. Are there details we have missed in Question 1? × Solution profit %&gt;% ggplot(aes(y = Profit, x = `Product Line`)) + geom_boxplot() + labs(title = &quot;Profit for each product line&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) The profit varies more for three of the product lines. Close Solution × Hint profit %&gt;% ggplot(aes(y = ___, x = ___)) + geom_boxplot() + labs(title = &quot;Profit for each product line&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Hint Make a boxplot of profitability of the product lines. Any insight? × Solution profit %&gt;% group_by(`Customer ID`) %&gt;% summarise(Profit = sum(Profit)) %&gt;% ggplot(aes(x = reorder(`Customer ID`, Profit), y = Profit)) + geom_col() + labs(title = &quot;Total profit for each customer&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Lowest and highest total profit is for PBI and WEM, respectively. Close Solution × Hint profit %&gt;% group_by(___) %&gt;% summarise(Profit = sum(___)) %&gt;% ggplot(aes(x = reorder(___, ___), y = Profit)) + geom_col() + labs(title = &quot;Total profit for each customer&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Hint Make a barplot that shows the total profitability of the customers. Which customer is best and worst? × Solution profit %&gt;% group_by(`Customer ID`) %&gt;% summarise(Profit = mean(Profit)) %&gt;% ggplot(aes(x = reorder(`Customer ID`, Profit), y = Profit)) + geom_col() + labs(title = &quot;Mean profit for each customer&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Since the number of transactions are not the same, the order of customers will not be the same. Close Solution × Hint profit %&gt;% group_by(`Customer ID`) %&gt;% summarise(Profit = ___) %&gt;% ggplot(aes(x = reorder(`Customer ID`, Profit), y = Profit)) + geom_col() + labs(title = &quot;Mean profit for each customer&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Hint Make a barplot that shows the mean profitability of the customers. Which customer is best and worst? Compare against Question 4 and discuss. × Solution profit %&gt;% group_by(`Customer ID`) %&gt;% summarise(ctr = n(), `Total Profit` = sum(Profit)) %&gt;% ggplot(aes(x = reorder(`Customer ID`, `Total Profit`), y = ctr, fill = `Total Profit`)) + geom_col() + labs(title = &quot;Number of transactions (rows) for each customer&quot;) + xlab(&quot;Customer&quot;) + ylab(&quot;Transactions&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Solution × Hint profit %&gt;% group_by(`Customer ID`) %&gt;% summarise(ctr = ___, `Total Profit` = sum(___)) %&gt;% ggplot(aes(x = reorder(___, `Total Profit`), y = ctr, fill = ___)) + geom_col() + labs(title = &quot;Number of transactions (rows) for each customer&quot;) + xlab(&quot;Customer&quot;) + ylab(&quot;Transactions&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Hint Make a plot illustrating number of transactions for each customer. Use total profit as fill atheistic. × Solution profit %&gt;% ggplot(aes(y = Profit, x = `Customer ID`)) + geom_boxplot() + labs(title = &quot;Profit for each customer&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Solution × Hint profit %&gt;% ggplot(aes(y = ___, x = ___)) + geom_boxplot() + labs(title = &quot;Profit for each customer&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Hint Make a boxplot illustrating the profit for each customer. 14.6.3 Exercise (COVID-19) Use the exercise R Markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). Countries around the world are responding to an outbreak of respiratory illness caused by a novel corona virus, COVID-19. The outbreak first started in Wuhan, China, but cases have been identified in a growing number of other locations internationally, including the United States. In this report we explore how the trajectory of the cumulative deaths in a number of countries. The data come from the coronavirus package, which pulls data from the Johns Hopkins University Center for Systems Science and Engineering (JHU CCSE) Corona virus repository. The corona virus package provides a tidy format dataset of the 2019 Novel Corona virus COVID-19 (2019-nCoV) epidemic. The package is available on GitHub here and is updated daily. First load the following packages: library(tidyverse) library(lubridate) # package for handling dates The data frame called coronavirus in the coronavirus package provides a daily summary of the Corona virus (COVID-19) cases by country. Each row in the data frame represents a country (or, where relevant, state/province). Note that the data provided in this package provides daily number of deaths, confirmed cases, and recovered cases. Since we just need the dataset we load it using read_csv: coronavirus &lt;- read_csv( &quot;https://raw.githubusercontent.com/RamiKrispin/coronavirus/master/csv/coronavirus.csv&quot;, col_types = cols( date = col_date(format = &quot;&quot;), province = col_character(), country = col_character(), lat = col_double(), long = col_double(), type = col_character(), cases = col_double() ) ) We calculate the total number of cases per day, cumulative numbers and days since first record: dat &lt;- coronavirus %&gt;% group_by(country, date, type) %&gt;% summarise(tot_cases = sum(cases)) %&gt;% group_by(country, type) %&gt;% arrange(date) %&gt;% mutate(cumulative_cases = cumsum(tot_cases)) %&gt;% ungroup() %&gt;% mutate( days_elapsed = as.numeric(date - min(date)), year = year(date) ) %&gt;% print() #&gt; # A tibble: 604,206 × 7 #&gt; country date type tot_cases cumulative_cases days_elapsed year #&gt; &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Afghanistan 2020-01-22 confirmed 0 0 0 2020 #&gt; 2 Afghanistan 2020-01-22 death 0 0 0 2020 #&gt; 3 Afghanistan 2020-01-22 recovery 0 0 0 2020 #&gt; 4 Albania 2020-01-22 confirmed 0 0 0 2020 #&gt; 5 Albania 2020-01-22 death 0 0 0 2020 #&gt; 6 Albania 2020-01-22 recovery 0 0 0 2020 #&gt; 7 Algeria 2020-01-22 confirmed 0 0 0 2020 #&gt; 8 Algeria 2020-01-22 death 0 0 0 2020 #&gt; 9 Algeria 2020-01-22 recovery 0 0 0 2020 #&gt; 10 Andorra 2020-01-22 confirmed 0 0 0 2020 #&gt; # … with 604,196 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows × Solution dat %&gt;% group_by(date, type) %&gt;% summarise(tot_cases = sum(tot_cases)) %&gt;% print() %&gt;% ggplot(aes(x = date, y = tot_cases)) + geom_col() + facet_grid(rows = vars(type), scales = &quot;free&quot;) + labs( title = &quot;Number of Covid 19 cases per day&quot;, y = &quot;cases&quot; ) #&gt; # A tibble: 3,006 × 3 #&gt; # Groups: date [1,002] #&gt; date type tot_cases #&gt; &lt;date&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 2020-01-22 confirmed 557 #&gt; 2 2020-01-22 death 17 #&gt; 3 2020-01-22 recovery 30 #&gt; 4 2020-01-23 confirmed 100 #&gt; 5 2020-01-23 death 1 #&gt; 6 2020-01-23 recovery 2 #&gt; 7 2020-01-24 confirmed 287 #&gt; 8 2020-01-24 death 8 #&gt; 9 2020-01-24 recovery 7 #&gt; 10 2020-01-25 confirmed 493 #&gt; # … with 2,996 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Close Solution × Hint 2 dat %&gt;% group_by(date, type) %&gt;% summarise(tot_cases = sum(tot_cases)) %&gt;% print() %&gt;% ggplot(aes(x = ___, y = ___)) + geom_col() + facet_grid(rows = vars(___), scales = &quot;___&quot;) + labs( title = &quot;___&quot;, y = &quot;___&quot; ) Close Hint 2 × Hint 1 dat %&gt;% group_by(date, ___) %&gt;% summarise(tot_cases = sum(___)) Note you must aggegrate the numbers for the countries. Close Hint 1 Calculate and plot the number of confirmed, death and recovered cases per day given date using facet_grid and geom_col. Consider the following set of countries: countries &lt;- c( &quot;China&quot;, &quot;France&quot;, &quot;Denmark&quot;, &quot;US&quot;, &quot;Italy&quot; ) × Solution dat %&gt;% filter(type == &quot;death&quot;, country %in% countries) %&gt;% ggplot(aes(x = days_elapsed, y = cumulative_cases, color = country)) + geom_line() + theme(legend.position = &quot;bottom&quot;) + labs( x = str_c(&quot;Days since &quot;, min(dat$date)), y = &quot;Cumulative number of deaths&quot;, title = &quot;Cumulative deaths from COVID-19, selected countries&quot; ) Close Solution × Hint 2 dat %&gt;% filter(type == &quot;death&quot;, country %in% countries) %&gt;% ggplot(aes(x = ___, y = ___, color = ___)) + geom_line() + theme(legend.position = &quot;bottom&quot;) + labs( x = str_c(&quot;Days since &quot;, min(dat$date)), y = &quot;___&quot;, title = &quot;Cumulative deaths from COVID-19, selected countries&quot; ) Close Hint 2 × Hint 1 dat %&gt;% filter(type == &quot;___&quot;, country %in% ___) %&gt;% First you have to filter type and country Close Hint 1 Plot a lineplot of the cumulative number of deaths as a function of days elapsed for the selected countries. Use country as color aesthetic. Since the countries have different population sizes, we would like to calculate some numbers relative to the population size. First we need population sizes for each country. They are given in the dataset world_pop in the tfa package: world_pop &lt;- tfa::world_pop %&gt;% filter(country %in% countries) %&gt;% print() #&gt; # A tibble: 1,505 × 3 #&gt; country year pop #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 China 1800 321675013 #&gt; 2 China 1801 324408862 #&gt; 3 China 1802 327165946 #&gt; 4 China 1803 329946461 #&gt; 5 China 1804 332750607 #&gt; 6 China 1805 335578586 #&gt; 7 China 1806 338430598 #&gt; 8 China 1807 341306850 #&gt; 9 China 1808 344207546 #&gt; 10 China 1809 347132894 #&gt; # … with 1,495 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows We can join the datasets using: dat &lt;- dat %&gt;% filter(country %in% countries) %&gt;% left_join(world_pop) %&gt;% print() #&gt; # A tibble: 15,030 × 8 #&gt; country date type tot_cases cumulative_cases days_elapsed year pop #&gt; &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 China 2020-01-22 confirmed 548 548 0 2020 1424548266 #&gt; 2 China 2020-01-22 death 17 17 0 2020 1424548266 #&gt; 3 China 2020-01-22 recovery 28 28 0 2020 1424548266 #&gt; 4 Denmark 2020-01-22 confirmed 0 0 0 2020 5796800 #&gt; 5 Denmark 2020-01-22 death 0 0 0 2020 5796800 #&gt; 6 Denmark 2020-01-22 recovery 0 0 0 2020 5796800 #&gt; 7 France 2020-01-22 confirmed 0 0 0 2020 65721165 #&gt; 8 France 2020-01-22 death 0 0 0 2020 65721165 #&gt; 9 France 2020-01-22 recovery 0 0 0 2020 65721165 #&gt; 10 Italy 2020-01-22 confirmed 0 0 0 2020 59132073 #&gt; # … with 15,020 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows any(is.na(dat)) # check if any missing values #&gt; [1] FALSE × Solution dat &lt;- dat %&gt;% mutate(tot_cases_pop = 100000 * tot_cases/pop) Close Solution Calculate tot_cases_pop as number of cases per 100000 inhabitants. That is, total cases divided by population and multiplied by 100000. × Solution dat %&gt;% filter(date &gt;= today() - days(21), type == &quot;confirmed&quot;) %&gt;% ggplot(aes(x = date, y = tot_cases_pop, fill = country)) + geom_col(position = position_dodge2()) Close Solution × Hint 2 dat %&gt;% filter(date &gt;= today() - days(21), type == ___) %&gt;% ggplot(aes(x = date, y = ___, fill = ___)) + geom_col(position = position_dodge2()) Close Hint 2 × Hint 1 # Use this to find date 21 days ago today() - days(21) #&gt; [1] &quot;2022-09-29&quot; Close Hint 1 Plot the number of confirmed cases per 100000 inhabitants for the last 21 days. Use country as fill aesthetic. × Solution dat %&gt;% filter(date &gt;= today() - days(14), country == &quot;Denmark&quot;, type == &quot;confirmed&quot;) %&gt;% ggplot(aes(x = date, y = tot_cases_pop)) + geom_col() Close Solution × Hint dat %&gt;% filter(date &gt;= ___, country == ___, type == ___) %&gt;% ggplot(aes(x = date, y = tot_cases_pop)) + geom_col() Close Hint Plot the number of confirmed cases per 100000 inhabitants in Denmark for the last 14 days. 14.6.4 Exercise (Lego and sales) Use the exercise R Markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). Consider (simulated) data of Lego sales in 2018 for a sample of customers who bought Legos in the U.S. The dataset is called lego_sales. You can find descriptions of each of the variables in the help file for the dataset, which you can access by running ?lego_sales in your Console. You need the tidyverse package as usual and the dsbox package for the data. library(tidyverse) library(dsbox) # install using devtools::install_github(&quot;rstudio-education/dsbox&quot;) Answer the following questions using a table with numbers and try to visualize it. For each question, state your answer in a sentence, e.g. “The first three common names of purchasers are …”. What are the three most common first names of purchasers? What are the three most common themes of Lego sets purchased? Among the most common theme of Lego sets purchased, what is the most common subtheme? × Hint Use the case_when() function. Close Hint Create a new variable called age_group and group the ages into the following categories: “18 and under”, “19 - 25”, “26 - 35”, “36 - 50”, “51 and over”. × Hint You may need to consider quantity of purchases. Close Hint Which age group has purchased the highest number of Lego sets. × Hint Hint: You will need to consider quantity of purchases as well as price of Lego sets. Close Hint Which age group has spent the most money on Legos? Come up with a question you want to answer using these data, and write it down. Then, create a data visualization that answers the question, and explain how your visualization answers the question. 14.6.5 Exercise (company ranking) This exercise is a slightly modified version an exam assignment (exam 2021-A3). Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). The dataset companies, in the tfa package, lists approx. 1000 of the world’s biggest companies, measured by sales, profits, assets and market value. The column/variables are: name: the name of the company. country: the country the company is situated in. category: the products the company produces. sales: the amount of sales of the company in billion USD. profits: the profit of the company in billion USD. assets: the assets of the company in billion USD. marketvalue: the market value of the company in billion USD. You can load the dataset using: # remotes::install_github(&quot;bss-osca/tfa-package&quot;, build = FALSE) # run if tfa not installed library(tidyverse) companies &lt;- read_csv(system.file(&quot;extdata/companies.csv&quot;, package = &quot;tfa&quot;)) Answer this assignment using the ggplot2 package in tidyverse (you might need dplyr for preparing the datasets you want to plot). × Solution companies %&gt;% count(category) %&gt;% ggplot(aes(x = reorder(category, -n), y = n)) + geom_col() + labs(title = &quot;Number of companies in each product category&quot;, x = &quot;Product category&quot;, y = &quot;&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Based on the plot, the lowest number of companies are in the Trading companies category. Close Solution × Hint companies %&gt;% count(___) %&gt;% ggplot(aes(x = reorder(___, -n), y = n)) + geom_col() + labs(title = &quot;Number of companies in each product category&quot;, x = &quot;Product category&quot;, y = &quot;&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Hint Create a visualization showing the number of companies for each product category with the following features: Number of companies is represented using bars and sorted increasingly or decreasingly. Informative figure title and axis titles are given. The labels on the x-axis are rotated 90 degrees. What product category has the lowest number of companies? × Solution companies %&gt;% filter(category %in% c(&quot;Drugs &amp; biotechnology&quot;, &quot;Media&quot;)) %&gt;% ggplot(aes(x = sales, y = profits, color = category)) + geom_point() + geom_smooth() + labs(title = &quot;Profit given sales&quot;, x = &quot;Sales (billion USD)&quot;, y = &quot;Profit (billion USD)&quot;, color = &quot;Product Category&quot;) + theme(legend.position = &quot;bottom&quot;) Based on the plot the Drugs &amp; biotechnology product category gives the best profit. Close Solution × Hint companies %&gt;% filter(category %in% c(___)) %&gt;% ggplot(aes(x = ___, y = ___, color = ___)) + geom_point() + geom_smooth() + labs(title = &quot;Profit given sales&quot;, x = &quot;Sales (billion USD)&quot;, y = &quot;Profit (billion USD)&quot;, color = &quot;Product Category&quot;) + theme(legend.position = &quot;bottom&quot;) Close Hint Consider product categories Drugs &amp; biotechnology and Media. Create a visualization showing the profit given sales of each company with the following features: Different colors are used for each product category. Informative figure title and axis titles are given. A trend line for each category is added using geom_smooth. Based on the trend lines which product category gives the best profit? × Solution companies &lt;- companies %&gt;% mutate(ratio = profits/sales) # Option 1 - Use a boxplot companies %&gt;% filter(category %in% c(&quot;Banking&quot;, &quot;Aerospace &amp; defense&quot;)) %&gt;% ggplot(aes(y = ratio, color = category)) + geom_boxplot() + labs(title = &quot;Ratio of profit/sales&quot;, x = &quot;&quot;, y = &quot;Profit/sales ratio&quot;, color = &quot;Product Category&quot;) + theme(legend.position = &quot;bottom&quot;) # Option 2 - Use a density plot companies %&gt;% filter(category %in% c(&quot;Banking&quot;, &quot;Aerospace &amp; defense&quot;)) %&gt;% ggplot(aes(x = ratio, fill = category)) + geom_density(alpha = 0.5) + labs(title = &quot;Ratio of profit/sales&quot;, y = &quot;Density&quot;, x = &quot;Profit/sales ratio&quot;, fill = &quot;Product Category&quot;) + theme(legend.position = &quot;bottom&quot;) Given the plot above, it can be seen that the highest ratio with respect to the mean and the median is for Banking. However, the variation is also highest here. Close Solution × Hint companies &lt;- companies %&gt;% mutate(ratio = ___) companies %&gt;% filter(category %in% c(___)) %&gt;% ggplot(aes(y = ___, color = ___)) + geom_boxplot() + labs(title = &quot;Ratio of profit/sales&quot;, x = &quot;&quot;, y = &quot;Profit/sales ratio&quot;, color = &quot;Product Category&quot;) + theme(legend.position = &quot;bottom&quot;) Close Hint Consider product categories Banking and Aerospace &amp; defense. Let ratio denote a variable/column that equals profit divided by sales. Create a visualization showing the variation in ratio with the following features: Different colors are used for each product category. Informative figure title and axis titles are given. Based on the visualization comment on the variation and median. Which product category gives the highest ratio? × Solution continents &lt;- read_csv(system.file(&quot;extdata/continents.csv&quot;, package = &quot;tfa&quot;)) companies %&gt;% left_join(continents) %&gt;% filter(continent %in% c(&quot;Americas&quot;, &quot;Europe&quot;)) %&gt;% filter(category %in% c(&quot;Banking&quot;, &quot;Aerospace &amp; defense&quot;, &quot;Telecommunications services&quot;, &quot;Semiconductors&quot;)) %&gt;% ggplot(aes(x = marketvalue, y = assets, color = continent)) + geom_point() + geom_smooth(method = lm) + facet_wrap(vars(category), scales = &quot;free&quot;) + labs(title = &quot;Assets given market value&quot;, x = &quot;Market value (billion USD)&quot;, y = &quot;Assets (billion USD)&quot;, color = &quot;Continent&quot;) + theme(legend.position = &quot;bottom&quot;) By considering the trend lines for Banking, it seems that if compare companies with the same marketvalue, then companies in Europe have more assets. Close Solution × Hint continents &lt;- read_csv(system.file(&quot;extdata/continents.csv&quot;, package = &quot;tfa&quot;)) companies %&gt;% left_join(___) %&gt;% filter(continent %in% c(___)) %&gt;% filter(category %in% c(___)) %&gt;% ggplot(aes(x = ___, y = ___, color = ___)) + geom_point() + geom_smooth(method = lm) + facet_wrap(vars(___), scales = &quot;free&quot;) + labs(title = &quot;Assets given market value&quot;, x = &quot;Market value (billion USD)&quot;, y = &quot;Assets (billion USD)&quot;, color = &quot;Continent&quot;) + theme(legend.position = &quot;bottom&quot;) Close Hint The continents dataset matches countries to continents and contains two columns: country: the country. continent: the corresponding continent. You can load the dataset using: continents &lt;- read_csv(system.file(&quot;extdata/continents.csv&quot;, package = &quot;tfa&quot;)) Consider product categories Banking, Aerospace &amp; defense, Telecommunications services and Semiconductors. Create a visualization showing assets given market value for each company with the following features (hint: you may need to do a mutating join): Two continents Americas and Europe are considered. Different colors are used for each continent. A plot is given for each product category (facet). Informative figure title and axis titles are given. A trend line for each category is added using geom_smooth(method = lm). Based on the visualization consider the trend lines for Banking and comment. 14.6.6 Exercise (Titanic) This exercise is a slightly modified version an exam assignment (reexam 2021-A3). Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). The dataset titanic, given in the appendix, lists approx. 1300 passengers on Titanic. The column/variables are: pclass: Passenger class (1 = 1st; 2 = 2nd; 3 = 3rd). survived: Survival (0 = No; 1 = Yes). name: Name. sex: Sex. age: Age. fare: Passenger Fare. cabin: Cabin number. embarked: Port of embarkation (C = Cherbourg; Q = Queenstown; S = Southampton). boat: Lifeboat number. You can read the dataset file titanic.csv into the dataset dat using # remotes::install_github(&quot;bss-osca/tfa-package&quot;, build = FALSE) # run if tfa not installed library(tidyverse) dat &lt;- read_csv(system.file(&quot;extdata/titanic.csv&quot;, package = &quot;tfa&quot;)) Answer this assignment using the ggplot2 package in tidyverse (you might need dplyr for preparing the datasets you want to plot). × Solution dat &lt;- dat %&gt;% mutate(harbor = case_when( embarked == &quot;C&quot; ~ &quot;Cherbourg&quot;, embarked == &quot;Q&quot; ~ &quot;Queenstown&quot;, embarked == &quot;S&quot; ~ &quot;Southampton&quot;, TRUE ~ NA_character_ )) dat %&gt;% ggplot(aes(x = harbor)) + geom_bar() + labs(title = &quot;Number of persons embarking each departure harbor&quot;, x = &quot;Harbor&quot;, y = &quot;Persons&quot;) The main harbor was Southampton. Close Solution × Hint dat &lt;- dat %&gt;% mutate(harbor = case_when( embarked == &quot;C&quot; ~ &quot;Cherbourg&quot;, embarked == &quot;Q&quot; ~ &quot;Queenstown&quot;, embarked == &quot;S&quot; ~ &quot;Southampton&quot;, TRUE ~ NA_character_ )) dat %&gt;% ggplot(aes(x = ___)) + geom_bar() + labs(title = &quot;Number of persons embarking each departure harbor&quot;, x = &quot;Harbor&quot;, y = &quot;Persons&quot;) Close Hint Create a visualization showing the number of persons embarking the different harbors with the following features: Number of persons is represented using bars. Informative figure title and axis titles are given. The labels on the x-axis are the harbor names (not abbreviations). What harbor was the main departure harbor? × Solution dat %&gt;% ggplot(aes(x = age)) + geom_histogram(binwidth = 2) + labs(title = &quot;Age distribution&quot;, x = &quot;Age&quot;, y = &quot;Persons&quot;) There where most people in their twenties. Close Solution × Hint dat %&gt;% ggplot(aes(x = ___)) + geom_histogram(binwidth = 2) + labs(title = &quot;Age distribution&quot;, x = &quot;Age&quot;, y = &quot;Persons&quot;) Close Hint Create a visualization showing the age distribution of the persons with the following features: Number of persons is represented using a histogram. Informative figure title and axis titles are given. Where there most people on board in their twenties or thirties? × Solution dat %&gt;% ggplot(aes(x = age, y = fare, color = sex)) + geom_point() + geom_smooth() + labs(title = &quot;Fare prices given age&quot;, x = &quot;Age&quot;, y = &quot;Price&quot;, color = &quot;Sex&quot;) + theme(legend.position = &quot;bottom&quot;) Based on the trend lines females in general pays more than males. Close Solution × Hint dat %&gt;% ggplot(aes(x = ___, y = ___, color = ___)) + geom_point() + geom_smooth() + labs(title = &quot;Fare prices given age&quot;, x = &quot;Age&quot;, y = &quot;Price&quot;, color = &quot;Sex&quot;) + theme(legend.position = &quot;bottom&quot;) Close Hint Create a visualization showing the fare as a function of age with the following features: Different colors are used for each sex. Informative figure title and axis titles are given. A trend line for each sex is added using geom_smooth. Based on the trend lines, do females in general pay more for a ticket? × Solution dat %&gt;% ggplot(aes(x = pclass, fill = as.logical(survived))) + geom_bar(position=&quot;fill&quot;) + labs(title = &quot;Survival rate given passenger class&quot;, x = &quot;Class&quot;, y = &quot;&quot;, fill = &quot;Survived&quot;) + theme(legend.position = &quot;bottom&quot;) Based on the plot most people survived at first classs. Close Solution × Hint dat %&gt;% ggplot(aes(x = ___, fill = as.logical(___))) + geom_bar(position=&quot;fill&quot;) + labs(title = &quot;Survival rate given passenger class&quot;, x = &quot;Class&quot;, y = &quot;&quot;, fill = &quot;Survived&quot;) + theme(legend.position = &quot;bottom&quot;) Close Hint Create a visualization showing the survival rate for each passenger class with the following features: Bars are used for each passenger class. All bars have same height (100 %). Colors are used to identify who survived and did not survived. Informative figure title and axis titles are given. Is the survival rate different on first and third class? × Solution dat &lt;- dat %&gt;% mutate(level = str_sub(cabin, 1, 1)) dat %&gt;% filter(!is.na(level)) %&gt;% ggplot(aes(x = level, y = fare)) + geom_boxplot() Based on the plot the fare prices at B and C level are more or less the same. Close Solution × Hint dat &lt;- dat %&gt;% mutate(level = str_sub(cabin, 1, 1)) dat %&gt;% filter(!is.na(___)) %&gt;% ggplot(aes(x = ___, y = ___)) + geom_boxplot() Close Hint Let column level denote the the first letter in cabin. Create a visualization showing the variance in fare prices with the following features: Ignore rows with missing level. Variation is shown using a boxplot. Informative figure title and axis titles are given. Is the fare price different at the B and C level? 14.6.7 Exercise (covid) This exercise is a slightly modified version an exam assignment (reexam 2022-A3). Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). Consider COVID-19 data obtained from Our World in Data in the file covid.csv. The dataset contains data from different countries. Some of the columns/variables are: cases: New confirmed cases of COVID-19. deaths: New deaths attributed to COVID-19. icu_patients: Number of COVID-19 patients in intensive care units (ICUs) on a given day. hosp_patients: Number of COVID-19 patients in hospital on a given day. tests: Total tests for COVID-19. positive_rate: The share of COVID-19 tests that are positive, given as a rolling 7-day average. vac: Total number of people who received at least one vaccine dose. fully_vac: Total number of people who received all doses prescribed by the vaccination protocol. population: Country population. Other columns are date, country, month and year. You can read the dataset file using # remotes::install_github(&quot;bss-osca/tfa-package&quot;, build = FALSE) # run if tfa not installed library(tidyverse) dat &lt;- read_csv(system.file(&quot;extdata/covid.csv&quot;, package = &quot;tfa&quot;)) Answer this assignment using the ggplot2 package in tidyverse (you may need dplyr for preparing the datasets you want to plot). × Solution dat %&gt;% filter(country == &quot;Denmark&quot;, !is.na(cases)) %&gt;% ggplot(aes(y = cases, x = date)) + geom_line(color = &quot;blue&quot;) + labs(title = &quot;Number of cases in Denmark&quot;, x = &quot;Date&quot;, y = &quot;Cases&quot; ) The number of cases in July 2020 are low. Close Solution × Hint dat %&gt;% filter(___) %&gt;% ggplot(aes(y = ___, x = ___)) + geom_line(color = &quot;blue&quot;) + labs(title = &quot;Number of cases in Denmark&quot;, x = &quot;Date&quot;, y = &quot;Cases&quot; ) Close Hint Create a visualization showing the number of cases for each date in Denmark with the following features: A blue line is used to visualize the data. Informative figure title and axis titles are given. Is the number of cases low or high in July 2020 in the plot? × Solution dat %&gt;% group_by(country) %&gt;% mutate(total_deaths = cumsum(replace_na(deaths, 0))) %&gt;% mutate(total_deaths_cap = total_deaths/(population/100000)) %&gt;% ggplot(aes(x = date, y = total_deaths_cap, color = country)) + geom_line() + labs(title = &quot;Total number of deaths per 100000&quot;, x = &quot;Date&quot;, y = &quot;Deaths per 100000 capita&quot;, color = &quot;Country&quot; ) + theme(legend.position = &quot;bottom&quot;) The highest relative number of deaths are for the United Kingdom. Close Solution × Hint dat %&gt;% group_by(___) %&gt;% mutate(total_deaths = cumsum(replace_na(deaths, 0))) %&gt;% mutate(total_deaths_cap = ___) %&gt;% ggplot(aes(x = ___, y = ___, color = ___)) + geom_line() + labs(title = &quot;Total number of deaths per 100000&quot;, x = &quot;Date&quot;, y = &quot;Deaths per 100000 capita&quot;, color = &quot;Country&quot; ) + theme(legend.position = &quot;bottom&quot;) Close Hint Create a visualization showing the total number of deaths per 100000 capita as a function of date with the following features: Different colours are used for each country. Lines are used to visualize the data. Legends are put at the bottom of the plot. Informative figure title and axis titles are given. Hint: you may use the cumsum function to add all deaths up until a given date. You may here consider NA values in the deaths column as equal to zero (e.g. using replace_na(deaths, 0)). Which country has the highest relative number of deaths in general? × Solution dat %&gt;% filter(year == 2021) %&gt;% mutate(partly = vac/population, full = fully_vac/population) %&gt;% pivot_longer(cols = c(partly, full)) %&gt;% ggplot() + geom_line(aes(x = date, y = value, color = name)) + facet_wrap(vars(country)) + labs(title = &quot;Percentage of vaccinated people&quot;, x = &quot;Date&quot;, y = &quot;%&quot;, color = &quot;Vac. type&quot;) + theme(legend.position = &quot;bottom&quot;) The plot showes that Denmark has the highest percentage of vaccinated people and the lowest gap between partly and full vaccinated. Close Solution × Hint dat %&gt;% filter(___) %&gt;% mutate(partly = ___, full = ___) %&gt;% pivot_longer(cols = c(partly, full)) %&gt;% ggplot() + geom_line(aes(x = ___, y = ___, color = ___)) + facet_wrap(vars(___)) + labs(title = &quot;Percentage of vaccinated people&quot;, x = &quot;Date&quot;, y = &quot;%&quot;, color = &quot;Vac. type&quot;) + theme(legend.position = &quot;bottom&quot;) Close Hint Create a visualization showing the percentage of persons vaccinated as a function of date with the following features: We consider 2021. Different colours are used to differ between vaccinated and fully vaccinated. The plot is divided using country (facet). Lines are used to visualize the data. Informative figure title and axis titles are given. Hint: If you calculated the two percentages in two new columns partly and full, then the values can be joined to one column using dat %&gt;% pivot_longer(cols = c(partly, full)) Which country has the highest percentage of vaccinated people and the lowest gap between partly and fully vaccinated? × Solution dat %&gt;% filter(country == &quot;Germany&quot;) %&gt;% ggplot(aes(y = icu_patients)) + geom_boxplot() + facet_grid(month ~ year, scales = &quot;free_y&quot;) + labs(title = &quot;ICU patients given year and month&quot;, x = &quot;&quot;, y = &quot;Patients&quot;) + theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank(), legend.position = &quot;bottom&quot;) In 2021 the mean value of the ICU patients was highest when considering October. Close Solution × Hint dat %&gt;% filter(___) %&gt;% ggplot(aes(y = ___)) + geom_boxplot() + facet_grid(___ ~ ___, scales = &quot;free_y&quot;) + labs(title = &quot;ICU patients given year and month&quot;, x = &quot;&quot;, y = &quot;Patients&quot;) + theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank(), legend.position = &quot;bottom&quot;) Close Hint Consider Germany. Create a visualization showing the variation in ICU patients with the following features: A sub-plot is given for each month and year (facet). Informative figure title and axis titles are given. In which year did the ICU have the most patients when considering October? × Solution dat %&gt;% group_by(country, year) %&gt;% summarise(deaths = sum(deaths/(population/100000) , na.rm = TRUE)) %&gt;% ggplot(aes(y = deaths, x = country, fill = factor(year))) + geom_col(position = position_dodge()) + labs(title = &quot;Total number of deaths&quot;, x = &quot;&quot;, y = &quot;Deaths&quot;, fill = &quot;Year&quot;) + theme(legend.position = &quot;bottom&quot;) Norway had the lowest number of deaths in 2021. Close Solution × Hint dat %&gt;% group_by(___) %&gt;% summarise(deaths = sum(___ , na.rm = TRUE)) %&gt;% ggplot(aes(y = ___, x = ___, fill = factor(___))) + geom_col(position = position_dodge()) + labs(title = &quot;Total number of deaths&quot;, x = &quot;&quot;, y = &quot;Deaths&quot;, fill = &quot;Year&quot;) + theme(legend.position = &quot;bottom&quot;) Close Hint Create a visualization showing the total number of deaths per 100000 capita for each country and year with the following features: The numbers are shown using columns for each country Different fill colours are used for year. Hint: columns for each year can be shown beside each other using position = position_dodge(). Informative figure title and axis titles are given. Which country had the lowest number of deaths in 2021? References "],["mod-r-dist-fit.html", "Module 15 Fitting probability distributions 15.1 Learning outcomes 15.2 Introduction 15.3 Fitting distributions to continuous data 15.4 Fitting distributions to discrete data 15.5 The Poisson process 15.6 Recap 15.7 Exercises", " Module 15 Fitting probability distributions Fitting distributions to data is a very common task in statistics and consists in choosing a probability distribution modelling the random variable, as well as finding parameter estimates for that distribution. This requires judgment and expertise and generally needs an iterative process of distribution choice, parameter estimation, and quality of fit assessment. In this module we will limit us to univariate data, i.e. univariate distributions such as normal, uniform, Poisson and exponential distributions. We will use the fitdistrplus package for fitting distributions. A template project for this module is given on RStudio Cloud (open it and use it while reading the notes). 15.1 Learning outcomes By the end of this module, you are expected to: Have knowledge about different univariate distributions. Identify continuous and discrete data. Fit different distributions to data. The learning outcomes relate to the overall learning goals number 7 and 11-14 of the course. 15.2 Introduction Fitting distributions to data is a very common task in statistics and consists in choosing a probability distribution modelling the random variable, as well as finding parameter estimates for that distribution. This requires judgment and expertise and generally needs an iterative process of distribution choice, parameter estimation, and quality of fit assessment. In this module we will limit us to univariate data, i.e. univariate distributions such as a normal, uniform, Poisson and exponential distribution. Consider a dataset \\(x = (x_1, \\ldots, x_n)\\) with \\(n\\) observations which is assumed to be sample observations of a random variable \\(X\\). Our goal is to find a distribution that fit the data well and estimate the parameters of the distribution. For instance if the distribution is a normal distribution then the mean and variance should be estimated. Finding the distribution is an iterative process by considering distribution choice, parameter estimation, and quality of fit assessment repeatedly until you are satisfied. The first step is to decide if you data is should fit a discrete or continuous distribution. That is, should the random variable always take discrete values or could/are continuous values possible/okay? Note even though your sample only contain discrete values it is not necessarily samples from a discrete distribution. Consider for instance the dataset groundbeef which contains values of serving sizes in grams of ground beef patties consumed by children under 5 years old: library(fitdistrplus) library(tidyverse) data(&quot;groundbeef&quot;) # activate the dataset dat &lt;- as_tibble(groundbeef) str(dat) #&gt; tibble [254 × 1] (S3: tbl_df/tbl/data.frame) #&gt; $ serving: num [1:254] 30 10 20 24 20 24 40 20 50 30 ... Serving size in grams is only given using integers; however it is obvious that a continuous distribution should be fitted. We select the serving column so dat becomes a vector with the observations. dat &lt;- dat$serving 15.3 Fitting distributions to continuous data Before fitting one or more distributions to a data set, it is generally necessary to choose good candidates among a predefined set of distributions. This choice may be guided by the knowledge of stochastic processes governing the modeled variable, or, in the absence of knowledge regarding the underlying process, by the observation of its empirical distribution. We will use the fitdistrplus package for fitting distributions. Let us continue with the groundbeef dataset. First of all, it is common to start with plots of the empirical distribution function and the histogram (or density plot), which can be obtained with the plotdist function which provides two plots where the left-hand plot is by default the histogram on a density scale and the right-hand plot the empirical cumulative distribution function (CDF). plotdist(dat, histo = TRUE, demp = TRUE) Figure 15.1: Empirical density and distribution. The empirical plots of the density and the CDF may give you a hit about the distribution of \\(X\\). But often additional descriptive statistics may help to choose candidates to describe a distribution among a set of parametric distributions. Especially the skewness and kurtosis, linked to the third and fourth moments, are useful for this purpose. A non-zero skewness reveals a lack of symmetry of the empirical distribution, while the kurtosis value quantifies the weight of tails in comparison to the normal distribution for which the kurtosis equals 3. The skewness and kurtosis and their corresponding estimate are given by \\[\\begin{equation} \\label{skewness} sk(X) = \\frac{E[(X-E(X))^3]}{Var(X)^{\\frac{3}{2}}}~,~ \\widehat{sk}=\\frac{\\sqrt{n(n-1)}}{n-2}\\times\\frac{m_{3}}{m_{2}^{\\frac{3}{2}}}, \\end{equation}\\] \\[\\begin{equation} \\label{kurtosis} kr(X) = \\frac{E[(X-E(X))^4]}{Var(X)^{2}}~,~ \\widehat{kr}=\\frac{n-1}{(n-2)(n-3)}((n+1) \\times \\frac{m_{4}}{m_{2}^{2}}-3(n-1)) + 3, \\end{equation}\\] where \\(m_{2}\\), \\(m_{3}\\), \\(m_{4}\\) denote empirical moments defined by \\(m_{k}=\\frac{1}{n}\\sum_{i=1}^n(x_{i}-\\overline{x})^{k}\\), with mean value \\(\\overline{x}\\). The descdist function provides classical descriptive statistics (minimum, maximum, median, mean, standard deviation), skewness and kurtosis. A skewness-kurtosis plot such as the one proposed by Cullen and Frey (1999) is provided by the descdist function for the empirical distribution On this plot, values for common distributions are displayed in order to help the choice of distributions to fit to data. For some distributions (normal, uniform, logistic, exponential), there is only one possible value for the skewness and the kurtosis. Thus, the distribution is represented by a single point on the plot. For other distributions, areas of possible values are represented, consisting of lines (as for gamma and lognormal distributions), or areas (as for beta distribution). Nevertheless, the user needs to know that skewness and kurtosis, like all higher moments, have a very high variance. Hence the skewness-kurtosis plot should then be regarded as indicative only and the properties of the random variable should be considered, notably its expected value and its range, as a complement to the use of the plotdist and descdist functions. Below is a call to the descdist function to describe the distribution of the serving size from the groundbeef data set and to draw the corresponding skewness-kurtosis plot. Looking at the results notice that the observed skewness is positive and the kurtosis is not far from 3. Hence the fit of three common right-skewed distributions could be considered: Weibull, gamma and lognormal distributions. descdist(dat) #&gt; summary statistics #&gt; ------ #&gt; min: 10 max: 200 #&gt; median: 79 #&gt; mean: 73.6 #&gt; estimated sd: 35.9 #&gt; estimated skewness: 0.735 #&gt; estimated kurtosis: 3.55 Figure 15.2: Skewness-kurtosis plot for a continuous variable (groundbeef). Once one or more parametric distributions have been selected they are fitted to the data set using maximum likelihood. This is done using the fitdist function: fitW &lt;- fitdist(dat, distr = &quot;weibull&quot;) fitG &lt;- fitdist(dat, distr = &quot;gamma&quot;) fitL &lt;- fitdist(dat, distr = &quot;lnorm&quot;) The function returns a list with information about the fit such as the parameter estimates, the loglikelihood, the Akaike and Bayesian information criteria (the so-called AIC and BIC). An overview can be seen using the summary function: summary(fitW) #&gt; Fitting of the distribution &#39; weibull &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; shape 2.19 0.105 #&gt; scale 83.35 2.527 #&gt; Loglikelihood: -1255 AIC: 2514 BIC: 2522 #&gt; Correlation matrix: #&gt; shape scale #&gt; shape 1.000 0.322 #&gt; scale 0.322 1.000 summary(fitG) #&gt; Fitting of the distribution &#39; gamma &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; shape 4.0083 0.34134 #&gt; rate 0.0544 0.00494 #&gt; Loglikelihood: -1254 AIC: 2511 BIC: 2518 #&gt; Correlation matrix: #&gt; shape rate #&gt; shape 1.000 0.938 #&gt; rate 0.938 1.000 summary(fitL) #&gt; Fitting of the distribution &#39; lnorm &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; meanlog 4.169 0.0337 #&gt; sdlog 0.537 0.0238 #&gt; Loglikelihood: -1261 AIC: 2527 BIC: 2534 #&gt; Correlation matrix: #&gt; meanlog sdlog #&gt; meanlog 1 0 #&gt; sdlog 0 1 The fit to the data can be plotted using four classical goodness-of-fit plots (Cullen and Frey 1999): a density plot representing the density function of the fitted distribution along with the histogram of the empirical distribution, a CDF plot of both the empirical distribution and the fitted distribution, a Q-Q plot representing the empirical quantiles (y-axis) against the theoretical quantiles (x-axis), a P-P plot representing the empirical distribution function evaluated at each data point (y-axis) against the fitted distribution function (x-axis). par(mfrow = c(2, 2)) # 4 plots in one figure pLegend &lt;- c(&quot;Weibull&quot;, &quot;lognormal&quot;, &quot;gamma&quot;) lst &lt;- list(fitW, fitL, fitG) denscomp(lst, legendtext = pLegend) qqcomp(lst, legendtext = pLegend) cdfcomp(lst, legendtext = pLegend) ppcomp(lst, legendtext = pLegend) Figure 15.3: Four Goodness-of-fit plots for various distributions fitted to the serving size data. The density plot and the CDF plot may be considered as the basic classical goodness-of-fit plots. The two other plots are complementary and can be very informative in some cases. The Q-Q plot emphasizes the lack-of-fit at the distribution tails while the P-P plot emphasizes the lack-of-fit at the distribution center. In the present example, none of the three fitted distributions correctly describes the center of the distribution, but the Weibull and gamma distributions could be preferred for their better description of the right tail of the empirical distribution. Moreover, these distributions also have the lowest AIC values. Other methods can be used to fit distributions to the data instead of maximum likelihood. For details see Delignette-Muller and Dutang (2015). 15.3.1 Example: breakdown times We consider a dataset that contains the recorded breakdown times of a machine part in days. library(tfa) # update to latest version using remotes::install_github(&quot;bss-osca/tfa-package&quot;, upgrade = FALSE) dat &lt;- breakdown plotdist(dat, histo = TRUE, demp = TRUE) Since breakdown times may be seen as a continuous variable we try to fit a continuous variable. First we try to find distribution candidates: descdist(dat) #&gt; summary statistics #&gt; ------ #&gt; min: 91 max: 280 #&gt; median: 182 #&gt; mean: 183 #&gt; estimated sd: 30.7 #&gt; estimated skewness: 0.0503 #&gt; estimated kurtosis: 3.32 The observation is close to the normal and lognormal values and we try to fit these two distributions: fitN &lt;- fitdist(dat, distr = &quot;norm&quot;) fitL &lt;- fitdist(dat, distr = &quot;lnorm&quot;) summary(fitN) #&gt; Fitting of the distribution &#39; norm &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; mean 183.2 1.99 #&gt; sd 30.6 1.41 #&gt; Loglikelihood: -1142 AIC: 2288 BIC: 2295 #&gt; Correlation matrix: #&gt; mean sd #&gt; mean 1 0 #&gt; sd 0 1 summary(fitL) #&gt; Fitting of the distribution &#39; lnorm &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; meanlog 5.196 0.01130 #&gt; sdlog 0.174 0.00799 #&gt; Loglikelihood: -1148 AIC: 2300 BIC: 2306 #&gt; Correlation matrix: #&gt; meanlog sdlog #&gt; meanlog 1 0 #&gt; sdlog 0 1 par(mfrow = c(2, 2)) # 4 plots in one figure pLegend &lt;- c(&quot;normal&quot;, &quot;lognormal&quot;) lst &lt;- list(fitN, fitL) denscomp(lst, legendtext = pLegend) qqcomp(lst, legendtext = pLegend) cdfcomp(lst, legendtext = pLegend) ppcomp(lst, legendtext = pLegend) Figure 15.4: Four Goodness-of-fit plots for various distributions fitted to the breakdown data. Note it seems that the normal distribution has a better fit (AIC smallest). Also intuitively it makes sense that breakdown times are normal distributed around a mean value (however the probability of negative values should be low). 15.4 Fitting distributions to discrete data You may also need to fit discrete distributions such as: The Poisson distribution which is a discrete probability distribution that expresses the probability of a given number of events occurring in a fixed interval of time and/or space if these events occur with a known average rate and independently of the time since the last event. The Poisson distribution can be applied to systems with a large number of possible events, each of which is rare. How many such events will occur during a fixed time interval? Under the right circumstances, this is a random number following a Poisson distribution. The binomial distribution which is a probability distribution that is used to model the number of successes in a sequence of \\(n\\) independent experiments with probability \\(p\\) for success. The Bernoulli distribution is a special case of the Binomial distribution where \\(n=1\\) (one experiment). The negative binomial distribution which is a discrete probability distribution that models the number of failures in a sequence of independent and identically distributed Bernoulli trials before a specified number of successes occurs. The geometric distribution which is a special case of the negative binomial distribution where the specified number of successes are one. 15.4.1 Example: sales of lottery tickets Consider data of the number of houses that must be visited before selling 20 lottery tickets (assuming only one is sold at a time). dat &lt;- lottery plotdist(dat, discrete = TRUE) Since the number of houses that must be visited (trials) is unknown, a negative binomial distribution seems as a good choice (with 20 successes). The fit of a discrete distribution to discrete data requires the same procedure as for continuous data. fit &lt;- fitdist(dat, distr = &quot;nbinom&quot;, discrete = TRUE, fix.arg = list(size = 20)) summary(fit) #&gt; Fitting of the distribution &#39; nbinom &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; mu 37.2 1.38 #&gt; Fixed parameters: #&gt; value #&gt; size 20 #&gt; Loglikelihood: -200 AIC: 402 BIC: 404 par(mfrow = c(1, 2)) # 2 plots in one figure pLegend &lt;- c(&quot;negative binomial&quot;) lst &lt;- list(fit) denscomp(lst, legendtext = pLegend) cdfcomp(lst, legendtext = pLegend) Figure 15.5: Four Goodness-of-fit plots for various distributions fitted to the breakdown data. Note only the density and CDF is plotted for discrete data. Moreover, this is an example where some of the parameters of the negative binomial distribution are known in advance. The negative binomial distribution has two parameters (see ?pnbinom): the specified number of successes to occur (size argument) and the probability of success in each trial (prob argument). Given the information about the dataset, size equals 20 and we want to to try finding the probability of success in each trial. You fix a parameter by using the fix.arg argument in fitdist. Note that the summary only outputs the mean estimate mu but prob = size/(size+mu): prob &lt;- 20/(20 + fit$estimate) names(prob) &lt;- NULL prob #&gt; [1] 0.35 That is the probability of success when visiting each house is approx. 35% and e.g. the number of houses that must be visited before all lottery tickets are sold with 95% probability is: qnbinom(0.95, size = 20, prob) #&gt; [1] 55 15.5 The Poisson process A Poisson process models a series of discrete events. The average time between events is known, but the exact timing of events is random: the waiting time between events are exponential distributed. Since the exponential distribution is memoryless, the arrival time of an event is independent of what happend in the past (e.g. the arrival time of the last event). A Poisson process is often used in queueing theory to model random events, such as the arrival of customers at a store or phone calls arriving at a call center. More formally a Poisson process is defined as process counting the total number of events \\(N(t)\\) at time \\(t\\) given the average arrival rate \\(\\lambda\\). The process satisfy that: \\(N(0)=0\\); The waiting time between events is exponential distributed with rate \\(\\lambda\\); The number of arrivals in any interval of length \\(\\tau\\) is Poisson distributed with parameter \\(\\tau\\lambda\\) The arrivals in a Poisson process with on average 4 arrivals per time unit (\\(\\lambda=4\\)) may look like: Let us consider the data set demand_goods containing demand for two different goods/products: library(tfa) # update to latest version using remotes::install_github(&quot;bss-osca/tfa-package&quot;, upgrade = FALSE) demand_goods #&gt; # A tibble: 362 × 3 #&gt; date demand product #&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2016-01-01 00:00:00 8 1 #&gt; 2 2016-01-06 00:00:00 10 1 #&gt; 3 2016-01-08 00:00:00 10 1 #&gt; 4 2016-01-11 00:00:00 7 1 #&gt; 5 2016-01-22 00:00:00 9 1 #&gt; 6 2016-02-01 00:00:00 8 1 #&gt; 7 2016-02-05 00:00:00 8 1 #&gt; 8 2016-02-06 00:00:00 7 1 #&gt; 9 2016-02-13 00:00:00 9 1 #&gt; 10 2016-02-14 00:00:00 8 1 #&gt; # … with 352 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows The arrival of demands and demand size may follow a compound Poisson process which differ from a Poisson process by allowing more than a demand of one given an arrival. That is, the inter arrival times should still follow an exponential distribution. Let us find the inter arrival times between each order and try to fit it: library(tidyverse) datDf &lt;- demand_goods %&gt;% group_by(product) %&gt;% mutate(between = as.numeric(date - lag(date), units=&quot;days&quot;)) %&gt;% print() #&gt; # A tibble: 362 × 4 #&gt; # Groups: product [2] #&gt; date demand product between #&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2016-01-01 00:00:00 8 1 NA #&gt; 2 2016-01-06 00:00:00 10 1 5 #&gt; 3 2016-01-08 00:00:00 10 1 2 #&gt; 4 2016-01-11 00:00:00 7 1 3 #&gt; 5 2016-01-22 00:00:00 9 1 11 #&gt; 6 2016-02-01 00:00:00 8 1 10 #&gt; 7 2016-02-05 00:00:00 8 1 4 #&gt; 8 2016-02-06 00:00:00 7 1 1 #&gt; 9 2016-02-13 00:00:00 9 1 7 #&gt; 10 2016-02-14 00:00:00 8 1 1 #&gt; # … with 352 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows dat &lt;- datDf %&gt;% filter(product == 1, !is.na(between)) %&gt;% pull(between) plotdist(dat, histo = TRUE, demp = TRUE) descdist(dat) #&gt; summary statistics #&gt; ------ #&gt; min: 0 max: 33 #&gt; median: 4 #&gt; mean: 5.08 #&gt; estimated sd: 4.72 #&gt; estimated skewness: 1.85 #&gt; estimated kurtosis: 8.86 The observation is close to the exponential and lognormal values. However, a lognormal distribution cannot equal zero values: fitE1 &lt;- fitdist(dat, distr = &quot;exp&quot;) summary(fitE1) #&gt; Fitting of the distribution &#39; exp &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; rate 0.197 0.0135 #&gt; Loglikelihood: -557 AIC: 1115 BIC: 1119 par(mfrow = c(2, 2)) # 4 plots in one figure pLegend &lt;- c(&quot;exp&quot;) lst &lt;- list(fitE1) denscomp(lst, legendtext = pLegend) qqcomp(lst, legendtext = pLegend) cdfcomp(lst, legendtext = pLegend) ppcomp(lst, legendtext = pLegend) Figure 15.6: Four Goodness-of-fit plots for various distributions fitted to the breakdown data. The fit seems okay. Note that the horizontal and vertical points in the Q-Q and P-P plot indicate that another scale on measuring the inter arrival times would have been better (such as hours or minutes). Using days may round the numbers to much. Let us do the analysis for product 2: dat &lt;- datDf %&gt;% filter(product == 2, !is.na(between)) %&gt;% pull(between) plotdist(dat, histo = TRUE, demp = TRUE) descdist(dat) #&gt; summary statistics #&gt; ------ #&gt; min: 0 max: 41 #&gt; median: 5 #&gt; mean: 7.36 #&gt; estimated sd: 7.26 #&gt; estimated skewness: 2 #&gt; estimated kurtosis: 8.4 The observation is close to the exponential values: fitE2 &lt;- fitdist(dat, distr = &quot;exp&quot;) summary(fitE2) #&gt; Fitting of the distribution &#39; exp &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; rate 0.136 0.0112 #&gt; Loglikelihood: -444 AIC: 889 BIC: 892 par(mfrow = c(2, 2)) # 4 plots in one figure pLegend &lt;- c(&quot;exp&quot;) lst &lt;- list(fitE2) denscomp(lst, legendtext = pLegend) qqcomp(lst, legendtext = pLegend) cdfcomp(lst, legendtext = pLegend) ppcomp(lst, legendtext = pLegend) Figure 15.7: Four Goodness-of-fit plots for various distributions fitted to the breakdown data. Again the fit seems okay. To summarize the demand rate for product 1 is estimated to be 0.2 per day and for product 2 to be 0.14 per day. Given a demand arrive the question is how much is the demand size? That is, we have to fit a distribution to the demand. Let us do the analysis for product 2: dat &lt;- datDf %&gt;% filter(product == 2) %&gt;% pull(demand) plotdist(dat, histo = TRUE, demp = TRUE, discrete = TRUE) Let us try to fit the negative binomial, Poisson and geometric distribution: fitN2 &lt;- fitdist(dat, distr = &quot;nbinom&quot;) fitP2 &lt;- fitdist(dat, distr = &quot;pois&quot;) fitG2 &lt;- fitdist(dat, distr = &quot;geom&quot;) summary(fitN2) #&gt; Fitting of the distribution &#39; nbinom &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; size 3.83 0.939 #&gt; mu 3.19 0.198 #&gt; Loglikelihood: -321 AIC: 645 BIC: 651 #&gt; Correlation matrix: #&gt; size mu #&gt; size 1.000000 -0.000436 #&gt; mu -0.000436 1.000000 summary(fitP2) #&gt; Fitting of the distribution &#39; pois &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; lambda 3.19 0.146 #&gt; Loglikelihood: -340 AIC: 683 BIC: 686 summary(fitG2) #&gt; Fitting of the distribution &#39; geom &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; prob 0.239 0.0171 #&gt; Loglikelihood: -343 AIC: 688 BIC: 691 par(mfrow = c(1, 2)) pLegend &lt;- c(&quot;neg binomial&quot;, &quot;Poisson&quot;, &quot;geometric&quot;) lst &lt;- list(fitN2, fitP2, fitG2) denscomp(lst, legendtext = pLegend) cdfcomp(lst, legendtext = pLegend) Figure 15.8: Four Goodness-of-fit plots for various distributions fitted to the breakdown data. The negative binomial seems to give the best fit and may be a good candidate. 15.6 Recap Fitting distributions to data is a very common task in statistics and consists in choosing a probability distribution modelling the random variable, as well as finding parameter estimates for that distribution. Fitting a univariate distribution requires judgment and expertise and generally needs an iterative process of distribution choice, parameter estimation, and quality of fit assessment. Steps may be: Examine data a decide on discrete vs continuous distribution. Find a set of candidate distributions. Fit the distributions using statistical methods and consider various plots. Decide on a distribution The AIC value may give you an indication about the best model fit. Other methods can be used to fit distributions to the data instead of maximum likelihood. For details see Delignette-Muller and Dutang (2015). This module have only considered uncensored data. See Delignette-Muller and Dutang (2015) on how to handle censored data. You may also have a look at the slides for this module. 15.7 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Some of the solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up too early. Put some effort into finding a solution! Always practice using shortcuts in RStudio (see Tools &gt; Keyboard Shortcuts Help). Go to the Tools for Analytics workspace and download/export the TM15 project. Open it on your laptop and have a look at the files in the exercises folder which can be used as a starting point. 15.7.1 Exercise - Call center Consider data from a call center: the Los Angeles 311 Call Center in 2014 from 8-17: library(tidyverse) library(tfa) library(skimr) skim(calls) Table 15.1: Data summary Name calls Number of rows 855077 Number of columns 6 _______________________ Column type frequency: character 3 difftime 1 numeric 1 POSIXct 1 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace department 79892 0.91 2 6 0 60 0 service 79892 0.91 4 70 0 1304 0 solved_how 0 1.00 3 30 0 17 0 Variable type: difftime skim_variable n_missing complete_rate min max median n_unique time 0 1 28800 secs 61200 secs 12:00:10 31964 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist zip 19512 0.98 91653 5420 0 90029 90094 91403 99999 ▁▁▁▁▇ Variable type: POSIXct skim_variable n_missing complete_rate min max median n_unique date 0 1 2014-01-01 2014-12-31 2014-07-04 363 We first transform the dataset a bit: library(lubridate) calls &lt;- calls %&gt;% group_by(date) %&gt;% arrange(date, time) %&gt;% mutate( arrival = row_number(), wday = wday(date, label = TRUE), hour = hour(time), between = time - lag(time) ) × Solution arrival = number of arrivals on the given day, wday = weekday, hour = hour considered, between = time between calls in secs (inter arrival times). Close Solution Explain the new columns. The number of calls may follow a Poisson process with a fixed rate of calls per hour during the day. Let us try to plot the hourly rates: calls %&gt;% count(date, hour, wday) %&gt;% group_by(hour, wday) %&gt;% summarize(rate = mean(n)) %&gt;% ggplot(aes(x = hour, y = rate)) + geom_line() + facet_wrap(~wday) + ylab(&quot;calls/hour&quot;) × Solution As can be seen the rate is not constaint over the day (we don't have a homogeneous Possion process). Moreover, in weekends the rate is much lower. Close Solution Is the rate constant during a day and is the rate the same for different weekdays (explain)? Since the rate is not fixed we may have a non-homogeneous Poisson process where the rate change during the day. Hence let us try to consider an specific hour and test if the rate here can be considered as fixed (i.e. we have a Poisson process with a fixed rate when considering a specific hour) × Solution library(fitdistrplus) dat &lt;- calls %&gt;% filter( wday == &quot;Tue&quot;, hour == 10, !is.na(between)) %&gt;% pull(between) %&gt;% as.numeric() descdist(dat) #&gt; summary statistics #&gt; ------ #&gt; min: 1 max: 98 #&gt; median: 6 #&gt; mean: 9.01 #&gt; estimated sd: 8.35 #&gt; estimated skewness: 1.95 #&gt; estimated kurtosis: 8.73 fit1 &lt;- fitdist(dat, distr = &quot;exp&quot;) fit2 &lt;- fitdist(dat, distr = &quot;lnorm&quot;) fit3 &lt;- fitdist(dat, distr = &quot;gamma&quot;) summary(fit1) #&gt; Fitting of the distribution &#39; exp &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; rate 0.111 0.00077 #&gt; Loglikelihood: -66456 AIC: 132914 BIC: 132922 summary(fit2) #&gt; Fitting of the distribution &#39; lnorm &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; meanlog 1.779 0.00673 #&gt; sdlog 0.971 0.00476 #&gt; Loglikelihood: -65826 AIC: 131657 BIC: 131673 #&gt; Correlation matrix: #&gt; meanlog sdlog #&gt; meanlog 1.00e+00 -1.17e-10 #&gt; sdlog -1.17e-10 1.00e+00 summary(fit3) #&gt; Fitting of the distribution &#39; gamma &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; shape 1.334 0.01180 #&gt; rate 0.148 0.00158 #&gt; Loglikelihood: -65966 AIC: 131936 BIC: 131952 #&gt; Correlation matrix: #&gt; shape rate #&gt; shape 1.000 0.827 #&gt; rate 0.827 1.000 par(mfrow = c(2, 2)) # 4 plots in one figure pLegend &lt;- c(&quot;exp&quot;, &quot;lnorm&quot;, &quot;gamma&quot;) lst &lt;- list(fit1, fit2, fit3) denscomp(lst, legendtext = pLegend) qqcomp(lst, legendtext = pLegend) cdfcomp(lst, legendtext = pLegend) ppcomp(lst, legendtext = pLegend) For a Poisson process the inter arrival times should follow an exponential distribution. It seems to be a good fit here. Close Solution × Hint library(fitdistrplus) dat &lt;- calls %&gt;% filter( wday == ___, hour == ___ !is.na(between)) %&gt;% pull(between) %&gt;% as.numeric() %&gt;% print() descdist(dat) ___ # try to fit the exp, lnorm and gamma Close Hint Consider Tuesdays from 10-11 and fit the inter arrival times (between). If the data follow a Poisson process then the distribution should be? × Solution library(fitdistrplus) dat &lt;- calls %&gt;% filter( wday == &quot;Tue&quot;, hour == 15, !is.na(between)) %&gt;% pull(between) %&gt;% as.numeric() descdist(dat) #&gt; summary statistics #&gt; ------ #&gt; min: 1 max: 103 #&gt; median: 7 #&gt; mean: 9.99 #&gt; estimated sd: 9.41 #&gt; estimated skewness: 2.01 #&gt; estimated kurtosis: 9.13 fit12 &lt;- fitdist(dat, distr = &quot;exp&quot;) fit22 &lt;- fitdist(dat, distr = &quot;lnorm&quot;) fit32 &lt;- fitdist(dat, distr = &quot;gamma&quot;) summary(fit12) #&gt; Fitting of the distribution &#39; exp &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; rate 0.1 0.000731 #&gt; Loglikelihood: -61883 AIC: 123768 BIC: 123776 summary(fit22) #&gt; Fitting of the distribution &#39; lnorm &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; meanlog 1.872 0.00719 #&gt; sdlog 0.985 0.00509 #&gt; Loglikelihood: -61398 AIC: 122800 BIC: 122816 #&gt; Correlation matrix: #&gt; meanlog sdlog #&gt; meanlog 1.00e+00 -3.33e-11 #&gt; sdlog -3.33e-11 1.00e+00 summary(fit32) #&gt; Fitting of the distribution &#39; gamma &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; shape 1.305 0.01214 #&gt; rate 0.131 0.00147 #&gt; Loglikelihood: -61501 AIC: 123007 BIC: 123022 #&gt; Correlation matrix: #&gt; shape rate #&gt; shape 1.000 0.824 #&gt; rate 0.824 1.000 par(mfrow = c(2, 2)) # 4 plots in one figure pLegend &lt;- c(&quot;exp&quot;, &quot;lnorm&quot;, &quot;gamma&quot;) lst &lt;- list(fit12, fit22, fit32) denscomp(lst, legendtext = pLegend) qqcomp(lst, legendtext = pLegend) cdfcomp(lst, legendtext = pLegend) ppcomp(lst, legendtext = pLegend) Close Solution Consider Tuesdays from 15-16 and fit the inter arrival times (between). × Solution fit1$estimate * 60 * 60 # 10-11 #&gt; rate #&gt; 400 fit12$estimate * 60 * 60 # 15-16 #&gt; rate #&gt; 360 The rate is higher (40 calls more per hour) in period 10-11. Close Solution × Hint You have to look at the estimates of the rate. Close Hint What is the estimated arrival rate per hour Tuesday 12-13 and 15-16? Is the arrival rate the same? References "],["mod-r-maps.html", "Module 16 Spatial data and maps 16.1 Learning outcomes 16.2 Services for obtatining spatial data 16.3 Calculating distances 16.4 Geocoding and reverse geocoding 16.5 Adding markers and routes to a map", " Module 16 Spatial data and maps Spatial data, also known as geospatial data, is a term used to describe any data related to or containing information about a specific location on a surface (often a map). We will consider distance matrix calculations for finding the shortest distance/travel time between a set of origins and destinations, geocoding which is the process of converting an address to geographic coordinates (latitude, longitude) and reverse geocoding which is the opposite process of converting a location as described by geographic coordinates (latitude, longitude) to a human-readable address or place name. Finally, we consider how to display spatial data on a map. 16.1 Learning outcomes By the end of this module, you are expected to be able to: Calculate euclidean, manhattan, etc. distances. Calculate a distance matrix, i.e. shortest paths between places using the Google and Bing API. Geocode an address using the Google and Bing API. Add markers and routes (lines) on a map. 16.2 Services for obtatining spatial data Often you need to connect to a service using an API for obtaining spatial data. The most common is Google and Bing (Microsoft) and to use the services you need an API key. Another service is also Here. If you use Google Maps you can obtain an API key here. Modest to light use is free; however, you need a valid credit card. Note you must enable the APIs you intend to use. Google in fact has several services for geo-related solutions. For example, the Maps Static API provides map images, while the Geocoding API provides geocoding and reverse geocoding services. You need to enable the APIs before you use them. You will only need to do that once, and then they will be ready for you to use. Enabling the APIs just means clicking a few radio buttons on the Google Maps Platform web interface. We will be using the ggmap package for Google services. You can add the API key using: library(ggmap) register_google(key = &quot;[your key]&quot;, write = TRUE) Sys.getenv(&quot;GGMAP_GOOGLE_API_KEY&quot;) Note the key is stored in the environment object GGMAP_GOOGLE_API_KEY. Moreover, it is saved in the file .Renviron so that it is automatically reloaded when you restart R. If you use Bing Maps you can obtain an API key here. No credit card is needed. You can add the API key using: usethis::edit_r_environ() # opens the .Renviron file Sys.setenv(BING_MAPS_API_KEY=[your key]) # so you don&#39;t have to restart R Add the line BING_MAPS_API_KEY=[your key] and save the file. Note your API keys is private and unique to you, so be careful not to share it online! 16.3 Calculating distances If you need to calculate euclidean, manhattan, etc. distances, you can use the dist R function: coord &lt;- matrix(c(0,0, 0,1, 1,0, 1,1), ncol = 2, byrow = TRUE) coord #&gt; [,1] [,2] #&gt; [1,] 0 0 #&gt; [2,] 0 1 #&gt; [3,] 1 0 #&gt; [4,] 1 1 dist(coord) #&gt; 1 2 3 #&gt; 2 1.00 #&gt; 3 1.00 1.41 #&gt; 4 1.41 1.00 1.00 as.matrix(dist(coord)) #&gt; 1 2 3 4 #&gt; 1 0.00 1.00 1.00 1.41 #&gt; 2 1.00 0.00 1.41 1.00 #&gt; 3 1.00 1.41 0.00 1.00 #&gt; 4 1.41 1.00 1.00 0.00 However, euclidean distances are often a poor approximation of shortest path lengths. 16.3.1 Using Google Maps Remember to have set your API key and activate the Distance Matrix API service on the Google Cloud Platform. We consider the following places: library(ggmap) library(tidyverse) dat &lt;- tibble::tribble( ~Id, ~Shop, ~Address, 1L, &quot;Bilka Esbjerg&quot;, &quot;Stormgade 157, 6715 Esbjerg, Denmark&quot;, 2L, &quot;Bilka Herning&quot;, &quot;Golfvej 5, 7400 Herning, Denmark&quot;, 3L, &quot;Bilka Hillerød&quot;, &quot;Slotsarkaderne 26, 3400 Hillerød, Denmark&quot;, 4L, &quot;Bilka Hjørring&quot;, &quot;A.F Heidemannsvej 20, 9800 Hjørring, Denmark&quot;, 5L, &quot;Bilka Holstebro&quot;, &quot;Nyholmvej 20, 7500 Holstebro, Denmark&quot;, ) dat #&gt; # A tibble: 5 × 3 #&gt; Id Shop Address #&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 1 Bilka Esbjerg Stormgade 157, 6715 Esbjerg, Denmark #&gt; 2 2 Bilka Herning Golfvej 5, 7400 Herning, Denmark #&gt; 3 3 Bilka Hillerød Slotsarkaderne 26, 3400 Hillerød, Denmark #&gt; 4 4 Bilka Hjørring A.F Heidemannsvej 20, 9800 Hjørring, Denmark #&gt; 5 5 Bilka Holstebro Nyholmvej 20, 7500 Holstebro, Denmark To calculate a distance matrix we use the mapdist function: mapdist(from = &quot;Stormgade 157, 6715 Esbjerg, Denmark&quot;, to = &quot;Golfvej 5, 7400 Herning, Denmark&quot;) #&gt; # A tibble: 1 × 9 #&gt; from to m km miles seconds minutes hours mode #&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 Stormgade 157, 6715 Esbjerg, Denmark Golfvej 5, 740… 85641 85.6 53.2 4420 73.7 1.23 driv… Note Google returns results for the fastest path between the two points. Let us try to define a function which calculate all the distances: #&#39; Calculate the distance matrix in long format. #&#39; #&#39; @param address A vector of addresses. #&#39; @param mode Driving, bicycling, walking, or transit. #&#39; @param symmetric Use symmetric distances (half the number of queries). #&#39; @return A data frame with the results #&#39; @note The API returns results for the fastest route. goo_calc_distances &lt;- function(address, mode = &quot;driving&quot;, symmetric = TRUE) { datDist &lt;- expand_grid(id_from = 1:length(address), id_to = 1:length(address)) datDist &lt;- datDist %&gt;% filter(id_from != id_to) if (symmetric) datDist &lt;- datDist %&gt;% filter(id_from &lt; id_to) datDist &lt;- datDist %&gt;% mutate(from = address[id_from], to = address[id_to]) res &lt;- mapdist(from = datDist %&gt;% pull(from), to = datDist %&gt;% pull(to), mode = mode) return(left_join(datDist, res, by = c(&quot;from&quot;, &quot;to&quot;))) } datDistGoo &lt;- goo_calc_distances(dat$Address) datDistGoo #&gt; # A tibble: 10 × 11 #&gt; id_from id_to from to m km miles seconds minutes hours mode #&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 1 2 Stormgade 157, 6715 Esbjerg, … Golf… 85641 85.6 53.2 4420 73.7 1.23 driv… #&gt; 2 1 3 Stormgade 157, 6715 Esbjerg, … Slot… 320933 321. 199. 11804 197. 3.28 driv… #&gt; 3 1 4 Stormgade 157, 6715 Esbjerg, … A.F … 322068 322. 200. 11253 188. 3.13 driv… #&gt; 4 1 5 Stormgade 157, 6715 Esbjerg, … Nyho… 103723 104. 64.5 5291 88.2 1.47 driv… #&gt; 5 2 3 Golfvej 5, 7400 Herning, Denm… Slot… 389576 390. 242. 17862 298. 4.96 driv… #&gt; 6 2 4 Golfvej 5, 7400 Herning, Denm… A.F … 375168 375. 233. 13748 229. 3.82 driv… #&gt; 7 2 5 Golfvej 5, 7400 Herning, Denm… Nyho… 332492 332. 207. 12178 203. 3.38 driv… #&gt; 8 3 4 Slotsarkaderne 26, 3400 Hille… A.F … 178198 178. 111. 7823 130. 2.17 driv… #&gt; 9 3 5 Slotsarkaderne 26, 3400 Hille… Nyho… 44504 44.5 27.7 1871 31.2 0.520 driv… #&gt; 10 4 5 A.F Heidemannsvej 20, 9800 Hj… Nyho… 181701 182. 113. 7859 131. 2.18 driv… Note that only the calculated distances are returned. If you want to have the whole distance matrix we define function: #&#39; Convert the data frame returned from calling a `___calc_distances` function to a distance matrix. #&#39; #&#39; @param dat The data frame returned from calling `___calc_distances`. #&#39; @param value_col The column containing the distances. #&#39; @return The distance matrix as_dist_matrix &lt;- function(dat, value_col) { lgt &lt;- max(dat$id_from, dat$id_to) distanceMat&lt;-matrix(NA, nrow=lgt, ncol = lgt) diag(distanceMat) &lt;- 0 map(1:nrow(dat), function(r) { distanceMat[dat$id_from[r], dat$id_to[r]] &lt;&lt;- dat[[value_col]][r] }) idx &lt;- which(is.na(distanceMat), arr.ind = TRUE) map(1:nrow(idx), function(r) { distanceMat[idx[r, &quot;row&quot;], idx[r, &quot;col&quot;]] &lt;&lt;- distanceMat[idx[r, &quot;col&quot;], idx[r, &quot;row&quot;]] }) return(distanceMat) } as_dist_matrix(datDistGoo, &quot;km&quot;) # distances in km #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] 0.0 85.6 320.9 322 103.7 #&gt; [2,] 85.6 0.0 389.6 375 332.5 #&gt; [3,] 320.9 389.6 0.0 178 44.5 #&gt; [4,] 322.1 375.2 178.2 0 181.7 #&gt; [5,] 103.7 332.5 44.5 182 0.0 as_dist_matrix(datDistGoo, &quot;seconds&quot;) # travel time in seconds #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] 0 4420 11804 11253 5291 #&gt; [2,] 4420 0 17862 13748 12178 #&gt; [3,] 11804 17862 0 7823 1871 #&gt; [4,] 11253 13748 7823 0 7859 #&gt; [5,] 5291 12178 1871 7859 0 16.3.2 Using Bing Maps Remember to have set your API key. We first define a bing_mapdist function: library(jsonlite) #&#39; Distance between two locations. #&#39; #&#39; @param from From address. #&#39; @param to To address. #&#39; @param mode Walking, driving or transit. #&#39; @param optimize Optimize either `distance` or `time`. #&#39; @return bing_mapdist &lt;- function(from, to, mode = &quot;driving&quot;, optimize = &quot;time&quot;) { if (is.data.frame(from)) { stopifnot(all(c(&quot;from&quot;, &quot;to&quot;) %in% names(from))) from_to_df &lt;- from %&gt;% select(&quot;from&quot;, &quot;to&quot;) %&gt;% as_tibble() } else { from_to_df &lt;- tibble(from = from, to = to) } dat &lt;- map_dfr(1:nrow(from_to_df), function(r) { url &lt;- str_c(&quot;http://dev.virtualearth.net/REST/V1/Routes/&quot;, mode, &quot;?wp.0=&quot;, from_to_df$from[r], &quot;&amp;wp.1=&quot;, from_to_df$to[r], &quot;&amp;optimize=&quot;, optimize, &quot;&amp;ra=excludeItinerary&amp;rpo=None&amp;ig=false&amp;du=km&quot;, &quot;&amp;avoid=minimizeTolls&amp;key=&quot;, Sys.getenv(&quot;BING_MAPS_API_KEY&quot;)) url &lt;- URLencode(url) lst &lt;- fromJSON(url) if (lst$statusCode != 200) return(tibble(km = NA, seconds = NA, mode = NA)) df &lt;- lst$resourceSets$resources[[1]] return(tibble(km = df$travelDistance, seconds = df$travelDuration, mode = df$travelMode)) }) return(bind_cols(from_to_df, dat)) } bing_mapdist(from = &quot;Stormgade 157, 6715 Esbjerg, Denmark&quot;, to = &quot;A.F Heidemannsvej 20, 9800 Hjørring, Denmark&quot;) #&gt; # A tibble: 1 × 5 #&gt; from to km seconds mode #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; #&gt; 1 Stormgade 157, 6715 Esbjerg, Denmark A.F Heidemannsvej 20, 9800 Hjørring, Den… 322. 10077 Driv… bing_mapdist(from = &quot;Stormgade 157, 6715 Esbjerg, Denmark&quot;, to = &quot;A.F Heidemannsvej 20, 9800 Hjørring, Denmark&quot;, optimize = &quot;distance&quot;) #&gt; # A tibble: 1 × 5 #&gt; from to km seconds mode #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; #&gt; 1 Stormgade 157, 6715 Esbjerg, Denmark A.F Heidemannsvej 20, 9800 Hjørring, Den… 257. 14301 Driv… Note we here can get both the shortest and fastest path between two points. Next, we use the bing_mapdist function for calculating distances: #&#39; Calculate the distance matrix in long format. #&#39; #&#39; @param address A vector of addresses. #&#39; @param symmetric Use symmetric distances (only half the number of queries). #&#39; @param ... Further parameters passed to `bing_mapdist`. #&#39; @return A data frame with the results #&#39; @note The API returns results for the fastest route. bing_calc_distances &lt;- function(address, symmetric = TRUE, ...) { datDist &lt;- expand_grid(id_from = 1:length(address), id_to = 1:length(address)) datDist &lt;- datDist %&gt;% filter(id_from != id_to) if (symmetric) datDist &lt;- datDist %&gt;% filter(id_from &lt; id_to) datDist &lt;- datDist %&gt;% mutate(from = address[id_from], to = address[id_to]) res &lt;- bing_mapdist(datDist %&gt;% select(from, to), ...) return(bind_cols(datDist %&gt;% select(id_from, id_to), res)) } datDistBing &lt;- bing_calc_distances(dat$Address) datDistBing #&gt; # A tibble: 10 × 7 #&gt; id_from id_to from to km seconds mode #&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; #&gt; 1 1 2 Stormgade 157, 6715 Esbjerg, Denmark Golfvej 5, 7400 H… 87.7 4726 Driv… #&gt; 2 1 3 Stormgade 157, 6715 Esbjerg, Denmark Slotsarkaderne 26… 322. 10570 Driv… #&gt; 3 1 4 Stormgade 157, 6715 Esbjerg, Denmark A.F Heidemannsvej… 322. 10077 Driv… #&gt; 4 1 5 Stormgade 157, 6715 Esbjerg, Denmark Nyholmvej 20, 750… 123. 5934 Driv… #&gt; 5 2 3 Golfvej 5, 7400 Herning, Denmark Slotsarkaderne 26… 334. 10718 Driv… #&gt; 6 2 4 Golfvej 5, 7400 Herning, Denmark A.F Heidemannsvej… 187. 8002 Driv… #&gt; 7 2 5 Golfvej 5, 7400 Herning, Denmark Nyholmvej 20, 750… 44.2 1758 Driv… #&gt; 8 3 4 Slotsarkaderne 26, 3400 Hillerød, Denmark A.F Heidemannsvej… 397. 17306 Driv… #&gt; 9 3 5 Slotsarkaderne 26, 3400 Hillerød, Denmark Nyholmvej 20, 750… 375. 12191 Driv… #&gt; 10 4 5 A.F Heidemannsvej 20, 9800 Hjørring, Denmark Nyholmvej 20, 750… 194. 8312 Driv… Note in general results from the API services are based on a set of assumptions and hence the results from different services may not be the same. You may use the different services to check if the distances are correct, by checking the results from different services: # Difference in minutes abs(as_dist_matrix(datDistGoo, &quot;seconds&quot;) - as_dist_matrix(datDistBing, &quot;seconds&quot;))/60 #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] 0.0 5.1 20.6 19.60 10.72 #&gt; [2,] 5.1 0.0 119.1 95.77 173.67 #&gt; [3,] 20.6 119.1 0.0 158.05 172.00 #&gt; [4,] 19.6 95.8 158.1 0.00 7.55 #&gt; [5,] 10.7 173.7 172.0 7.55 0.00 # Km from 1 to 3 mapdist(from = &quot;Stormgade 157, 6715 Esbjerg, Denmark&quot;, to = &quot;Slotsarkaderne 26, 3400 Hillerød, Denmark&quot;) #&gt; # A tibble: 1 × 9 #&gt; from to m km miles seconds minutes hours mode #&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 Stormgade 157, 6715 Esbjerg, Denmark Slotsarkadern… 320933 321. 199. 11804 197. 3.28 driv… bing_mapdist(from = &quot;Stormgade 157, 6715 Esbjerg, Denmark&quot;, to = &quot;Slotsarkaderne 26, 3400 Hillerød, Denmark&quot;) #&gt; # A tibble: 1 × 5 #&gt; from to km seconds mode #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; #&gt; 1 Stormgade 157, 6715 Esbjerg, Denmark Slotsarkaderne 26, 3400 Hillerød, Denmark 322. 10570 Driv… 16.4 Geocoding and reverse geocoding 16.4.1 Using Google maps Remember to enable the Geocoding API. To get the coordinates of an address we use the geocode function: geocode(&quot;Stormgade 157, 6715 Esbjerg, Denmark&quot;) #&gt; # A tibble: 1 × 2 #&gt; lon lat #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 8.46 55.5 We may use mutate_geocode to add the coordinates to a dataset: dat &lt;- dat %&gt;% mutate_geocode(Address) dat #&gt; # A tibble: 5 × 5 #&gt; Id Shop Address lon lat #&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 Bilka Esbjerg Stormgade 157, 6715 Esbjerg, Denmark 8.46 55.5 #&gt; 2 2 Bilka Herning Golfvej 5, 7400 Herning, Denmark 9.00 56.1 #&gt; 3 3 Bilka Hillerød Slotsarkaderne 26, 3400 Hillerød, Denmark 12.3 55.9 #&gt; 4 4 Bilka Hjørring A.F Heidemannsvej 20, 9800 Hjørring, Denmark 10.0 57.4 #&gt; 5 5 Bilka Holstebro Nyholmvej 20, 7500 Holstebro, Denmark 8.62 56.4 To reverse geocode use the revgeocode function: revgeocode(c(dat$lon[1], dat$lat[1])) #&gt; [1] &quot;Stormgade 157, 6715 Esbjerg Kommune, Denmark&quot; To apply it to the dataset use: dat &lt;- dat %&gt;% mutate(AddressGeoGoo = map_chr(1:n(), function(i) { revgeocode(c(lon = lon[i], lat = lat[i])) })) dat #&gt; # A tibble: 5 × 6 #&gt; Id Shop Address lon lat AddressGeoGoo #&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 1 Bilka Esbjerg Stormgade 157, 6715 Esbjerg, Denmark 8.46 55.5 Stormgade 157, 671… #&gt; 2 2 Bilka Herning Golfvej 5, 7400 Herning, Denmark 9.00 56.1 Golfvej 5, 7400 He… #&gt; 3 3 Bilka Hillerød Slotsarkaderne 26, 3400 Hillerød, Denmark 12.3 55.9 Slotsarkaderne 26,… #&gt; 4 4 Bilka Hjørring A.F Heidemannsvej 20, 9800 Hjørring, Denmark 10.0 57.4 A F Heidemanns Vej… #&gt; 5 5 Bilka Holstebro Nyholmvej 20, 7500 Holstebro, Denmark 8.62 56.4 Nyholmvej 20, 7500… 16.4.2 Use Bing Maps To get the coordinates of an address we define the bing_geocode function: #&#39; Geocode addresses #&#39; #&#39; @param address Address(es) to geocode. #&#39; @return The coordinates as a data frame. bing_geocode &lt;- function(address) { dat &lt;- map_dfr(address, function(s) { url &lt;- str_c(&quot;http://dev.virtualearth.net/REST/v1/Locations?q=&quot;, s, &quot;&amp;key=&quot;, Sys.getenv(&quot;BING_MAPS_API_KEY&quot;)) url &lt;- URLencode(url) lst &lt;- fromJSON(url) if (lst$statusCode != 200) return(tibble(lon = NA, lat = NA)) v &lt;- lst$resourceSets$resources[[1]]$point$coordinates[[1]] if (is.null(v)) return(tibble(lon = NA, lat = NA)) return(tibble(lon = v[2], lat = v[1])) }) return(dat) } bing_geocode(&quot;A.F. Heidemannsvej 20, 9800 Hjørring, Denmark&quot;) #&gt; # A tibble: 1 × 2 #&gt; lon lat #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 10.0 57.4 bing_geocode(dat$Address) #&gt; # A tibble: 5 × 2 #&gt; lon lat #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 8.46 55.5 #&gt; 2 9.00 56.1 #&gt; 3 12.3 55.9 #&gt; 4 10.0 57.4 #&gt; 5 8.62 56.4 We may use bing_mutate_geocode to add the coordinates to a dataset: dat &lt;- dat %&gt;% select(-lat, -lon) mutate_bing_geocode &lt;- function (data, address, ...) { adr &lt;- data[[deparse(substitute(Address))]] gcdf &lt;- bing_geocode(adr) bind_cols(data, gcdf) } dat &lt;- dat %&gt;% mutate_bing_geocode(Address) dat #&gt; # A tibble: 5 × 6 #&gt; Id Shop Address AddressGeoGoo lon lat #&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 Bilka Esbjerg Stormgade 157, 6715 Esbjerg, Denmark Stormgade 157, 671… 8.46 55.5 #&gt; 2 2 Bilka Herning Golfvej 5, 7400 Herning, Denmark Golfvej 5, 7400 He… 9.00 56.1 #&gt; 3 3 Bilka Hillerød Slotsarkaderne 26, 3400 Hillerød, Denmark Slotsarkaderne 26,… 12.3 55.9 #&gt; 4 4 Bilka Hjørring A.F Heidemannsvej 20, 9800 Hjørring, Denmark A F Heidemanns Vej… 10.0 57.4 #&gt; 5 5 Bilka Holstebro Nyholmvej 20, 7500 Holstebro, Denmark Nyholmvej 20, 7500… 8.62 56.4 To reverse geocode use the bing_revgeocode function: #&#39; Reverse geocode coordinates #&#39; #&#39; @param coordinates A vector with two elements (lon, lat). #&#39; @return The address as a data frame. bing_revgeocode &lt;- function(coordinates) { url &lt;- str_c(&quot;http://dev.virtualearth.net/REST/v1/Locations/&quot;, coordinates[2], &quot;,&quot;, coordinates[1], &quot;?key=&quot;, Sys.getenv(&quot;BING_MAPS_API_KEY&quot;)) url &lt;- URLencode(url) lst &lt;- fromJSON(url) if (lst$statusCode != 200) return(NA) v &lt;- lst$resourceSets$resources[[1]]$address$formattedAddress if (is.null(v)) return(NA) return(v) } bing_revgeocode(c(dat$lon[1], dat$lat[1])) #&gt; [1] &quot;Stormgade 157, 6715 Esbjerg, Denmark&quot; To apply it to the dataset use: dat &lt;- dat %&gt;% mutate(AddressGeoBing = map_chr(1:n(), function(i) { bing_revgeocode(c(lon = lon[i], lat = lat[i])) })) dat #&gt; # A tibble: 5 × 7 #&gt; Id Shop Address AddressGe…¹ lon lat Addre…² #&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 1 Bilka Esbjerg Stormgade 157, 6715 Esbjerg, Denmark Stormgade … 8.46 55.5 Stormg… #&gt; 2 2 Bilka Herning Golfvej 5, 7400 Herning, Denmark Golfvej 5,… 9.00 56.1 Golfve… #&gt; 3 3 Bilka Hillerød Slotsarkaderne 26, 3400 Hillerød, Denmark Slotsarkad… 12.3 55.9 Slotsa… #&gt; 4 4 Bilka Hjørring A.F Heidemannsvej 20, 9800 Hjørring, Denmark A F Heidem… 10.0 57.4 A.F. H… #&gt; 5 5 Bilka Holstebro Nyholmvej 20, 7500 Holstebro, Denmark Nyholmvej … 8.62 56.4 Nyholm… #&gt; # … with abbreviated variable names ¹​AddressGeoGoo, ²​AddressGeoBing 16.5 Adding markers and routes to a map Leaflet is an open-source JavaScript library for interactive maps. It’s used by websites ranging from The New York Times and The Washington Post to GitHub and Flickr, as well as GIS specialists like OpenStreetMap, Mapbox, and CartoDB. The leaflet package makes it easy to create Leaflet maps from R. Note Leaflet is open-source and free so you do not need an API key for making maps. If you would like to use Google maps instead then have a look at the googleway package instead. First let us create a map with two base layers library(leaflet) library(htmlwidgets) m &lt;- leaflet() %&gt;% # Base maps addTiles(group = &quot;Map&quot;) %&gt;% addProviderTiles(&#39;Esri.WorldImagery&#39;, group = &quot;Satelite&quot;) %&gt;% addProviderTiles(&quot;CartoDB.PositronOnlyLabels&quot;, group = &quot;Map&quot;) %&gt;% # Center and zoom setView(10.2, 56.2, zoom = 7) %&gt;% # Layer control addLayersControl( baseGroups = c(&quot;Map&quot;, &quot;Satelite&quot;), options = layersControlOptions(collapsed = TRUE) ) m Next, let us add the places: dat &lt;- tibble::tribble( ~Id, ~Shop, ~Address, 1L, &quot;Bilka Esbjerg&quot;, &quot;Stormgade 157, 6715 Esbjerg, Denmark&quot;, 2L, &quot;Bilka Herning&quot;, &quot;Golfvej 5, 7400 Herning, Denmark&quot;, 3L, &quot;Bilka Hillerød&quot;, &quot;Slotsarkaderne 26, 3400 Hillerød, Denmark&quot;, 4L, &quot;Bilka Hjørring&quot;, &quot;A.F Heidemannsvej 20, 9800 Hjørring, Denmark&quot;, 5L, &quot;Bilka Holstebro&quot;, &quot;Nyholmvej 20, 7500 Holstebro, Denmark&quot;, ) dat &lt;- dat %&gt;% mutate_geocode(Address) m &lt;- m %&gt;% addMarkers(~lon, ~lat, popup = ~Address, label = ~str_c(Id, &quot; - &quot;, Shop), data = dat) m To add a line between a set of points use the addPolylines function: routeIds &lt;- c(2, 5, 1, 2) route &lt;- dat[routeIds,] m %&gt;% addPolylines(lng = ~lon, lat = ~lat, data = route, weight = 2, label = &quot;Route 1&quot;) A more advanced setup is to use the addFlows function from the leaflet.minicharts package. First let us define some lines: datLines &lt;- tibble(FromId = c(2, 5, 1, 2, 4, 3), ToId = c(5, 1, 2, 4, 3, 2)) datLines &lt;- left_join(datLines, dat %&gt;% select(-Shop, -Address), by = c(&quot;FromId&quot; = &quot;Id&quot;)) %&gt;% rename(&quot;FromLat&quot; = &quot;lat&quot;, &quot;FromLon&quot; = &quot;lon&quot;) %&gt;% left_join(dat %&gt;% select(-Shop, -Address), by = c(&quot;ToId&quot; = &quot;Id&quot;)) %&gt;% rename(&quot;ToLat&quot; = &quot;lat&quot;, &quot;ToLon&quot; = &quot;lon&quot;) datLines #&gt; # A tibble: 6 × 6 #&gt; FromId ToId FromLon FromLat ToLon ToLat #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2 5 9.00 56.1 8.62 56.4 #&gt; 2 5 1 8.62 56.4 8.46 55.5 #&gt; 3 1 2 8.46 55.5 9.00 56.1 #&gt; 4 2 4 9.00 56.1 10.0 57.4 #&gt; 5 4 3 10.0 57.4 12.3 55.9 #&gt; 6 3 2 12.3 55.9 9.00 56.1 Note we have a from/to pair in each row. We add the lines to the map: library(leaflet.minicharts) m %&gt;% addFlows(datLines$FromLon, datLines$FromLat, datLines$ToLon, datLines$ToLat, flow = 1, maxFlow = 20, opacity = 0.5, popup = popupArgs(noPopup = TRUE)) Let us define a function for adding routes: add_route &lt;- function(dat = NULL, route, solution = 1) { route_id = if_else(is.null(dat), 1, max(dat$RouteId) + 1) tmp &lt;- tibble(From = route[1:(length(route)-1)], To = route[2:length(route)]) tmp &lt;- tmp %&gt;% mutate(Sol = solution, RouteId = route_id) dat &lt;- bind_rows(dat, tmp) } datLines &lt;- add_route(route = c(2, 5, 1, 2)) %&gt;% add_route(route = c(2, 4, 3, 2)) %&gt;% add_route(route = c(2, 3, 1, 2), solution = 2) %&gt;% add_route(route = c(2, 5, 4, 2), solution = 2) datLines &lt;- left_join(datLines, dat %&gt;% select(-Shop, -Address), by = c(&quot;From&quot; = &quot;Id&quot;)) %&gt;% rename(&quot;FromLat&quot; = &quot;lat&quot;, &quot;FromLon&quot; = &quot;lon&quot;) %&gt;% left_join(dat %&gt;% select(-Shop, -Address), by = c(&quot;To&quot; = &quot;Id&quot;)) %&gt;% rename(&quot;ToLat&quot; = &quot;lat&quot;, &quot;ToLon&quot; = &quot;lon&quot;) %&gt;% mutate(group = str_c(&quot;Solution &quot;, Sol)) datLines #&gt; # A tibble: 12 × 9 #&gt; From To Sol RouteId FromLon FromLat ToLon ToLat group #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 2 5 1 1 9.00 56.1 8.62 56.4 Solution 1 #&gt; 2 5 1 1 1 8.62 56.4 8.46 55.5 Solution 1 #&gt; 3 1 2 1 1 8.46 55.5 9.00 56.1 Solution 1 #&gt; 4 2 4 1 2 9.00 56.1 10.0 57.4 Solution 1 #&gt; 5 4 3 1 2 10.0 57.4 12.3 55.9 Solution 1 #&gt; 6 3 2 1 2 12.3 55.9 9.00 56.1 Solution 1 #&gt; 7 2 3 2 3 9.00 56.1 12.3 55.9 Solution 2 #&gt; 8 3 1 2 3 12.3 55.9 8.46 55.5 Solution 2 #&gt; 9 1 2 2 3 8.46 55.5 9.00 56.1 Solution 2 #&gt; 10 2 5 2 4 9.00 56.1 8.62 56.4 Solution 2 #&gt; 11 5 4 2 4 8.62 56.4 10.0 57.4 Solution 2 #&gt; 12 4 2 2 4 10.0 57.4 9.00 56.1 Solution 2 A map with Solution 1: col_pal &lt;- rainbow(max(datLines$RouteId)) datP &lt;- datLines %&gt;% filter(Sol == 1) m %&gt;% addFlows(datP$FromLon, datP$FromLat, datP$ToLon, datP$ToLat, flow = datP$RouteId, maxThickness = 2, color = col_pal[datP$RouteId], opacity = 0.5, popup = popupArgs(labels = &quot;Route&quot;)) A map with Solution 2: col_pal &lt;- rainbow(max(datLines$RouteId)) datP &lt;- datLines %&gt;% filter(Sol == 2) m %&gt;% addFlows(datP$FromLon, datP$FromLat, datP$ToLon, datP$ToLat, flow = datP$RouteId, maxThickness = 2, color = col_pal[datP$RouteId], opacity = 0.5, popup = popupArgs(labels = &quot;Route&quot;)) An interactive map with both solutions: mm &lt;- m res &lt;- map(1:nrow(datLines), function(i) { tmp &lt;- tibble(lat = c(datLines$FromLat[i], datLines$ToLat[i]), lon = c(datLines$FromLon[i], datLines$ToLon[i])) mm &lt;&lt;- mm %&gt;% addPolylines(lng = ~lon, lat = ~lat, color = col_pal[datLines$Sol[i]], group = datLines$group[i], data = tmp, weight = 2, label = datLines$group[i]) return(invisible(NULL)) }) mm &lt;- mm %&gt;% # Layer control addLayersControl( baseGroups = c(&quot;Map&quot;, &quot;Satelite&quot;), overlayGroups = unique(datLines$group), options = layersControlOptions(collapsed = FALSE) ) %&gt;% hideGroup(unique(datLines$group)) %&gt;% showGroup(&quot;Solution 1&quot;) mm Note unfortunately arrows cannot be shown in this case. "],["groups.html", "A Working in groups Using Git together with GitHub", " A Working in groups During the course you have been allocated into groups. You are expected to solve the exercises and write the project reports in these groups. Before you start, it is a good idea to agree on a set of group rules. First, agree on a coding convention. Most people in the R community use snake case but camel case is also okay. Next, setup rules on when to meet and how you will organize the work. For instance, it is a good idea that all try to solve some of the exercises before you meet and you then discuss the answers, problems etc. Finally, it is a good idea to have a common place for your code. You have different options: Use a cloud storage services such as Dropbox, OneDrive or Google Drive. Use a version control system such as Git together with GitHub. GitHub is a code sharing and publishing service and may be seen as a social networking site for programmers. If you use RStudio Cloud then one person in the group can create a shared workspace with projects: First create a new workspace named e.g. Shared. Press Members and add the group members as moderators. Now go back to Projects in the Tools for Analytics workspace and move one project to the shared workspace. Rename it to e.g. Group Project. Members will now have access to this project where you can share code. NOTE you can not work collectively on a file simultaneously. That is, only one member can change a file at a time! Hence it is a good idea to have your own private project to work on and use this project as a place where you can share code. If you want to download a project to your laptop then press the export button. The benefit of a cloud storage service is that it is well known to you and easy to setup. Cons are that you cannot work on the same file simultaneously. The benefit of Git and GitHub is that it manages the evolution of a set of files – called a repository – in a sane, highly structured way. If you have no idea what I’m talking about, think of it as the “Track Changes” features from Microsoft Word on steroids. Here you can work on files simultaneously. Moreover, it can be used from within RStudio. Cons are that it is harder to setup and learn. For a detailed description see Why Git? Why GitHub?. The Using Git together with GitHub section gives a tutorial on how to setup Git and GitHub. Skip it if you use a cloud storage service. Using Git together with GitHub Git is a version control system. Git manages the evolution of a set of files – called a repository – in a sane, highly structured way. If you have no idea what I’m talking about, think of it as the “Track Changes” features from Microsoft Word on steroids. GitHub provide a home for your Git-based projects on the internet. If you have no idea what I’m talking about, think of it as DropBox but much, much better. It allows other people to see your stuff, sync up with you, and perhaps even make changes. Even for private solo projects, it’s a good idea to push your work to a remote location for peace of mind. To configure your computer go though the following steps: Register a free GitHub account Sign-up at GitHub. Some thoughts about your username: Incorporate your actual name! People like to know who they’re dealing with. Also makes your username easier for people to guess or remember. Reuse your username from other contexts, e.g., Twitter or Slack. But, of course, someone with no GitHub activity will probably be squatting on that. Pick a username you will be comfortable revealing to your future boss. Shorter is better than longer. Be as unique as possible in as few characters as possible. In some settings GitHub auto-completes or suggests usernames. Make it timeless. Don’t highlight your current university, employer, or place of residence, e.g. JennyFromTheBlock. Avoid the use of upper vs. lower case to separate words. We highly recommend all lowercase. GitHub treats usernames in a case insensitive way, but using all lowercase is kinder to people doing downstream regular expression work with usernames, in various languages. A better strategy for word separation is to use a hyphen - or underscore _. Install Git Find installation instructions below for your operating system. Windows Install Git from the web. Windows prefers for Git to be installed below C:/Program Files and this appears to be the default. This implies, for example, that the Git executable on my Windows system is found at C:/Program Files/Git/bin/git.exe. Unless you have specific reasons to otherwise, follow this convention. If asked about “Adjusting your PATH environment”, make sure to select “Git from the command line and also from 3rd-party software”. macOS Option 1 (highly recommended): Install the Xcode command line tools (not all of Xcode), which includes Git. Go to the shell and enter one of these commands to elicit an offer to install developer command line tools: git --version git config Accept the offer! Click on “Install”. Here’s another way to request this installation, more directly: xcode-select --install We just happen to find this Git-based trigger apropos. Note also that, after upgrading macOS, you might need to re-do the above and/or re-agree to the Xcode license agreement. We have seen this cause the RStudio Git pane to disappear on a system where it was previously working. Use commands like those above to tickle Xcode into prompting you for what it needs, then restart RStudio. Option 2 (recommended): Install Git from here: http://git-scm.com/downloads. This arguably sets you up the best for the future. It will certainly get you the latest version of Git of all approaches described here. The GitHub home for the macOS installer is here: https://github.com/timcharper/git_osx_installer. At that link, you can find more info if something goes wrong or you are working on an old version of macOS. Option 3 (recommended): If you anticipate getting heavily into scientific computing, you’re going to be installing and updating lots of software. You should check out Homebrew, “the missing package manager for OS X”. Among many other things, it can install Git for you. Once you have Homebrew installed, do this in the shell: brew install git Linux Install Git via your distro’s package manager. Ubuntu or Debian Linux: sudo apt-get install git Fedora or RedHat Linux: sudo yum install git A comprehensive list for various Linux and Unix package managers: https://git-scm.com/download/linux Check your installation Quit and re-launch RStudio if there’s any doubt in your mind about whether you opened RStudio before or after installing Git. You can set your Git user name and email from within R using the usethis package: ## install if needed (do this exactly once): ## install.packages(&quot;usethis&quot;) library(usethis) use_git_config(user.name = &quot;Jane Doe&quot;, user.email = &quot;jane@example.org&quot;) What user name should you give to Git? This does not have to be your GitHub user name, although it can be. Another good option is your actual first name and last name. If you commit from different machines, sometimes people work that info into the user name. Your commits will be labelled with this user name, so make it informative to potential collaborators and future you. What email should you give to Git? This must be the email associated with your GitHub account. These commands return nothing. You can check that Git understood what you typed by looking at the output of git config --global --list from a shell. An easy way to get into a shell from RStudio is **Tools &gt; Terminal* or *Tools &gt; Shell**. If you have any problems go though Chapters 4-14 on the Happy Git site. Setup projects using Git and GitHub You have different options depending on how you start you project. I will only highlight the prefererd one. New project, GitHub first Here we create a project with “GitHub first, then RStudio” sequence: Step 1: Go to GitHub and make sure you are logged in. Click green “New repository” button. Or, if you are on your own profile page, click on “Repositories”, then click the green “New” button. Repository name: test (or whatever you wish) Public YES Initialize this repository with a README Click the big green button “Create repository.” Copy the HTTPS clone URL to your clipboard via the green “Clone or Download” button. Step 2: In RStudio, start a new Project: File &gt; New Project &gt; Version Control &gt; Git. In the “repository URL” paste the URL of your new GitHub repository. It will be something like this https://github.com/[you-username]/test.git. Be intentional about where you create this Project. Suggest you “Open in new session”. Click “Create Project” to create a new directory, which will be all of these things: a directory or “folder” on your computer a Git repository, linked to a remote GitHub repository an RStudio Project In the absence of other constraints, I suggest that all of your R projects have exactly this set-up. This should download the README.md file that we created on GitHub in the previous step. Look in RStudio’s file browser pane for the README.md file. There’s a big advantage to the “GitHub first, then RStudio” workflow: the remote GitHub repo is added as a remote for your local repo and your local master branch is now tracking master on GitHub. This is a technical but important point about Git. The practical implication is that you are now set up to push and pull. No need to fanny around setting up Git remotes and tracking branches on the command line. Step 3: Make local changes, save, commit. Do this every time you finish a valuable chunk of work, probably many times a day. From RStudio, modify the README.md file, e.g., by adding the line “This is a line from RStudio”. Save your changes. Commit these changes to your local repo. How? Click the “Git” tab in upper right pane Check “Staged” box for any files whose existence or modifications you want to commit. To see more detail on what’s changed in file since the last commit, click on “Diff” for a Git pop-up If you’re not already in the Git pop-up, click “Commit” Type a message in “Commit message”, such as “Commit from RStudio”. Click “Commit” Step 4: Push your local changes to GitHub Do this a few times a day, but possibly less often than you commit. You have new work in your local Git repository, but the changes are not online yet. This will seem counterintuitive, but first let’s stop and pull from GitHub. Why? Establish this habit for the future! If you make changes to the repo in the browser or from another machine or (one day) a collaborator has pushed, you will be happier if you pull those changes in before you attempt to push. Click the blue “Pull” button in the “Git” tab in RStudio. I doubt anything will happen, i.e. you’ll get the message “Already up-to-date.” This is just to establish a habit. Click the green “Push” button to send your local changes to GitHub. You should see some message along these lines. [master dc671f0] blah 3 files changed, 22 insertions(+) create mode 100644 .gitignore create mode 100644 myrepo.Rproj Step 5: Confirm the local change propagated to the GitHub remote Go back to the browser. I assume we’re still viewing your new GitHub repo. Refresh. You should see the new “This is a line from RStudio” in the README. If you click on “commits,” you should see one with the message “Commit from RStudio”. Step 6: Make a change on GitHub Click on README.md in the file listing on GitHub. In the upper right corner, click on the pencil for “Edit this file”. Add a line to this file, such as “Line added from GitHub.” Edit the commit message in “Commit changes” or accept the default. Click the big green button “Commit changes.” Step 7: Pull from GitHub Back in RStudio locally … Inspect your README.md. It should NOT have the line “Line added from GitHub”. It should be as you left it. Verify that. Click the blue Pull button. Look at README.md again. You should now see the new line there. The end Now just repeat these operations when you do group work. Do work somewhere. Commit it. Push it or pull it depending on where you did it, but get local and remote “synced up”. Repeat. Note that in general (and especially in future when collaborating with other developers) you will usually need to pull changes from the remote (GitHub) before pushing the local changes you have made. For this reason, it’s a good idea to try and get into the habit of pulling before you attempt to push. If you have to type in your password over and over again, this can be avoided. Have a look at Chapter 10 of Happy Git. Existing project, GitHub first See details in Chapter 16 of Happy Git. Existing project, GitHub last See details in Chapter 17 of Happy Git. "],["annotate.html", "B Annotate the course notes", " B Annotate the course notes I recommend using hypothes.is to annotate the online course notes. You can create both private and public annotations. Collaborative annotation helps people connect to each other and what they’re reading, even when they’re keeping their distance. You may also use public notes to help me indicate spell errors, unclear content etc. in the notes. "],["help.html", "C Getting help", " C Getting help We all get stuck sometimes and need some help. Below are some advises on how to help yourself and ask for help: First try to understand the error message and solve the problem. You may try to debug your code by inserting break points in VBA or use browser() in your R code. See Chapter 11 in Bryan and H (n.d.) for further details. Google is your friend. This is always the first step. Try searches like “vba range”, “r dplyr filter”, “r tidyverse”, “r subset vector”, etc. Do you need help for a specific function in R then try ?[function-name] such as ?geom_line, ?mutate, etc. Mostly, focus on the last section with examples. Moreover, some packages may have written vignettes try browseVignettes(package = \"package_name\") to check. Have a look at Help &gt; Cheatsheets in RStudio. If you can’t find an answer then it is time to ask on-line. I recommend asking a question at stackoverflow. To make your question effective, the idea is to make things as easy as possible for someone to answer. This stack overflow thread How to make a great R reproducible example? give you some good hints. The process of providing a good minimal reproducible example (reprex) often causes you to answer your own question! See also Stack Exchange’s ‘How to ask’ and How to make a reprex at tidyverse. If you have a more course related question then ask it at our course forum and we will try to answer your question asap. Students are also welcome in helping each other. You can also try to annotate the online course notes if something is unclear. I will try to answer asap. You can get help from our TAs at study cafés. Note help using mail correspondence is not supported! References "],["coding-convention.html", "D Coding/naming convention D.1 Commenting your code", " D Coding/naming convention The main reason for using a consistent set of coding conventions is to standardize the structure and coding style of an application so that you and others can easily read and understand the code. Good coding conventions result in precise, readable, and unambiguous source code that is consistent with other language conventions and as intuitive as possible. Different ways of naming you variables exists. You are advised to adopt a naming convention; some use snake case others use camel case. The Leszynski naming convention define variables with a consistent prefix that makes it easy to identify its data type. It is common to use Leszynski convention within the VBA community. The R community use snake case but camel case is also okay. Some common prefixes used for the Leszynski naming convention are: Type Prefix Example Boolean bln blnFound Currency cur curRevenue Date (Time) dtm dtmStart Double dbl dblTolerance Integer int intQuantity Long lng lngDistance String str strFName Variant vnt vntCheckSum Array ary aryNumbers (optional) User form frm frmProcess Worksheet wst wstDistances Workbook wbk wbkData Many other prefixes can be used also. Choose the naming convention you like best in your study group. But stick only to one of them. A few examples: this_is_snake_case # note you do not use capital letters here thisIsCamelCase # you start each word with a capital letter (except the first) dblTolerance # Lezynski convention naming a double (dbl) variable strFullName # Lezynski naming a string (str) variable When defining variables and functions, it is in general good practice to use nouns for variables and verbs for functions. D.1 Commenting your code It is always good practice to comment your code. Such that others can get a fast overview and understand your code easier. We will use roxygen documentation comments which are widely known. A few examples in VBA are The top of a module file: &#39;&#39;&#39; Module description. &#39; Can be more than one line. &#39; @remarks Put your remarks on the module implementation here &#39; @author Lars Relund &lt;junk@relund.dk&gt; &#39; @date 2016-08-26 Before each sub, function etc. write: &#39;&#39; Sub description &#39; @pre Precondition &#39; @post Postcondition &#39; @param strA Explanation of input parameter strA &#39; @param intB Explanation of input parameter intB &#39; @return Return value (if a function) &#39; @remarks Further remarks Public Function MyFunc(strA As String, intB As Integer) As Integer { ... } Further tags (i.e. keywords starting with @) can be seen here. In R we use a ‘hash’ (#’) to comment functions: #&#39; Subtract two vectors #&#39; #&#39; @param x First vector. #&#39; @param y Vector to be subtracted. #&#39; #&#39; @return The difference. #&#39; @export #&#39; #&#39; @examples #&#39; subtract(x = c(5,5), y = c(2,3)) subtract &lt;- function(x, y) { return(x-y) } "],["apdx-vba.html", "E VBA specific topics E.1 Debugging your code E.2 Error handling E.3 Course procedures", " E VBA specific topics E.1 Debugging your code You debug you code to find errors and correct bugs in your program. VBA has a built-in debugger that you may use to step though you code and check if the values in memory are correct. You start and use the debugger using the debugger buttons in the VBA editor, e.g. set the cursor in the top of a sub and press the Step Into button ( F8, ⇧⌘I). You can now repeatedly press the button to step though the code. In the Locals window you can see the values of the variables as you run you code. Finally, if you want to run the program until a specific line or code then insert a break-point by clicking the margin of that line in the VBA editor. Next, run you sub and the debugger will stop at that line. For more details you may have a look at Chapter 9 in Wøhlk (2010) or the videos Debug toolbar, Locals window and Breakpoints. E.2 Error handling See https://excelmacromastery.com/vba-error-handling/ E.3 Course procedures The course have a set of course procedures that you may use ‘as is’ during the course and at the exam without any warranty. I will explicitly state if you are not allowed to use them. An overview is given in Table E.1. All procedures within a topic start with the same suffix so you easy can find them using auto complete in the VBA editor (Ctrl + Space). On a mac you may have to disable the default shortcut (Ctrl + Space) for switching input sources. You can go to the System Preferences -&gt; Keyboard -&gt; Shortcuts -&gt; Input Sources and disable it. For instance all procedures related to arrays start with suffix Ary. Similar the procedures are stored in module ModAry. The modules are stored in the template files for each teaching module (if used) and all course procedures can be found in as text files. If you want to use a procedure copy/import the whole module containing the procedure to the Excel file. Table E.1: Course procedures. See the modules named ModRng, ModAry, ModWst, ModCol, ModTm, and ModRand for further info. Procedure Type Description AryDim function Array dimension AryEmpty function Check if an array empty AryFromCSV sub Read a csv file to and array AryPaste sub Paste a 1D or 2D array to a sheet AryQuickSort sub Sort a 2-Dimensional array using a quicksort algorithm AryRead sub Read a range into a 2D array AryReadLong sub Read a range (long format) into an array (up to a 5D array is supported) AryToSeq sub Set all array elements to a sequence AryToStr function Convert an array to a string AryToVal sub Set all array elements to a specific value Col2Str function Convert a collection to a string ColCopy function Copy a collection RandGenBinomial sub Generate random numbers from a binomial distribution RandGenDiscrete sub Generate a random number from a custom discrete distribution RandGenNormal sub Generate random numbers from a normal distribution RandGenPoisson sub Generate random numbers from a poisson distribution RandGenUniformCont sub Generate random numbers from a continuous uniform distribution RandGenUniformDisc sub Generate random numbers from a discrete uniform distribution RandInvBinomial function Generate a random number from a binomial distribution RandInvDiscrete function Generate a random number from a custom discrete distribution RandInvNormal function Generate a random number from a normal distribution RandInvPoisson function Generate a random number from a Poisson distribution RandInvUniformCont function Generate a random number from a continuous uniform distribution RandInvUniformDisc function Generate a random number from a discrete uniform distribution RngClear sub Clear a range RngCurRegion function Return the current region of a range RngFormat sub Format a range RngFromCSV function Read a csv file and output it to cells RngGetAddress function Return the address of a range. RngGetColLetter function Convert column number to letter RngGetCols function Columns in range RngGetCurRegionAddress function Return the address of the current region of a range RngGetCurRegionCols function Columns in current region RngGetCurRegionFirstCol function First column in current region RngGetCurRegionFirstRow function First row in current region RngGetCurRegionLastCol function Last column in current region RngGetCurRegionLastRow function Last row in current region RngGetCurRegionLowerLeft function Return the lower left cell of the current region RngGetCurRegionLowerRight function Return the lower right cell of the current region RngGetCurRegionRange function Return the part of the current region starting with upper right cell in row and col RngGetCurRegionRows function Rows in current region RngGetCurRegionUpperLeft function Return the upper left cell of the current region RngGetCurRegionUpperRight function Return the upper right cell of the current region RngGetFirstCol function First column in range RngGetFirstRow function First row in range RngGetLastCol function Last column in range RngGetLastRow function Last row in range RngGetLowerLeft function Return the lower left cell of the range RngGetLowerRight function Return the lower right cell of the range RngGetRange function Return the part of the range starting with upper right cell in row and col RngGetRows function Rows in range RngGetUpperLeft function Return the upper left cell of the range RngGetUpperRight function Return the upper right cell of the range RngJoin function Join two ranges RngPaste function Paste a range on a sheet. RngRemoveInterior sub Remove fill colors in cell range RngToCSV sub Write a range to a csv file TmElapsed function Time since timer has be started. TmEx sub Example of using the timer procedures TmRestoreAfterSpeedOptimize sub Restore properties for the Application object after have called ApplicationSpeedOptimize TmSpeedOptimize sub Set some properties for the Application object to optimize excecution of vba TmStart function Start timer (unit seconds) WstClear function Clear a worksheet if it exists WstCreate function Create a worksheet WstDelete function Delete a worksheet if it exists WstExists function Check if a worksheet exists WstRename function Rename a worksheet if it exists and no sheet with the new name References "],["lg-course.html", "F Learning goals", " F Learning goals The purpose of this course is to give students a knowledge about IT tools for Analytics which requires the analyst to be qualified in handling tools beyond e.g. basic Excel. After having participated in the course, the student must, in addition to achieving general academic skills, demonstrate: Knowledge of how a computer works at a basic level. basic programming such as variables, arrays, loops, functions and procedures. what an algorithm is. how to implement an algorithm based on a description. different programming languages. how to manage a code in a collaborative working environment. Skills to handle data such as import, tidy, transform, visualize and export. develop well-structured code. perform testing and debugging. implement/code selected algorithms. apply analytical techniques on data. apply relevant methods, algorithms and techniques from this course in order to solve a specific problem. Competences to independently handle data given a problem. independently analyze data given a relevant research question. compare different programming languages. compare different algorithms solving a problem and discuss their advantages and disadvantages. interpret and discuss results based on a data analysis in relation to the relevant academic literature. communicate results from applied research in a scientific way, e.g. using literate programming. "],["ba.html", "G Business Analytics", " G Business Analytics Business Analytics (BA) refers to the scientific process of transforming data into insight for making better decisions in business. BA can both be seen as the complete decision making process for solving a business problem or as a set of methodologies that enable the creation of business value. As a process it can be characterized by descriptive, predictive, and prescriptive model building using “big” data sources. Descriptive Analytics: A set of technologies and processes that use data to understand and analyze business performance. Descriptive analytics are the most commonly used and most well understood type of analytics. Descriptive analytics categorizes, characterizes, consolidates, and classifies data. Examples are standard reporting and dashboards (KPIs, what happened or is happening now?) and ad-hoc reporting (how many/often?). Descriptive analytics often serves as a first step in the successful application of predictive or prescriptive analytics. Predictive Analytics: The use of data and statistical techniques to make predictions about future outputs/outcomes, identify patterns or opportunities for business performance. Examples of techniques are data mining (what data is correlated with other data?), pattern recognition and alerts (when should I take action to correct/adjust a spare part?), Monte-Carlo simulation (what could happen?), neural networks (which customer group are best?) and forecasting (what if these trends continue?). Prescriptive Analytics: The use of optimization and other decision modelling techniques using the results of descriptive and predictive analytics to suggest decision options with the goal of improving business performance. Prescriptive analytics attempt to quantify the effect of future decisions in order to advise on possible outcomes before the decisions are actually made. Prescriptive analytics predicts not only what will happen, but also why it will happen and provides recommendations regarding actions that will take advantage of the predictions. Prescriptive analytics are relatively complex to administer, and most companies are not yet using it in their daily course of business. However, when implemented correctly, it can have a huge impact on business performance and how businesses make decisions. Examples on prescriptive analytics are optimization in production planning and scheduling, inventory management, the supply chain and transportation planning. Companies who use BA focus on fact-based management to drive decision making and treats data and information as a strategic asset that is shared within the company. This enterprise approach generates a companywide respect for applying descriptive, predictive and prescriptive analytics in areas such as supply chain, marketing and human resources. Related areas: In the past Business Intelligence traditionally focuses on querying, reporting, online analytical processing, i.e. descriptive analytics. However, a more modern definition of Business Intelligence is the union of descriptive and predictive analytics. Operations Research or Management Science deals with the application of advanced analytical methods to help make better decisions and can hence be seen as prescriptive analytics. However, traditionally it has been taking a more theoretical approach and focusing on problem-driven research while BA takes a more data-driven approach. Logistics is a cross-functional area focusing on the effective and efficient flows of goods and services, and the related flows of information and cash. Supply Chain Management adds a process-oriented and cross-company perspective. Both can be seen as prescriptive analytics with a more problem-driven research focus. Advanced Analytics is often used as a classification of both predictive and prescriptive analytics. Data science is an interdisciplinary field about scientific methods, processes, and systems to extract knowledge or insights from data in various forms, either structured or unstructured and can be seen as Business analytics applied to a wider range of data. Resources http://analytics-magazine.org/the-analytics-journey/ https://en.wikipedia.org/wiki/Business_analytics http://connect.informs.org/analytics/home https://www.or-exchange.org/questions/5645/informs-analytics-definition https://en.wikipedia.org/wiki/Prescriptive_analytics https://en.wikipedia.org/wiki/Predictive_analytics "],["colophon.html", "H Colophon", " H Colophon These notes were written in bookdown inside RStudio. This version of the book was built with: #&gt; Finding R package dependencies ... [19/29] \b\b\b\b\b\b\b\b[20/29] \b\b\b\b\b\b\b\b[21/29] \b\b\b\b\b\b\b\b[22/29] \b\b\b\b\b\b\b\b[23/29] \b\b\b\b\b\b\b\b[24/29] \b\b\b\b\b\b\b\b[25/29] \b\b\b\b\b\b\b\b[26/29] \b\b\b\b\b\b\b\b[27/29] \b\b\b\b\b\b\b\b[28/29] \b\b\b\b\b\b\b\b[29/29] Done! #&gt; setting value #&gt; version R version 4.2.1 (2022-06-23) #&gt; os Ubuntu 20.04.5 LTS #&gt; system x86_64, linux-gnu #&gt; ui X11 #&gt; language (EN) #&gt; collate C.UTF-8 #&gt; ctype C.UTF-8 #&gt; tz UTC #&gt; date 2022-10-20 #&gt; pandoc 2.7.3 @ /usr/bin/ (via rmarkdown) Along with these packages: "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
