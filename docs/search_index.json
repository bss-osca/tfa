[["index.html", "Tools for Analytics (TFA) Course notes Module 1 Introduction to the course 1.1 Learning outcomes 1.2 Purpose for the course 1.3 R vs Excel/VBA 1.4 How a computer works 1.5 How the notes are organized 1.6 Acknowledgements 1.7 How to cite 1.8 Exercises", " Tools for Analytics (TFA) Course notes Lars Relund Nielsen 2025-08-05 Module 1 Introduction to the course This site contains course notes for the course “Tools for Analytics” held at Aarhus BSS. The notes show the learning path for each week and contain. The course is an introductory course at the Operations and Supply Chain Analytics programme and intended to give knowledge about IT tools for Analytics. Expect the notes to be updated when the course runs. The date listed above is the last time the notes was updated. A set of slides are also available. Learning path diagram Click/hover the nodes to follow links and see details. A detailed description of Business Analytics have been pointed out as an extra supplement in the learning path diagram. You may have a look at it if you like. 1.1 Learning outcomes By the end of this module, you are expected to: Memorize the purpose of the course. Describe what the term Business Analytics mean. Identify pros and cons of using Excel, VBA and R. Describe how a computer works. Describe what an algorithm is. Know how the course is organized. The learning outcomes relate to the overall learning goals number 1, 3 and 5 of the course. 1.2 Purpose for the course Since the amount of available data has increased extensively in many companies, there is a need for analysts with the ability to do tasks within Analytics. For instance, extract relevant data and perform valid quantitative analysis. Clearly, it is also important that the analyst can communicate the results of the analysis to their surroundings. This requires for the analyst to be particularly qualified in handling IT based tools beyond e.g. basic Excel. Business Analytics (BA) (or just Analytics) refers to the scientific process of transforming data into insight for making better decisions in business. BA can both be seen as the complete decision making process for solving a business problem and the creation of business value by integration of concepts, methods and data. As a process, it can be characterized by descriptive, predictive, and prescriptive model building using data sources. For a full definition see the appendix. Within a Business Analytics (BA) framework the course focuses on giving you an introduction to programming, handeling data and doing descriptive analytics. Descriptive analytics categorizes, characterizes, consolidates, and classifies data. Examples are standard reporting and dashboards (key performance indicators (KPIs), what happened or is happening now?) and ad-hoc reporting (how many/often?). Descriptive analytics often serves as a first step in the successful application of predictive or prescriptive analytics. Predictive and prescriptive analytics are covered in other courses of the programme. Analytics may be seen as a data driven process: Figure 1.1: Analytics as a data driven process. For doing data driven analytics you first must import your data. That is, take data from a database, file, web API etc. and transform it into a data frame/table. In general raw data may be messy and need to be structured in a tidy way. Tidying your data means storing it in a structured form suitable for analysis. In brief, when your data is tidy, each column is a variable, and each row is an observation. Tidy data is important because the consistent structure lets you focus your struggle on questions about the data. Once you have tidy data, a common first step is to transform it. Transformation includes narrowing in on observations of interest (e.g. only observations from a specific year or warehouse), creating new variables based on existing variables (e.g. the cost of using the machine that day given idle time). Together, tidying and transforming are called wrangling, because it can be a hard process to get your data in the right form. The next step is to do a simple exploration of you data such as calculating a set of summary statistics (like counts, means or KPIs). A good way to get an overview over your data is by visualization. A good visualisation will show you things that you did not expect, raise new questions about the data or confirm your hypothesis. A good visualization might also hint that you’re asking the wrong question, or you need to collect different data. Exploration and visualization are descriptive analytics and used to answer questions such as: What happened? How many, how often, where? Where exactly is the problem? What actions are needed? Models are complementary tools to visualization. Once you have made your questions sufficiently precise, you can use a model to answer them. A model is a description of a system using mathematical concepts and a simplification of the real system. That is, the results of a model are based on a set of assumptions. Models for statistical analysis, forecasting, system behavior are predictive analytics and answer questions like: Why is this happening? What if these trends continue? What will happen next? Models for prescriptive analytics use optimization and other decision modeling techniques to suggest decision options with the goal of improving business performance and answer questions like: What is the best that can happen? Exploration, visualization and modeling may be seen as different steps which can be used for analyzing the data and answer the overall questions. This course will focus on the two first steps. Given an analysis, communication is an absolutely critical part. It does not matter how well your models and visualization have led you to understand the data unless you can also communicate your results to decision makers. Note that analytics is not a one-way process, it is common that you several times have to tidy and transform your data, explore and visualize based on the results of a model, rerun the model based on feedback from the decision makers etc. Common connections are visualized using directed arrows in Figure 1.1. Surrounding the process is programming. Programming is the Swiss army knife you use during parts of the process. An introduction to programming is given using both VBA in Excel and the programming language and free software environment R. Programming focus on writing algorithms. An algorithm is a finite sequence of well-defined instructions to solve a specific problem or to perform a computation. That is, we use a programming language to program an algorithm that solves a specific task, e.g. find the best route, sort words, make a plot, etc. 1.3 R vs Excel/VBA This course gives you an introduction to programming using both VBA and R. The two programming languages are different and here are some comparisons: Excel Pros: Initial learning curve is quite minimal. Analysis can be done via point-and-click. Useful for fast analysis (you can change a cell and see effects on other cells, plots etc.) It is not exceedingly hard to make basic graphs and charts. Data can be stored inside the sheets. Cons: The mixture of data entries, analysis, and visualization makes it easy to confuse cells that contain raw data from those that are the product of analysis. The analysis directly manipulates the only copy of the raw data. Using mouse clicks means that a mistaken click or drag action can lead to errors or the overwriting of data. Do not handle non-tabular data well. VBA VBA is a compiled language implemented using compilers (translators that generate machine code from source code). That is, code need to be compiled first before running it. Pros: Can be used inside MS Office applications e.g. Excel. Already contained in Excel, i.e. if you have Excel installed you can start coding. The VBA code is stored within the spreadsheet, allowing any user with access to the spreadsheet to easily run the code. VBA is easy to learn. Especially if you are already experienced in Excel. Good for automating tasks in Excel. Still used in many companies. Cons: A programming language, meaning the initial learning curve is steeper. It will take you some time to become familiar with the interface and master the various functions. Since a compiled language, compiling code may take time. Powerful inside Excel but other programming languages are better to learn for general tasks. An old programming language (Microsoft stopped investing in VBA in 2008). R R is an interpreted language with step-by-step execution of source code (no pre-runtime translation takes place) from the command line or using a script file. Pros: There is a clear division between data entry and analysis. You import the data, create an object that is a copy of the raw data and do manipulations on this copy. That is, the original data are never altered in any way and there is no way to mess up the raw data. Manipulating a copy of the data enables you to experiment. A line of code that fails to produce the expected result can be tweaked and rerun. All manipulations can be done in code. The process of analysis are easily reproduced by the code. That is, the use of code for data analysis enables the creation of more reproducible research. With code all analysis is documented instead of being hidden behind mouse clicks. Saving analysis in code has the immediate benefit that it can be easily rerun anytime that new data is added or the code can also be applied to a completely new data set. Free and with a large community that promotes sharing of libraries for data analysis. Can produce complex and advanced data visualizations. Cons: R is a programming language, meaning the initial learning curve is steeper. It will take you some time to become familiar with the interface and master the various functions. 1.4 How a computer works As a prerequisite for this course you need some basic knowledge about what a computer is. Have a look at these slides and this video. 1.5 How the notes are organized Module 1 (this module) gives a short introduction to the course. The course notes consists of different parts each containing teaching modules about specific topics: Part I consider tools for analytics using VBA in Excel (mainly programming). Module 2 gives you an introduction to VBA so you can get started programming. In Module 3 loop and conditional statements are introduced and Module 4 focus on how to make procedures. Next, we consider advanced data types and usage in Module 5. Finally, Module 6 considers generation of random numbers in VBA and how they can be used for simulation. Part II consider tools for analytics using R. Module 7 give advices on how to install R on your laptop. An introduction to R is given in Module 8. Loops and conditionals are covered in Module 9. Module 10 cover how to create functions in R. A introduction to the tidyverse packages are given in Module 11 which also consider how to write reproducible reports. Importing and exporting data are considered in Module 12. In Module 13 ways to transform data is given. Finally, Module 14 look at data visualization in R. Part III Provides you with some extra topics in R that might be handy when you e.g. write your master thesis. This part is NOT part of syllabus. The appendix contains different modules that may be helpful for you including hints on how to work in groups, how to get help if you are stuck and how to annotate the course notes. 1.6 Acknowledgements Some of the materials in these notes are taken from various places The bookdown skeleton and some notes are based on the Stat545 course. Some parts in Module 1 are inspired by Chapter 1 in H. Wickham (2017). The VBA modules are inspired by the book Wøhlk (2010). This also holds for some of the exercises. Module 7 is inspired by Chapter 1 in Bryan (2017). Module 8 is using some text and images from Chapter 1 in Ismay and Kim (2020) and Chapter 2 in Bryan (2017). A few exercises are inspired by Chapter 2 in Irizarry (2020). Notes about git and GitHub in the appendix are based on Bryan, STAT 545 TAs, and Hester (2020). Exercise 13.5.1 is a revision of Chapters 6-7 in Bryan (2017). Exercise 13.5.2 is a revision of Session 3 in the Welcome to the tidyverse course. Exercise 14.6.1 is a revision of Chapter 9 in Irizarry (2020). Exercise 14.6.3 is inspired by the COVID19 application exercise at the data science in a box course. Exercise 14.6.4 is inspired by the Lego homework exercise at the data science in a box course. Exercise 13.5.4 is inspired by the Fisheries application exercise at the data science in a box course. I would like to thank all for their inspiration. Also thanks to Solveig for proofreading the draft. This work is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International CC BY-NC-SA 4.0. 1.7 How to cite You can cite these notes using Nielsen (2024) (follow the link to see how it is cited). 1.8 Exercises 1.8.1 Exercise - How to annotate The online course notes can be annotated using hypothes.is. You can create both private and public annotations. Collaborative annotation helps people connect to each other and what they’re reading, even when they’re keeping their distance. You may also use public notes to help indicate spell errors, unclear content etc. in the notes. Sign-up at hypothes.is. If you are using Chrome you may also install the Chrome extension. Go back to this page and login in the upper right corner (there should be some icons e.g. &lt;). Select some text and try to annotate it using both a private and public annotation (you may delete it again afterwards). Go to the slides for this module and try to annotate the page with a private comment. References Bryan, J. 2017. STAT 545 - Data Wrangling, Exploration, and Analysis with r. https://stat545.com/. Bryan, J., the STAT 545 TAs, and J. Hester. 2020. Happy Git and GitHub for the useR. https://happygitwithr.com/. Irizarry, R. A. 2020. Introduction to Data Science - Data Analysis and Prediction Algorithms with r. https://rafalab.github.io/dsbook/. Ismay, C., and A. Y. Kim. 2020. Statistical Inference via Data Science. ModernDrive. https://moderndive.netlify.app/. Nielsen, L. R. 2024. Tools for Analytics - Course Notes. https://bss-osca.github.io/tfa/. Wickham, H. 2017. R for Data Science. O’Reilly. https://r4ds.had.co.nz/. Wøhlk, S. 2010. VBA Programming in Business Economics. DJØF Publishing. "],["mod-vba-intro.html", "Module 2 An introduction to VBA 2.1 Learning outcomes 2.2 What is VBA 2.3 Setup Excel for VBA 2.4 Your first program 2.5 The macro recorder 2.6 VBA - A short overview 2.7 Good coding pratice 2.8 Recap 2.9 Exercises", " Module 2 An introduction to VBA This module gives a short introduction to VBA, so you can get started programming and run your code. A template with VBA code is given in the file vba-template.xlsm (open it and use it while reading the notes). Have a look inside the module TM2_ex in the VBA editor for examples used in the notes and during lectures. Have a look at module TM2_exercises for exercises. Guiding answers for the exercises can be found in the file vba-solution.xlsm . Learning path diagram Click/hover the nodes to follow links and see details. If you like a different learning style there is a lot for videos about VBA online such as course 14-Hour VBA Course. The videos have been pointed out as extra online supplements in the learning path diagram. However, they are not necessary for the course. Since Excel change as new versions arrive and it work on different operating systems, the look in the screenshots and videos might be a bit different from your version. However, you still should be able to understand it. 2.1 Learning outcomes By the end of this module, you are expected to: Describe what VBA is. Setup Excel for VBA. Know how the macro recorder works. Make your first program. Have an overview over what VBA can do. Describe what a variable is. Name different data types and how they effect memory size. Declare a variable as a data type. Make a simple procedure. Do simple loops and conditional statements. Recorded you first macro using the macro recorder The learning outcomes relate to the overall learning goals number 2 and 4 of the course. 2.2 What is VBA Visual Basic for Applications (VBA) is an implementation of the BASIC programming language intended to control and automate Microsoft Office applications, developed by Microsoft. For instance, you can automatically create sheets, delete objects, create user-defined functions or read/write data to a sheet. It is not a standalone program, it can only run in the host application. In this course we will focus on running VBA from Excel. VBA is widely used in the industry (specially linked to Excel) and easy to learn. Microsoft stopped investing in VBA in 2008. It only update it for small changes. However, VBA is still a vital part of desktop Office applications, and will continue to be so in the future. VBA is a compiled language implemented using compilers (translators that generate machine code from source code). That is, code need to be compiled first before running it. You can only run VBA using the desktop version of Excel. That is, you can’t create, run, or edit VBA in Excel for the web. With VBA you can extend Excel and automate tasks by coding different algorithms that for instance can be run by pressing a button. Since VBA is a programming language, the initial learning curve is steeper compared to Excel. However, you will get started fast because you already know Excel. 2.3 Setup Excel for VBA First, note that this course is taught in English. Hence it is strongly recommended that you change your language setting for Excel to English, so the menus and Excel functions are in English! On a mac ( ) go to System settings &gt; General &gt; Language &amp; Region and add English as primary language (press the + sign and add it). Note this will affect all your programs on your mac, since this is the way Apple do it. On windows ( ), select File &gt; Options &gt; Language in Excel and under Office display Language, make sure the display language is English. Second, the VBA code editor does not work well with auto save turned on. That is, if you have a version of Excel with the option to turn auto save on/off then set it to off. Third, for running VBA code you must trust the code in the macro enables Excel files (ending with .xlsm) you download. Hence if asked then trust the macros when opening the file. You may also change the security settings under Excels preferences. Finally, For running VBA code the Developer tab needs to be visible in Excel. This can be done by check marking the Developer tab under the ‘Ribbon and Toolbar’ options in Excel. You add it by choosing Excel -&gt; Preferences -&gt; Ribbon and toolbar ( ) or right click a tab and choose Customize ribbon … ( ). Figure 2.1: The VBA editor. In the Developer tab you open the VBA editor by pressing the Visual basic button ( Alt + F11, ⌥ + F11). The VBA editor is where you write your VBA code. A screenshot of the VBA editor can be seen in Figure 2.1. You can setup the editor so it consists of a set of different sub-windows. Here we will highlight the ones you will use the most: Code: The code window is where you can see the code of your modules. Process Explorer: Gives you an overview over all your open workbooks (a Excel file) and the VBA modules (a place to write VBA code) inside each workbook. Properties: Each element in the Process Explorer can be seen as an object and each object has a set of properties. For instance a module have a property called Name containing the name of the module. You can edit the name by modifying the field in the Properties window. Similar a worksheet has a set of properties (try selecting one of the sheets in the Process Explorer). Locals: This is a window which can be used for debugging. During debugging you can run your code line by line by inserting breakpoints. You can then observe the values of your variables in the Locals window. If you do not see the sub-windows in the editor. Then you can open them using the icons in the toolbar (hoover over the icons to find them). Finally, let us set the preferences for the VBA editor. Open the preferences/options Excel -&gt; Preferences -&gt; Editor ( ) or Tools -&gt; Options -&gt; Editor ( ). Uncheck mark ‘Auto Syntax Check’ and check mark ‘Require Variable Declaration’. 2.4 Your first program Let us try to make your first piece of code. Download the template file vba-template.xlsm, open the file and open the VBA editor under the Developer tab. Add a new module by clicking the Insert Module icon (upper left corner - note you can hoover over the icons to see what they do). Rename the module (named Module1) to TM2_hello (note you have to use underscores). Open the module by double clicking on the module in the Process Explorer Add the code &#39; Your first program/macro Sub TM2_SayHello() MsgBox (&quot;Say hello world :-)&quot;) End Sub The code is a procedure (sub) and since it does not have any input arguments it is called a macro and can be run directly. Note if a line starts with a ' then the line is considered as a comment and not used by the program. Run the macro by pressing the Play icon or using the shortcut F5. What happend? Go to the worksheet TM2 in Excel. In the Developer tab press the Button icon and click on cell G3. In the popup window select macro name TM2_SayHello and click OK. Rename the button by clicking the text and call it ‘Say Hello’. Click besides the button to finish. Run the button by clicking it. Try right clicking the button and move/resize it. Save the workbook (Excel file). Note the Excel file has extension .xlsm and not .xlsx because it contains VBA code. You have now finished your first program by saying hello to the world using a message box. 2.5 The macro recorder It is possible to use the Macro recorder to turn your actions in Excel into VBA code. This can be particularly useful if you have forgotten the code for a specific color, the name of a function or need to plot a graph. Unfortunately, you cannot record if-statements or loops, so the recorder is not an easy way out of learning to code. But it is a handy tool for getting pieces of code. Let us try to record a macro that make a scatter plot of cells D8:E12 and change the title: Click the Record Macro icon under under the Developer tab. Name the macro TM2_Plot and click OK (the recorder is now running). Go to the worksheet TM2 and select cells D8:E12. Add a scatter plot of the points. Rename the title to ‘A line’. Click the Stop Recording icon under under the Developer tab. You have now finished recording your macro. Let us have a look at the code by going to the TM2_Plot sub in the VBA editor. You should have something similar to: Sub TM2_Plot() &#39; &#39; TM2_Plot Macro &#39; Worksheets(&quot;TM2&quot;).Activate Range(&quot;D8:E12&quot;).Select ActiveSheet.Shapes.AddChart2(240, xlXYScatterSmooth).Select ActiveChart.SetSourceData Source:=Range(&quot;&#39;TM2&#39;!$D$8:$E$12&quot;) ActiveChart.ChartTitle.Select ActiveChart.ChartTitle.Select ActiveChart.ChartTitle.Text = &quot;A line&quot; Selection.Format.TextFrame2.TextRange.Characters.Text = &quot;A line&quot; With Selection.Format.TextFrame2.TextRange.Characters(1, 6).ParagraphFormat .TextDirection = msoTextDirectionLeftToRight .Alignment = msoAlignCenter End With With Selection.Format.TextFrame2.TextRange.Characters(1, 1).Font .BaselineOffset = 0 .Bold = msoFalse .NameComplexScript = &quot;+mn-cs&quot; .NameFarEast = &quot;+mn-ea&quot; .Fill.Visible = msoTrue .Fill.ForeColor.RGB = RGB(89, 89, 89) .Fill.Transparency = 0 .Fill.Solid .Size = 14 .Italic = msoFalse .Kerning = 12 .Name = &quot;+mn-lt&quot; .UnderlineStyle = msoNoUnderline .Spacing = 0 .Strike = msoNoStrike End With With Selection.Format.TextFrame2.TextRange.Characters(2, 5).Font .BaselineOffset = 0 .Bold = msoFalse .NameComplexScript = &quot;+mn-cs&quot; .NameFarEast = &quot;+mn-ea&quot; .Fill.Visible = msoTrue .Fill.ForeColor.RGB = RGB(89, 89, 89) .Fill.Transparency = 0 .Fill.Solid .Size = 14 .Italic = msoFalse .Kerning = 12 .Name = &quot;+mn-lt&quot; .UnderlineStyle = msoNoUnderline .Spacing = 0 .Strike = msoNoStrike End With ActiveChart.ChartArea.Select End Sub In general a recorded macro contains a lot of unnecessary code which can be removed. For instance, here we just want to make a scatter plot of cells D8:E12 and change the title. That is, the code can be reduced to: &#39; Add a scatter plot Sub TM2_Plot() Worksheets(&quot;TM2&quot;).Activate Range(&quot;D8:E12&quot;).Select ActiveSheet.Shapes.AddChart2(240, xlXYScatterSmooth).Select ActiveChart.SetSourceData Source:=Range(&quot;&#39;TM2&#39;!$D$8:$E$12&quot;) ActiveChart.ChartTitle.Text = &quot;A line&quot; End Sub Which code to remove can sometimes be hard to realize. However, you may try to remove small parts of code, run the macro and check if the results still are as wanted. Finally, try to add a button ‘Make plot’ that run the macro. Go to the worksheet TM2 and do steps: In the Developer tab press the Button icon and click on cell G8. In the popup window select macro name TM2_Plot and click OK. Rename the button by clicking the text and call it ‘Make plot’. Click besides the button to finish. Run the button by clicking it. 2.6 VBA - A short overview Let us have a short overview over some VBA features so you can get started coding. Basic building blocks in programming are: Variables store stuff in memory. Procedures (functions and subs) execute a set of instructions. Input and output are needed to read data and output the result. Conditional statements are used to execute different instructions depending on a true/false value. Loops are used to execute code repeatedly. 2.6.1 Variables Variables are used to store information that is saved in memory. You may visualize a variable as a box in memory (see Figure 2.2). The variable name can be seen as the label on the box. Figure 2.2: Visualization of computer memory The box can contain for instance a number, a date or a boolean. That is, any data type defined by VBA. Some of the basic data types used by VBA are: Table 2.1: Basic data types. Name Type Details Byte Numerical Whole number between 0 and 255. Integer Numerical Whole number between -32768 and 32767. Long Numerical Whole number between - 2147483648 and 2147483647. Double Numerical Floating decimal number between -1.79769313486232E308 and 1.79769313486232E308. String Text Text. Date Date Date and time. Boolean Boolean True or False. Variant Any type Any kind of data (default type if the variable is not declared). All basic data types can be seen in the VBA documentation. Note that some data types are numericals, i.e. they represent a number (either an integer or a decimal number), other data types represent a set of characters (a string), a boolean or a date. More advanced data types such as a group of numbers (a numeric array), a range of cells in a worksheet (an object) or a set of numbers (a collection) will be considered in Module 5. Your memory contains a limited amount of storage and it is therefore important to use it wisely. The computer memory can be seen as a group of bits (zero and ones) and we can measure the memory size by counting the number of bits or bytes (8 bits = 1 byte). Different data types take up different amounts of memory. For example, the memory requirements for some of the basic data types are: Table 2.2: Memory requirements for some data types. Data type Storage size Byte 1 byte Boolean 2 bytes Integer 2 bytes Long (long integer) 4 bytes Double (double-precision floating-point) 8 bytes Date 8 bytes String 10 bytes + string length * 2 bytes Variant (a number) 16 bytes Variant (a string) 22 bytes + string length * 2 bytes 8 Bits = 1 Byte, 1024 Bytes = 1 Kilobyte, 1024 Kilobytes = 1 Megabyte, 1024 Megabytes = 1 Gigabyte and 1024 Gigabytes = 1 Terabyte. Always declare your variables explicit in VBA. If you can add Option Explicit in the top of your module, undefined variables will raise an error. You can add it by default by modifying the preferences for the VBA editor (see Section 2.3). Declaring variables is good coding practice since it reduces the memory requirements and avoid type errors such as Option Explicit Dim intCtr as integer intCtr = 10 intCtr = intCtg + 10 This will raise an error because intCtg is not defined (you have made a typo and meant intCtr). Without Option Explicit the code will run and assume that intCtg is another variable (initialized to zero). As can be seen a double takes 4 times the memory compared to an integer. That is, you can save memory by considering what data type you need. Consider an example where you have 10000 customer locations on a map and you want to store the distance between customer \\(i\\) and \\(j\\). That is, you have to store \\(10000 \\cdot 10000 = 100.000.000\\) numbers. The memory requirements given different data types are: Data type Memory requirements Variant \\((10000\\cdot 10000\\cdot 16)/1024/1024 \\approx 1526\\) MB Double \\((10000\\cdot 10000\\cdot 8)/1024/1024 \\approx 763\\) MB Integer \\((10000\\cdot 10000\\cdot 2)/1024/1024 \\approx 191\\) MB If you do not think about memory usage a Variant data type would have been used taking up the double the size compared to using a Double (a decimal number). Moreover, if it is enough to measure the distance using an Integer between 0 and 32767, then we can reduce the memory requirements to only 191 MB. Often the free memory in your computer is around 5 GB, i.e. think about which data type you need! You declare variables using the Dim keyword: &#39;&#39; Declare some variables Sub TM03_DeclareVariables() &#39; Always declare variables in the top of a procedure (memory is allocated) Dim intPersons As Integer Dim dblAmount As Double Dim strText As String &#39; Here we assign values to the variables (modify the memory) intPersons = 10 dblAmount = 27.4 strText = &quot;Number of persons are &quot; MsgBox (strText &amp; intPersons &amp; &quot; which own &quot; &amp; dblAmount &amp; &quot;$&quot;) End Sub Three variables are declared on the first three lines in the sub (good coding practice). Variables can be of different data types (here an integer, a double and a string). We allocate values to the variables on the next lines and finally output the result in a message box. Note VBA code is case-insensitive, i.e. strText and strtext is the same variable. It is good coding practice to be consistent and often the VBA editor will help you by changing strtext to strText automatically. 2.6.2 Procedures In VBA we deal with two kinds of procedures: A Sub which can work as a “macro” in Excel, i.e. we can call it using e.g. a button and a Function which can work like Excel functions, i.e. return a value. We already have declared some subs. Let us try to make a function: &#39;&#39; A function joining two strings Function TM2_StringJoin(strF As String, strL As String) As String Dim strJ As String strJ = strF &amp; &quot; &quot; &amp; strL TM2_StringJoin = strJ End Function First observe that the function have two string input arguments strF and strL. These two strings are joined into one string (saved in the variable strJ) by using the string concatenate symbol &amp;. Finally, the value is returned by assigning the value to same variable as the function name TM2_StringJoin. The function can be called from Excel like any other function by using the function name (have a look at cell D5 in the worksheet TM2). You may also use all the built-in Excel functions in VBA: &#39;&#39; Call an Excel function Sub TM2_ExcelFunction() MsgBox (&quot;The sum of cells D9:D12 are &quot; &amp; WorksheetFunction.Sum(Worksheets(&quot;TM2&quot;).Range(&quot;D9:D12&quot;))) End Sub Note all Excel functions are accessed using the WorksheetFunction object. That is, we write WorksheetFunction.&lt;function name&gt;. VBA also has a set of built-in functions which can be used. For instance the Date and InStr function: &#39;&#39; Call VBA functions (run it using F5) Sub TM2_VBAFunction() MsgBox (&quot;The current date is &quot; &amp; Date) MsgBox (&quot;Jen is found at char number: &quot; &amp; InStr(&quot;Hi Jen how are you&quot;, &quot;Jen&quot;)) End Sub We will have a closer look on procedures in Module 4. 2.6.3 Input and output Input and output are needed to read data and output the result. Examples on input/output are dialog boxes which can be created using MsgBox or InputBox: Sub TM2_Dialog() Dim strName As String strName = InputBox(&quot;Type your name:&quot;) MsgBox &quot;Your name is &quot; &amp; strName End Sub First, a string is declared. Next, a value is read to the string using an input box. Finally, the result is output using a message box. You can also write/read values from a sheet using Range or Cells. Note it is always a good idea to know which sheet you are considering by using the Worksheets function: &#39;&#39; Read and write to sheet Sub TM2_ReadWriteSheet() Dim str1 As String Dim int1 As Integer Worksheets(&quot;TM2&quot;).Activate &#39; We activate a sheet so know use this sheet &#39; Input values from sheet str1 = Range(&quot;D4&quot;) &#39; read cell D4 int1 = Cells(9, 4) &#39; read row 9 and col 4 (cell D9) &#39; Output values Range(&quot;B7&quot;) = str1 &amp; &quot;(&quot; &amp; int1 &amp; &quot;)&quot; Cells(8, 2) = str1 End Sub After declaring variables, the worksheet TM2 is activated and we input/output values using the Range and Cells functions. We will have a closer look on the range object in Module 5. 2.6.4 Conditional statements Conditional statements execute different instructions depending on a true/false value. &#39;&#39; Conditional statements example Sub TM2_CondStatement() Dim strName As String Dim intAnswer As Integer Worksheets(&quot;TM2&quot;).Activate strName = InputBox(&quot;Type your name:&quot;) intAnswer = MsgBox(&quot;Do you want to display your name in a message box?&quot;, vbYesNo) &#39; you can use vbYes and vbNo in your code If intAnswer = vbYes Then &#39; Make the message box: MsgBox (&quot;Your name is &quot; &amp; strName) Else &#39; Write to the sheet: Range(&quot;B10&quot;) = strName MsgBox (&quot;Your name is in cell B10&quot;) End If End Sub After declaring variables and activating the worksheet, a dialog box is used for reading your name. Next, based on your answer we use an If/Else statement to do two different tasks. We will have a closer look on conditional statements in Module 3. 2.6.5 Loops Loops can be used to execute code repeatedly: &#39;&#39; Loops example Sub TM2_Loops() Dim k As Integer Worksheets(&quot;TM2&quot;).Activate For k = 2 To 5 Cells(k, 10) = &quot;Row &quot; &amp; k Next End Sub Here a For loop is used to write out values to cells J2:J5. We will have a closer look on loops in Module ??. 2.7 Good coding pratice It is always a good idea to maintain a consistent coding practice. The main reason for using a consistent set of coding conventions is to standardize the structure and coding style of an application so that you and others can easily read and understand the code. Good coding conventions result in precise, readable, and unambiguous source code that is consistent with other language conventions and as intuitive as possible. As you already have seen the code in this teaching module has been structured in VBA modules (we use the prefix TM2_ for all modules related to this teaching module). Each procedure starts with a capital letter and we use code indention to read the code easier. Different ways of naming variables exists (naming convention). Some use snake case others use camel case. The Leszynski naming convention define variables with a consistent prefix that makes it easy to identify its data type. Some common prefixes used for the Leszynski naming convention are: Table 2.3: Prefixes for some variables. Type Prefix Example Boolean bln blnFound Currency cur curRevenue Date (Time) dtm&lt; dtmStart Double dbl dblTolerance Integer int intQuantity Long lng lngDistance String str strFName Variant vnt vntCheckSum Array ary aryNumbers (optional) Worksheet wst wstDistances Workbook wbk wbkData Many other prefixes can be used also. It is common to use Leszynski convention within the VBA community. A few examples: this_is_snake_case # note you do not use capital letters here (not used) thisIsCamelCase # you start each word with a capital letter intAmount # Lezynski convention naming an integer (int) variable strFullName # Lezynski naming a string (str) variable We adapt the Leszynski naming convention together with camel case. One exception is that we add the suffix TM2_ when we name procedures so that we can easy find procedures related to a given teaching module. When defining variables and functions, it is in general good practice to use nouns for variables and verbs for functions. It is always good practice to comment your code. Such that others can get a fast overview and understand your code easier. We will use roxygen documentation comments which are widely known. For example in the top of a module file you may write: &#39;&#39; Module description. &#39; Can be more than one line. &#39; @author Lars Relund &lt;junk@relund.dk&gt; Before each sub, function etc. write something like: &#39;&#39; Sub description &#39; &#39; @pre Precondition &#39; @post Postcondition &#39; &#39; @param strA Explanation of input parameter strA &#39; @param intB Explanation of input parameter intB &#39; @return Return value (if a function) &#39; @remarks Further remarks Function MyFunc(strA As String, intB As Integer) As Integer { ... } For further details about coding/naming convention see Section D. 2.8 Recap This module gives a short introduction to VBA: A programming language intended to control and automate Microsoft Office applications (we use Excel). VBA (Visual Basic for Applications) is an implementation of BASIC developed by Microsoft. A compiled language. That is, code need to be compiled first before running it. You can only run VBA using the desktop version of Excel (not the web version). With VBA you can extend Excel and automate tasks by coding different algorithms that for instance can be run by pressing a button. It is strongly recommended that you change your language setting for Excel to English, so the menus and Excel functions are in English! On a mac ( ) go to System settings &gt; General &gt; Language &amp; Region and add English as primary language (press the + sign and add it). Note this will affect all your programs on your mac, since this is the way Apple do it. On windows ( ), select File &gt; Options &gt; Language in Excel and under Office display Language, make sure the display language is English. For running VBA code the Developer tab needs to be visible in Excel. This can be done by check marking the Developer tab under the ‘Ribbon and Toolbar’ options in Excel. You add it by choosing Excel -&gt; Preferences -&gt; Ribbon and toolbar ( ) or right click a tab and choose Customize ribbon … ( ). In the Developer tab you open the VBA editor by pressing the Visual basic button ( Alt + F11, ⌥ + F11). A few useful shortcuts: Toggle VBA editor and Excel ( Alt + F11, ⌘⇧´). Run current procedure or continues execution after pausing (F5). Auto complete code (Ctrl + Space). On a mac you may have to disable the default shortcut (Ctrl + Space) for switching input sources. You can go to the System Preferences -&gt; Keyboard -&gt; Shortcuts -&gt; Input Sources and disable it. Use the debugger and go to next line of code ( F8, ⇧⌘I). Switch between subs/functions ( Ctrl + Up/Down, ⌘ + Up/Down). Basic building blocks in programming: Variables store stuff in memory. Procedures (functions and subs) execute a set of instructions. Conditional statements are used to execute different instructions depending on a true/false statement. Loops are used to execute code repeatedly. Input/output are needed to read data and output the result. Variables are used to store information in the program. Think of it as a box that can contain e.g. a number, a string or a date. The variable name is the label on the box. In VBA we deal with two kinds of procedures: A Sub which can work as a “macro” in Excel, i.e. we can call it using e.g. a button and a Function which can work like Excel functions, i.e. return a value. Examples on input/output are dialog boxes which can be created using MsgBox or InputBox. You can also write/read values from a sheet using Range or Cells. Note it is always a good idea to know which sheet you are considering by using Worksheets(\"&lt;sheet name&gt;\").Activate. Conditional statements (decisions) execute different instructions depending on a true/false. Loops can be used to execute code repeatedly. Excel functions can be called with the WorksheetFunction e.g. WorksheetFunction.Sum(Range(\"D2:E5\")) Always remember to save workbooks with VBA code using the file has extension .xlsm and not .xlsx otherwise the VBA code will be removed from the file! You may also have a look at the slides for this module . 2.9 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Some of the solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up too early. Put some effort into finding a solution! A template with VBA code is given in the file vba-template.xlsm (open it and use it while reading the notes). Have a look inside the module TM2_ex in the VBA editor for examples used in the notes and during lectures. Have a look at module TM2_exercises for exercises. Guiding answers for the exercises can be found in the file vba-solution.xlsm . 2.9.1 Exercise - Hello Consider the procedure TM2_SayHello in Section 2.4 and modify it into procedure TM2_SayHelloAdv with features: Use an input box to ask for your name. Output Hello in cell B11 in worksheet TM2. Run it using the shortcut F5. 2.9.2 Exercise - Record a macro Do the following steps: Type ‘My name is:’ in cell B12. Type you name in cell B13 and activate it (click on it). Start the macro recorder and call the macro TM2_ChangeLayout. Change the color to blue and font size to 14. Stop the macro recorder. Activate cell B12 and run the macro. Open the VBA editor and inspect the macro. Cleanup the macro so only stuff about color and size are maintained. Add a button to run the macro. Select cells D15:E17 and run the macro. Modify the macro in the editor so the font size is 10 and test it. 2.9.3 Exercise - User input Write a procedure (sub) TM2_CheckNumber that: Ask for an integer using an input box. Make a message box telling if the number is above or at most 10. Write the number to cell B14. What happens if you do type in a string in the input box? 2.9.4 Exercise - Max and min number The worksheet TM2_Numbers contains a button to a procedure that generate 40 random integers in the interval \\([-1000,1000]\\). × Hint Sub TM2_FindMax() Dim intM As Integer Dim r As Integer Worksheets(&quot;TM2_Numbers&quot;).Activate intM = -1001 For r = 1 To 40 If Cells(r, 1) ___ intM Then intM = ___ End If Next Range(&quot;D1&quot;) = ___ End Sub Close Hint Create a procedure that use loops and conditional statements to find the maximum number and write it to cell D1. Assign the procedure to button Find max. Create a procedure that use loops and conditional statements to find the minimum number and write it to cell D2. Assign the procedure to button Find min. × Hint Sub TM2_FindRange() Dim intM1 As Integer Dim intM2 As Integer Dim r As Integer Worksheets(&quot;TM2_Numbers&quot;).Activate intM1 = 1001 intM2 = -1001 For r = 1 To 40 ___ Next Range(&quot;D3&quot;) = &quot;[&quot; &amp; intM1 &amp; &quot;,&quot; &amp; intM2 &amp; &quot;]&quot; End Sub Close Hint Create a procedure that use loops and conditional statements to find the number range (min value and max value) and write it to cell D3. Assign the procedure to button Find range. Given two numbers m1 and m2, you can concatenate them to a string using &amp; e.g. \"[\" &amp; m1 &amp; \",\" &amp; m2 &amp; \"]\". Create a procedure that use loops and conditional statements to count the number of positives and write it to cell D4. Assign the procedure to button Count positives. It may often be nice to know the row number of the minimum and maximum values. Create a procedure that finds the maximum row number and write it to cell D5. Assign the procedure to button Find max row. Create a procedure that finds the minimum row number and write it to cell D6. Assign the procedure to button Find min row. The procedure TM2_RunAll which is already linked to button Run All, runs all the procedures. Have a look at the code and try it out. "],["mod-vba-loops-cond.html", "Module 3 Loops and conditional statements 3.1 Learning outcomes 3.2 Relational and logical operators 3.3 Loops 3.4 Conditional statements 3.5 Example - Find Jen 3.6 Example - A distance matrix 3.7 Recap 3.8 Exercises", " Module 3 Loops and conditional statements This module gives an introduction to loops and conditional statements. Loops are used to repeat code and conditional statements are used to redirect code execution based on the conditions. Both are basic building blocks in programming. A template with VBA code is given in the file vba-template.xlsm (open it and use it while reading the notes). Have a look inside the module TM3_ex in the VBA editor for examples used in the notes and during lectures. Have a look at module TM3_exercises for exercises. Guiding answers for the exercises can be found in the file vba-solution.xlsm . Learning path diagram Click/hover the nodes to follow links and see details. If you like a different learning style there is a lot for videos about VBA online such as course 14-Hour VBA Course. The videos have been pointed out as online supplements in the learning path diagram. However, they are not necessary for the course. Since Excel change as new versions arrive and it work on different operating systems, the look in the screenshots and videos might be a bit different from your version. However, you still should be able to understand it. 3.1 Learning outcomes By the end of this module, you are expected to be able to: Describe what a conditional statement is. Test a condition built using relational/logical operators. Declare a conditional statement. Describe what a loop is. Declare a loop. Declare nested loops. Exit a loop. The learning outcomes relate to the overall learning goals number 1, 2, 4, 8, 9-12 and 16 of the course. 3.2 Relational and logical operators Often you will need to compare a variable with another one. For this you need the relational operators given in Table 3.1 (also called comparison operators). Table 3.1: Comparison/relational operators. Operator Description Example = Equal to. A = B ’ False &lt;&gt; Not equal to A &lt;&gt; B ’ True &gt; Greater than. A &gt; B ’ False &lt; Less than. A &lt; B ’ True &gt;= Greater than or equal to. A &gt;= B ’ False &lt;= Less than or equal to. A &lt;= B ’ True Assume that A = 2 and B=4. Let us consider an example (try to guess the output before running the procedure): &#39;&#39; Comparison of two variables Sub TM3_Comparison() Dim intA As Integer Dim intB As Integer intA = 10 intB = 20 If intA = intB Then MsgBox (&quot;A = B is True&quot;) Else MsgBox (&quot;A = B is False&quot;) End If If intA &lt;&gt; intB Then MsgBox (&quot;A not equal B is True&quot;) Else MsgBox (&quot;A not equal B is False&quot;) End If If intA &gt; intB Then MsgBox (&quot;A greter then B is True&quot;) Else MsgBox (&quot;A greter then B is False&quot;) End If If intA &lt;= intB Then MsgBox (&quot;A less than or equal to B is True&quot;) Else MsgBox (&quot;A less than or equal to B is False&quot;) End If End Sub Given two boolean expressions we use logical operators to compare them (see Table 3.2) Table 3.2: Logical operators. Operator Description Example AND If both the conditions are True, then the expression is true. A&lt;&gt;0 AND B&lt;&gt;0 ’ False OR If any of the two conditions are True, then the expression is true. A&lt;&gt;0 OR B&lt;&gt;0 ’ True NOT Reverse logical: if the expression is true, then the NOT operator returns false. NOT(A&lt;&gt;0 OR B&lt;&gt;0) ’ False XOR Logical Exclusion. If exactly one condition is True, the result is True. A&lt;&gt;0 XOR B&lt;&gt;0 ’ True Assume that A = 0 and B=4. Let us consider an example (try to guess the output before running the procedure): Sub TM3_Logical() If 5 &gt; 4 And 6 &gt; 2 Then MsgBox (&quot;5 &gt; 4 And 6 &gt; 2 is True&quot;) Else MsgBox (&quot;5 &gt; 4 And 6 &gt; 2 is False&quot;) End If If 1 &gt; 4 Or 1 &gt; 2 Then MsgBox (&quot;1 &gt; 4 Or 1 &gt; 2 is True&quot;) Else MsgBox (&quot;1 &gt; 4 Or 1 &gt; 2 is False&quot;) End If If 6 &gt; 4 Or 1 &gt; 2 Then MsgBox (&quot;6 &gt; 4 Or 1 &gt; 2 is True&quot;) Else MsgBox (&quot;6 &gt; 4 Or 1 &gt; 2 is False&quot;) End If If 5 &gt; 4 And Not 6 &gt; 2 Then MsgBox (&quot;5 &gt; 4 And Not 6 &gt; 2 is True&quot;) Else MsgBox (&quot;5 &gt; 4 And Not 6 &gt; 2 is False&quot;) End If &#39; If more than two boolean expressions remember parenthesis If (5 &gt; 4 Xor 6 &gt; 2) And 7 &gt; 10 Then &#39; Xor (exactly one is true) MsgBox (&quot;(5 &gt; 4 Xor 6 &gt; 2) And 7 &gt; 10 is True&quot;) Else MsgBox (&quot;(5 &gt; 4 Xor 6 &gt; 2) And 7 &gt; 10 is False&quot;) End If If 5 &gt; 4 Xor (6 &gt; 2 And 7 &gt; 10) Then MsgBox (&quot;5 &gt; 4 Xor (6 &gt; 2 And 7 &gt; 10) is True&quot;) Else MsgBox (&quot;5 &gt; 4 Xor (6 &gt; 2 And 7 &gt; 10) is False&quot;) End If End Sub Note parentheses have an impact on the result. Remember to use them correctly. 3.3 Loops Loops are used to repeat pieces of code. There are many types of loops statements but here we will consider For and While loops. The structure of a For loop is: For i = 1 To 10 &lt;code&gt; Next Here i is a counter used to repeat the code inside the loop 10 times. In general we do not use a suffix for counter variables (i should have been named intI according to our naming convention). An example on a simple for loop is: Sub TM3_Loop1() Dim i As Integer For i = 1 To 3 MsgBox (i) &#39; What will the output be? Next End Sub You can use the Step keyword to increment the counter by more than one: Sub TM3_Loop2() Dim i As Integer For i = 2 To 9 Step 2 If i &lt;&gt; 4 Then MsgBox (i) &#39; What will the output be? End If Next End Sub You can use Exit For to end a for loop prematurely (jump to the code after the loop): &#39;&#39; Write the row number in column A and exit after row 10 even though the loop runs to 20 Sub TM3_WriteNumbers1() Dim r As Integer Worksheets(&quot;TM3&quot;).Activate &#39; activate the sheet we want to use For r = 6 To 20 If r &gt; 10 Then Exit For End If Cells(r, 1) = r &#39; write to row r, col 1 (A) Next End Sub Loops may be nested inside each other. For instance if some action needs to be performed for each day and each employee or for each project and each work package of that project. Sub TM3_NestedLoops() Dim i As Integer Dim j As Integer For i = 1 To 2 For j = 1 To 3 MsgBox (&quot;(&quot; &amp; i &amp; &quot;,&quot; &amp; j &amp; &quot;)&quot;) Next Next End Sub The structure of a While loop is: Do While &lt;condition true&gt; &lt;code&gt; Loop Here the loops runs until the condition is not true. While loops are useful when you do not know how many times to do the loop in advance. An example on a simple while loop is: &#39;&#39; Write the row number in column B and exit after row 10 Sub TM3_WriteNumbers2() Dim r As Integer Worksheets(&quot;TM3&quot;).Activate r = 6 Do While r &lt; 11 Cells(r, 2) = r &#39; write to row r, col 2 (B) r = r + 1 Loop End Sub You can use Exit Do to end a while loop prematurely (jump to the code after the loop): &#39;&#39; Write 2, 4, ... in column C and exit after 21 or if equals 12 Sub TM3_WriteNumbers3() Dim i As Integer, r As Integer Worksheets(&quot;TM3&quot;).Activate r = 6 i = 2 Do While i &lt; 21 Cells(r, 3) = i &#39; write to row r, col 3 (C) If i = 12 Then Exit Do End If r = r + 1 i = i + 2 Loop End Sub Beware of endless loops. If the stopping criteria is NOT reached when using a while loop, the computer will keep going: &#39; An endless loop. Do not run if you don&#39;t know how to stop Sub TM3_EndlessLoop() Dim i As Integer While i &gt;= 0 i = i + 1 Wend End Sub An endless loop can be hard to stop depending on the operating system you use. Therefore always “save” before you “run” the code. Make sure the stopping criterion will be reached. You may try to stop the program using a shortcut ( try Ctrl + Break or Ctrl + Alt + Delete. try ⌘., ⌃ + Esc or ⌘⌥ + Esc.) Finally, the For Each loop has to be mentioned: Sub TM3_ForEach() Dim rngC As Range Dim i As Integer Worksheets(&quot;TM3&quot;).Activate i = 1 For Each rngC In Range(&quot;D6:E9&quot;) rngC = i i = i + 1 Next End Sub The loop is used for running trough a set of objects (we will have a closer look at objects in Section 5.3). Here rngC is used to run through all the cells in the range and set values. Note a range is scanned left-down. 3.4 Conditional statements Conditional statements are used to redirect code execution based on the conditions. If the condition is met then the code is executed. The general layout of an if-then-else conditional statement is: If &lt;condition&gt; Then &lt;code&gt; ElseIf &lt;condition&gt; Then &lt;code&gt; ElseIf &lt;condition&gt; Then &lt;code&gt; Else &lt;code&gt; End If If &lt;condition&gt; Then &lt;code&gt; Else &lt;code&gt; &#39; single line form You can drop the ElseIf and Else code chunks. Other conditional statements exists but in general you can formulate them using an if-then-else statement. Let us try to use a conditional statement to separate persons in two groups: &#39;&#39; Seperate persons into two groups (names are written in 2 columns) Sub TM3_SeparatePersons1() Dim r As Integer Worksheets(&quot;TM3_Separate1&quot;).Activate &#39; activate the correct sheet For r = 2 To 12 &#39; scan rows 2-12 If Cells(r, 2) = &quot;Professor&quot; Then Cells(r, 3) = Cells(r, 1) &#39; output in row C Else Cells(r, 4) = Cells(r, 1) &#39; output in row D End If Next End Sub We use variable r to store the row number we want to write to and then an if statement to separate professors from others. The output will be: Figure 3.1: Separate into two groups. If you want to separate both professors and associate professors from others, you may modify the if statement and use an ElseIf: &#39;&#39; Seperate persons into 3 groups (names are written in 3 columns) Sub TM3_SeparatePersons2() Dim r As Integer Worksheets(&quot;TM3_Separate2&quot;).Activate &#39; activate the correct sheet For r = 2 To 12 If Cells(r, 2) = &quot;Professor&quot; Then Cells(r, 3) = Cells(r, 1) ElseIf Cells(r, 2) = &quot;Associate Professor&quot; Then Cells(r, 4) = Cells(r, 1) Else Cells(r, 5) = Cells(r, 1) End If Next End Sub Finally, let us try to separate into five groups: &#39;&#39; Seperate persons into 5 groups (names are written in 5 columns) Sub TM3_SeparatePersons3() Dim r As Integer Worksheets(&quot;TM3_Separate3&quot;).Activate &#39; activate the correct sheet For r = 2 To 12 If Cells(r, 2) = &quot;Professor&quot; Then Cells(r, 3) = Cells(r, 1) ElseIf Sheet1.Cells(r, 2) = &quot;Associate Professor&quot; Then Cells(r, 4) = Cells(r, 1) ElseIf Sheet1.Cells(r, 2) = &quot;Post Doc&quot; Then Cells(r, 5) = Cells(r, 1) ElseIf Sheet1.Cells(r, 2) = &quot;PhD student&quot; Then Cells(r, 6) = Cells(r, 1) Else Cells(r, 7) = Cells(r, 1) End If Next End Sub Here the output will be: Figure 3.2: Separate into five groups. 3.5 Example - Find Jen Consider column A in Figure 3.2. Assume we want to check if Jen is in a name and output her position. We can use a for loop for this: &#39;&#39; Find cell with Jen using a For loop Sub TM3_FindJen1() Dim r As Integer Worksheets(&quot;TM3_Separate1&quot;).Activate &#39; activate the correct sheet For r = 2 To 12 If InStr(Cells(r, 1), &quot;Jen &quot;) &gt; 0 Then &#39; InStr returns first char position at which match is found (0 if no match) MsgBox &quot;Jen is a &quot; &amp; Cells(r, 2) &amp; &quot; (Row &quot; &amp; r &amp; &quot;)&quot; Exit For &#39; exit the loop End If Next End Sub We scan all rows for Jen and return her position. If we found her, then we exit the for loop (no need to search further). What happens if we search for \"Jen\" and not \"Jen \"? Figure 3.3: Search for Jen. The same can be done using a while loop: &#39;&#39; Find cell with Jen using a While loop Sub TM3_FindJen2() Dim r As Integer r = 2 Do While InStr(Cells(r, 1), &quot;Jen &quot;) = 0 r = r + 1 Loop MsgBox &quot;Jen is a &quot; &amp; Cells(r, 2) &amp; &quot; (Row &quot; &amp; r &amp; &quot;)&quot; End Sub Beware of endless looping here. What happens if Jen is not present in column A? A more error safe while loop is: &#39;&#39; Find cell with Jen using a While loop and better stopping criteria Sub TM3_FindJen3() Dim r As Integer r = 2 Do While InStr(Cells(r, 1), &quot;Jen &quot;) = 0 And r &lt; 13 r = r + 1 Loop If (r = 13) Then MsgBox (&quot;Jen not found&quot;) Else MsgBox &quot;Jen is a &quot; &amp; Cells(r, 2) &amp; &quot; (Cell A&quot; &amp; r &amp; &quot;)&quot; End If End Sub 3.6 Example - A distance matrix Assume that you have a set of \\(n=10\\) locations: Table 3.3: A set of locations Location number \\(x\\)-coordinate \\(y\\)-coordinate 1 6 1 2 1 5 3 6 3 4 7 4 5 4 6 6 4 7 7 5 2 8 1 4 9 4 2 10 6 5 The euclidean distance \\(d\\) between location \\(l_1 = (x_1, y_1)\\) and \\(l_2 = (x_2, y_2)\\) are: \\[d(1,2)=\\sqrt{(x_1-x_2)^2 + (y_1-y_2)^2}.\\] In VBA the function becomes: &#39;&#39; Calculate distance between two points &#39; &#39; @param x1 x-coordinate of first point. &#39; @param y1 y-coordinate of first point. &#39; @param x2 x-coordinate of second point. &#39; @param y2 y-coordinate of second point. Function TM3_Distance(x1 As Double, y1 As Double, x2 As Double, y2 As Double) As Double Dim x As Double Dim y As Double x = x1 - x2 y = y1 - y2 TM3_Distance = Sqr((x * x) + (y * y)) End Function Assume that you want to calculate the distance matrix \\(D\\) where entry \\((i,j)\\) contains the distance between location \\(i\\) and location \\(j\\). Consider the locations in columns B and C: Figure 3.4: Distance matrix worksheet. We want to fill out the cells F1:P11 with the distances. This have been done using procedure: &#39;&#39; Create a distance matrix starting in column 6 &#39; &#39; @pre Assume that coordinates are stored in column B and C starting from row 2 &#39; and that number of points are stored in E1. Public Sub TM3_MakeDistanceMatrix() Dim n As Integer Dim i As Integer Dim j As Integer n = Range(&quot;E1&quot;) For i = 1 To n &#39; add row and column headers Cells(i + 1, 6) = Cells(1 + i, 1) &#39; row equals i+1 Cells(1, 6 + i) = Cells(1 + i, 1) &#39; column equals i+6 Next &#39; add distances For i = 1 To n For j = 1 To n Cells(i + 1, j + 6) = TM3_Distance(Cells(i + 1, 2), Cells(i + 1, 3), Cells(j + 1, 2), Cells(j + 1, 3)) Next Next End Sub First, row and column headers are written to the cells. Next, we use a nested for loop to calculate the distances and output them to the cells. Note we in fact calculate the same distance two times (the distance from \\(i\\) to \\(j\\) equals the distance from \\(j\\) to \\(i\\)). Since we have symmetric distances there is no need to do this and it can be avoided by letting the inner loop in the nested loops be dependent on the outer loop: &#39;&#39; Create a symetric distance matrix with only the upper right part filled starting in column 6. &#39; &#39; @pre Assume that coordinates are stored in column B and C starting from row 2 &#39; and that number of points are stored in E1. Public Sub TM3_MakeSymetricDistanceMatrix() Dim n As Integer Dim i As Integer Dim j As Integer n = Range(&quot;E1&quot;) For i = 1 To n Cells(i + 1, 6) = Cells(1 + i, 1) Cells(1, 6 + i) = Cells(1 + i, 1) Next For i = 1 To n For j = i + 1 To n Cells(i + 1, j + 6) = TM3_Distance(Cells(i + 1, 2), Cells(i + 1, 3), Cells(j + 1, 2), Cells(j + 1, 3)) Next Next End Sub Figure 3.5: Distance matrix worksheet with symmetric distances. 3.7 Recap Loops are used to repeat pieces of code. For loops (repeat a number of times): For i = 1 To 10 &lt;code&gt; Next While loops (repeat until a condition is met): Do While &lt;condition&gt; &#39; repeat while true &lt;code&gt; Loop Use Exit for and Exit Do to break a For and a Do While loop before it ends (jump to the code after the loop). Loops may be nested inside each other: For i = 1 To 2 For j = 1 To 3 MsgBox (&quot;(&quot; &amp; i &amp; &quot;,&quot; &amp; j &amp; &quot;)&quot;) Next Next Conditional Statements are used to make decisions based on the conditions. If the condition is met then the code is executed. An if-then-else statement: If &lt;condition&gt; Then &lt;code&gt; ElseIf &lt;condition&gt; Then &lt;code&gt; Else &lt;code&gt; End If You may drop the ElseIf and Else code chunks. You may also have a look at the slides for this module . 3.8 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Some of the solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up too early. Put some effort into finding a solution! A template with VBA code is given in the file vba-template.xlsm (open it and use it while reading the notes). Have a look inside the module TM3_ex in the VBA editor for examples used in the notes and during lectures. Have a look at module TM3_exercises for exercises. Guiding answers for the exercises can be found in the file vba-solution.xlsm . 3.8.1 Exercise - Loops Use the sheet TM3 for output. Create a for loop that writes numbers 1 to 4 in rows 25 to 28 in column A. Create a do while loop that writes numbers 1 to 4 in rows 25 to 28 in column B. Create a loop that writes numbers 1 to 4 in rows 27 to 30 in column C. Create a loop that writes numbers -1 to -4 in rows 25 to 28 in column D. Create a loop that writes numbers 1 to 4 in rows 28 to 31 in column E, except if the number is 3 then the output should to a string missing. Create a do while loop that writes numbers i = 1, 2, … in column F (starting in row 25) until i/5 + 3 = 8. Hint: you may use a Exit Do to quit the loop. Create a sub that runs all the loops. 3.8.2 Exercise - Conditional statements Consider worksheet TM3_Numbers, which contains a set of numbers. Create a procedure with the following features Make a copy of the numbers with the upper left cell starting in G1. Scan all the numbers and remove (clear the cell) all the negative numbers (you may use a For Each loop). Highlight all the numbers above 20 (using e.g. rngC.Interior.ColorIndex = 37). Add a button to worksheet TM3_Numbers that run the procedure. Create a procedure with the following features: Scan the numbers and find the sum of all non-negative numbers, the mean of all negative numbers. Use a message box to display the sum and mean calculated. Add a button to worksheet TM3_Numbers that run the procedure. This exercise is a slightly modified version an exam assignment (reexam 2022-A5). "],["mod-vba-procedures.html", "Module 4 Procedures 4.1 Learning outcomes 4.2 Subs and functions - The basics 4.3 Optional arguments 4.4 Public and private procedures 4.5 Passing arguments by reference or by value 4.6 Built-in functions 4.7 Example - Selection of test persons 4.8 Recap 4.9 Exercises", " Module 4 Procedures This module gives a short introduction to procedures. A procedure is a piece of code stored in a module which contains a series of computational steps that will be carried out when the procedure is called. VBA has two kinds of procedures subs (short for subroutine) and functions. Both are basic building blocks in programming. The main differences between a sub and a function is: Subs Can make changes to the worksheet. Can modify its surroundings. Can be executed by a button (a macro - if no arguments). Cannot return anything. Functions Can return something. Can be used in Excel. Cannot be used as a macro. A template with VBA code is given in the file vba-template.xlsm (open it and use it while reading the notes). Have a look inside the module TM4_ex in the VBA editor for examples used in the notes and during lectures. Have a look at module TM4_exercises for exercises. Guiding answers for the exercises can be found in the file vba-solution.xlsm . During execution of procedures it may be useful to use the debugger to run the code step by step. A very short introduction to debugging in VBA is given in Section E.1. Read it before continuing this teaching module. Learning path diagram Click/hover the nodes to follow links and see details. 4.1 Learning outcomes By the end of this module, you are expected to be able to: Describe what a procedure is. Explain what kind of procedures there are in VBA and what they can be used for. Declare and call a procedure. Explain what the difference is by using input arguments by reference or by value in a procedure. Set the scope of a procedure using private or public procedures. Set default input arguments. Call built-in functions for VBA and Excel. The learning outcomes relate to the overall learning goals number 1, 2, 4, 8 and 9 of the course. 4.2 Subs and functions - The basics A sub is declared using: Sub SubName(arg1 As &lt;datatype&gt;, arg2 As &lt;datatype&gt;) &lt;code&gt; End Sub The name of the sub is SubName and it takes two arguments arg1 and arg2. A sub can take an arbitrary number of arguments. Until now we have mostly considered subs with no arguments often called a macro. Macros can be called using a button in Excel. A function is declared using: Function FunctionName(arg1 As &lt;datatype&gt;, arg2 As &lt;datatype&gt;) As &lt;return datatype&gt; &lt;code&gt; FunctionName = value &#39; assign a return value to the function End Sub The name of the function is FunctionName and it takes two arguments arg1 and arg2. A function can take an arbitrary number of arguments. A function always return a value of a data type (a sub do not return anything). You return a value by assigning it to the variable FunctionName (same as the function name). Let us consider a simple sub with one argument: Sub TM4_SimpleSub(str As String) MsgBox (str) End Sub and a simple function with two arguments: Function TM4_SimpleFunc(dblA As Double, dblB As Double) As Double TM4_SimpleFunc = dblA + dblB &#39; return variable equals function name End Function You call a sub from another procedure using the Call keyword and a another function by assigning its return value to a variable: &#39; Try running it using the debugger (Ctrl + F8 (win) or cmd + shift + I (mac)) Sub TM4_CallSimpleProc() Dim dblV As Double MsgBox (&quot;Ready&quot;) Call TM4_SimpleSub(&quot;SimpleSub&quot;) &#39; call a sub within a procedure dblV = TM4_SimpleFunc(3, 4) &#39; call a function within a procedure MsgBox (&quot;Value is &quot; &amp; dblV) End Sub It is always good coding practice to document you procedures: &#39;&#39; Product of two numbers &#39; @param i First number &#39; @param j Second number &#39; @return The product i * j &#39; @remarks The numbers are doubles. Function TM4_ProductFunc(i As Double, j As Double) As Double TM4_ProductFunc = i * j End Function &#39;&#39; Product of two numbers which are stored in dblV (since ByRef is the default). &#39; @param i First number &#39; @param j Second number &#39; @param dblV Stores the product &#39; @remarks The numbers are doubles. Private Sub TM4_ProductSub(i As Double, j As Double, dblV As Double) dblV = i * j End Sub Note both procedures above do the same thing. The function returns the product and the procedure stores the product in argument dblV which is modified when the function call is returned: &#39;&#39; Use TM4_ProductSub (TM4_ProductFunc produce the same result) &#39; Try running it using the debugger (Ctrl + F8 (win) or cmd + shift + I (mac)) Sub TM4_RunProductSub() Dim dblV As Double dblV = 4 MsgBox (&quot;Current value is &quot; &amp; dblV) &#39; Current value is 4 Call TM4_ProductSub(7, 3, dblV) &#39; dblV = TM4_ProductFunc(7, 3) (same result) MsgBox (&quot;Current value is &quot; &amp; dblV) &#39; Current value is 21 End Sub The reason is that arguments are per default references pointing to the same place in memory (we will look at the details in Section 4.5). You can use Exit Sub/Exit Function to exit the sub/function early in the code: &#39;&#39; Division of two numbers &#39; @param i First number. &#39; @param j Second number. &#39; @return Divison i / j. &#39; @remarks The numbers are doubles. Sub TM4_DivisionSub(i As Double, j As Double) If j = 0 Then MsgBox (&quot;Error: division with zero!&quot;) Exit Sub End If MsgBox (&quot;Value is &quot; &amp; i / j) End Sub &#39;&#39; Run using F5 Sub TM4_TestDivisionSub() Call TM4_DivisionSub(8, 2) &#39; no error Call TM4_DivisionSub(8, 0) &#39; gives an error message End Sub 4.3 Optional arguments Often you define procedures that have arguments with a default value. You can do this using the Optional keyword: &#39;&#39; Convert kilograms to grams or pounds &#39; @param dblKg Kilograms. &#39; @param blnToGrams Convert to grams (if true) otherwise to pounds. &#39; @return Converted value. Function TM4_ConvertKg(dblKg As Double, Optional blnToGrams As Boolean = True) If blnToGrams Then TM4_ConvertKg = dblKg * 1000 Exit Function End If TM4_ConvertKg = dblKg * 2.20462 End Function &#39;&#39; Run using F5 Sub TM4_TestConvertKg() MsgBox (TM4_ConvertKg(10)) &#39; use default value (to grams) MsgBox (TM4_ConvertKg(10, False)) &#39; to pounds End Sub Here we have one optional argument with default value equal to true. Now the function can be called with one argument (use the default value of the second argument) or with two arguments. Have a look at cells A8:C13 in worksheet TM4 (Figure 4.1) where we use the function to find convert to grams (TM4_ConvertKg(A8)) and pounds (TM4_ConvertKg(A8; FALSE)). Let us try to define a sub that format some cells (the content have been found using the macro recorder and then cleaned): &#39;&#39; Format a range &#39;@param rng Range to format. &#39;@param intInteriorColor Interior color index. &#39;@param intFontColor Font color index. &#39;@param intFontSize Font size. Sub TM4_FormatCell(rng As Range, Optional intInteriorColor As Integer = 0, _ Optional intFontColor As Integer = 44, Optional intFontSize As Integer = 12) rng.Interior.ColorIndex = intInteriorColor rng.Font.ColorIndex = intFontColor rng.Font.Size = intFontSize End Sub &#39;&#39; Run using F5 Sub TM4_TestingFormatCell() Dim rng As Range Worksheets(&quot;TM4&quot;).Activate Call TM4_FormatCell(Range(&quot;A16&quot;)) &#39; use default values Call TM4_FormatCell(Range(&quot;B16&quot;), 46) &#39; use background color index 46 Call TM4_FormatCell(Range(&quot;C16&quot;), , 21) &#39; set font color Call TM4_FormatCell(rng:=Range(&quot;D16&quot;), intFontSize:=16, intFontColor:=23) &#39; call sub using argument names explicit End Sub Observe that there is different ways to call a procedure with optional arguments. If you have may optional arguments it is best to use the last where you explicit state the argument names (here the order of the arguments do not matter either). Note that every argument following an optional argument in the procedure definition must also be optional. Moreover, if lines are to long you may split them using _ (underscore). In the example above we use the color index values in VBA (56 different ones). Let us have a look at them: &#39;&#39; Run using F5 Sub TM4_SeeColorIndex() Dim r As Integer Dim c As Integer Dim i As Integer Worksheets(&quot;TM4&quot;).Activate i = 1 For r = 18 To 40 For c = 2 To 5 Cells(r, c) = i Call TM4_FormatCell(rng:=Cells(r, c), intInteriorColor:=i, intFontColor:=1 + i Mod 4) If i = 56 Then Exit Sub End If i = i + 1 Next Next End Sub The output will be outputted from row 18 (column B-E): Figure 4.1: TM4 worksheet. 4.4 Public and private procedures You may use the keyword Private or Public (default) when you define a procedure. For instance: Private Sub SubName(arg1 As &lt;datatype&gt;, arg2 As &lt;datatype&gt;) &lt;code&gt; End Sub A private procedure can only be used by other procedures in the module. This may be useful if you want to define ‘internal’ procedures that you only want to use in the module. This also imply that a private sub can not be called from a button and a private function can not be called from a cell. Note the default value is Public. That is, if Private or Public is excluded, VBA will always treat the sub as if it were Public: Sub SubName(arg1 As &lt;datatype&gt;, arg2 As &lt;datatype&gt;) &#39; VBA assumes it is public (the default) &lt;code&gt; End Sub Public Sub SubName(arg1 As &lt;datatype&gt;, arg2 As &lt;datatype&gt;) &#39; same result as above &lt;code&gt; End Sub 4.5 Passing arguments by reference or by value There are two ways of passing arguments to procedures: Sub SubName(ByRef arg1 As &lt;datatype&gt;, ByVal arg2 As &lt;datatype&gt;) &lt;code&gt; End Sub Argument arg1 is passed by reference (default). That is, no new memory is allocated when the procedure is called and as a result the procedure can have changed the value of arg1 when the procedure stops. Note since the default, the result is the same if we omitted the keyword ByRef. Argument arg2 is passed by value. That is, a copy of the variable is created in memory. Hence the procedure cannot change the value of arg2 when the procedure stops (the copy is deleted). Using ByRef is faster and saves memory since we do not have to allocate new memory. We may use ByRef to return updated values of the input arguments (sub TM4_ProductSub did that). In fact you may have multiple arguments which when the sub finished have been modified. See it as the arguments have been modified with the result of the sub. Using ByVal is safer if you want be sure that the argument is not modified inside the procedure. Try guessing the result of running sub TM4_TestingBy: Private Function TM4_ByVal(ByVal i As Integer) As Integer i = i * 2 MsgBox (&quot;In ByVal i is &quot; &amp; i) TM4_ByVal = i * 5 End Function &#39;&#39; Note &quot;Function TM4_ByRef(i As Integer) As Integer&quot; gives same result Private Function TM4_ByRef(ByRef i As Integer) As Integer i = i * 2 MsgBox (&quot;In ByRef i is &quot; &amp; i) TM4_ByRef = i * 5 End Function &#39; Try running it using F5 or the debugger (Ctrl + F8 (win) or cmd + shift + I (mac)) Private Sub TM4_TestBy() Dim n As Integer Dim i As Integer i = 5 MsgBox (&quot;In the start i is &quot; &amp; i) n = TM4_ByVal(i) MsgBox (&quot;Try gussing the values of n and i&quot;) MsgBox (&quot;After TM4_ByVal i is &quot; &amp; i &amp; &quot; and &quot; &amp; n &amp; &quot; is returned.&quot;) n = TM4_ByRef(i) MsgBox (&quot;Try gussing the values of n and i&quot;) MsgBox (&quot;After TM4_ByRef i is &quot; &amp; i &amp; &quot; and &quot; &amp; n &amp; &quot; is returned.&quot;) End Sub 4.5.1 Return values from a sub Since ByRef does not create a new copy of the argument in memory. We can update multiple values from a sub by Pass arguments (variables) by reference in the sub. Modify the variables inside the sub. When the sub returns after it has been called the variables used a arguments contain the new updated values. See e.g TM4_ProductSub which updates the product in variable dblV. 4.6 Built-in functions VBA has a set of built-in functions such as Abs, Log and Date. You call them by just writing their name: &#39;&#39; Test VBA functions &#39; You can always get help by putting the crusor in the function name and press F1 Sub TM4_TestVBAfunctions() MsgBox (&quot;Absolute value: &quot; &amp; Abs(-4.2)) MsgBox (&quot;Integer part: &quot; &amp; Fix(-4.2)) MsgBox (&quot;Floor of the number: &quot; &amp; Int(-4.2)) MsgBox (&quot;Natural logarithm: &quot; &amp; Log(16)) MsgBox (&quot;Random number [0,1[: &quot; &amp; Rnd()) MsgBox (&quot;Current date: &quot; &amp; Date) MsgBox (&quot;Days from now: &quot; &amp; DateDiff(&quot;d&quot;, Date, DateValue(&quot;October, 28, 2022&quot;))) End Sub You can also use the worksheet functions in Excel. You call them using the WorksheetFunction object. A few examples: &#39;&#39; Test worksheetfunctions &#39; You can always get help by putting the crusor in the function name and press F1 Sub TM4_TestWorksheetfunctions() Dim r As Integer Dim c As Integer Worksheets(&quot;TM4&quot;).Activate MsgBox (&quot;Numbers above 80: &quot; &amp; WorksheetFunction.CountIf(Range(&quot;B33:E38&quot;), &quot;&gt;80&quot;)) &#39; count numbers above MsgBox (&quot;Sumproduct: &quot; &amp; WorksheetFunction.SumProduct(Range(&quot;B33:E33&quot;), Range(&quot;B34:E34&quot;))) MsgBox (&quot;Max: &quot; &amp; WorksheetFunction.Max(Range(&quot;B33:E38&quot;))) For r = 40 To 45 For c = 2 To 4 Cells(r, c) = WorksheetFunction.RandBetween(0, 9) Next Next End Sub 4.7 Example - Selection of test persons This example is a slightly modified version an exam assignment (exam 2021-A6). A virus has infected a number of persons. A possible cure has been developed, but the effect of it is expected to be dependent on the persons’ height. The cure can be tested on non-infected persons and the findings of this test can be directly transferred to any infected person whose height is within a range of 2 cm from the height of the tested person. For example, if the cure is tested on a non-infected person of height \\(172.2\\), then any infected person whose height is in the interval \\([170.2 ; 174.2]\\) is covered by the test. Figure 4.2: Infected and test persons. Figure 4.2 shows the data in worksheet TM4_Virus: Cell D1 states the number of infected persons. Columns A and B provide the person’s ID and height for each person. Cell D2 states the number of non-infected persons volunteering to be test persons. Columns F and G provide their ID and height. The testing process is extremely resource demanding, and thus it is only possible to test a limited number of test volunteers. This number is stated in cell D3. Given a test person we make a function TM4_TestCover that takes person id as argument and return the number of new infected persons covered. A person is already covered, if that person has a 1 in the Covered column. Function TM4_TestCover(intId As Integer) As Integer Dim intI As Integer &#39; number of infected Dim intC As Integer &#39; number of covered Dim dblHeight As Double &#39; height of test person Dim r As Integer intI = Range(&quot;D1&quot;) dblHeight = Range(&quot;G&quot; &amp; intId + 6) intC = 0 For r = 7 To intI + 6 &#39; loop through all infected If Cells(r, 2) &gt;= dblHeight - 2 And Cells(r, 2) &lt;= dblHeight + 2 And Cells(r, 3) &lt;&gt; 1 Then intC = intC + 1 End If Next TM4_TestCover = intC End Function First, note that given a test person id, the height is found in row id + 6 and column G. Next, we use the counter intC to count new covered persons. This result is returned by the function. To find the right test persons the following greedy strategy is used: Step 1: Select the test person (not already selected) that can cover most new infected persons (not yet covered). If more than one test person have the same cover, select the one with the smallest ID. Step 2: Add ones to the Covered column for all infected persons covered by the test person. Step 3: Go to Step 1 until found the test persons needed. We implement the the greedy strategy: Sub TM4_FindTestPersons() Dim intI As Integer &#39; number of infected Dim intT As Integer &#39; number of test volunteers Dim intS As Integer &#39; number of selected persons Dim intC As Integer &#39; number of covered Dim intBestId As Integer &#39; best id found Dim intBestC As Integer &#39; best cover value found Dim r As Integer Worksheets(&quot;TM4_Virus&quot;).Activate intI = Range(&quot;D1&quot;) intT = Range(&quot;D2&quot;) intS = 0 &#39; no selected yet Do While intS &lt; Range(&quot;D3&quot;) &#39; stop when have found needed test persons intBestId = -1 intBestC = -1 For r = 7 To intT + 6 &#39; loop through all test volunteers If Cells(r, 8) &lt;&gt; 1 Then &#39; not selected already intC = TM4_TestCover(Cells(r, 6)) If intBestC &lt; intC Then &#39; found a better person intBestC = intC intBestId = Cells(r, 6) End If End If Next Cells(intBestId + 6, 8) = 1 &#39; select best For r = 7 To intI + 6 &#39; add ones in covered column If Abs(Cells(r, 2) - Cells(intBestId + 6, 7)) &lt;= 2 Then Cells(r, 3) = 1 End If Next intS = intS + 1 Loop End Sub First, the number of persons are stored in variables. Next, a Do While loop is used to find the test persons. We use two variables to store the best id and cover value. The first inner for loop scan the test persons and for each person (not yet selected) we find the cover (using TM4_TestCover), check if better than current and update. The second inner for loop add ones to the Covered column. The output is given in Figure 4.3. Figure 4.3: Infected and test persons. In total 13 infected persons are covered by 3 test persons. 4.8 Recap A procedure is a piece of code stored in a module. A procedure contains a series of computational steps that will be carried out when the procedure is called. VBA has two kinds of procedures: Subs: Can make changes to the worksheet. Can modify its surroundings. Can be executed by a button (if no arguments). Cannot return anything. Functions: Can return something. Can be used in Excel. Cannot be used as a macro. You declare a procedure using Sub SubName(arg1 As &lt;datatype&gt;, arg2 As &lt;datatype&gt;) &lt;code&gt; End Sub Function FunctionName(arg1 As &lt;datatype&gt;, arg2 As &lt;datatype&gt;) As &lt;return datatype&gt; &lt;code&gt; FunctionName = value &#39; assign a return value to the function End Sub You can use Exit Sub/Exit Function to exit the sub/function early in the code. Procedures can be either public or private: Public (default): Can be used from other modules, from other files and from Excel. Public Sub SubName() ... End Sub Private: Can only be used from within its own module. Private Sub SubName() ... End Sub Use the Call keyword to call a sub: Call SubName(arg1, arg2) Call a function by assigning its return value to a variable result = FunctionName(arg1, arg2) There are two ways of passing arguments to procedures: Sub SubName(ByRef arg1 As &lt;datatype&gt;, ByVal arg2 As &lt;datatype&gt;) &lt;code&gt; End Sub Argument arg1 is passed by reference (default). That is, no new memory is allocated when the procedure is called and hence the procedure can have changed the value of arg1 when the procedure stops. Since the default is ByRef, the result is the same if we omitted the keyword ByRef. Argument arg2 is passed by value. That is, a copy of the variable is created in memory with local scope. Hence the procedure cannot change the value of arg2 when the procedure stops (the local variables is deleted). Using ByRef is faster and saves memory since we do not have to allocate new memory. We may use ByRef to return updated values of the input arguments. Use the Optional keyword to indicate default input arguments: Sub SubName(arg1 As &lt;datatype&gt;, Optional arg2 As &lt;datatype&gt; = &lt;defaultValue&gt;) You can now call the procedure using: Call SubName(arg1) &#39; assume that arg2 = defaultValue Every parameter following an optional parameter in the procedure definition must also be optional. VBA has a set of built-in functions such as Abs, Log and Date. You call them by just writing their name: dtm as Date dtm = Date() You can also use the worksheet functions in Excel. You call them using the WorksheetFunction object: sum = WorksheetFunction.Sum(Range(&quot;A1:D5&quot;)) You may also have a look at the slides for this module . 4.9 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Some of the solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up too early. Put some effort into finding a solution! A template with VBA code is given in the file vba-template.xlsm (open it and use it while reading the notes). Have a look inside the module TM4_ex in the VBA editor for examples used in the notes and during lectures. Have a look at module TM4_exercises for exercises. Guiding answers for the exercises can be found in the file vba-solution.xlsm . 4.9.1 Exercise - Subs Create a sub GetMsg that takes a string and a Boolean as input and create a message box with the string content if the Boolean is true. Test the procedure using the TestGetMsg sub. Modify the procedure so the Boolean have a default value equal to true. Create a sub PrintNameAge that takes two arguments as input (name and age) and create a message box with the persons name and age. Write a sub TestPrintNameAge that uses two input boxes to ask for name and age and then call sub PrintNameAge. 4.9.2 Exercise - Temperatures This exercise is a slightly modified version an exam assignment (reexam 2022-A4). Temperatures in Fahrenheit can be converted to Celsius using \\[C = \\frac{5(F-32)}{9}\\] Similar temperatures in Celsius can be converted to Fahrenheit using \\[F = \\frac{9C}{5} + 32\\] Make functions: TM4_CelsiusToFahrenheit that takes a double dblVal in Celsius as input argument and returns the number converted to Fahrenheit. TM4_FahrenheitToCelsius that takes a double dblVal in Fahrenheit as input argument and returns the number converted to Celsius. Make a function TM4_ConvertTemp with the following features: Input arguments are a double dblVal and a string strIUnit. If the input unit strIUnit equals “c” then the returned number is converted to Fahrenheit. If the input unit strIUnit equals “f” then the returned number is converted to Celsius. If the input unit strIUnit does not equals “f” or “c” then a message box is given with an error. Test function TM4_ConvertTemp on worksheet TM4 (row 66). 4.9.3 Exercise - Functions Write a function TM4_Discount which takes a two input arguments (doubles): the discount percentage and the amount. The function returns the discounted value. For instance if the discount is 10 percent and amount 100 then the discounted value is \\(90 = 100\\cdot(1-0.1)\\). Have a look at the unfinished sub TM4_Discount for hints. Note the comments describing the function using the coding convention. Check the test results starting from row 47 in worksheet TM4. Write a function Larger which takes two integer arguments and returns true if the first is larger than the last; otherwise false. Check the test results starting from row 53 in worksheet TM4. Write a function NumbDays that takes a date as argument and return the number of days from today. Hint: Have a look at the DateDiff function. Check the test results starting from row 59 in worksheet TM4. Write a sub that uses an input box to ask for an amount a then returns the discounted amount when the discount is 20%. The sub should use the function in Question 1. Test it using the button in worksheet TM4 (row 49). 4.9.4 Exercise - Worksheet functions The worksheet TM4_Numbers contains a button that runs a procedure which generate a set of numbers. Create a procedure TM4_Summary that uses worksheet functions to: Find the maximum number and write it to cell D1. Find the minimum number and write it to cell D2. Find the sum of the numbers and write it to cell D3. Count the number of positives and write it to cell D4. Find the row number with maximum value and write it to cell D5. Google is a good place to start if you want to find a specific Excel function, e.g. try to search ‘excel row with max value’. Test the procedure using the Summary button in worksheet TM4_Numbers. "],["mod-vba-datatypes.html", "Module 5 Advanced data types and usage 5.1 Learning outcomes 5.2 Strings 5.3 Objects 5.4 The Worksheet object 5.5 The Range object 5.6 Arrays 5.7 Collections 5.8 Example - Job sequencing 5.9 Recap 5.10 Exercises", " Module 5 Advanced data types and usage Recall that variables are used to store information that is saved in memory. A variable may store different data types. Until now we have mostly considered basic data types such as an integer, a double or a string. In this module a short introduction to some of the more advanced data types is given such as a group of integers (an array), a range of cells in a worksheet (a range object) or a set of numbers (a collection). A template with VBA code is given in the file vba-template.xlsm (open it and use it while reading the notes). Have a look inside the module TM5_ex in the VBA editor for examples used in the notes and during lectures. Have a look at module TM5_exercises for exercises. Guiding answers for the exercises can be found in the file vba-solution.xlsm . Learning path diagram Click/hover the nodes to follow links and see details. If you like a different learning style there is a lot for videos about VBA online such as course 14-Hour VBA Course. The videos have been pointed out as extra online supplements in the learning path diagram. However, they are not necessary for the course. Since Excel change as new versions arrive and it work on different operating systems, the look in the screenshots and videos might be a bit different from your version. However, you still should be able to understand it. 5.1 Learning outcomes By the end of this module, you are expected to be able to: Name different data types and how they effect memory size. Declare a variable as a data type. Declare and manipulate strings. Describe what the object is. Declare and set an object. Manipulate worksheets (add, delete, clear). Understand what a range is and extract info about it such as rows, start row, address, start column etc. Use the current region of a range to get information about the size for data. Sort, paste and modify a range. Declare and use an array with both fixed and dynamic dimension. Sort, read and modify an array. Explain why using arrays is often better than ranges. Declare and use a collection. Explain what a collection of objects are. Use a For Each loop to iterate though a collection of objects. The learning outcomes relate to the overall learning goals number 1, 2, 4, 8 and 9 of the course. 5.2 Strings Strings contain a group of characters (an empty string is of length zero). Memory requirements vary with the length of the string (10 bytes + length \\(\\cdot\\) 2 byte). We use the symbol &amp; to concatenate strings (glue strings together): &#39;&#39; Concatenate two strings Sub TM5_StrConcat() Dim strX As String Dim strY As String Dim strRes As String strX = &quot;VBA&quot; strY = &quot;Strings&quot; strRes = strX &amp; &quot; &quot; &amp; strY MsgBox (strRes) MsgBox (strX &amp; vbCr &amp; strY) &#39; use vbCr to insert a new line End Sub Note you can use constant vbCr to add a new line. There are many VBA functions that can be used to manipulate strings. Some examples: &#39;&#39; String functions Sub TM5_StrFunc() Dim str As String str = &quot;VBA Strings&quot; MsgBox (&quot;The length is: &quot; &amp; Len(str)) MsgBox (&quot;In lowercase: &quot; &amp; LCase(str)) MsgBox (&quot;Last 7 char: &quot; &amp; Right(str, 7)) MsgBox (&quot;Replace: &quot; &amp; Replace(str, &quot;Strings&quot;, &quot;Rules&quot;)) MsgBox (&quot;Compare: &quot; &amp; StrComp(str, &quot;VBA Strings&quot;)) &#39; result is 0 (equal) MsgBox (&quot;Compare: &quot; &amp; StrComp(str, &quot;Apple&quot;)) &#39; result is 1 (str alfabetically after) MsgBox (&quot;Compare: &quot; &amp; StrComp(str, &quot;Wait&quot;)) &#39; result is -1 (str alfabetically before) MsgBox (&quot;String is starting at char number: &quot; &amp; InStr(str, &quot;String&quot;)) &#39; result is 0 if not found End Sub 5.3 Objects VBA have a lot of predefined objects you can use. Think of an object as a datatype that holds a group of variables. Examples of some objects are Range, Worksheet, and WorksheetFunction. Objects are grouped, nested and you refer to an object by specifying the path, e.g.: Workbooks(&quot;Jobs.xlsm&quot;).Worksheets(&quot;Data values&quot;).Range(&quot;D4&quot;).value Here we refer to the value in cell D4 in worksheet Data values in the file Jobs.xlsm. You may skip parts of the path (VBA then uses the current active one): Workbooks(&quot;Jobs.xlsm&quot;).Worksheets(&quot;Data values&quot;).Range(&quot;D4&quot;).value &#39; full specification Worksheets(&quot;Data values&quot;).Range(&quot;D4&quot;).value &#39; same result if Excel file &quot;Jobs.xlsm&quot; is active Range(&quot;D4&quot;) &#39; same result if Excel sheet &quot;Data values&quot; is active and &quot;Jobs.xlsm&quot; file Note .value has been dropped in the last line because it is the default, i.e. you do not have to write it explicit. Object variables are declared like any other variables: Dim rng As Range Dim wst As Worksheet Use Set to allocate the Object: Set rng = Range(&quot;F7&quot;) Set wst = Worksheets(&quot;Data values&quot;) Now rng is a reference to cell F7 and wst is a reference to worksheet Data values. Think of a reference as a value that identify where in memory the object is. In the next sections let us have a look at some relevant objects. 5.4 The Worksheet object The Worksheet object refer to a worksheet in the Excel file and you can use it to e.g. modify cells: Sub TM5_TestWorksheet() ThisWorkbook.Activate &#39; activate this workbook Worksheets(&quot;TM5_Test1&quot;).Range(&quot;B2&quot;) = &quot;Testing Worksheet&quot; &#39; write to cell in sheet TM5_Test1 Sheet_TM5_Test1.Range(&quot;B3&quot;) = &quot;Use the sheets code name&quot; &#39; use the code name (also work if sheet renamed) &#39;ThisWorkbook.Worksheets(&quot;Test3&quot;).Range(&quot;B5&quot;) = &quot;Test&quot; &#39; Error since there is no sheet Test3 in this workbook Range(&quot;B4&quot;) = &quot;Do you know which sheet is active?&quot; &#39; Active sheet &#39; Good coding pratice is always to specify the full path (as above) or make the sheet under considration active Worksheets(&quot;TM5_Test1&quot;).Activate &#39; Make sheet active so know where is Range(&quot;B5&quot;) = &quot;I know which sheet is active!&quot; End Sub It is always good practice to make sure that you are working with the correct Excel file. Otherwise you will get errors if another file is active. This can be done using the ThisWorkbook object. Similar you either refer to a worksheet directly using its name or its code name. The code name can be set in the Properties window in the VBA editor. An alternative is to activate the worksheet. You can use Worksheet variables: Sub TM5_TestWorksheetVar() Dim wst1 As Worksheet &#39; define a variable which hold a reference to a Worksheet object Dim wst2 As Worksheet &#39; define a variable which hold a reference to a Worksheet object Dim rng As Range Set wst1 = ThisWorkbook.Worksheets(&quot;TM5_Test1&quot;) &#39; set the reference Set wst2 = ThisWorkbook.Worksheets(&quot;TM5_Test2&quot;) &#39; set the reference wst1.Range(&quot;B6&quot;) = &quot;Writing using wst1&quot; wst2.Range(&quot;B2&quot;) = &quot;Writing using wst2&quot; wst1.Activate &#39; just to have a look End Sub Here by having two worksheet variables we can write directly to cells in different worksheets without activating the worksheet. You may check if a worksheet exists using: &#39;&#39; Check if a worksheet exists &#39; @param strName Name of worksheet. &#39; @return True if exists. Function WstExists(strName As String) As Boolean WstExists = Evaluate(&quot;ISREF(&#39;&quot; &amp; strName &amp; &quot;&#39;!A1)&quot;) End Function The worksheet object has a lot of methods/properties (think of methods as procedures defined inside the object) for instance wst.Add and wst.Delete. Let us try to define a function that delete a worksheet: &#39;&#39; Delete a worksheet if it exists &#39; @param strName Name of worksheet. &#39; @return True if deleted. &#39; @author Lars Relund &lt;lars@relund.dk&gt; Function WstDelete(strName As String) As Boolean Dim wst As Worksheet Dim bln As Boolean bln = Application.DisplayAlerts Application.DisplayAlerts = False &#39; no &quot;really want to delete&quot; alert If WstExists(strName) Then Worksheets(strName).Delete WstDelete = True Else WstDelete = False End If Application.DisplayAlerts = bln &#39; restore value End Function We first use the function WstExists to check if there is a worksheet. If there is, we call the .delete method and delete the worksheet. Note since we do not want an alert stating if we really want to delete the worksheet this is disabled using the Application object. The function returns true if the worksheet has been deleted. Let us try to define a function that create a worksheet: &#39;&#39; Create a worksheet &#39; @param strName Name of worksheet. &#39; @param blnForce Force deletion of worksheet if exists. &#39; @return True if created. Function WstCreate(strName As String, Optional blnForce As Boolean = False) As Boolean Dim wst As Worksheet If blnForce And WstExists(strName) Then Call WstDelete(strName) If Not WstExists(strName) Then Set wst = Worksheets.Add wst.Name = strName WstCreate = True Else WstCreate = False End If End Function We use an optional argument to force deletion of the old worksheet (if a worksheet with the same name). Next, we create the worksheet using the .Add method and rename it using the .Name method. The function returns true if the worksheet has been created. Finally, let us create a function that clear a worksheet: &#39;&#39; Clear a worksheet if it exists &#39; @param strName Name of worksheet. &#39; @param blnCells Delete cell contents, formats, comments, etc. (default). &#39; @param blnContents Delete cell contents. &#39; @param blnFormat Delete cell format. &#39; @param blnObjects Delete cell buttons and charts. &#39; @return True if cleared. Function WstClear(strName As String, _ Optional blnCells As Boolean = True, _ Optional blnContents As Boolean = False, _ Optional blnFormat As Boolean = False, _ Optional blnObjects As Boolean = False) As Boolean Dim wst As Worksheet On Error Resume Next If WstExists(strName) Then Set wst = Worksheets(strName) If blnCells Then wst.UsedRange.Clear If blnContents Then wst.Cells.ClearContents If blnFormat Then wst.Cells.ClearFormats If blnObjects Then wst.ChartObjects.Delete wst.Buttons.Delete End If WstClear = True Else WstClear = False End If End Function First note that we have a lot of optional arguments depending on what we want to clear. Next the On Error Resume Next statement is used to make the program not stop even if an error happens. Finally, depending on the setting of the optional arguments we e.g. clear the format in all cells if blnFormat is true. All the functions above is part of the course procedures that you may use ‘as is’ during the course and at the exam. I will explicitly state if you are not allowed to use them otherwise. All the worksheet procedures start with Wst so you easy can find them using auto complete in the VBA editor. All worksheet procedures are stored in the ModWst module. You may open the module to have a look at the procedures. Let us see them in action: &#39;&#39; Test the worksheet functions Sub TM5_TestWorksheetFunc() If WstCreate(&quot;Test&quot;, blnForce:=True) Then MsgBox (&quot;Created Test&quot;) If WstRename(&quot;Test&quot;, &quot;Test1&quot;) Then MsgBox (&quot;Renamed the Test to Test1&quot;) &#39; only work if no Test1 sheet If WstClear(&quot;Test8&quot;) Then MsgBox (&quot;Cleared Test8&quot;) &#39; no clearing since on sheet with that name If WstDelete(&quot;Test1&quot;) Then MsgBox (&quot;Deleted Test1&quot;) End Sub 5.5 The Range object Ranges are objects that refer to parts of a worksheet e.g. a cell, a row, a column, or a rectangular selection of cells. Ranges can be used to read and write to cells Sub TM5_RangeEx1() Dim rng As Range Dim cell As Range Dim i As Integer Call TM5_ClearTestTM5 &#39; clear test cells so have empty cells ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate &#39; Modify a range to a fixed value Set rng = Range(&quot;G4:I6&quot;) rng = 145 &#39; cell value in rng MsgBox rng.Address &#39; range address &#39; Use for each to scan range (direction left-down) Set rng = Range(&quot;G8:I10&quot;) i = 1 For Each cell In rng cell = &quot;Entry &quot; &amp; i i = i + 1 Next &#39; Use Cells to set a range Set rng = Range(Cells(23, 3), Cells(25, 6)) MsgBox rng.Address End Sub The method .Address is used to return the cell address. Figure 5.1: TM5 worksheet. Similar the number of rows can by found using .rows.Count: &#39;&#39; Rows in range &#39; @param rng A range. Function RngGetRows(rng As Range) As Long RngGetRows = rng.rows.Count End Function We can also find number of columns, address of upper left cell or lower right cell etc. In the course procedures (module ModRng) all these have been defined. Let us try to use them: Sub TM5_RangeEx2() Dim rng As Range Set rng = ThisWorkbook.Worksheets(&quot;TM5&quot;).Range(&quot;C4:E19&quot;) MsgBox (&quot;Number of rows: &quot; &amp; RngGetRows(rng)) MsgBox (&quot;Number of cols: &quot; &amp; RngGetCols(rng)) MsgBox (&quot;First column number: &quot; &amp; RngGetFirstCol(rng)) MsgBox (&quot;First column letter: &quot; &amp; RngGetFirstCol(rng, asLetter:=True)) MsgBox (&quot;Lower right cell: &quot; &amp; RngGetLowerRight(rng, asString:=True)) MsgBox (&quot;Upper right cell: &quot; &amp; RngGetUpperRight(rng, asString:=True)) End Sub 5.5.1 Named ranges in Excel It is possible to define named ranges directly in Excel. For instance the named range UserAmounts referring to cells C5:E19 in Figure 5.1 has been created by selecting cells C5:E19 and defining UserAmounts with Formulas -&gt; Define Name. You can now use UserAmounts in VBA by Sub TM5_NamedRangeEx() Dim rng As Range ThisWorkbook.Activate Set rng = Range(&quot;UserAmounts&quot;) MsgBox (&quot;Number of rows: &quot; &amp; RngGetRows(rng)) MsgBox (&quot;Number of cols: &quot; &amp; RngGetCols(rng)) MsgBox (&quot;First column number: &quot; &amp; RngGetFirstCol(rng)) MsgBox (&quot;First column letter: &quot; &amp; RngGetFirstCol(rng, asLetter:=True)) MsgBox (&quot;Lower right cell: &quot; &amp; RngGetLowerRight(rng, asString:=True)) MsgBox (&quot;Upper right cell: &quot; &amp; RngGetUpperRight(rng, asString:=True)) End Sub Now try to redefine UserAmounts in Excel to cells C31:D33 (Formulas &gt; Name Manager &gt; Edit) and run the code again. That is, by using named ranges you can modify the reference directly in Excel. 5.5.2 Current region of a range An important method is the current region .CurrentRegion which expands the range until all cells surrounding the range is empty. This is very useful if don’t know the size for data. Let us make a function that return the current region: &#39;&#39; Return the current region of a range. &#39; @param rng The range to get the current region from. Function RngCurRegion(rng As Range) As Range Set RngCurRegion = rng.CurrentRegion End Function Note we have to use the Set keyword since the return value is a range (object). We can now test the course procedures starting with prefix RngGet: Sub TM5_CurrentRegionEx1() Dim rng As Range ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate &#39; Try to guess the output Set rng = RngCurRegion(Range(&quot;D7&quot;)) &#39; rng now is the current region MsgBox (&quot;Address: &quot; &amp; RngGetAddress(rng)) MsgBox (&quot;Rows = &quot; &amp; RngGetRows(rng) &amp; &quot; cols = &quot; &amp; RngGetCols(rng)) MsgBox (&quot;First row number = &quot; &amp; RngGetFirstRow(rng) &amp; &quot;. Last row number = &quot; &amp; RngGetLastRow(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col number = &quot; &amp; RngGetFirstCol(rng) &amp; &quot;. Last col number = &quot; &amp; RngGetLastCol(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col letter = &quot; &amp; RngGetFirstCol(rng, True) &amp; &quot;. Last col letter = &quot; &amp; RngGetLastCol(rng, True) &amp; &quot;.&quot;) &#39; Try to guess the output Set rng = RngCurRegion(Range(&quot;C23&quot;)) &#39; assume we know that data contains cell C23 MsgBox (&quot;Address: &quot; &amp; RngGetAddress(rng)) End Sub The same result can be obtained using the course procedures starting with RngGetCurRegion: Sub TM5_CurrentRegionEx2() Dim rng As Range ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate &#39; Try to guess the output Set rng = Range(&quot;D7&quot;) &#39; assume we know that data contains cell D7 MsgBox (&quot;Address: &quot; &amp; RngGetCurRegionAddress(rng)) MsgBox (&quot;Rows = &quot; &amp; RngGetCurRegionRows(rng) &amp; &quot; cols = &quot; &amp; RngGetCurRegionCols(rng)) MsgBox (&quot;First row number = &quot; &amp; RngGetCurRegionFirstRow(rng) &amp; &quot;. Last row number = &quot; &amp; RngGetCurRegionLastRow(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col number = &quot; &amp; RngGetCurRegionFirstCol(rng) &amp; &quot;. Last col number = &quot; &amp; RngGetCurRegionLastCol(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col letter = &quot; &amp; RngGetCurRegionFirstCol(rng, True) &amp; &quot;. Last col letter = &quot; &amp; RngGetCurRegionLastCol(rng, True) &amp; &quot;.&quot;) Set rng = Range(&quot;C23&quot;) &#39; assume we know that data contains cell C23 MsgBox (&quot;Address: &quot; &amp; RngGetCurRegionAddress(rng)) End Sub Note the difference in how rng is defined. 5.5.3 Input and output You can read/write and copy/paste values to a range using the course procedures: Sub TM5_RangeEx3() Dim rng As Range Dim rngNew As Range Set rng = RngCurRegion(Range(&quot;D7&quot;)) &#39; get current region MsgBox (&quot;Copy to H14 (upper left corner).&quot;) Set rngNew = RngPaste(rng, Range(&quot;H14&quot;)) &#39; rngNew is now the new range MsgBox (&quot;Make yellow.&quot;) Call RngFormat(rngNew, &quot;yellow&quot;) MsgBox (&quot;Remove format.&quot;) Call RngClear(rngNew, blnCells:=False, blnFormat:=True) MsgBox (&quot;Clear range.&quot;) Call RngClear(rngNew) End Sub Here RngPaste is used to copy a range and paste it to another range. Note you may use RngFormat to format cells of a range. Moreover, you can read/write values from/to a csv file. A comma-separated values (csv) file is a delimited text file that uses a delimiter to separate values. Each line of the file is a data record. Each record consists of one or more fields, separated by the delimiter. The file format is not fully standardized, i.e. the delimiter may be a semicolon, a colon or another delimiter. Moreover, a field may be surrounded with quotation marks. Let us have a look at a csv file data1.csv with a header using a semicolon as delimiter: Year;Brand;Model 1997;Ford;E350 2000;Mercury;Cougar and the csv file data2.csv without a header using a semicolon as delimiter: 55,18,34,1,81,26,90,11,46,32,93 49,95,73,82,53,40,99,10,52,38,92 59,90,97,100,59,73,88,33,78,61,24 96,84,32,36,94,82,49,94,48,49,1 59,21,24,57,3,78,54,79,57,42,8 Let us try to read the two files: Sub TM5_RngFromCSVEx() Dim rng As Range ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Call TM5_ClearTestTM5 &#39; clear test cells so have empty cells &#39;&#39; Read data1.csv file (NOTE you must know the separator in the csv file beforehand!) Range(&quot;G3&quot;) = &quot;Content of data1.csv:&quot; Set rng = RngFromCSV(&quot;data1.csv&quot;, Range(&quot;G4&quot;), &quot;;&quot;) &#39; paste file in range with upper left cell G4 MsgBox (RngGetAddress(rng)) &#39;&#39; Read data2.csv file (NOTE you must know the separator in the csv file beforehand!) Range(&quot;G8&quot;) = &quot;Content of data2.csv:&quot; Set rng = RngFromCSV(&quot;data2.csv&quot;, Range(&quot;G9&quot;), &quot;,&quot;) &#39; paste file in range with upper left cell G9 MsgBox (RngGetAddress(rng)) End Sub Here we use the course procedure RngFromCSV to read the file and specify the upper left corner cell of where to paste. Note the function returns the pasted range. You can write the content of a range to a csv file using: Sub TM5_RngToCSVEx() Dim rng As Range ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Call TM5_ClearTestTM5 &#39; clear test cells so have empty cells &#39;&#39; Write to csv file Set rng = Range(&quot;C4:E19&quot;) Call RngToCSV(&quot;test.csv&quot;, rng, &quot;;&quot;) &#39; semicolon (;) separated file &#39;&#39; Read test.csv file to check Range(&quot;G3&quot;) = &quot;Content of test.csv:&quot; Set rng = RngFromCSV(&quot;test.csv&quot;, Range(&quot;G4&quot;), &quot;;&quot;) End Sub Here we use the course procedure RngToCSV to write the range to the file. Note you can specify different delimiters (here we use a semicolon). 5.5.4 Sorting a range Ranges can be sorted using the .Sort method: Sub TM5_SortRangeEx() Dim rng As Range Dim rngCur As Range ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Call TM5_ClearTestTM5 &#39; clear test cells so have empty cells Set rng = RngCurRegion(Range(&quot;C4&quot;)) &#39;&#39; Sort based on second column ascending Set rngCur = RngPaste(rng, Range(&quot;G4&quot;), withFormat:=True) &#39; make a copy to work with Call rngCur.Sort(Key1:=rngCur.Columns(2), Header:=xlYes) rngCur(1).Offset(-1, 0) = &quot;Sort 2. column&quot; &#39; offset first cell in range by -1 row and 0 col &#39;&#39; Sort based on second column and afterwards 3. column (descending) Set rngCur = RngPaste(rng, Range(&quot;K4&quot;), True) Call rngCur.Sort(Key1:=rngCur.Columns(2), Header:=xlYes, Key2:=rngCur.Columns(3), Order2:=xlDescending) rngCur(1).Offset(-1, 0) = &quot;Sort 2. and next 3. column&quot; End Sub We use the Key arguments to identify which columns we want to sort and the Header argument to identify if the first row in the range is a header. Finally the ordering is given using the Order argument (either xlAscending (default) or xlDescending). 5.6 Arrays Arrays are used to store groups of variables of a specific datatype: &#39;&#39; Define an array (run using the debugger - step into) &#39; How to check the content of an array? &#39; Use the Locals window together with debug mode or a message box Sub TM5_ArrayEx1() Dim intAry(4) As Integer &#39; define array with index 0-4 Dim strAry(3 To 5) As String &#39; define array with index 3-5 Dim i As Integer &#39; Set values intAry(0) = 9 intAry(1) = 12 intAry(2) = 222 intAry(3) = 4 intAry(4) = 100 &#39; Information about the array MsgBox (&quot;Lowest index: &quot; &amp; LBound(intAry)) MsgBox (&quot;Largest index: &quot; &amp; UBound(intAry)) MsgBox (&quot;Number of elements: &quot; &amp; UBound(intAry) - LBound(intAry) + 1) MsgBox (&quot;Array as a string: &quot; &amp; AryToStr(intAry)) &#39; Read and assign values For i = 3 To 5 strAry(i) = ThisWorkbook.Worksheets(&quot;TM5&quot;).Cells(23 + i, 3) Next MsgBox (&quot;Array values: &quot; &amp; AryToStr(strAry)) End Sub Array intAry contain 5 elements which can be accessed using index 0, 1, 2, …, 4. In memory this is done by allocating memory for 5 integers (see Figure 5.2) with index 0-4. The lower and upper index bounds can be found using LBound and UBound and we can use the course procedure AryToStr to print it. Figure 5.2: An array in memory. Note the default start index is 0. If you want another start index you can use e.g. Dim strAry(3 To 5) As String which use indices 3-5 (\\(3 = 5-3+1\\) elements). Moreover, if you want to start with index 1 as default then add Option Base 1 to the top of your module. Arrays require 20 bytes of memory plus 4 bytes for each array dimension plus the number of bytes occupied by the data itself. A Variant containing an array requires 12 bytes more than the array alone. 5.6.1 Multi-dimensional arrays Figure 5.3: Arrays with different dimensions. An array can have different dimensions (see Figure 5.3) e.g. and array with three dimensions is declared using: Dim intOrderSize(52, 100, 50) As Integer where indices may be (week, customer, product) number. Let us assume that index start from 1 then we have an array with \\(52 \\cdot 100 \\cdot 50\\) elements which can be accessed using e.g. MsgBox(intOrderSize(2, 10, 20)) &#39; order size week 2, customer 10, product 20 Let us consider an example: Sub TM5_MultiDimArrayEx() Dim intA(20, 10) As Integer Dim i As Integer, j As Integer ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Call TM5_ClearTestTM5 &#39; clear test cells so have empty cells &#39; Assign some values For i = LBound(intA, 1) To UBound(intA, 1) For j = LBound(intA, 2) To UBound(intA, 2) intA(i, j) = WorksheetFunction.RandBetween(1, 1000) Next Next &#39; print results from G4 For i = LBound(intA, 1) To UBound(intA, 1) For j = LBound(intA, 2) To UBound(intA, 2) Cells(i + 4, j + 7) = intA(i, j) Next Next &#39; Call AryPaste(intA, Range(&quot;G4&quot;)) &#39; same result End Sub We first assign random values to intA in the first loop. Note we use LBound and UBound to find the range of the indices (the second argument is the dimension we consider). Next, the results are printed to the sheet with upper left equal to G4. Here you may also have used the course procedure AryPaste instead. 5.6.2 Dynamic arrays Often we do not know the size of the array we need when we start the program. For this we use dynamic arrays: Sub TM5_DynArrayEx() Dim ary() As String &#39; dynamic array, note use empty () Dim i As Integer ThisWorkbook.Worksheets(&quot;TM5_Test3&quot;).Activate ReDim ary(2 To 5) &#39; create entries a(2) to a(5) For i = 2 To 5 ary(i) = Cells(i + 1, 1) &#39; read from Array sheet Next MsgBox (&quot;Values are: &quot; &amp; AryToStr(ary)) MsgBox (&quot;The lowest and higest index are &quot; &amp; LBound(ary) &amp; &quot; and &quot; &amp; UBound(ary)) ReDim ary(3 To 5) &#39; reallocate array, all values are set to default (empty string) MsgBox (&quot;Values are: &quot; &amp; AryToStr(ary)) For i = 3 To 5 ary(i) = Cells(i + 1, 1) Next MsgBox (&quot;Values are: &quot; &amp; AryToStr(ary)) MsgBox (&quot;The lowest and higest index are &quot; &amp; LBound(ary) &amp; &quot; and &quot; &amp; UBound(ary)) End Sub First, the dynamic array is declared using empty parenthesis Dim ary() As String. Next the ReDim keyword is used to set the dimension. 5.6.3 Input and output A set of course procedures (module ModAry) have been defined to read/set the values in an array and output the values of an array: Sub TM5_IOAryEx() Dim ary() As Integer Dim strAry() As String ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Call TM5_ClearTestTM5 &#39;&#39; Set to value single value ReDim ary(2) Call AryToVal(ary, 5) Range(&quot;G4&quot;) = &quot;A fixed value:&quot; Call AryPaste(ary, Range(&quot;G5&quot;)) &#39; the upper left cell is G5 &#39;&#39; Paste vertical Range(&quot;K4&quot;) = &quot;Paste vertical:&quot; Call AryPaste(ary, Range(&quot;K5&quot;), False) &#39;&#39; Set to sequence Call AryToSeq(ary, 1, 6) Range(&quot;G10&quot;) = &quot;A sequence:&quot; Call AryPaste(ary, Range(&quot;G11&quot;)) &#39;&#39; Read strings from a range Call AryRead(strAry, Range(&quot;C31:D33&quot;)) &#39; read a 2D array Range(&quot;G31&quot;) = &quot;Names in the &quot; &amp; AryDim(strAry) &amp; &quot;D array:&quot; Call AryPaste(strAry, Range(&quot;G32&quot;)) End Sub You set all entries in the array to a single value using AryToVal and a sequence using AryToSeq. Moreover, use AryRead to read the values of a range into an array. Finally, AryPaste can be used to paste values of an array to a sheet. You just have to specify the upper left cell where you want to paste. Procedure AryRead can both read values into 1D and 2D arrays: Sub TM5_AryReadEx() Dim ary() As Integer ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Call TM5_ClearTestTM5 &#39;&#39; Read values from a range with only 1 column Call AryRead(ary, Range(&quot;C5:C9&quot;)) Range(&quot;G4&quot;) = AryDim(ary) &amp; &quot;D array:&quot; Call AryPaste(ary, Range(&quot;G5&quot;), False) &#39;&#39; Read values from a range with only 1 row Call AryRead(ary, Range(&quot;C5:E5&quot;)) Range(&quot;I4&quot;) = AryDim(ary) &amp; &quot;D array:&quot; Call AryPaste(ary, Range(&quot;I5&quot;)) &#39;&#39; Read values from a range with only 1 column/row but use 2D array Call AryRead(ary, Range(&quot;C11:C14&quot;), blnReduceDim:=False) Range(&quot;G10&quot;) = AryDim(ary) &amp; &quot;D array:&quot; Call AryPaste(ary, Range(&quot;G11&quot;), False) &#39;&#39; Use other start and end index Call AryRead(ary, Range(&quot;C17:E19&quot;), intStartIdx1:=2, intStartIdx2:=5) Range(&quot;G16&quot;) = AryDim(ary) &amp; &quot;D array with start index &quot; &amp; LBound(ary, 1) &amp; &quot; and &quot; &amp; LBound(ary, 2) &amp; &quot;:&quot; Call AryPaste(ary, Range(&quot;G17&quot;)) End Sub First, note that if the optional argument blnReduceDim is not set to false the array automatically becomes a 1D array if a range with one row or column is read. Next, you can use another start index of the array (default is 1) by specifying the optional arguments intStartIdx1 and intStartIdx2. Procedure AryRead fails if we want to set values for arrays with more than 2 dimensions. For this the AryReadLong can be used which can read arrays until five dimensions: Sub TM5_AryReadLongEx() Dim ary() As Integer ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Call TM5_ClearTestTM5 &#39;&#39; Read 1D array Call AryReadLong(ary, Range(&quot;A36:B38&quot;), 3) &#39; default value = 3 Range(&quot;G35&quot;) = &quot;Values in the &quot; &amp; AryDim(ary) &amp; &quot;D array:&quot; Call AryPaste(ary, Range(&quot;G36&quot;)) &#39;&#39; Read 2D array Call AryReadLong(ary, Range(&quot;A41:C47&quot;), 4) &#39; default value = 4 Range(&quot;G40&quot;) = &quot;Values in the &quot; &amp; AryDim(ary) &amp; &quot;D array:&quot; Call AryPaste(ary, Range(&quot;G41&quot;)) &#39;&#39; Read 3D array (cannot be pasted to the sheet, have a look at it using the debugger) Call AryReadLong(ary, Range(&quot;A50:D56&quot;), 5) &#39; default value = 5 End Sub Procedure AryReadLong assumes that you specify the values in long format, i.e. there is index values in all columns except the last which contains the values (see Figure 5.4). For instance, if we consider row 54, then the specification says that ary(1,3,1) = 49. Note we do not have to specify all combination of indices, e.g. in the specification A41:C47 the index (2,4) is missing and set to the default value 4. It is assumed that indices start from the lowest to highest index in each dimension. Figure 5.4: Reading values to an array using a long format (TM5 worksheet). You can also read a csv file into an array. Let us have a look at a csv file data2.csv using a colon as delimiter: 55,18,34,1,81,26,90,11,46,32,93 49,95,73,82,53,40,99,10,52,38,92 59,90,97,100,59,73,88,33,78,61,24 96,84,32,36,94,82,49,94,48,49,1 59,21,24,57,3,78,54,79,57,42,8 You can read the values into an array using AryFromCSV: Sub TM5_AryReadCSVEx() Dim rng As Range Dim ary() As Integer ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Call TM5_ClearTestTM5 &#39;&#39; Read csv file (NOTE you must know the separator in the csv file beforehand!) Range(&quot;G3&quot;) = &quot;Array values:&quot; Call AryFromCSV(ary, &quot;data2.csv&quot;, &quot;,&quot;) &#39; know that it contains integers (otherwise use variant) Call AryPaste(ary, Range(&quot;G4&quot;)) End Sub 5.6.3.1 Example - Reading values from a sheet This example is a slightly modified version an exam assignment (exam 2022-A4). Consider the data in worksheet TM5_AryData. Our goal is to create a procedure that reads the strings in the worksheet into a 2D array with the following features: Indexing must start from 1 in both dimensions. The procedure should work for other datasets with a different number of columns and rows. You may assume that the data starts in cell A1. A message box should be given after the data has been read with the value of array entry (1,3). If the entry does not exists a warning should be given instead. A button in worksheet TM5_AryData should run the procedure. If you are not allowed to read the data into an array using the course procedure AryRead, you must use for loop(s) to assign values to the array: Sub TM5_AryReadValuesPlainVBA() Dim ary() As String Dim rng As Range Dim r As Integer, c As Integer Worksheets(&quot;TM5_AryData&quot;).Activate Set rng = RngCurRegion(Range(&quot;A1&quot;)) &#39; get current region ReDim ary(1 To RngGetLastRow(rng), 1 To RngGetLastCol(rng)) &#39; redim array &#39; allocate values For r = 1 To RngGetLastRow(rng) For c = 1 To RngGetLastCol(rng) ary(r, c) = Cells(r, c) Next Next &#39; print ary(1,3) If (UBound(ary, 2) &lt; 3) Then MsgBox (&quot;Array does not have 3 columns!&quot;) Exit Sub End If MsgBox (&quot;Value entry (1,3) is: &quot; &amp; ary(1, 3)) End Sub If you are allowed to use AryRead then you can skip the for loop: Sub TM5_AryReadValues() Dim ary() As String Dim rng As Range Dim r As Integer, c As Integer Worksheets(&quot;TM5_AryData&quot;).Activate Set rng = RngCurRegion(Range(&quot;A1&quot;)) &#39; get current region Call AryRead(ary, rng) &#39; allocate values &#39; print ary(1,3) If (UBound(ary, 2) &lt; 3) Then MsgBox (&quot;Array does not have 3 columns!&quot;) Exit Sub End If MsgBox (&quot;Value entry (1,3) is: &quot; &amp; ary(1, 3)) End Sub 5.6.4 Sorting arrays Arrays can be sorted using AryQuickSort: Sub TM5_ArySortEx() Dim ary() As Integer ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Call TM5_ClearTestTM5 &#39;&#39; Read from a range and sort Call AryRead(ary, Range(&quot;C5:E19&quot;)) Call AryQuickSort(ary, 2) Range(&quot;G3&quot;) = &quot;Sort w.r.t. 2. column:&quot; Call RngPaste(Range(&quot;C4:E4&quot;), Range(&quot;G4&quot;)) &#39; copy header Call AryPaste(ary, Range(&quot;G5&quot;)) End Sub Here we sort based on the 2. column in the array. 5.6.5 Use arrays instead of ranges Since a range represent a block of cells in a sheet, one may think of a range a some kind of 1D or 2D array. Hence one may use a range directly to read/write values instead of an array (we did that in Section 4.7). However, often arrays are better to use than ranges: You can set indices as you like so they give a meaning to you, e.g. intOrderSize(2, 10, 20) denote the order size of product 20, in week 2 for customer 10. Arrays are much faster to update than ranges, More specific, it is much faster to update the values many times in an array compared to a range. You worksheet and ranges may be seen as a place where you keep your data. Hence, when you run an algorithm, you first read the data into some arrays. Next, do some calculations (update the arrays) and finally output the result to a worksheet again. Consider for example the distance matrix calculations in Section 3.6. Here it would be faster to store the distance matrix in a 2D array: Sub TM5_MakeDistArray() Dim n As Integer Dim aryDist() As Double Dim i As Integer Dim j As Integer ThisWorkbook.Worksheets(&quot;TM3_DistanceMatrix&quot;).Activate n = Range(&quot;E1&quot;) ReDim aryDist(1 To n, 1 To n) For i = 1 To n For j = i + 1 To n aryDist(i, j) = TM3_Distance(Cells(i + 1, 2), Cells(i + 1, 3), Cells(j + 1, 2), Cells(j + 1, 3)) aryDist(j, i) = aryDist(i, j) &#39; set symetric value Next Next End Sub Afterwards aryDist can be used during in an algorithm. 5.7 Collections Collections are a way of storing a group of items together (think of it as a set). Collections and arrays are both used to group variables. They both store a set of items e.g. a list of student marks or country names. If we compare collections against arrays: Collections are similar to arrays but better to use when the number of items is not fixed. With an array you normally set the size once. On the contrary you often add or remove items from a collection. Collections are better when adding and removing items. An item in a collection are read-only whereas an entry in an array are read/write. Collection can be accessed using a key or an index (starting from 1). Items of a collection do not have to share the same data type. Collections are a part of the predefined objects in VBA and hence a collection have to be defined in a special way. Let us consider an example: Sub TM5_ColEx() Dim col As New Collection &#39; declare and create Dim e As Variant ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Call TM5_ClearTestTM5 &#39;&#39; Add items Call col.Add(&quot;Apple&quot;) Call col.Add(&quot;Pear&quot;) Call col.Add(123) Cells(4, 7) = &quot;The collection now contains &quot; &amp; col.Count &amp; &quot; items: &quot; &amp; Col2Str(col) &#39;&#39; Use For Each to scan elements For Each e In col MsgBox (e) Next e &#39;&#39; Access values in the collection using index Cells(5, 7) = &quot;The 1. item is: &quot; &amp; col(1) Cells(6, 7) = &quot;The 3. item is: &quot; &amp; col(3) &#39; Remove items Call col.Remove(2) Cells(7, 7) = &quot;The collection now contains &quot; &amp; col.Count &amp; &quot; items: &quot; &amp; Col2Str(col) &#39;&#39; Note index of items has now changed (the 3. item has become the 2. item) Cells(8, 7) = &quot;The 1. item is: &quot; &amp; col(1) Cells(9, 7) = &quot;The 2. item is: &quot; &amp; col(2) &#39;&#39; Clear collection Set col = Nothing Cells(10, 7) = &quot;The collection now contains &quot; &amp; col.Count &amp; &quot; items.&quot; End Sub First we declare and create a collection: Dim col As New Collection The collection (or set) is now defined with zero items. You can add items using Call col.Add(&quot;Apple&quot;) Call col.Add(&quot;Pear&quot;) Call col.Add(123) Let us create a function that prints the items of a collection as string: Function Col2Str(col As Collection, Optional strSep As String = &quot;, &quot;) As String Dim e As Variant Dim str As String For Each e In col str = str &amp; e &amp; strSep Next e Col2Str = Left(str, Len(str) - Len(strSep)) End Function Then the output of &quot;The collection now contains &quot; &amp; col.Count &amp; &quot; items: &quot; &amp; Col2Str(col) becomes &quot;The collection now contains 3 items: Apple, Pear, 123&quot; You can access values in the collection using index: &quot;The 1. item is: &quot; &amp; col(1) &quot;The 3. item is: &quot; &amp; col(3) The 1. item is: Apple The 3. item is: 123 Items are removed using: Call col.Remove (2) &quot;The collection now contains &quot; &amp; col.Count &amp; &quot; items: &quot; &amp; Col2Str(col) The collection now contains 2 items: Apple, 123 Note index of items has now changed (the 3. item has become the 2. item): &quot;The 1. item is: &quot; &amp; col(1) &quot;The 2. item is: &quot; &amp; col(2) The 1. item is: Apple The 2. item is: 123 You clear a collection using: Set col = Nothing &quot;The collection now contains &quot; &amp; col.Count &amp; &quot; items.&quot; The collection now contains 0 items. 5.7.1 Accessing collections using keys An item in a collection can be given a key (think af a key as a name tag given to each item): Sub TM5_ColKeyEx() Dim col As New Collection &#39; declare and create Dim k As Variant ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate &#39;&#39; Add using keys Call col.Add(&quot;Hans Jørgensen&quot;, &quot;ID123&quot;) &#39; value, key Call col.Add(&quot;Jens Hansen&quot;, &quot;ID234&quot;) Call col.Add(&quot;Lone Nielsen&quot;, &quot;ID456&quot;) &#39; col.Add &quot;Sine Mikkelsen&quot;, &quot;ID456&quot; &#39; gives an error since already used the key Cells(12, 7) = &quot;The collection now contains &quot; &amp; col.Count &amp; &quot; items: &quot; &amp; Col2Str(col) &#39;&#39; Access values using keys Cells(13, 7) = &quot;The item with key ID123 is: &quot; &amp; col(&quot;ID123&quot;) &#39; Remove items using keys col.Remove &quot;ID123&quot; Cells(14, 7) = &quot;The collection now contains &quot; &amp; col.Count &amp; &quot; items: &quot; &amp; Col2Str(col) End Sub Here we add items using a key: Call col.Add(&quot;Hans Jørgensen&quot;, &quot;ID123&quot;) &#39; value, key Call col.Add(&quot;Jens Hansen&quot;, &quot;ID234&quot;) Call col.Add(&quot;Lone Nielsen&quot;, &quot;ID456&quot;) &quot;The collection now contains &quot; &amp; col.Count &amp; &quot; items: &quot; &amp; Col2Str(col) The collection now contains 3 items: Hans Jørgensen, Jens Hansen, Lone Nielsen You can now access the item using the key: &quot;The item with key ID123 is: &quot; &amp; col(&quot;ID123&quot;) The item with key ID123 is: Hans Jørgensen Similar you can remove an item using a key: Call col.Remove(&quot;ID123&quot;) &quot;The collection now contains &quot; &amp; col.Count &amp; &quot; items: &quot; &amp; Col2Str(col) The collection now contains 2 items: Jens Hansen, Lone Nielsen It is recommended to use keys since using keys has three advantages: If the order changes your code will still access the correct item You can directly access the item without reading through the entire collection It can make you code more readable 5.7.2 Collections containing objects In general you cannot change the values of an item. However, this is possible if you store an object. To do this you need a class definition. How classes work is beyond this course. However let us consider an example with a simple class. First, we define a class Insert &gt; Class module. You can now see a class module named Class 1 in the Process Explorer window. Rename it to SKUInfo, double click it and add code Public Items As Integer Public Size As Double Public Shell As String We have now defined a custom class containing 3 variables and can create objects of this class that can be stored in a collection: Sub TM5_ColWObjectEx() Dim col As New Collection &#39; declare and create Dim rng As Range Dim r As Integer, c As Integer Dim oSKU As SKUInfo ThisWorkbook.Worksheets(&quot;TM5_Col&quot;).Activate Set rng = RngGetCurRegionRange(Range(&quot;F2&quot;), row:=2) &#39; read from 2. row so no headers &#39; Read the data For r = 1 To RngGetRows(rng) Set oSKU = New SKUInfo &#39; create an object oSKU.Items = rng(r, 2) oSKU.Size = rng(r, 3) oSKU.Shell = rng(r, 4) Call col.Add(oSKU, rng(r, 1)) &#39; add to collection with SKU as key Next &#39; print info and change a value (this is possible since it is an object) MsgBox (&quot;There are &quot; &amp; col(&quot;G6Y89&quot;).Items &amp; &quot; items in stock for SKU G6Y89&quot;) col(&quot;G6Y89&quot;).Items = 5 MsgBox (&quot;There are &quot; &amp; col(&quot;G6Y89&quot;).Items &amp; &quot; items in stock for SKU G6Y89&quot;) &#39; remove a SKU Call col.Remove(&quot;G6Y89&quot;) MsgBox (&quot;The collection now contains &quot; &amp; col.Count &amp; &quot; items.&quot;) End Sub First the data is read into the collection. Here we create a new object SKUInfo, set the values and store the object as an item in the collection: For r = 1 To RngGetRows(rng) Set oSKU = New SKUInfo &#39; create an object oSKU.Items = rng(r, 2) oSKU.Size = rng(r, 3) oSKU.Shell = rng(r, 4) Call col.Add(oSKU, rng(r, 1)) &#39; add to collection with SKU as key Next Next, we print some info and change a value. Note, this is possible since SKUInfo is an object (passed by a reference): MsgBox (&quot;There are &quot; &amp; col(&quot;G6Y89&quot;).Items &amp; &quot; items in stock for SKU G6Y89&quot;) col(&quot;G6Y89&quot;).Items = 5 MsgBox (&quot;There are &quot; &amp; col(&quot;G6Y89&quot;).Items &amp; &quot; items in stock for SKU G6Y89&quot;) Finally, we delete the SKU: Call col.Remove(&quot;G6Y89&quot;) MsgBox (&quot;The collection now contains &quot; &amp; col.Count &amp; &quot; items.&quot;) For more information about collections you may have a look at this webpage. 5.8 Example - Job sequencing Consider \\(i = 1,...,n\\) jobs that has to be done on a machine and let \\(c_{ij}\\) denote the setup cost of switching from job \\(i\\) to job \\(j\\). Moreover, let \\(c_{0i}\\) denote the setup cost of setting up job \\(i\\) when the machine is idle (index 0). Let \\(s = (0, s_1, \\ldots, s_n)\\) denote the sequence of jobs and \\(C\\) the total setup costs, e.g. if \\(s = (0,1,3,2,6,5,4)\\), then \\(C = c_{01} + c_{13} + c_{32} + c_{26} + c_{65} + c_{54}\\). Different algorithms for finding a good strategy minimizing the total setup costs exists. A greedy algorithm is: Step 0: Select the first job as one with minimal idle setup cost. Step 1: Given current job \\(i\\) select the unscheduled with minimal setup cost. Step 2: If no unscheduled jobs then stop and output the found job sequence else go to Step 1. Often a better algorithm is: Step 0: For each column \\(j\\) find \\(\\bar{c}_j = min(c_{0j},\\ldots,c_{j-1,j},c_{j+1,j},\\ldots,c_{nj})\\) and define relative setup costs \\(\\hat{c}_{ij} = c_{ij}-\\bar{c}_{j}\\) (the cost is subtracted the minimum value in that column). Step 1: Call the greedy algorithm using costs \\(\\hat{c}_{ij}\\). Examples on how data could look like can be seen in worksheet TM5_JobSeq that contains the setup costs (Figure 5.5). Columns M-T contain three datasets for which we want to calculate a job sequence. Figure 5.5: Worksheet TM5_JobSeq. Let us try to implement the greedy algorithm which takes the cost array costs as arguments and output the job sequence and cost: &#39;&#39; Job sequeceing using a cost array &#39; &#39; @param costs An 2D array with setup costs &#39; @param strSeq The job sequence found (returned ByRef). &#39; @param dblCosts The total setup costs (returned ByRef). Sub TM5_GreedyAlg(costs() As Double, strSeq As String, dblCosts As Double) Dim intJobs As Integer &#39; number of jobs Dim used() As Integer &#39; an entry equals 1 if already scheduled Dim intCurJob As Integer &#39; current job Dim intNextJob As Integer &#39; best candidate for next job (= intM if not found yet) Dim dblNextCost As Double &#39; setup cost current to next job Dim c As Integer &#39; iterators Dim intM As Integer &#39; big number &#39;&#39; Allocate arrays intJobs = UBound(costs, 1) ReDim used(1 To intJobs) &#39; set size Call AryToVal(used, 0) &#39; set to 0 &#39;&#39; Run greedy strSeq = &quot;0&quot; &#39; start idle intM = 1000 &#39; a number bigger than largest cost intCurJob = 0 &#39; start idle dblCosts = 0 Do While True &#39; find next job given current intNextJob = intM dblNextCost = intM For c = 1 To intJobs &#39; scan row in array to find next unused job with minimal cost If used(c) &lt;&gt; 1 And costs(intCurJob, c) &lt; dblNextCost Then intNextJob = c dblNextCost = costs(intCurJob, c) End If Next If intNextJob = intM Then Exit Do &#39; no new job found (all jobs used) dblCosts = dblCosts + dblNextCost used(intNextJob) = 1 intCurJob = intNextJob strSeq = strSeq &amp; &quot;, &quot; &amp; intNextJob Loop End Sub First observe that the procedure have three arguments costs, strSeq and dblCosts. The array costs contain the setup costs and is an input argument to the algorithm. The last two arguments are output arguments. Since arguments are passed by reference by default (no new memory is allocated), we modify them with the solution. Next, to run the algorithm we need to keep track of which jobs have been used. We use the array used for this and set it to 0 (not used) and 1 (used). Finally, the Do While loop is used to scan a row in the cost array. We want to find the minimum cost and hence use a big number as starting value, then scan all unused jobs and choose the one with minimum cost. If no new job is found we finish; otherwise we update strSeq and dblCosts. Note that the procedure do not have any interaction with a worksheet. It simply takes an array as input argument and store the result in two output arguments. That is, the procedure is independent of where the data is from (could e.g. be an csv file instead of a worksheet). Let us try to link the greedy algorithm to the data in workheet TM5_JobSeq. Columns M-T contain three datasets for which we want to calculate a job sequence. First, let us make a procedure that copies a dataset to A4 (upper left cell): Sub TM5_CopyData() Dim str As String ThisWorkbook.Worksheets(&quot;TM5_JobSeq&quot;).Activate &#39; so use the correct sheet str = InputBox(&quot;Specify cell in data (e.g. N7)&quot;) &#39; get a cell value Call TM5_CleanJobSeq &#39; delete previous data Call RngPaste(RngCurRegion(Range(str)), Range(&quot;A4&quot;), withFormat:=True) &#39; paste the current region End Sub Note we use the current region of the cell value to retrieve the dataset. We can now run the greedy algorithm using the data starting in A4: Sub TM5_RunGreedy() Dim costs() As Double &#39; setup costs Dim strSeq As String &#39; job seq Dim dblCosts As Double &#39; total setup costs Dim rng As Range ThisWorkbook.Worksheets(&quot;TM5_JobSeq&quot;).Activate &#39; Allocate costs to array Set rng = RngCurRegion(Range(&quot;A4&quot;)) &#39; rng now is the whole dataset with headers Set rng = Range(&quot;B5:&quot; &amp; RngGetLastCol(rng, asLetter:=True) &amp; RngGetLastRow(rng)) &#39; rng now is the costs Call AryRead(costs, rng, 0, 1) &#39; start index from 0 (first dim) and 1 (second dim) &#39; Run algorithm Call TM5_GreedyAlg(costs, strSeq, dblCosts) &#39; Write results to sheet Range(&quot;C1&quot;) = UBound(costs, 1) Range(&quot;C2&quot;) = strSeq Range(&quot;F1&quot;) = dblCosts End Sub First, observe how we allocate values to the ‘costs’ array. We use the course procedure AryRead and hence first have to find the range containing the setup costs. This can be done may ways, but we know that the upper left cell is B5 and the lower right is found using the RngGet functions. Next, we call AryRead and set the index to start from 0 (first dimension) and 1 (second dimension). Given setup costs, we call the greedy algorithm which returns updated strSeq and dblCosts. Finally, we output the results to the worksheet. To implement the ‘better’ algorithm we need to modify the costs array and subtract the minimum column value: Sub TM5_RunBetter() Dim minCol() As Double &#39; min value in col c Dim intJobs As Integer &#39; number of jobs Dim costs() As Double &#39; setup costs Dim strSeq As String &#39; job seq Dim dblCosts As Double &#39; total setup costs Dim rng As Range Dim dbl As Double Dim r As Integer, c As Integer ThisWorkbook.Worksheets(&quot;TM5_JobSeq&quot;).Activate &#39; Allocate costs to array Set rng = RngCurRegion(Range(&quot;A4&quot;)) &#39; rng now is the whole dataset with headers Set rng = Range(&quot;B5:&quot; &amp; RngGetLastCol(rng, asLetter:=True) &amp; RngGetLastRow(rng)) &#39; rng now is the costs Call AryRead(costs, rng, 0, 1) &#39; start index from 0 (first dim) and 1 (second dim) &#39; Calc min value in each col intJobs = UBound(costs, 1) ReDim minCol(1 To intJobs) For c = 1 To intJobs dbl = 10000000 &#39; a big number For r = 0 To intJobs If costs(r, c) &lt; dbl And r &lt;&gt; c Then dbl = costs(r, c) Next minCol(c) = dbl Next &#39; Calc relative For c = 1 To intJobs For r = 0 To intJobs costs(r, c) = costs(r, c) - minCol(c) Next Next &#39; Run algorithm Call TM5_GreedyAlg(costs, strSeq, dblCosts) &#39; Write results to sheet Range(&quot;C1&quot;) = intJobs Range(&quot;C2&quot;) = strSeq Range(&quot;F1&quot;) = dblCosts + WorksheetFunction.Sum(minCol) End Sub First, an array minCol is used to store the minimum values for each column. Next, we update the costs array with the relative values and the greedy algorithm is run with the relative setup cost values. Finally, we output the results. Note we have to add the minimum costs back to dblCosts (the sum of the minCol values). 5.9 Recap Variables are used to store information that is saved in memory. A variable may store different data types such an integer, a double, a group of doubles (an array), a range of cells in a worksheet (a range object) or a set of numbers (a collection). Strings are special variables with varying length. Use the &amp; to concatenate strings (glue strings together). An empty string is of length zero. VBA have a lot of predefined objects you can use. Think of an object as a datatype that holds a group of variables. Examples of some objects are Range, Worksheet, and WorksheetFunction. Refer to an object by specifying the path in the hierarchy e.g.  Workbooks(&quot;Jobs.xlsm&quot;).Worksheets(&quot;Data values&quot;).Range(&quot;D4&quot;).value You may skip parts of the path (VBA then uses the current active one). Warning, you must know which sheet is active. Always specify what you want to be active ThisWorkbook.Worksheets(&quot;Data values&quot;).Activate &#39; activate the sheet dbl = Range(&quot;D4&quot;) Declare object variables using: Dim rng As Range Dim wst As Worksheet Set a reference to object variables using the keyword Set: Set rng = Range(&quot;F7&quot;) Set wst = Worksheets(&quot;Data values&quot;) A Worksheet object refer to a worksheet and you can use it to e.g. modify cells: Worksheets(&quot;TM5_Test1&quot;).Range(&quot;B2&quot;) = &quot;Testing Worksheet&quot; &#39; write to cell in sheet TM5_Test1 Set wst1 = ThisWorkbook.Worksheets(&quot;TM5_Test1&quot;) &#39; set a reference to a worksheet wst1.Range(&quot;B6&quot;) = &quot;Writing using wst1&quot; Different functions for worksheets is part of the course procedures. All the worksheet procedures start with Wst so you easy can find them using auto complete in the VBA editor. All worksheet procedures are stored in the ModWst module. You may open the module to have a look at the procedures. Examples: If WstCreate(&quot;Test&quot;, blnForce:=True) Then MsgBox (&quot;Created Test&quot;) If WstRename(&quot;Test&quot;, &quot;Test1&quot;) Then MsgBox (&quot;Renamed the Test to Test1&quot;) &#39; only work if no Test1 sheet If WstClear(&quot;Test8&quot;) Then MsgBox (&quot;Cleared Test8&quot;) &#39; clear sheet Test8 if exists If WstDelete(&quot;Test1&quot;) Then MsgBox (&quot;Deleted Test1&quot;) Ranges are objects that refer to parts of a worksheet e.g. a cell, a row, a column, or a rectangular selection of cells. Ranges can be used to read and write to cells Dim rng As Range Set rng = Range(&quot;A1:D5&quot;) rng = 145 &#39; cell value MsgBox rng.Address &#39; range address ($A$1:$D$5) You can use the course procedures (module ModRng) with prefix RngGet to retrieve info about the range: Set rng = ThisWorkbook.Worksheets(&quot;TM5&quot;).Range(&quot;C4:E19&quot;) MsgBox (&quot;Number of rows: &quot; &amp; RngGetRows(rng)) MsgBox (&quot;Number of cols: &quot; &amp; RngGetCols(rng)) MsgBox (&quot;First column number: &quot; &amp; RngGetFirstCol(rng)) MsgBox (&quot;First column letter: &quot; &amp; RngGetFirstCol(rng, asLetter:=True)) MsgBox (&quot;Lower right cell: &quot; &amp; RngGetLowerRight(rng, asString:=True)) MsgBox (&quot;Upper right cell: &quot; &amp; RngGetUpperRight(rng, asString:=True)) The current region of a range is found by expanding the range until all cells surrounding the range is empty rng = Range(&quot;D23&quot;).CurrentRegion This is useful if don’t know the size for data. You can use the course procedures (module ModRng) with prefix RngGetCurRegion to retrieve info about the current region of a range: Set rng = Range(&quot;D7&quot;) &#39; assume we know that data contains cell D7 MsgBox (&quot;Address: &quot; &amp; RngGetCurRegionAddress(rng)) MsgBox (&quot;Rows = &quot; &amp; RngGetCurRegionRows(rng) &amp; &quot; cols = &quot; &amp; RngGetCurRegionCols(rng)) MsgBox (&quot;First row number = &quot; &amp; RngGetCurRegionFirstRow(rng) &amp; &quot;. Last row number = &quot; &amp; RngGetCurRegionLastRow(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col number = &quot; &amp; RngGetCurRegionFirstCol(rng) &amp; &quot;. Last col number = &quot; &amp; RngGetCurRegionLastCol(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col letter = &quot; &amp; RngGetCurRegionFirstCol(rng, True) &amp; &quot;. Last col letter = &quot; &amp; RngGetCurRegionLastCol(rng, True) &amp; &quot;.&quot;) You copy/paste a range using: Set rng = Range(&quot;D7:E10&quot;) Set rngNew = RngPaste(rng, Range(&quot;H14&quot;)) &#39; paste with upper left = H14, rngNew is now the new range You can read values from a csv file using: Set rng = RngFromCSV(&quot;data1.csv&quot;, Range(&quot;G4&quot;), &quot;;&quot;) &#39; paste file in range with upper left cell G4 You can write values from a range to a csv file using: Call RngToCSV(&quot;test.csv&quot;, rng, &quot;;&quot;) &#39; semicolon (;) separated file The columns in a range can be sorted. For instance sort a range ascending with respect to the second column and next descending with respect to the first column. Call rng.Sort(Key1:=rng.Columns(2), Order1:=xlAscending, _ Key2:=rng.Columns(1), Order2:=xlDescending, Header:=xlYes) An array store groups of variables of a specific data type. For example Dim intValues(8) As Integer The variable intValues is an array with 9 elements which can be accessed using index 0, 1, 2, …, 8. The default start index of an array is 0. If you want to start with index 1 then add Option Base 1 to the top of your module or use: Dim strAry(3 To 5) As String &#39; define array with index 3-5 An array can have different dimensions, e.g. three: Dim intOrderSize(52, 100, 50) As Integer where indices may be (week, customer, product) number. Let us assume that index start from 1 then we have an array with \\(52 \\cdot 100 \\cdot 50\\) elements which can be accessed using e.g. intOrderSize(2,10, 20) &#39; order size week 2, customer 10, product 20 Arrays require 20 bytes of memory plus 4 bytes for each array dimension plus the number of bytes occupied by the data itself. A Variant containing an array requires 12 bytes more than the array alone. Dynamic arrays are arrays where the dimension is unknown when they are declared. Use ReDim to set the dimension later: Dim strPeople() As String ... n = 8 ReDim strPeople(n) You can set values for an array by reading from a range: Dim ary() As Integer Call AryRead(ary, Range(&quot;C5:E9&quot;)) You can paste values of an array to a range: Call AryPaste(ary, Range(&quot;G5&quot;)) &#39; the upper left cell is G5 You can set values for an array with more than 2 dimensions by reading from a range: Dim ary() As Integer Call AryReadLong(ary, Range(&quot;A36:B38&quot;), 3) &#39; default value = 3 The procedure AryReadLong assumes that you specify the values in long format, i.e. there is index values in all columns except the last which contains the values. You can read a csv file into an array using: Dim ary() As Integer Call AryFromCSV(ary, &quot;data2.csv&quot;, &quot;,&quot;) &#39; know that it contains integers (otherwise use variant) Arrays can be sorted using: Dim ary() As Integer Call AryQuickSort(ary, 2) &#39; sort w.r.t. 2. column Often arrays are better to use than ranges: You can set indices as you like so they give a meaning to you, e.g. intOrderSize(2, 10, 20) denote the order size of product 20, in week 2 for customer 10. Arrays are much faster to update that ranges. It is much faster to update the values many times in an array compared to a range. You worksheet and ranges may be seen as a place where you keep your data. Hence, when you run an algorithm, you first read the data into some arrays. Next, do some calculations (update the arrays) and finally output the result to a worksheet again. Collections are used for storing a group of items together (think of it as a set). Collections and arrays are both used to group variables. If we compare collections against arrays: Collections are similar to arrays but better to use when the number of items is not fixed. With an array you normally set the size once. On the contrary you often add or remove items from a collection. Collections are better when adding and removing items. An item in a collection are read-only whereas an entry in an array are read/write. Collection can be accessed using a key or an index (starting from 1). Items of a collection do not have to share the same data type. Declare and create a collection: Dim col As New Collection Add items using: Call col.Add(&quot;Apple&quot;) Call col.Add(&quot;Pear&quot;) Items are removed using: Call col.Remove (2) Clear a collection using: Set col = Nothing An item in a collection can be given a key (think af a key as a name tag given to each item): Call col.Add(&quot;Hans Jørgensen&quot;, &quot;ID123&quot;) &#39; value, key Call col.Add(&quot;Jens Hansen&quot;, &quot;ID234&quot;) You can now access the item using the key: &quot;The item with key ID123 is: &quot; &amp; col(&quot;ID123&quot;) You can remove an item using a key: Call col.Remove(&quot;ID123&quot;) It is recommended to use keys since using keys has three advantages: If the order changes your code will still access the correct item You can directly access the item without reading through the entire collection It can make you code more readable You may also have a look at the slides for this module . 5.10 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Some of the solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up too early. Put some effort into finding a solution! A template with VBA code is given in the file vba-template.xlsm (open it and use it while reading the notes). Have a look inside the module TM5_ex in the VBA editor for examples used in the notes and during lectures. Have a look at module TM5_exercises for exercises. Guiding answers for the exercises can be found in the file vba-solution.xlsm . 5.10.1 Exercise - Equal entries This exercise is a slightly modified version an exam assignment (exam 2021-A4). Consider worksheet TM5_Equal with seven data sets. Each data set consists of a list of integer values and is contained in a single column. Your code should be able to run on any of these data sets, but only on one data set at a time. The value in cell C1 states the column to use, so you can change the data set by changing this value (the values can be 1, 3, 5, …). The data sets vary in size. If you need to know the number of values in the data set, it should be done as part of your vba code. Write a sub TM5_Equal that stores the values of the data set indicated in cell C1 in an array; creates an array equal, where equal(k,j) is 1, if the k’th and j’th values are equal, and 0 otherwise. A named range Numbers has been stored in Excel using Formulas -&gt; Define Name. Write a sub TM5_EqualNamedRange that stores the values of the data set saved in the named range Numbers. creates an array equal, where equal(k,j) is 1, if the k’th and j’th values are equal, and 0 otherwise. Try to redefine Numbers using Formulas &gt; Name Manager &gt; Edit so reference to another dataset and rerun the the sub. 5.10.2 Exercise - Product search Consider the worksheet TM5_Products containing a set of products with product code and price. Create a sub TM5_FindProduct that Declare two arrays to store the price and product code. Assign values to the arrays. Use an input box to ask for a product code. Use a for loop to search for the product and output the price in a message box. Hint: the Exit sub may be useful. Add a button to the worksheet that run the procedure. Test you code using different product codes. What happens if you write the product code without capital letters? If your code do not work, have a look at the UCase function. Modify your code so that if the product is not found then “Product not found!” is given in a message box. 5.10.3 Exercise - Read collections Consider worksheet TM5_Col with numbers in column A to be read into a collection. Create a procedure TM5_ColNoKeys that: Create a collection col and add all the numbers. Print the collection in a message box (you may use the function Col2Str here). Create another collection colC and add all the items in col with value below 5. Consider worksheet TM5_Col with some ID numbers and prices for a set of products in columns C-D. Create a procedure TM5_ColKeys that: Create a collection col and add all the prices using ID as key. Print the price of the product with ID92011 in a message box. What happens if you try to print the price of ID92? 5.10.4 Exercise - Read arrays Consider the worksheet TM5_Array containing 3 datasets to be read into an array. The first two are in long format and the last in range format. Write a procedure TM5_ReadArrays that use course procedures AryRead and AryReadLong to read the values into three arrays. Assume that For the first dataset is the default array value 10. For the second dataset is the default array value 5. For the third dataset index must start from 3 (first dimension) and 5 (second dimension). Use the debugger to inspect if the values have been read correctly into the arrays. 5.10.5 Exercise - Process numbers This exercise is a slightly modified version an exam assignment (reexam 2022-A5). Consider worksheet TM5_ProcessData, which contains a set of numbers. Create a procedure TM5_Process with the following features: Copy the numbers to worksheet TM5_Process. Scan all the numbers and remove (clear the cell) all the negative numbers. Highlight all the numbers above 20. Add a button to the worksheet TM5_Process that run the procedure. The procedure should work for other datasets with a different size. You may assume that the data starts in cell A1. Create a procedure TM5_Stat with the following features: Scan the numbers and find the sum of all non-negative numbers, the mean of all negative numbers. Use a message box to display the sum and mean calculated. Add a button to the worksheet TM5_ProcessData that run the procedure. The procedure should work for other datasets with a different size. You may assume that the data starts in cell A1. 5.10.6 Exercise - Search payments This exercise is a slightly modified version an exam assignment (reexam 2022-A6). Consider worksheet TM5_PaymentsData which contains a table with three columns. The table contains data about payments for clients at a set of dates. Create a procedure TM5_SearchPayments that searches the table with the following features: Read the payment boolean in cell B1 (TRUE or FALSE) and the grouping string in cell B2 (None or Year) on worksheet TM5_Payments. Only consider payments where cells in the Payment column equals the payment boolean. If the grouping string equals None then count the number of payments for each client. Next, output the results on worksheet TM5_Payments. See worksheet TM5_PaymentsEx1 for an example. If the grouping string equals Year then count the number of payments for each client and year. Next, output the results on worksheet TM5_Payments. See worksheet TM5_PaymentsEx2_ for an example. Add a button to worksheet TM5_Payments that run the procedure. The procedure should work for other datasets with different number of rows too. 5.10.7 Exercise - Flight search The worksheet TM5_FlightData contains a set of flights between different destinations. You task is to create a procedure TM5_SearchFlights that can search for matching flights given a set of origins and destinations. Have a look at the results in worksheet TM5_FlightData. The origin and destinations to search for are given in columns A and B and the search result in columns D, E and F. Try pressing the Clear Search button and see what happens. Have a look at the code in the VBA editor for this sub and get an overview. × Hint Set the range you want to read and use AryRead Close Hint Try to finish the first part of the TM5_SearchFlights sub and store the flights in arrays. Use the debugger to check if the values are stored correctly. Try to finish the second part of the SearchFlights sub and search for matching origin-destination pairs. Note origins and destinations listed to be searched for are also matching origin-destination pairs if they are not in the same row. 5.10.8 Exercise - Search table This exercise is a slightly modified version an exam assignment (exam 2022-A6). Consider worksheet TM5_Search which contains a table with three columns starting in cell A1. You want to search this table and output the matching rows to a new sheet. Create a procedure TM5_Search1 that searches the table with the following features: First, a message box is used to ask if a name should be searched. If the answer is yes, then use an input box to type the name. Next, use a message box to ask if an amount should be searched. If the answer is yes, then use an input box to type the amount (search for amounts greater than or equal the typed amount). Scan the table and output all rows that match the specified criteria, and output the resulting table with matching rows in worksheet TM5_SearchOutput. If no criteria are used, then return all rows. Add a button to worksheet TM5_SearchOutput that run the procedure. The procedure should work for other datasets with different number of rows too (such as the dataset starting in cell E1). Create a procedure TM5_Search2 that searches the table with the following features: Copy the whole table to worksheet TM5_SearchOutput. Sort the table non-increasing order of the column Sales Amount, then next based on the Title column. Use an input box to ask for an amount \\(x\\). Highlight the cells in the rows where the Sales Amount is less than \\(x\\). Add a button to worksheet TM5_SearchOutput that run the procedure. 5.10.9 Exercise - Find next task This exercise is a slightly modified version an exam assignment (reexam 2021-A6). Consider worksheet TM5_Tasks which contains a list of tasks. For each task, you see the task ID and a descriptive text, along with the following information: Column C: The number indicates any task that must start before the current task. For instance, Task 6 (Check social media) must be started before Task 8 (Filter false news) can be started. Note that the task just have to start, not finish. You may assume that at most one task is required to start in each case. Column D: A number indicating how attractive the task is to perform. Higher values indicate higher attractiveness. Column E: A 1 is stated, if the task is already started. Given a set of tasks, where some are already started, write a sub that selects the next task with the following features: Among the tasks not started, your sub should select the most attractive task that respects the predecessor requirement. Output the next task in a message box. Indicate in column E that the task is now started. Add a button that run the procedure. 5.10.10 Exercise - Seat reservation This exercise is a larger assignment and is more extensive than the exam and is not a mandatory/part of curriculum. Do not expect such a large assignment at the exam. However, by doing this exercise you will improve your VBA skills which may be beneficial at the exam or when write your master thesis. A template file is given for this exercise, which should be used as a starting point. The file already contains skeletons for some of the procedures and some procedures that you may use to help you. Implement ALL your code in module ModSeatRes. This exercise considers a seat reservation problem. Consider a train with \\(I\\) seats that is travelling between a start station \\(1\\) and an end station \\(S\\) with \\(S-2\\) stations in between. All seats must be reserved and requests for seat reservations arrive on-line. For ease we assume that a request \\(r\\) is for a single seat between a start station \\(s_1(r)\\) and the end station \\(s_2(r)\\). A decision must be made immediately after the arrival of the request to either accept the request or reject it. If the request is accepted, the reservation must be assigned to a seat and this decision cannot be changed subsequently. That is, there is no knowledge about future requests. The train company want to find a strategy that accept as many requests as possible. For further references about the seat reservation problem see J. Boyar and Larsen (1999) and Joan Boyar, Krarup, and Nielsen (2004). Consider the following requests arriving for a train with 3 seats and 14 stations: Request From To 1 1 3 2 7 9 3 2 5 4 9 13 5 2 6 6 11 14 7 10 13 8 8 9 9 7 11 A possible assignment of requests to seats is given in Figure 5.6. Figure 5.6: Assignment of requests (Greedy strategy). Observe that the reservation number is assigned to a slot where slot \\(s\\) is from station \\(s\\) to \\(s+1\\). That is, for each seat there is \\(S-1\\) slots. Given a request \\(r\\) consider strategies: Greedy: Scan seats from 1 to \\(I\\). If seat \\(i\\) is available from \\(s_1(r)\\) to \\(s_2(r)\\) then accept the request and assign the reservation to seat \\(i\\). Otherwise reject the request. Minimize Slots (MinSlots): For each seat \\(i\\) available from \\(s_1(r)\\) to \\(s_2(r)\\) calculate the total free slots before and after stations \\(s_1\\) to \\(s_2\\). Assign the request to a seat where it leaves as little total consecutive free slots (before and after) as possible. Otherwise reject the request. Maximize Slots (MaxSlots): For each seat \\(i\\) available from \\(s_1(r)\\) to \\(s_2(r)\\) calculate the total free slots before and after stations \\(s_1\\) to \\(s_2\\). Assign the request to a seat where it leaves most total free slots as possible. Otherwise reject the request. The result of a strategy Greedy is given in Figure 5.6 and for MinSlots in Figure 5.7. Note that by using the MinSlots strategy all requests are accepted. Figure 5.7: Assignment of requests (MinSlots strategy). Two statistics are used to measure the quality of a strategy applied to the dataset with \\(R\\) requests are: Accepted requests in percent. Used slots in percent \\[\\frac{\\sum_r L_r(s_2(r)-s_1(r))}{I(S-1)}.\\] Where \\(L_r = 1\\) if request \\(r\\) is accepted and 0 otherwise. That is, slots used divided with total number of slots. You task is to create a program with the following features/tasks (implement your code in module ModSeatRes) : Data handling Consider and understand the procedure CopyDataSheet that asks for a number \\(d\\) and copies the data in worksheet Data-\\(d\\) to the Run strategy worksheet. Add a button to the Run strategy worksheet that calls the procedure and test it. Modify procedure ReadData that reads the data from a worksheet (e.g. Run strategy) and store it in two integers and an array. Hint: the procedure AryRead in module ModAry may be useful here. Algorithm implementation Consider and understand the procedure BtnGreedy. Add a button to the Run strategy worksheet that calls the procedure. Also consider and understand the procedure PrintSolution that prints the solution found to a worksheet and range. Modify procedure Greedy so use the greedy strategy described given the data stored by calling ReadData. Test it using the button in the Run strategy worksheet. Modify procedures BtnMinSlots and BtnMaxSlots that use the strategies on the data given in the Run strategy worksheet and print out the solution. Add buttons to the Run strategy worksheet that calls the procedure. Modify procedures MinSlots and MaxSlots so use the strategies above given the data stored by calling ReadData. Test the algorithms using the buttons in the Run strategy worksheet. Copy manually the data in worksheet Ex - Run strategy and test the buttons in worksheet Run strategy to see if you get the same results. Simuation Consider the procedure GenerateData that generate a dataset and modify procedure BtnGenerateData that call GenerateData and add the dataset to worksheet Run strategy. Add a button that runs it in worksheet Run strategy and test it. Modify procedure Simulate that calculate the strategies for 100 datasets, print out the results and calculate statistics. The output should be in the worksheet Simulation. See worksheet Ex - Simulation for an example. Which strategy seems to be the best/worse? Parameter analysis Modify procedure Seats which does a parameter variation on the number of seats. Apply the following approach: Use the dataset in worksheet Data-1. Use the MinSlots strategy. Find solutions when there are 1 to 150 seats available. Store the results in worksheet Seats (see worksheet Ex - Seats for an example). Make a plot of the results (you may use the macro recorder to get some code). How do the two statistics develop as the number of seats increase? Comments to the features/tasks can the added in the Main worksheet. 5.10.11 Exercise - Transform data (select and filter) This exercise is a slightly modified version an exam assignment (exam 2024-A1). Consider the Excel template file provided. The file contains different datasets in worksheets starting with TM5_Data. You may assume that all datasets have a header in the first row (starting in cell A1). Each column contains either doubles or strings. If the header title of a column starts with str then the column contains strings; otherwise the column contains doubles. A dataset can be stored in two arrays where one store the column headers and one the data. For instance, the following code in VBA read the data in worksheet TM5_Data1 into two arrays: Sub TM5_ReadData1() Dim aryData As Variant Dim aryHeaders() As String Dim rng As Range ThisWorkbook.Worksheets(&quot;TM5_Data1&quot;).Activate Set rng = Range(&quot;A1:&quot; &amp; RngGetCurRegionLastCol(Range(&quot;A1&quot;), asLetter:=True) &amp; &quot;1&quot;) Call AryRead(aryHeaders, rng) Set rng = RngGetCurRegionRange(Range(&quot;A1&quot;), row:=2, col:=1) Call AryRead(aryData, rng) End Sub The array storing the header titles contains strings. However, since we do not know the datatype of a column in the dataset, the array aryData is of type Variant. That is, we don’t write Dim aryData() As Variant (which we normally do when defining a dynamic array), but Dim aryData As Variant, since a variant in itself can be an array. Write a set of VBA procedures that answer/complete the following questions/tasks. All procedures MUST be documented using a skeleton similar to the examples given in the course notes (Section D1). Given a header title, create a procedure TM5_IsColumnString with the following features: The procedure takes a header title (string) as argument. Returns true if the string starts with str and false otherwise. That is, if call the procedure with string str_desc then the procedure would return true, while calling the procedure with string item_id would return false. Hint: The LEFT string function in VBA may be useful. Given the array with header titles, create a procedure TM5_GetColumnIndex that return the column index of a header title with the following features: The procedure takes an array as argument containing the header titles. The procedure takes a string as argument with the header title to search for. Returns the index of the header title (if found) else -1. For instance, if the header titles are array (\"Ship\", \"Profit\", \"Cost\") with index starting from 1. Then a call to the procedure searching for Cost would return 3 while searching for Boat would return -1. Create a procedure TM5_SelectColumns that selects a set of columns in a dataset stored using two arrays with the following features: The procedure takes the two arrays representing the dataset (header and data) as arguments. The procedure takes an array of strings as argument containing the header titles to select. If this array contains header titles not present in the dataset, then they are ignored. The modified dataset is output/pasted to the worksheet named TM5_Select (starting in cell A1), i.e. no new arrays are needed to store the new dataset. This worksheet is cleared if it contains old data. The procedure should work for different datasets stored in the arrays (e.g. the dataset in worksheet TM5_Data2). The procedure does not have any intermediate steps which use ranges to select columns. Hint: The course procedure AryPasteColumn stored in module ModAry may be useful. Test SelectColumns by writing a procedure SelectTest that: Loads the dataset in worksheet TM5_Data1 in two arrays (a dataset of orders to a set of ships). Select columns ship, price and item_id (in that sequence). Create message box with the value of cell B2 in worksheet Select along with the column name. Given the original dataset, select columns ship, boat and item_id (in that sequence). Create message box with the value of cell B2 in worksheet Select along with the column name. Add a button running the procedure to worksheet TM5_Select. Create a procedure TM5_Filter that filter some rows based on a criteria in a dataset stored using two arrays with the following features: The procedure takes the two arrays representing the dataset (header and data) as arguments. The procedure takes a string as argument containing the header title of the column to filter on. The procedure takes a string as argument containing the compare operator used. The valid compare operators are &lt;= : less than or equal (valid for a double column). &gt;= : greater than or equal (valid for a double column). = : equal (valid for all column types). in : contained in (valid for a string column). The procedure takes a variant as argument containing the value to compare with. The modified dataset is output to the worksheet named TM5_Filter (starting in cell A1), i.e. no new arrays are needed to store the new dataset. This worksheet is cleared if it contains old data. If the header title or the compare operator is not valid then nothing should be output to the TM5_Filter worksheet. The procedure should work for different datasets stored in the arrays. The procedure does not have any intermediate steps which use ranges to filter rows. For instance, calling the procedure with header title price, compare operator &lt;= and value 4, will output the rows of the dataset where the values in the price column is less than or equal 4. Similar calling the procedure with header title str_item_desc, compare operator in and value Gasket, will return the rows of the dataset where the values in the str_item_desc column contain the string Gasket. Hint: The course procedure AryPasteRow stored in module ModAry may be useful. Test Filter by finishing the code of procedure TM5_FilterTest that: Loads the dataset in worksheet TM5_Data1 in two arrays. Filter so get rows where price is greater than or equal 500000. Create message box with the value of cell G2 in worksheet TM5_Filter along with the column name. Given the original dataset, filter so get rows where the item description contains Gasket. Create message box with the value of cell B2 in worksheet TM5_Filter along with the column name. Add a button running the procedure to worksheet TM5_Filter. The TM5_Filter procedure can only be used with a single compare operator. Consider the dataset in worksheet TM5_Data1 and discuss how a sequence of calls to Filter can be used to find rows where price is less than or equal to 400 AND supplier id equals 11, price is less than or equal to 400 OR price is greater than or equal to 3000, (price is less than or equal to 400 AND supplier id equals 11) OR item description contains Gasket. Add your discussion as a VBA comment (at most 10 sentences). Note you should not code this, just comment. 5.10.12 Exercise - Transform data (arrange and mutate) Consider the Excel template file provided. The file contains different datasets in worksheets starting with TM5_Data. You may assume that all datasets have a header in the first row (starting in cell A1). Each column contains either doubles or strings. If the header title of a column starts with str then the column contains strings; otherwise the column contains doubles. A dataset can be stored in two arrays where one store the column headers and one the data. For instance, the following code in VBA read the data in worksheet TM5_Data1 into two arrays: Sub TM5_ReadData1() Dim aryData As Variant Dim aryHeaders() As String Dim rng As Range ThisWorkbook.Worksheets(&quot;Data1&quot;).Activate Set rng = Range(&quot;A1:&quot; &amp; RngGetCurRegionLastCol(Range(&quot;A1&quot;), asLetter:=True) &amp; &quot;1&quot;) Call AryRead(aryHeaders, rng) Set rng = RngGetCurRegionRange(Range(&quot;A1&quot;), row:=2, col:=1) Call AryRead(aryData, rng) End Sub The array storing the header titles contains strings. However, since we do not know the datatype of a column in the dataset, the array aryData is of type Variant. That is, we don’t write Dim aryData() As Variant (which we normally do when defining a dynamic array), but Dim aryData As Variant, since a variant in itself can be an array. Write a set of VBA procedures that answer/complete the following questions/tasks. All procedures MUST be documented using a skeleton similar to the examples given in the course notes (Section D1). You may use the procedures (e.g. TM5_getColumnIndex and TM5_isColumnString) from Exercise 5.10.11 as subprocedures. Given the header titles, create sub TM5_Rename that rename a header title with the following features: The function takes an array as argument containing the header titles. The function takes a string containing the header title to rename as argument. The function takes a string containing the new name of the header title as argument. If the header title to rename is present in an entry in the array, it is renamed (the array modified ByRef); otherwise the array is not modified. For instance, if the header titles are array (\"Ship\", \"Profit\", \"Cost\"), then renaming Profit to Income would modify the array to (\"Ship\", \"Income\", \"Cost\"). Create a procedure TM5_Arrange that arranges/sorts a column in a dataset stored using two arrays with the following features: The function takes the two arrays representing the dataset (header and data) as arguments. The function takes a string as argument containing the header title of the column to sort. The sorted dataset is output/pasted to the worksheet named TM5_Arrange (starting in cell A1), i.e. no new arrays are needed to store the modified dataset. This worksheet is cleared if it contains old data. The procedure should work for different datasets stored in the arrays (e.g. the dataset in worksheet TM5_Data1). The procedure does not have any intermediate steps which use ranges to sort the dataset. Hint: The course procedure AryQuickSort stored in module ModAry may be useful. Note that this procedure takes a Long as second argument. Test TM5_Arrange by writing a procedure TM5_ArrangeTest that: Loads the dataset in worksheet TM5_Data2 into two arrays (a dataset of fright handling operations). Renames the delivery_cost column to cost. Arranges the dataset based on column cost. Uses a message box to write out the meaning and value of cell E2 in worksheet TM5_Arrange. Add a button running the procedure to worksheet TM5_Arrange. Create a procedure TM5_Distinct that finds all distinct/unique values of a column in a dataset stored using two arrays with the following features: The function takes the two arrays representing the dataset (header and data) as arguments. The function takes a string as argument containing the header title from which to find distinct values. The distinct values are output/pasted to the worksheet named TM5_Distinct (starting in cell A1), i.e. no new arrays are needed to store the new dataset. This worksheet is cleared if it contains old data. The procedure should work for different datasets stored in the arrays. The procedure does not have any intermediate steps which use ranges to find distinct values. Hint: One way to find distinct values of a column could be to sort first and then output each time values in the column change. If you need to compare using strings, you may need to cast to a string using the CStr function in VBA. Test TM5_Distinct by writing a procedure TM5_DistinctTest that: Loads the dataset in worksheet TM5_Data2 into two arrays. Finds the distinct values of column str_type Uses a message box to write the number of different values. Add a button running the procedure to worksheet TM5_Distinct. Create a procedure TM5_Mutate that adds a new column to a dataset stored using two arrays with the following features: The function takes the two arrays representing the dataset (header and data) as arguments. The function takes an array with two strings as argument containing the header titles to mutate from. The function takes a string as argument containing the operator to use on the two columns. The valid operators are + : The new column is the sum of the two columns (valid if both columns are doubles). - : The new column is the first column minus the second column (valid if both columns are doubles). * : The new column is the product of the two columns (valid if both columns are doubles). / : The new column is the first column divided by the second column (valid if both columns are doubles). join : The new column (strings) is the first column joined by the second column with a separator in between (valid for all column types). The function takes a string as argument containing the name of the new column. The function takes a string as argument containing the separator used for the join operator with default value \" \". The mutated dataset is output to the worksheet named TM5_Mutate (starting in cell A1), i.e. no new arrays are needed to store the modified dataset. This worksheet is cleared if it contains old data. If the header titles or the compare operator is not valid then nothing should be output to the TM5_Mutate worksheet. The procedure should work for different datasets stored in the arrays. The procedure does not have any intermediate steps which use ranges to add columns. For instance, calling the procedure with header titles (\"income\", \"cost\"), operator - and new column \"profit\", will output the dataset with a new column profit which is the difference between columns income and cost. Test TM5_Mutate by writing a procedure TM5_MutateTest that: Loads the dataset in worksheet TM5_Data1 in two arrays. Creates a new column total which is the product of columns price and quantity. Uses a message box to write out the meaning and value of cell I2 in worksheet TM5_Mutate. Given the original dataset, create a new column ship_w_desc which is obtained by joining columns ship and str_item_desc seperated by \" - \". Add a button running the procedure to worksheet TM5_Mutate. References Boyar, J., and K. S. Larsen. 1999. “The Seat Reservation Problem.” Algorithmica 25 (4): 403–17. https://doi.org/10.1007/pl00009286. Boyar, Joan, Susan Krarup, and Morten N Nielsen. 2004. “Seat Reservation Allowing Seat Changes.” Journal of Algorithms 52 (2): 169–92. https://doi.org/10.1016/j.jalgor.2004.02.002. "],["mod-vba-random-numbers.html", "Module 6 Generating random numbers 6.1 Learning outcomes 6.2 Generating random numbers 6.3 Simulation 6.4 Recap 6.5 Exercises", " Module 6 Generating random numbers This module gives a short introduction on how to generate random numbers and using them in a simulation. Simulation studies that you do in Excel may be done easier using VBA together with Excel. For more advanced simulation studies you may use dedicated programs (such as Arena) or Excel plugins (such as @Risk). A template with VBA code is given in the file vba-template.xlsm (open it and use it while reading the notes). Have a look inside the module TM6_ex in the VBA editor for examples used in the notes and during lectures. Have a look at module TM6_exercises for exercises. Guiding answers for the exercises can be found in the file vba-solution.xlsm . Learning path diagram Click/hover the nodes to follow links and see details. 6.1 Learning outcomes By the end of this module, you are expected to be able to: Describe what a random number is. Generate a random number from a distribution. Run a simulation and compare/analyse results. The learning outcomes relate to the overall learning goals number 2-4, 8-14 and 16 of the course. 6.2 Generating random numbers Often we want to model a system where some of the elements are uncertain. To simulate the system we want to generate some random numbers following different distributions. This can be done using the built-in VBA and Excel functions for most distributions. The course procedures (module ModRand) contain a set of procedures for generating random numbers. Let us have a look at how to generate random numbers from a continuous uniform distribution: &#39;&#39; Generate a random number from a continuous uniform distribution &#39; @param dblMin Minimum number. &#39; @param dblMax Maximum number (not included). Function RandInvUniformCont(dblMin As Double, dblMax As Double) As Double RandInvUniformCont = dblMin + (dblMax - dblMin) * Rnd() End Function Here a single random number is returned. The Rnd function is used to generate random numbers in the interval \\([0,1[\\), i.e. a continuous uniform distribution. The Rnd function is a built-in VBA function. To generate random numbers between [dblMin, dblMax[, we use the formula dblMin + (dblMax - dblMin) * Rnd(). If you need more than a single random number, you can use the almost same procedure with Gen in its name instead of Inv: &#39;&#39; Generate random numbers from a continuous uniform distribution &#39; @param intSize Random numbers generated &#39; @param dblMin Minimum number. &#39; @param dblMax Maximum number (not included). &#39; @param ary Array to store the values in. Sub RandGenUniformCont(intSize As Integer, dblMin As Double, dblMax As Double, ary() As Double) Dim i As Integer ReDim ary(intSize) As Double For i = 1 To intSize ary(i) = dblMin + (dblMax - dblMin) * Rnd() Next End Sub The difference is that an array ary of intSize is used to store the random numbers. Let us consider another example, the normal distribution: &#39;&#39; Generate a random number from a normal distribution &#39; @param dblMean Mean. &#39; @param dblSD Standard deviation. Function RandInvNormal(dblMean As Double, dblSD As Double) As Double RandInvNormal = Application.WorksheetFunction.NormInv(Rnd, dblMean, dblSD) End Function The procedure takes the mean and standard deviation as arguments and return a random number. Multiple random numbers are found using: &#39;&#39; Generate random numbers from a normal distribution &#39; @param intSize Random numbers generated &#39; @param dblMean Mean. &#39; @param dblSD Standard deviation. &#39; @param ary Array to store the values in. Sub RandGenNormal(intSize As Integer, dblMean As Double, dblSD As Double, ary() As Double) Dim i As Integer ReDim ary(intSize) As Double For i = 1 To intSize ary(i) = Application.WorksheetFunction.NormInv(Rnd, dblMean, dblSD) Next End Sub Here intSize random numbers in stored in the output array ary. Similar procedures can be found for the uniform (discrete), binomial, poisson and a custom discrete distribution. Let us try some examples: Sub TM6_RandDistEx() Dim aryDens As Variant Randomize &#39; initialize random-number generator MsgBox (&quot;Normal: &quot; &amp; RandInvNormal(100, 20)) &#39; Cont. uniform [10,500[ MsgBox (&quot;Uniform (continuous): &quot; &amp; RandInvUniformCont(10, 500)) &#39; Discrete uniform 10,...,500 MsgBox (&quot;Uniform (discrete): &quot; &amp; RandInvUniformDisc(10, 500)) &#39; Binomial 100 trials, pr = 0.2 MsgBox (&quot;Binomial: &quot; &amp; RandInvBinomial(100, 0.2)) &#39; Poisson lambda = 5 MsgBox (&quot;Poisson: &quot; &amp; RandInvPoisson(5)) &#39; Custom discrete ReDim aryDens(1 To 4, 1 To 2) aryDens(1, 1) = &quot;A&quot; aryDens(2, 1) = &quot;B&quot; aryDens(3, 1) = &quot;C&quot; aryDens(4, 1) = &quot;D&quot; aryDens(1, 2) = 0.1 aryDens(2, 2) = 0.3 aryDens(3, 2) = 0.5 aryDens(4, 2) = 0.1 MsgBox (&quot;Custom (discrete): &quot; &amp; RandInvDiscrete(aryDens)) End Sub First, observe that in the start of the procedure, the Randomize procedure is called. Randomize initialize the random-number generator and it is always a good idea to call it if you want true random numbers. Next we generate a random number from the different distributions. For generating random numbers from a custom discrete distribution we need a 2D array where each row store the outcome and the probability. For instance here the probability of outcome 5 is 50%. Let us try to generate 20 random numbers from each distribution: Sub TM6_RandDistAryEx() Dim ary() As Double Dim ary1 As Variant Dim aryDens As Variant Dim intSize As Integer ThisWorkbook.Worksheets(&quot;TM6&quot;).Activate Call TM6_ClearTestTM6 Randomize &#39; initialize random-number generator intSize = 20 &#39; generate 20 numbers for each distribution &#39; Normal Call RandGenNormal(intSize, 100, 20, ary) Range(&quot;A1&quot;) = &quot;Normal&quot; Call AryPaste(ary, Range(&quot;A2&quot;), False) &#39; Cont. uniform [10,500[ Call RandGenUniformCont(intSize, 10, 500, ary) Range(&quot;B1&quot;) = &quot;Uniform&quot; Call AryPaste(ary, Range(&quot;B2&quot;), False) &#39; Discrete uniform 10,...,500 Call RandGenUniformDisc(intSize, 10, 500, ary) Range(&quot;B1&quot;) = &quot;Uniform&quot; Call AryPaste(ary, Range(&quot;B2&quot;), False) &#39; Binomial 100 trials, pr = 0.2 Call RandGenBinomial(intSize, 100, 0.2, ary) Range(&quot;C1&quot;) = &quot;Binomial&quot; Call AryPaste(ary, Range(&quot;C2&quot;), False) &#39; Poisson lambda = 5 Call RandGenPoisson(intSize, 5, ary) Range(&quot;D1&quot;) = &quot;Poisson&quot; Call AryPaste(ary, Range(&quot;D2&quot;), False) &#39; Custom discrete ReDim aryDens(1 To 4, 1 To 2) aryDens(1, 1) = &quot;A&quot; aryDens(2, 1) = &quot;B&quot; aryDens(3, 1) = &quot;C&quot; aryDens(4, 1) = &quot;D&quot; aryDens(1, 2) = 0.1 aryDens(2, 2) = 0.3 aryDens(3, 2) = 0.5 aryDens(4, 2) = 0.1 Call RandGenDiscrete(intSize, aryDens, ary1) Range(&quot;E1&quot;) = &quot;Custom&quot; Call AryPaste(ary1, Range(&quot;E2&quot;), False) Range(&quot;G3&quot;) = &quot;Custom distribution:&quot; Range(&quot;G4&quot;) = &quot;Value&quot; Range(&quot;H4&quot;) = &quot;Prob.&quot; Call AryPaste(aryDens, Range(&quot;G5&quot;)) End Sub 6.3 Simulation Given an uncertain system we simulate the system by: Constructing a deterministic model (that is we assume the random numbers have some specific values) and algorithms for solving it. Generate random numbers and use them to solve the model and store the results. Repeat a number of times and gather statistics such as minimum, mean, standard deviation or maximum value. Let us consider some examples in the next sections. 6.3.1 Example - Traveling salesman problem The travelling salesman problem (TSP) asks the following question: Given a list of cities and the distances between each pair of the cities, what is the shortest possible route that visits each city exactly once and returns to the origin city? The problem is an NP-hard problem (worst case solution time grows exponential with the number of cities) in combinatorial optimization, important in theoretical computer science and operations research. The problem was first formulated in 1930 and is one of the most intensively studied problems in optimization. Even though the problem is computationally difficult, many heuristics and exact algorithms are known. The goal with this example is to test different heuristics on a set of problem instances. To see which one works best. Let us first create a procedure TM6_GenTSPData that generate a TSP instance: &#39;&#39; Generate cities for the TSP (a TSP problem instance) &#39; @param dblCoord A (cities x 3) array to store the generated id and coordinates in (output ByRef). &#39; @param intCities Number of cities to generate. If 0 then ask. &#39; @param blnPrint If true then print out the data in columns A:C in the TM6_TSP sheet. Sub TM6_GenTSPData(dblCoord() As Double, Optional intCities As Integer = 0, _ Optional blnPrint As Boolean = False) Dim dblMin As Double Dim dblMax As Double Dim i As Integer Dim ary1() As Double, ary2() As Double Randomize &#39; Min and max values for uniform distribution dblMin = 0 dblMax = 10 &#39; Reallocate If intCities = 0 Then intCities = InputBox(&quot;How many points should I generate?&quot;) ReDim dblCoord(1 To intCities, 1 To 3) &#39; Generate random numbers Call RandGenUniformCont(intCities, dblMin, dblMax, ary1) Call RandGenUniformCont(intCities, dblMin, dblMax, ary2) For i = 1 To intCities dblCoord(i, 1) = i dblCoord(i, 2) = ary1(i) dblCoord(i, 3) = ary2(i) Next &#39;&#39; Print data If blnPrint Then ThisWorkbook.Worksheets(&quot;TM6_TSP&quot;).Activate Call TM6_ClearTestTSP Cells(1, 1).value = &quot;City&quot; Cells(1, 2).value = &quot;x-coord&quot; Cells(1, 3).value = &quot;y-coord&quot; For i = 1 To intCities Cells(i + 1, 1).value = dblCoord(i, 1) Cells(i + 1, 2).value = dblCoord(i, 2) Cells(i + 1, 3).value = dblCoord(i, 3) Next End If End Sub Note we specify the number of cities as an input argument. Each city has an id number and a \\(x\\) and \\(y\\)-coordinate and the result is stored in array dblCoord with intCities rows and three columns (column 1 store the city id, column 2 the \\(x\\)-coordinate and column 3 the \\(y\\)-coordinate). The \\(x\\) and \\(y\\)-coordinates are random numbers from an uniform distribution between 0 and 10. If blnPrint is true then coordinates are printed to the sheet and if intCities is zero then use an input box to ask for the number of cities. Figure 6.1: TSP algorithms and cost (TM6_TSP worksheet). We now can create a procedure BtnGenTSPData that calls GenTSPData, ask for the number of cities and print the result to the sheet. A button linking to the procedure is made in worksheet TM6_TSP (see Figure 6.1): Sub TM6_BtnGenTSPData() Dim dblCoord() As Double Call TM6_GenTSPData(dblCoord, 0, True) End Sub Given the \\(x\\) and \\(y\\)-coordinates of a problem instance (stored in dblCoord) we need to calculate the distance matrix: &#39;&#39; Calculate distance matrix &#39; @param dblDist The distance matrix to store distances (output ByRef). &#39; @param dblCoord A (cities x 3) array with id and coordinates. &#39; @pre Assume that dblCoord has not been sorted yet! &#39; @post Distances stored in dblDist. Sub TM6_CalcDistArray(ByRef dblDist() As Double, dblCoord() As Double) Dim i As Integer, j As Integer Dim dblDiffX As Double, dblDiffY As Double Dim intCities As Integer intCities = UBound(dblCoord, 1) ReDim dblDist(intCities, intCities) For i = 1 To intCities For j = i + 1 To intCities dblDiffX = dblCoord(i, 2) - dblCoord(j, 2) dblDiffY = dblCoord(i, 3) - dblCoord(j, 3) dblDist(i, j) = Sqr((dblDiffX * dblDiffX) + (dblDiffY * dblDiffY)) dblDist(j, i) = dblDist(i, j) &#39; assume symmetric Next Next End Sub The procedure takes the \\(x\\) and \\(y\\)-coordinates (stored in dblCoord) and calculate the distance matrix stored in dblDist, i.e. dblDist(i, j) store the euclidean distance between city i and j. Symmetric distances are assumed, i.e. dblDist(i, j) = dblDist(j, i). We are now ready to consider algorithms for calculating a TSP route. Let us first consider a procedure TM6_SolveTSPIncX that sort the array dblCoord increasing in the x-coordinate and visit the cities in the order of the sorted array and return to the starting city: &#39;&#39; Calculate visiting sequence based on increasing x-coord &#39; @param dblCoord A (cities x 3) array with id and coordinates. &#39; @param dblDist The distance matrix. &#39; @param dblCost Total cost (output ByRef). &#39; @param intSeq The visiting sequence (output ByRef). &#39; @post The total cost and sequence returned. Sub TM6_SolveTSPIncX(dblCoord() As Double, dblDist() As Double, _ dblCost As Double, intSeq() As Integer) Dim j As Integer Dim intCities As Integer &#39; Sort intCities = UBound(dblDist, 1) ReDim intSeq(intCities) Call AryQuickSort(dblCoord, 2) &#39; Store visiting sequence For j = 1 To intCities intSeq(j) = dblCoord(j, 1) Next dblCost = TM6_CalcCost(dblDist, intSeq) End Sub First, observe that we sort the array using course procedure AryQuickSort. Next, the visiting city sequence are stored in intSeq. Finally, the total cost are stored in dblCost which call the function TM6_CalcCost: &#39;&#39; Calculate the cost of a route &#39; @param dblDist The distance matrix. &#39; @param intSeq The visiting sequence (output ByRef). &#39; @return The cost of a route. Function TM6_CalcCost(dblDist() As Double, intSeq() As Integer) As Double Dim dblCost As Double Dim intCities As Integer Dim j As Integer intCities = UBound(intSeq) dblCost = 0 For j = 1 To intCities - 1 dblCost = dblCost + dblDist(intSeq(j), intSeq(j + 1)) Next TM6_CalcCost = dblCost + dblDist(intSeq(intCities), intSeq(1)) &#39; cost + cost of returning to start End Function If we want to use the algorithm on the data in sheet TM6_TSP we first need a procedure reading the data: &#39;&#39; Read the coordinates into an 2D array &#39; @param dblCoord A (cities x 3) array to store the generated id and coordinates in. &#39; @post Generated data stored in dblCoord. Sub TM6_ReadCoord(dblCoord() As Double) Dim rng As Range ThisWorkbook.Worksheets(&quot;TM6_TSP&quot;).Activate Set rng = RngGetCurRegionRange(Range(&quot;A1&quot;), 2) &#39;current region except the header Call AryRead(dblCoord, rng) End Sub and then a procedure TM6_BtnSolveTSPIncX that calls TM6_SolveTSPIncX using the TSP data in the sheet and print out the total cost in cell H4. We include a button linking to the procedure (see Figure 6.1): Sub TM6_BtnSolveTSPIncX() Dim dblCoord() As Double Dim dblDist() As Double Dim intSeq() As Integer Dim dblCost As Double Call TM6_ReadCoord(dblCoord) Call AryQuickSort(dblCoord, 1) &#39; so sure sorted by id Call TM6_CalcDistArray(dblDist, dblCoord) Call TM6_SolveTSPIncX(dblCoord, dblDist, dblCost, intSeq) Range(&quot;H3&quot;) = &quot;Cost:&quot; Range(&quot;H5&quot;) = dblCost End Sub Another algorithm TM6_SolveTSPIncY that sort the array dblCoord increasing in the \\(y\\)-coordinate and visit the cities in the order of the sorted array and return to the starting city can be made similar to above (see Figure 6.1). A possibility is also an algorithm that visit the cities in the order of the dblCoord array and return to the starting city. This may seen as we visit the cities in random order since we generate the \\(x\\) and \\(y\\)-coordinate random. Finally, we will consider a nearest neighbour algorithm. We start in City 1. Given the current city, the next city (not already visited) is the city with the shortest distance: &#39;&#39; Calculate visiting sequence based on nearest neighbour &#39; @param dblCoord A (cities x 3) array with id and coordinates. &#39; @param dblDist The distance matrix. &#39; @param dblCost Total cost. &#39; @param intSeq The visiting sequence. &#39; @post The total cost and sequence returned. Sub TM6_SolveTSPNN(dblCoord() As Double, dblDist() As Double, ByRef dblCost As Double, ByRef intSeq() As Integer) Dim i As Integer, id As Integer Dim intCities As Integer, intCurCity As Integer, intBestCity As Integer Dim dblMinDist As Double Dim intUsed() As Integer &#39; intUsed(id) = 1 if city id have been used in sequence intCities = UBound(dblDist, 1) ReDim intSeq(intCities) ReDim intUsed(intCities) &#39; Find nearst neighbor id = 1 intSeq(1) = id &#39; start in city id = 1 intUsed(id) = 1 For i = 2 To intCities &#39; find next city to add to intSeq(i) dblMinDist = 1000000 &#39; large number intCurCity = intSeq(i - 1) For id = 2 To intCities &#39; scan for next candidate (id = 1 already used) If intUsed(id) = 0 And dblDist(intCurCity, id) &lt; dblMinDist Then &#39; shorter distance found intBestCity = id dblMinDist = dblDist(intCurCity, id) End If Next intSeq(i) = intBestCity intUsed(intBestCity) = 1 Next dblCost = TM6_CalcCost(dblDist, intSeq) End Sub Here we need to have an array intUsed to store if a city already visited (equal 1 if yes). Nested loops is used to scan for the not-visited city nearest to the current one. The results for all the algorithms on an problem instance with 20 cities can be seen in Figure 6.1. We now have a set of algorithms which can be tested on some problem instances that we can generate. On the problem instance we used above the nearest neighbour algorithm seems to find the best route (shortest cost). However, we can not state that this holds in general without testing on many problem instances. Hence we want to do a simulation study with steps: Generate a problem instance with intCities cities which are chosen random between 10 and 500. Calculate the distance matrix. Solve the instance using all of the above algorithms. Store the result in a row in the TM6_TSPSim sheet. Repeat 100 times and calculate min, mean and max values for each solution algorithm. This is done in procedure TM6_TSPSim: Sub TM6_TSPSim() Dim intCities As Integer Dim s As Integer Dim dblCoord() As Double Dim dblDist() As Double Dim intSeq() As Integer Dim dblCost As Double Dim intRow As Integer &#39; Setup sheet ThisWorkbook.Worksheets(&quot;TM6_TSPSim&quot;).Activate Call RngClear(Range(&quot;A:F&quot;)) Cells(1, 1) = &quot;Simulation results&quot; Cells(3, 2) = &quot;Min&quot; Cells(4, 2) = &quot;Mean&quot; Cells(5, 2) = &quot;Max&quot; intRow = 7 Cells(intRow, 1) = &quot;Run&quot; Cells(intRow, 2) = &quot;Cities&quot; Cells(intRow, 3) = &quot;IncX&quot; Cells(intRow, 4) = &quot;IncY&quot; Cells(intRow, 5) = &quot;Random&quot; Cells(intRow, 6) = &quot;NN&quot; &#39; Run simulation For s = 1 To 100 Cells(s + intRow, 1) = s intCities = WorksheetFunction.RandBetween(10, 500) &#39; number of cities Cells(s + intRow, 2) = intCities Call TM6_GenTSPData(dblCoord, intCities, False) Call TM6_CalcDistArray(dblDist, dblCoord) Call TM6_SolveTSPIncX(dblCoord, dblDist, dblCost, intSeq) Cells(s + intRow, 3) = dblCost Call TM6_SolveTSPIncY(dblCoord, dblDist, dblCost, intSeq) Cells(s + intRow, 4) = dblCost Call TM6_SolveTSPRand(dblCoord, dblDist, dblCost, intSeq) Cells(s + intRow, 5) = dblCost Call TM6_SolveTSPNN(dblCoord, dblDist, dblCost, intSeq) Cells(s + intRow, 6) = dblCost Next &#39; Calc statistics For s = 3 To 6 Cells(3, s) = WorksheetFunction.Min(Range(Cells(intRow + 1, s), Cells(intRow + 100, s))) Cells(4, s) = WorksheetFunction.Average(Range(Cells(intRow + 1, s), Cells(intRow + 100, s))) Cells(5, s) = WorksheetFunction.Max(Range(Cells(intRow + 1, s), Cells(intRow + 100, s))) Next &#39; Format cells Call RngFormat(Cells(3, 2).CurrentRegion, &quot;green&quot;) Call RngFormat(Cells(intRow, 1).CurrentRegion, &quot;orange&quot;, True) End Sub First, we setup the worksheet TM6_TSPSim so it is ready for the results. Next, we run the simulation 100 times in a for loop. In each loop we first generate the number of instances, then a problem instance for which we find the distance matrix. The algorithms is then run on the problem instance and results are added to the worksheet. After the loop we calculate statistics for all the runs. Finally, the results are formatted for nice appearance. Figure 6.2: Simulation comparing TSP algorithms (TM6_TSPSim worksheet). The results are given in Figure 6.2. As can be seen the nearest neighbour algorithm is best and gives the shortest average distance. 6.4 Recap Often we want to model a system where some of the elements are uncertain. To simulate the system we want to generate some random numbers following different distributions. This can be done using the built-in VBA and Excel functions for most distributions. Initialize generation of random numbers using Randomize() &#39; chooses a random seed Or Randomize(100) &#39; generate the same sequence of random numbers We normally use the first option. When generating random numbers in VBA and writing them to the worksheet, they will NOT be changed when the worksheet is updated! Only when the code is executed! The course procedures (module ModRand) also contain a set of procedures for generating random numbers that are stored in an array. Given an uncertain system we simulate the system by: Constructing a deterministic model (that is we assume the random numbers have some specific values) and algorithms for solving it. Generate random numbers and use them to solve the model and store the results. Repeat a number of times and gather statistics such as minimum, mean, standard deviation or maximum value. You may also have a look at the slides for this module . 6.5 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Some of the solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up too early. Put some effort into finding a solution! A template with VBA code is given in the file vba-template.xlsm (open it and use it while reading the notes). Have a look inside the module TM6_ex in the VBA editor for examples used in the notes and during lectures. Have a look at module TM6_exercises for exercises. Guiding answers for the exercises can be found in the file vba-solution.xlsm . 6.5.1 Exercise - Two random integers This exercise is a slightly modified version an exam assignment (reexam 2021-A4). Consider worksheet TM6. Write a sub TM6_RandInt1 that reads two integer numbers, \\(a\\) and \\(b\\) (assume that \\(a &lt; b\\)) from cells B24 and B25, and generates two random integer numbers, \\(r_1\\) and \\(r_2\\), uniformly between \\(a\\) and \\(b\\) such that \\(r_1 \\neq r_2\\). The sub should write \\(r_1\\) and \\(r_2\\) in cells D24 and D25 with the smaller of the two numbers in D24. Write a sub TM6_RandInt2 that should take two integer arguments, \\(a\\) and \\(b\\), and generate two random numbers \\(r_1\\) and \\(r_2\\) following the same rules as in Question 1. However, \\(r_1\\) and \\(r_2\\) may not be written to the spreadsheet. Instead, they should be updated by calling the sub TM6_RandInt2. Write a sub TM6_RandInt2Main that call TM6_RandInt2 using \\(a=2\\) and \\(b=17\\) and output \\(r_1\\) and \\(r_2\\) in a message box. Is your code robust? What happens if \\(a&gt;b\\)? 6.5.2 Exercise - Swap entries This exercise is a slightly modified version an exam assignment (reexam 2021-A5). Consider worksheet TM6_Swap which contains a list of names (from A4) and two numbers between 1 and 20 (in B1 and B2). You may assume that the number in B2 is strictly larger than the one in B1. In the following, let \\(r_1\\) and \\(r_2\\) represent these two numbers. Sometimes, we need to change the order of the items in such lists, and in this assignment, you will be asked to do that in three different ways. Write a sub TM6_Swap1 that, given values of \\(r_1\\) and \\(r_2\\) (to be read from B1 and B2), swaps the \\(r_1\\)’th and the \\(r_2\\)’th name in the list. Print the result in column D. Write a sub TM6_Swap2 that, given values of \\(r_1\\) and \\(r_2\\) (to be read from B1 and B2), reverses the sequence from the \\(r_1\\)’th to the \\(r_2\\)’th name in the list. Print the result in column E. Write a sub TM6_Swap3 that changes the order of the names so they appear in random order. Print the result in column F. Figure 6.3 gives an example on the swap operations. Figure 6.3: Swap entries (TM6_Swap worksheet). 6.5.3 Exercise - Dan’s bakery Dan owns a small bakery baking a single cold-rised bread. The demand level \\(l\\) for bread is uncertain and on a given day the demand level equals \\(l=1\\) (low) with probability 0.2, \\(l=2\\) (medium) with probability 0.5 and \\(l=3\\) (high) with probability 0.3. The actual demand (number of customers) depends on the demand level and is Poisson distributed with mean \\(50 + 60l\\). Currently, the sales price per bread is 45 DKK and production cost 7 DKK. If a customer arrives and Dan has no bread left then he estimates the loss of goodwill to be 10 DKK. A customer always buy one bread. Dan can have 20 breads in the oven a time and hence always produce a multiple of 20 breads. Create a function TM6_DanProfit that returns the daily profit given a specific demand and production. The profit given demand \\(d\\) and production \\(p\\) using the current prices and costs is \\[(45-7)\\min(d,p) - 7\\max(0,p-d) - 10\\max(0,d-p).\\] Let the arguments of the function be: &#39; @param dblDemand Demand. &#39; @param dblProd Production. &#39; @param dblPrice Sales price. &#39; @param dblCost Production costs. &#39; @param dblGW Lost goodwill cost. Create a procedure TM6_DanSim that simulate the system for \\(y\\) days given that Dan choose to produce \\(x\\) breads each day. The procedure arguments are: &#39; @param dblProd Production (x). &#39; @param dblPrice Sales price. &#39; @param dblCost Production costs. &#39; @param dblGW Lost goodwill cost. &#39; @param aryDens Demand level density array (needed for RandGenDiscrete). &#39; @param intDays Days to simulate (y). &#39; @param aryStat Array to store the output statistics (output ByRef). The result array aryProfit has entries: number of runs (days), production sales price production cost lost goodwill cost average profit standard deviation min and max profit Create a procedure TM6_DanBtnSim that calls TM6_DanSim for production levels 20, 40, …, 400 and output the results in worksheet TM6_DanSim. The procedure must use the demand level distribution, prices and cost given in the worksheet. What is the best production level? What is the best production level if the demand levels changes to low with probability 0.7, medium with probability 0.2 and high with probability 0.1? 6.5.4 Exercise - Generating random numbers Create a procedure TM6_GenRandNumb that generate 5000 random numbers of A normal distribution with mean 100 and standard deviation 20. An continuous uniform distribution with range 10 to 500. A binomial distribution with 100 trials and a 0.2 probability of success. A poisson distribution with mean 5. Plot the results for each distribution using TM6_PlotFreq (given). 6.5.5 Exercise - Stochastic functions This exercise is a slightly modified version an exam assignment (exam 2022-A5). Given an investment of \\(x\\) thousand dollars you have the option of investing in two projects: Project 1: The profit function is \\[ \\pi_1(x) = \\begin{cases} A_1 x, &amp; \\text{if $0 \\leq x &lt; 20$}\\\\ A_2 x - 40, &amp; \\text{if $20\\leq x &lt; 50$}\\\\ A_3 x - 140 &amp; \\text{if $x \\geq 50$} \\end{cases} \\] where \\(A_i\\) is normal distributed with mean \\(2i\\) and standard deviation \\(0.1i\\). Project 2: The profit function is \\[ \\pi_2(x) = \\begin{cases} 1.25 x, &amp; \\text{if $0 \\leq x &lt; 40$}\\\\ (x - A_1)^2 + 50, &amp; \\text{if $40\\leq x &lt; 60$}\\\\ A_2 x + 510 &amp; \\text{if $x \\geq 60$} \\end{cases} \\] where \\(A_1\\) is a continuous random number between 38 and 42 (uniform distributed) and \\(A_2\\) is a continuous random number between -2 and -0.5 (uniform distributed). Create two functions (TM6_ProfitP1 and TM6_ProfitP2) that return the profit of Project 1 and 2 given investment \\(x\\) as input argument, i.e. the random samples \\(A_i\\) is calculated inside the functions. Make a sub TM6_FunctionSim that do a simulation with the following features: Considers investment sizes \\(x = 10, 20, 30, ..., 100\\). Uses 50 samples for each investment \\(x\\). Calculates the average profit and standard deviation of the two projects for each \\(x\\). Stores the results in worksheet TM6_Functions. 6.5.6 Exercise - Customer demand This exercise is a slightly modified version an exam assignment (exam 2024-A2). A company sells a product and the demand \\(D\\) of the product depends on the price \\(p\\). The demand has been estimated to be \\(D = D_1 + D_2\\), where \\(D_i\\) denote the demand from Customer Segment \\(i\\). The demand from Customer Segment 1 is stochastic and follows a custom discrete distribution: \\(D_1=\\frac{625}{p}-5\\) with probability \\(0.25\\) \\(D_1=\\frac{625}{p}\\) with probability \\(0.5\\) \\(D_1=\\frac{625}{p}+5\\) with probability \\(0.25\\) The demand from Customer Segment 2 is stochastic and follows a Possion distribution with parameter/mean equal to \\(8000/p^2\\). Hint: The course procedure RandInvPoisson stored in module ModRand may be useful. Write a set of VBA procedures that answer/complete the following questions/tasks. All procedures should be documented using a skeleton similar to the examples given in the course notes (Section D1). Create two procedures TM6_Demand1 and TM6_Demand2 that return the stochastic demand \\(D_1\\) and \\(D_2\\) given a price. Next, create a procedure TM6_Demand that use the procedures TM6_Demand1 and TM6_Demand2 to calculate the total stochastic demand. The company has a production capacity of 75 units. If the demand is above the production capacity then sales is 75 and the remaining demand is lost at a cost of \\(l\\) DKK per unit. The profit is given by the sales revenue minus the lost sales cost. Create a procedure TM6_Profit that calculates the profit given price \\(p\\) and lost sales cost \\(l\\) with the following features: Stochastic demand are used inside the procedure and returned (ByRef) The number of sold units is returned (ByRef). The number of lost sales units is returned (ByRef). The profit is returned (ByRef). The default value of \\(l\\) is 10 DKK. You may test TM6_Profit using procedure TM6_ProfitTest: Sub TM6_ProfitTest() Dim dblDemand As Double Dim dblSold As Double Dim dblLost As Double Dim dblProfit As Double Call TM6_Profit(20, dblDemand, dblSold, dblLost, dblProfit, dblCost:=20) MsgBox (&quot;The profit is &quot; &amp; dblProfit) End Sub The company consider setting the price \\(p\\) of the product in the range \\(5, \\ldots, 40\\). Make a procedure TM6_ProfitSim that does a simulation with the following features: An input box is used to give the lost sales cost \\(l\\). Given a price calculate measures: demand, number of sold units, number of lost sales units and the profit. For each price in the range do 500 runs and calculate the averages for each measure. Output the results in worksheet TM6_CustDemand so one row is given for each price with the averages. Add a button running the procedure to worksheet TM6_CustDemand. Which price gives the best profit given \\(l=15\\) (add this as a comment inside the procedure)? 6.5.7 Exercise - A simple game Consider a simple game using an uneven dice with outcomes 1-8. The outcome \\(D\\) of the dice follows a custom discrete distribution (unknown to the player): \\[ \\Pr(D = x) = \\begin{cases} 0.1, &amp; x = 1, 2, 4, 5, 7\\\\ 0.3, &amp; x = 3\\\\ 0.15, &amp; x = 6\\\\ 0.05, &amp; x = 8 \\end{cases} \\] The player of the game bet on an outcome \\(x\\), next he throws the dice 6 times and wins if the dice hit \\(x\\) at least one time. Write a set of VBA procedures that answer/complete the following questions/tasks. All procedures MUST be documented using a skeleton similar to the examples given in the course notes (Section D1). Create a function TM6_PlayAGame that returns true if the game is won given argument \\(x\\) (the number to bet on); otherwise false is returned. Create a procedure TM6_Play with the following features: Use an input box to ask for the number \\(x\\) to bet on. Play the game 4 times and store the results of each play in a collection. Use message box(s) to output which games you won or that you did not win any games. Add a button running the procedure to worksheet TM6_Game. If you bet on number \\(x\\) then it costs you \\(x/2\\) and if you win then you receive \\(x\\). That is, the profit is \\[ \\pi = \\begin{cases} -x/2, &amp; \\text{if loose}\\\\ x - x/2, &amp; \\text{if win} \\end{cases} \\] Make a sub TM6_SimGame that does a simulation with the following features: For each bet \\(x\\) calculate the average profit based on 1000 runs. Output the results in worksheet Game so one row is given for each bet \\(x\\) with the bet \\(x\\) and average profit. Add a button running the procedure to worksheet TM6_Game. Which bet gives the best average profit (add this as a comment inside the procedure)? "],["mod-r-install.html", "Module 7 Setting up R 7.1 Learning outcomes 7.2 Install R and RStudio 7.3 Setup and test Posit Cloud", " Module 7 Setting up R R is a programming language and free software environment. The R language is widely used among statisticians and data miners for developing statistical software and data analysis. For a further overview and description of the history of R see Chapter 2 in Peng (2018). R can be run from a terminal but in general you use an IDE (integrated development environment) RStudio for running R and to saving your work. R and RStudio can either be run from your laptop or using Posit Cloud which run R in the cloud using your browser. During this course it is recommend that you have R and RStudio installed on your laptop and use it to solve your exercises. Moreover, you are going to use the laptop version at the exam. We may use Posit Cloud during the lectures. Some pros and cons of using R in the cloud vs on the laptop are Cloud (Posit Cloud) Pros: Log in and you are ready to use R. No need to download anything. Packages easier to install. Everything can be run using a browser. Cons: There is a limit on user time and CPU time. You need to pay if need more time. Often slower than the desktop version. Need an internet connection. Risky to use at the exam if the internet connection is slow or is down. Use the laptop version instead. Laptop (R and RStudio) Pros: Can be used without any internet connection. No limit on user time and CPU usage. Good if computations takes a lot of time. Cons: You need to install R and RStudio to get started. Packages must be installed. Other needed programs may have to be installed. Updates must be installed. Learning path diagram Click/hover the nodes to follow links and see details. If you like a different learning style there is a lot for videos about R online. The videos have been pointed out as extra online supplements in the learning path diagram. However, they are not part of curriculum. 7.1 Learning outcomes By the end of this module, you are expected to have: Installed R and RStudio on your laptop. Tested R and RStudio on your laptop. Installed some packages on your laptop Signed up on Posit Cloud and tested it. The learning outcomes relate to the overall learning goal number 5 of the course. 7.2 Install R and RStudio R is a programming language and free software environment. The R language is widely used among statisticians and data miners for developing statistical software and data analysis. For a further overview and description of the history of R see Chapter 2 in Peng (2018). To run R you need to install it on your computer. Moreover, you need the IDE (integrated development environment) RStudio to save your work. If you have a pre-existing installation of R and/or RStudio, reinstall both to the latest versions. It can be considerably harder to run old software than new. Install R from CRAN (Comprehensive R Archive Network). Install the latest precompiled binary distribution for your operating system (use the links at the top of the CRAN page). I you are using a mac also install Xcode using the terminal and the GNU Fortran compiler see here. Install the desktop version of RStudio, a powerful user interface for R. Under Windows it is a good idea to always open R with administrator rights: Add a shortcut for RStudio (e.g. to the taskbar or desktop). Ctrl+Shift+Right-Click the shortcut and choose Properties: Choose Properties Under Shortcut click Advanced and set Run as administrator You now always can open RStudio with this shortcut. 7.2.1 Test your installation Do whatever is appropriate for your OS to launch RStudio. You should get a window similar to the screenshot you have here, but yours will be more boring because you have not written any code or made any figures yet. Put your cursor in the pane labeled Console, which is where you interact with the live R process. Create a simple object using code like x &lt;- 2 * 4 (followed by enter or return). Then inspect the x object by typing x followed by enter or return. You should see the value 8 print to screen. If yes, you have succeeded in installing R and RStudio. Try to open a new file File &gt; New File &gt; New RMarkdown…. Use the defaults and press OK. Next save the file and compile it using Knit (Ctrl+Shift+K). You have now compiled a document with R code embedded. 7.2.2 Add-on packages R is an extensible system and many people share useful codes they have developed as a package via CRAN or GitHub. To install a package from CRAN, for example the dplyr package for data manipulation, one way to do it is in the R console. install.packages(&quot;dplyr&quot;, dependencies = TRUE) By including dependencies = TRUE, we are being explicit and extra careful to install any additional packages the target package, dplyr in the example above is dependent on. Install the package tidyverse which is in fact a bundle of packages by running (note this operation may take a long time): install.packages(&quot;tidyverse&quot;, dependencies = TRUE) Check if you have successfully installed tidyverse by loading the package: library(tidyverse) If your install was unsuccessful try to install the packages who fails one by one. You may also see this short video explaining what packages are. 7.3 Setup and test Posit Cloud Posit Cloud works as your laptop version except that a workspace with projects for each module already is created. Join the Tools for Analytics workspace on Posit Cloud (signup if you have not done it yet). Click the Projects link (in the top) and open the project TM7. A personal copy of the project is loaded for you. Put your cursor in the pane labelled Console, which is where you interact with the live R process. Create a simple object using code like x &lt;- 2 * 4 (followed by enter or return). Then inspect the x object by typing x followed by enter or return. You should see the value 8 print to screen. Try to open a new file File &gt; New File &gt; New RMarkdown…. Use the defaults and press OK. Next save the file and compile it using Knit (Ctrl+Shift+K). You have now compiled a document with R code embedded. References Peng, R. D. 2018. R Programming for Data Science. https://bookdown.org/rdpeng/rprogdatascience/. "],["mod-r-workflow.html", "Module 8 R basics and workflows 8.1 Learning outcomes 8.2 Working with R at the command line in RStudio 8.3 Your first DataCamp course 8.4 Pipes 8.5 RStudio projects 8.6 Recap 8.7 Exercises", " Module 8 R basics and workflows This module contains an introduction to using R, the syntax, data types etc. Coding in R is, as VBA, best learnt by trying it out and learn by trial and error. Hence the modules often contains links to interactive tutorials. A template project for this module is given on Posit Cloud (open it and use it while reading the notes). Learning path diagram It is recommended that you follow the green learning path; however, you may like a different learning style. In the learning path diagram, there are links to alternative online content (video or reading). Note this is an alternative to the standard learning path that you may use instead (you should not do both). The learning path may also have extra content, that is NOT a part of syllabus (only look at it if you want more info)! 8.1 Learning outcomes By the end of this module, you are expected to have: Tried R and RStudio. Learned how the RStudio IDE works. Finished your first course on DataCamp. Solved your first exercises. The learning outcomes relate to the overall learning goals number 2, 5, 6, 8, 11, 13 and 15 of the course. 8.2 Working with R at the command line in RStudio R is a programming language and free software environment. The R language is widely used among statisticians and data miners for data analysis. To run R you need to install it on your laptop or use a cloud version. We will use R via RStudio. First time users often confuse the two. At its simplest, R is like a car’s engine while RStudio is like a car’s dashboard as illustrated in Figure 8.1. Figure 8.1: Analogy of difference between R and RStudio. More precisely, R is a programming language that runs computations, while RStudio is an integrated development environment (IDE) that provides an interface by adding many convenient features and tools. So just as the way of having access to a speedometer, rearview mirrors, and a navigation system makes driving much easier, using RStudio’s interface makes using R much easier as well. RStudio can be accessed using both your laptop version or Posit Cloud. We will assume that you are using R via Posit Cloud if not stated otherwise. Compared to Excel, the benefit of using Excel is that the initial learning curve is quite minimal, and most analysis can be done via point-and-click on the top panel. Once a user imports their data into the program, it’s not exceedingly hard to make basic graphs and charts. R is a programming language, however, meaning the initial learning curve is steeper. It will take you some time to become familiar with the interface and master the various functions. Luckily, using R can quickly become second-nature with practice. For a detailed comparison you may see Excel vs R: A Brief Introduction to R by Jesse Sadler. Compared to VBA, R is an interpreted language; users typically access it through a command-line or script file. To run VBA you need to compile and execute it. Launch Posit Cloud (follow this link to get to the correct project). An personal copy of the project is now created for you. Consider the panes: Console (left) Environment/History (tabbed in upper right) Files/Plots/Packages/Help (tabbed in lower right) FYI: you can change the default location of the panes, among many other things: Customizing RStudio. Now that you are set up with R and RStudio, you are probably asking yourself, “OK - now how do I use R?”. The first thing to note is that unlike other software programs like Excel or SPSS that provide point-and-click interfaces, R is an interpreted language. This means you have to type in commands written in R code. In other words, you have to code/program in R. Note that we will use the terms “coding” and “programming” interchangeably. Go into the Console, where we interact with the live R process. Make an assignment and then inspect the object you just created: x &lt;- 3 * 4 x #&gt; [1] 12 All R statements where you create objects – “assignments” – have this form: object_name &lt;- value and in my head I hear, e.g., “x equals 12”. You will make lots of assignments and the operator &lt;- is a pain to type. Do not be lazy and use =, although it would work, because it will just sow confusion later. Instead, utilize RStudio’s keyboard shortcut: Alt+- (the minus sign). Note that RStudio automatically surrounds &lt;- with spaces, which demonstrates a useful code formatting practice. Give your eyes a break and use spaces. RStudio offers many handy keyboard shortcuts. Also, check Tools &gt; Keyboard Shortcuts Help which brings up a keyboard shortcut reference card. Object names cannot start with a digit and cannot contain certain other characters such as a comma or a space. You are advised to adopt a coding convention; some use snake case others use camel case. Choose the naming convention you like best in your study group. But stick only to one of them. this_is_snake_case # note you do not use capital letters here thisIsCamelCase # you start each word with a capital letter Make another assignment: this_is_a_long_name &lt;- 2.5 To inspect this, try out RStudio’s completion facility: type the first few characters, press TAB, add characters until you agree, then press return. In VBA you have procedures and functions. In R we only use functions which always return an object. R has a mind-blowing collection of built-in functions that are accessed like so: function_name(arg1 = val1, arg2 = val2, ...) Let’s try function seq() which makes regular sequences of numbers and at the same time demo more helpful features of RStudio. Type se and hit TAB. A pop-up shows you possible completions. Specify seq() by typing more or use the up/down arrows to select. Note the floating tool-tip-type help that pops up, reminding you of a function’s arguments. If you want even more help, press F1 as directed to get the full documentation in the help tab of the lower right pane. Now open the parentheses and note the automatic addition of the closing parenthesis and the placement of the cursor in the middle. Type the arguments 1, 10 and hit return. seq(1, 10) #&gt; [1] 1 2 3 4 5 6 7 8 9 10 The above also demonstrates something about how R resolves function arguments. Type seq and press F1 or type: ?seq The Help tab of the lower right pane will show the help documentation of function seq with a description of usage, arguments, return value etc. Note all function arguments have names. You can always specify arguments using name = value form. But if you do not, R attempts to resolve by position. So above, it is assumed that we want a sequence from = 1 that goes to = 10. Since we did not specify step size, the default value of by in the function definition is used, which ends up being 1 in this case. Note since the default value for from is 1, the same result is obtained by typing: seq(to = 10) #&gt; [1] 1 2 3 4 5 6 7 8 9 10 Make this assignment and note similar help with quotation marks. yo &lt;- &quot;hello world&quot; If you just create an assignment, you do not see the value. You may see the value by: yo # same as print(yo) #&gt; [1] &quot;hello world&quot; print(yo) #&gt; [1] &quot;hello world&quot; Now look at your Environment tab in the upper right pane where user-defined objects accumulate. You can also get a listing of these objects with commands: objects() #&gt; [1] &quot;add_graph_legend&quot; &quot;addIconOld&quot; &quot;addIconTasks&quot; &quot;addSolution&quot; #&gt; [5] &quot;create_learning_path&quot; &quot;ctrSol&quot; &quot;dat&quot; &quot;eval_inline&quot; #&gt; [9] &quot;exercises_r_text&quot; &quot;g&quot; &quot;learning_path_text_r&quot; &quot;link_excel_file&quot; #&gt; [13] &quot;link_excel_file_text&quot; &quot;link_rcloud_text&quot; &quot;link_slide_file_text&quot; &quot;module_name&quot; #&gt; [17] &quot;module_number&quot; &quot;module_number_prefix&quot; &quot;project_name_prefix&quot; &quot;sheet_name_prefix&quot; #&gt; [21] &quot;strExercises&quot; &quot;strLPath&quot; &quot;this_is_a_long_name&quot; &quot;x&quot; #&gt; [25] &quot;yo&quot; ls() #&gt; [1] &quot;add_graph_legend&quot; &quot;addIconOld&quot; &quot;addIconTasks&quot; &quot;addSolution&quot; #&gt; [5] &quot;create_learning_path&quot; &quot;ctrSol&quot; &quot;dat&quot; &quot;eval_inline&quot; #&gt; [9] &quot;exercises_r_text&quot; &quot;g&quot; &quot;learning_path_text_r&quot; &quot;link_excel_file&quot; #&gt; [13] &quot;link_excel_file_text&quot; &quot;link_rcloud_text&quot; &quot;link_slide_file_text&quot; &quot;module_name&quot; #&gt; [17] &quot;module_number&quot; &quot;module_number_prefix&quot; &quot;project_name_prefix&quot; &quot;sheet_name_prefix&quot; #&gt; [21] &quot;strExercises&quot; &quot;strLPath&quot; &quot;this_is_a_long_name&quot; &quot;x&quot; #&gt; [25] &quot;yo&quot; If you want to remove the object named yo, you can do this: rm(yo) To remove everything: rm(list = ls()) or click the broom in RStudio’s Environment pane. 8.3 Your first DataCamp course DataCamp is an online platform for learning data science. We are going to use the platform for online tutorials. First, sign up to the organization Tools for analytics at DataCamp using your university e-mail here (IMPORTANT do this before running the course/tutorial below!). DataCamp runs all the courses in your browser. That is, R is run on a server and you do not use RStudio here. The first course gives an Introduction to R. You are expected to have completed the course before continuing this module! 8.4 Pipes Most functions support the pipe operator which is a powerful tool for clearly expressing a sequence of multiple operations. The native pipe operator is |&gt;, but you may also use the pipe operator %&gt;%, that comes from the magrittr package and is loaded automatically when you load tidyverse. To insert the pipe operator, you may use the RStudio keyboard shortcut Ctrl+Shift+M. This by default uses the %&gt;% pipe operator. If you want to use the native open Tools &gt; Global Options… &gt; Code and check mark Use native pipe operator … (recommended). Consider the following code: # calculate x as a sequence of operations x &lt;- 16 x &lt;- sqrt(x) x &lt;- log2(x) x #&gt; [1] 2 # same as y &lt;- log2(sqrt(16)) y #&gt; [1] 2 Note we here calculate x using a sequence of operations: \\[ \\mbox{original data (x)} \\rightarrow \\mbox{ sqrt } \\rightarrow \\mbox{ log2 }. \\] That is, we take what is left of the arrow (the object x) and put it into the function on the right of the arrow. These operations can be done using the pipe operator: library(tidyverse) x &lt;- 16 x &lt;- x |&gt; sqrt() |&gt; log2() x #&gt; [1] 2 In general, the pipe sends the result of the left side of the pipe to be the first argument of the function on the right side of the pipe. That is, you may have other arguments in your functions: 16 |&gt; sqrt() |&gt; log2() #&gt; [1] 2 16 |&gt; sqrt() |&gt; log(base = 2) # equivalent #&gt; [1] 2 The above example is simple but illustrates that you can use pipes to skip intermediate assignment operations. Later you will do more complex pipes when we consider data wrangling. For instance, mtcars |&gt; select(cyl, gear, hp, mpg) |&gt; filter(gear == 4, cyl == 4) #&gt; cyl gear hp mpg #&gt; Datsun 710 4 4 93 22.8 #&gt; Merc 240D 4 4 62 24.4 #&gt; Merc 230 4 4 95 22.8 #&gt; Fiat 128 4 4 66 32.4 #&gt; Honda Civic 4 4 52 30.4 #&gt; Toyota Corolla 4 4 65 33.9 #&gt; Fiat X1-9 4 4 66 27.3 #&gt; Volvo 142E 4 4 109 21.4 selects the columns related to cylinders, gears, horse power and miles, and then rows with cars having four cylinders and gears. For a more detailed introduction to pipes see Chapter 18 in H. Wickham (2017). 8.5 RStudio projects One day you will need to quit R, do something else and return to your analysis later. One day you will have multiple analyses going that use R and you want to keep them separate. One day you will need to bring data from the outside world into R and send numerical results and figures from R back out into the world. To handle these real life situations, you need to store your work in a project that keeps all the files associated with a project organized together (such as input data, R scripts, analytical results and figures). RStudio has built-in support for this via its [projects][rstudio-using-projects]. You may think of a project as a folder where you store all you work. On Posit Cloud you create a project inside a workspace. Projects have already been made for most modules. However, let us try to create a project in your Your Workspace workspace. Expand the left menu and select your Your Workspace workspace. Press the New Project button and select New RStudio Project. The project is now created and you can rename it in the upper left corner. Go back to the project 01-module-12 in the Tools for Analytics workspace that we will use for the remaining of the module. For RStudio on your laptop you create a project for the rest of this module by doing this: File &gt; New Project… &gt; New Directory &gt; New Project &gt;. The directory name you choose here will be the project name. Call it whatever you want (or follow me for convenience). I used tfa_testing in my tmp directory (that is tfa_testing is now a subfolder of tmp. You now need a way to store R code in your project. We will use 2 ways of storing your code. An R script file or an R Markdown document. Normally you store lines of R code in a script file that you need to run. R Markdown provides an easy way to produce a rich, fully-documented reproducible analysis. Here you combine text, figures and metadata needed to reproduce the analysis from the beginning to the end in a single file. R Markdown compiles to nicely formatted HTML, PDF, or Word. We are going to use R Markdown for larger projects (e.g. the mandatory R report). We will come back to R Markdown later. 8.5.1 Storing your code in a script file R code can be stored in a script file with file suffix .R. A script file contains a line for each R command to run (think of each line as a command added to the console). Create a new script file File &gt; New File &gt; R Script. Let us add some R code to the file: # this is a comment a &lt;- 2 b &lt;- -3 sig_sq &lt;- 0.5 x &lt;- runif(40) y &lt;- a + b * x + rnorm(40, sd = sqrt(sig_sq)) (avg_x &lt;- mean(x)) write(avg_x, &quot;avg_x.txt&quot;) plot(x, y) abline(a, b, col = &quot;purple&quot;) dev.print(pdf, &quot;toy_line_plot.pdf&quot;) Save the file as testing.R Now run each line by setting the cursor at the first line, hit Ctrl+Enter (runs the line in the Console and moves the cursor to the next line). Repeat Ctrl+Enter until you have run all the lines. Alternatively you may select all the code and hit Ctrl+Enter. Change some things in your code. For instance set a sample size n at the top, e.g. n &lt;- 40, and then replace all the hard-wired 40’s with n. Change some other minor, but detectable, stuff, e.g. alter the sample size n, the slope of the line b, the color of the line etc. Practice the different ways to rerun the code: Walk through line by line by keyboard shortcut (Ctrl+Enter) or mouse (click “Run” in the upper right corner of editor pane). Source the entire document by entering source('testing.R') in the Console or use keyboard shortcut (Shift+Ctrl+S) or mouse (click “Source” in the upper right corner of editor pane or select from the mini-menu accessible from the associated down triangle). Source with echo from the Source mini-menu. Try to get an overview of the different planes and tabs. For instance in the Files tab (lower right plane) you can get an overview of your project files. You may also see this video about projects. 8.6 Recap R is a programming language that runs computations, while RStudio is an integrated development environment (IDE) that provides an interface by adding many convenient features and tools. Adopt a naming convention. Either use snake case or use camel case. Choose the naming convention you like best in your study group. But stick only to one of them. Store your work in a project that keeps all the files associated with a project organized together (such as input data, R scripts, analytical results and figures). You may think of a project as a folder where you store all your work. This workflow will serve you well in the future: Create an RStudio project for an analytical project (a project for most modules is already created in Posit Cloud) Keep inputs there (we will soon talk about importing) Keep scripts there; edit them, run them in bits or as a whole from there Keep outputs there (like the PDF written above) Avoid using the mouse for pieces of your analytical workflow, such as loading a dataset or saving a figure. This is extremely important for the reproducibility and for making it possible to retrospectively determine how a numerical table or PDF was actually produced. Learn and use shortcuts as much as possible. For instance Alt+- for the assignment operator and Ctrl+Shift+M for the pipe operator. A reference card of shortcuts can be seen using Alt+Shift+K. Store your R commands in a script file and R scripts with a .R suffix. Comments start with one or more # symbols. Use them. RStudio helps you (de)comment selected lines with Ctrl+Shift+C (Windows and Linux) or Cmd+Shift+C (Mac). Values saved in R are stored in Objects. The interactive DataCamp course gave an introduction to some basic programming concepts and terminology: Data types: integers, doubles/numerics, logicals, and characters. Integers are values like -1, 0, 2, 4092. Doubles or numerics are a larger set of values containing both the integers but also fractions and decimal values like -24.932 and 0.8. Logicals are either TRUE or FALSE while characters are text such as “Hamilton”, “The Wire is the greatest TV show ever”, and “This ramen is delicious.” Note that characters are often denoted with the quotation marks around them. Vectors: a series of values. These are created using the c() function, where c() stands for “combine” or “concatenate.” For example, c(6, 11, 13, 31, 90, 92) creates a six element series of positive integer values . Factors: categorical data are commonly represented in R as factors. Categorical data can also be represented as strings. Data frames: rectangular spreadsheets. They are representations of datasets in R where the rows correspond to observations and the columns correspond to variables that describe the observations. Lists are general containers that can be used to store a set of different objects under one name (that is, the name of the list) in an ordered way. These objects can be matrices, vectors, data frames, even other lists, etc. It is not even required that these objects are related to each other in any way. Comparison operators known to R are: &lt; for less than, &gt; for greater than, &lt;= for less than or equal to, &gt;= for greater than or equal to, == for equal to each other (and not = which is typically used for assignment!), != not equal to each other. A pipe (|&gt;) sends the result of the left side of the pipe to be the first argument of the function on the right side of the pipe. Use pipes if you have many intermediate assignment operations. You may also have a look at the slides for this module . 8.7 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Some of the solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up too early. Put some effort into finding a solution! Always practice using shortcuts in RStudio (see Tools &gt; Keyboard Shortcuts Help). Go to the Tools for Analytics workspace and download/export the TM8 project. Open it on your laptop and have a look at the files in the exercises folder which can be used as a starting point. 8.7.1 Exercise (group work) You are not expected to start solving this exercise before you meet in your group. You have all been allocated into groups. During the course, you are expected to solve the R exercises in these groups. Before you start, it is a good idea to agree on a set of group rules: It is a good idea to have a shared place for your code. Have a look at the section Working in groups and decide on a place to share your code. Create a shared folder where you can share your projects. Agree on a coding convention. 8.7.2 Exercise (piping) Solve this exercise using a script file (e.g. exercises/pipe.R which already has been created). Remember that you can run a line in the file using Ctrl+Enter. The pipe |&gt; can be used to perform operations sequentially without having to define intermediate objects (Ctrl+Shift+M). Have a look at the dataset mtcars: head(mtcars) ?mtcars The pipe library(tidyverse) mtcars |&gt; select(cyl, gear, hp, mpg) |&gt; filter(gear == 4 &amp; cyl == 4) #&gt; cyl gear hp mpg #&gt; Datsun 710 4 4 93 22.8 #&gt; Merc 240D 4 4 62 24.4 #&gt; Merc 230 4 4 95 22.8 #&gt; Fiat 128 4 4 66 32.4 #&gt; Honda Civic 4 4 52 30.4 #&gt; Toyota Corolla 4 4 65 33.9 #&gt; Fiat X1-9 4 4 66 27.3 #&gt; Volvo 142E 4 4 109 21.4 selects the columns related to cylinders, gears, horse power and miles, and then rows with cars having four cylinders and (operator &amp;) gears. × Solution mtcars |&gt; select(mpg, hp, am, gear) #&gt; mpg hp am gear #&gt; Mazda RX4 21.0 110 1 4 #&gt; Mazda RX4 Wag 21.0 110 1 4 #&gt; Datsun 710 22.8 93 1 4 #&gt; Hornet 4 Drive 21.4 110 0 3 #&gt; Hornet Sportabout 18.7 175 0 3 #&gt; Valiant 18.1 105 0 3 #&gt; Duster 360 14.3 245 0 3 #&gt; Merc 240D 24.4 62 0 4 #&gt; Merc 230 22.8 95 0 4 #&gt; Merc 280 19.2 123 0 4 #&gt; Merc 280C 17.8 123 0 4 #&gt; Merc 450SE 16.4 180 0 3 #&gt; Merc 450SL 17.3 180 0 3 #&gt; Merc 450SLC 15.2 180 0 3 #&gt; Cadillac Fleetwood 10.4 205 0 3 #&gt; Lincoln Continental 10.4 215 0 3 #&gt; Chrysler Imperial 14.7 230 0 3 #&gt; Fiat 128 32.4 66 1 4 #&gt; Honda Civic 30.4 52 1 4 #&gt; Toyota Corolla 33.9 65 1 4 #&gt; Toyota Corona 21.5 97 0 3 #&gt; Dodge Challenger 15.5 150 0 3 #&gt; AMC Javelin 15.2 150 0 3 #&gt; Camaro Z28 13.3 245 0 3 #&gt; Pontiac Firebird 19.2 175 0 3 #&gt; Fiat X1-9 27.3 66 1 4 #&gt; Porsche 914-2 26.0 91 1 5 #&gt; Lotus Europa 30.4 113 1 5 #&gt; Ford Pantera L 15.8 264 1 5 #&gt; Ferrari Dino 19.7 175 1 5 #&gt; Maserati Bora 15.0 335 1 5 #&gt; Volvo 142E 21.4 109 1 4 Close Solution × Hint mtcars |&gt; select(___, ___, ___, ___) Close Hint Create a pipe that selects columns related to miles, horsepower, transmission and gears. × Solution mtcars |&gt; select(mpg, hp, am, gear) |&gt; filter(mpg &lt; 20, gear == 4) #&gt; mpg hp am gear #&gt; Merc 280 19.2 123 0 4 #&gt; Merc 280C 17.8 123 0 4 Close Solution × Hint mtcars |&gt; select(mpg, hp, am, gear) |&gt; filter(___, ___) Close Hint Given the answer in 1), filter so cars have miles less than 20 and 4 gears. × Solution mtcars |&gt; select(mpg, hp, am, gear) |&gt; filter(mpg &lt; 20 | gear == 4) #&gt; mpg hp am gear #&gt; Mazda RX4 21.0 110 1 4 #&gt; Mazda RX4 Wag 21.0 110 1 4 #&gt; Datsun 710 22.8 93 1 4 #&gt; Hornet Sportabout 18.7 175 0 3 #&gt; Valiant 18.1 105 0 3 #&gt; Duster 360 14.3 245 0 3 #&gt; Merc 240D 24.4 62 0 4 #&gt; Merc 230 22.8 95 0 4 #&gt; Merc 280 19.2 123 0 4 #&gt; Merc 280C 17.8 123 0 4 #&gt; Merc 450SE 16.4 180 0 3 #&gt; Merc 450SL 17.3 180 0 3 #&gt; Merc 450SLC 15.2 180 0 3 #&gt; Cadillac Fleetwood 10.4 205 0 3 #&gt; Lincoln Continental 10.4 215 0 3 #&gt; Chrysler Imperial 14.7 230 0 3 #&gt; Fiat 128 32.4 66 1 4 #&gt; Honda Civic 30.4 52 1 4 #&gt; Toyota Corolla 33.9 65 1 4 #&gt; Dodge Challenger 15.5 150 0 3 #&gt; AMC Javelin 15.2 150 0 3 #&gt; Camaro Z28 13.3 245 0 3 #&gt; Pontiac Firebird 19.2 175 0 3 #&gt; Fiat X1-9 27.3 66 1 4 #&gt; Ford Pantera L 15.8 264 1 5 #&gt; Ferrari Dino 19.7 175 1 5 #&gt; Maserati Bora 15.0 335 1 5 #&gt; Volvo 142E 21.4 109 1 4 Close Solution × Hint mtcars |&gt; select(mpg, hp, am, gear) |&gt; filter(___ | ___) Close Hint Given the answer in 1), filter so cars have miles less than 20 or 4 gears. The “or” operator in R is |. × Solution mtcars |&gt; filter(mpg &lt; 20, gear == 4) |&gt; select(wt, vs) #&gt; wt vs #&gt; Merc 280 3.44 1 #&gt; Merc 280C 3.44 1 Close Solution × Hint mtcars |&gt; filter(mpg &lt; 20, gear == 4) |&gt; select(___, ___) Close Hint Create a pipe that filters the cars having miles less than 20 and 4 gears and selects columns related to weight and engine. × Solution dat &lt;- mtcars dat &lt;- filter(dat, mpg &lt; 20, gear == 4) dat &lt;- select(dat, wt, vs) dat #&gt; wt vs #&gt; Merc 280 3.44 1 #&gt; Merc 280C 3.44 1 Close Solution × Hint dat &lt;- mtcars dat &lt;- filter(dat, ___) dat &lt;- select(dat, ___) dat Close Hint Solve Question 4 without the pipe operator. 8.7.3 Exercise (working dir) Do this exercise from the Console in RStudio. When reading and writing to local files, your working directory becomes important. You can get and set the working directory using functions getwd and setwd. Set the working directory to the project directory using the menu: Session &gt; Set Working Directory &gt; To Project Directory. Now let us create some files: library(tidyverse) dir.create(&quot;subfolder&quot;, showWarnings = FALSE) write_file(&quot;Some text in a file&quot;, file = &quot;test1.txt&quot;) write_file(&quot;Some other text in a file&quot;, file = &quot;subfolder/test2.txt&quot;) Which folders and files have been created? You may have a look in the Files tab in RStudio. We can read the file again using: read_file(&quot;test1.txt&quot;) × Solution read_file(&quot;subfolder/test2.txt&quot;) Close Solution × Hint read_file(&quot;subfolder/___&quot;) Close Hint Read the file test2.txt. Set the working directory to subfolder using function setwd. Note that setwd supports relative paths. Check that you are in the right working directory using getwd. You may also have a look at the files in the directory using function list.files. × Solution setwd(&quot;subfolder&quot;) # done in Q3 read_file(&quot;../test1.txt&quot;) read_file(&quot;test2.txt&quot;) Close Solution × Hint setwd(&quot;subfolder&quot;) # done in Q3 read_file(&quot;../___&quot;) read_file(&quot;___&quot;) Close Hint Read files test1.txt and test2.txt. Note that in relative paths ../ means going to the parent folder. What is different compared to Question 2? 8.7.4 Exercise (vectors) Solve this exercise using a script file. × Solution n &lt;- 100 n * (n+1) / 2 #&gt; [1] 5050 Close Solution What is the sum of the first 100 positive integers? The formula for the sum of integers \\(1\\) through \\(n\\) is \\(n(n+1)/2\\). Define \\(n=100\\) and then use R to compute the sum of \\(1\\) through \\(100\\) using the formula. What is the sum? × Solution n &lt;- 1000 n * (n+1) / 2 #&gt; [1] 5e+05 Close Solution Now use the same formula to compute the sum of the integers from 1 through 1000. × Solution The answer is b). Close Solution Look at the result of typing the following code into R: n &lt;- 1000 x &lt;- seq(1, n) sum(x) Based on the result, what do you think the functions seq and sum do? You can use e.g help(\"sum\") or ?sum. sum creates a list of numbers and seq adds them up. seq creates a list of numbers and sum adds them up. seq creates a random list and sum computes the sum of 1 through 1,000. sum always returns the same number. × Solution Sample 30 integers in the range [1, 100]. Close Solution Run code. What does sample.int do (try running ?sample.int)? set.seed(123) v &lt;- sample.int(100,30) v #&gt; [1] 31 79 51 14 67 42 50 43 97 25 90 69 57 9 72 26 7 95 87 36 78 93 76 15 32 84 82 41 23 27 × Solution sum(v) #&gt; [1] 1598 mean(v) #&gt; [1] 53.3 sd(v) #&gt; [1] 28.8 Close Solution What is the sum, mean, and standard deviation of v? × Solution v[c(1, 6, 4, 15)] #&gt; [1] 31 42 14 72 Close Solution × Hint v[c(1, ___, ___, ___)] Close Hint Select elements 1, 6, 4, and 15 of v. × Solution v[v &gt; 50] #&gt; [1] 79 51 67 97 90 69 57 72 95 87 78 93 76 84 82 Close Solution Select elements with value above 50. × Solution v[v &gt; 75 | v &lt; 25] #&gt; [1] 79 14 97 90 9 7 95 87 78 93 76 15 84 82 23 Close Solution × Hint v[___ | ___] Close Hint Select elements with value above 75 or below 25. × Solution v[v == 43] #&gt; [1] 43 Close Solution Select elements with value 43. × Solution v[is.na(v)] #&gt; integer(0) Close Solution × Hint v[is.na(___)] Close Hint Select elements with value NA. × Solution which(v &gt; 75 | v &lt; 25) #&gt; [1] 2 4 9 11 14 17 18 19 21 22 23 24 26 27 29 Close Solution × Hint which(___ | ___) Close Hint Which elements have value above 75 or below 25? Hint: see the documentation of function which (?which). 8.7.5 Exercise (matrices) Solve this exercise using a script file. Consider matrices m1 &lt;- matrix(c(37, 8, 51, NA, 50, 97, 86, NA, 84, 46, 17, 62L), nrow = 3) m2 &lt;- matrix(c(37, 8, 51, NA, 50, 97, 86, NA, 84, 46, 17, 62L), nrow = 3, byrow = TRUE) m3 &lt;- matrix(c(37, 8, 51, NA, 50, 97, 86, NA, 84, 46, 17, 62L), ncol = 3) What is the difference between the three matrices (think/discuss before running the code). × Solution rowSums(m1, na.rm = T) #&gt; [1] 169 75 294 colSums(m2, na.rm = T) #&gt; [1] 171 151 154 62 Close Solution × Hint rowSums(___, na.rm = ___) colSums(___, na.rm = ___) Close Hint Calculate the row sums of m1 and column sums of m2 ignoring NA values. Hint: have a look at the documentation of rowSums. × Solution rbind(m1, c(1, 2, 3, 4)) #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 37 NA 86 46 #&gt; [2,] 8 50 NA 17 #&gt; [3,] 51 97 84 62 #&gt; [4,] 1 2 3 4 Close Solution × Hint rbind(___, ___) Close Hint Add row c(1, 2, 3, 4) as last row to m1. × Solution rbind(c(1, 2, 3, 4), m1) #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 1 2 3 4 #&gt; [2,] 37 NA 86 46 #&gt; [3,] 8 50 NA 17 #&gt; [4,] 51 97 84 62 Close Solution × Hint rbind(___, ___) Close Hint Add row c(1, 2, 3, 4) as first row to m1. × Solution cbind(m3, c(1, 2, 3, 4)) #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 37 50 84 1 #&gt; [2,] 8 97 46 2 #&gt; [3,] 51 86 17 3 #&gt; [4,] NA NA 62 4 Close Solution × Hint cbind(___, ___) Close Hint Add column c(1, 2, 3, 4) as last column to m3. × Solution m1[2,4] #&gt; [1] 17 Close Solution Select the element in row 2 and column 4 of m1. × Solution m1[2:3,1:2] #&gt; [,1] [,2] #&gt; [1,] 8 50 #&gt; [2,] 51 97 Close Solution × Hint m1[2:3,___] Close Hint Select elements in rows 2-3 and columns 1-2 of m1. × Solution m1[3, c(1,3,4)] #&gt; [1] 51 84 62 Close Solution × Hint m1[3,___] Close Hint Select elements in row 3 and columns 1, 3 and 4 of m1. × Solution m1[3,] #&gt; [1] 51 97 84 62 Close Solution Select elements in row 3 of m1. × Solution m2[is.na(m2)] #&gt; [1] NA NA Close Solution × Hint m2[is.na(___)] Close Hint Select all NA elements in m2. × Solution m2[m2 &gt; 50] #&gt; [1] 84 97 51 86 NA NA 62 Close Solution Select all elements greater that 50 in m2. 8.7.6 Exercise (data frames) Solve this exercise using a script file. Data frames may be seen as cell blocks in Excel. They are representations of datasets in R where the rows correspond to observations and the columns correspond to variables that describe the observations. We consider the data frame mtcars: str(mtcars) glimpse(mtcars) ?mtcars Use the head and tail functions to have a look at the data. × Solution mtcars[,4] #&gt; [1] 110 110 93 110 175 105 245 62 95 123 123 180 180 180 205 215 230 66 52 65 97 150 150 245 #&gt; [25] 175 66 91 113 264 175 335 109 mtcars[,&quot;hp&quot;] #&gt; [1] 110 110 93 110 175 105 245 62 95 123 123 180 180 180 205 215 230 66 52 65 97 150 150 245 #&gt; [25] 175 66 91 113 264 175 335 109 mtcars$hp #&gt; [1] 110 110 93 110 175 105 245 62 95 123 123 180 180 180 205 215 230 66 52 65 97 150 150 245 #&gt; [25] 175 66 91 113 264 175 335 109 Close Solution × Hint mtcars[,___] mtcars[,&quot;___&quot;] mtcars$___ Close Hint Select column hp using index (column 4), its name, and the $ operator. × Solution mtcars1 &lt;- rbind(mtcars, c(34, 3, 87, 112, 4.5, 1.515, 167, 1, 1, 5, 3)) rownames(mtcars1)[33] &lt;- &quot;Phantom XE&quot; Close Solution × Hint mtcars1 &lt;- rbind(mtcars, ___) rownames(mtcars1)[___] &lt;- &quot;Phantom XE&quot; Close Hint Update mtcars by adding row c(34, 3, 87, 112, 4.5, 1.515, 167, 1, 1, 5, 3). Name the row ‘Phantom XE’. × Solution col &lt;- c(NA, &quot;green&quot;, &quot;blue&quot;, &quot;red&quot;, NA, &quot;blue&quot;, &quot;green&quot;, &quot;blue&quot;, &quot;red&quot;, &quot;red&quot;, &quot;blue&quot;, &quot;green&quot;, &quot;blue&quot;, &quot;blue&quot;, &quot;green&quot;, &quot;red&quot;, &quot;red&quot;, NA, NA, &quot;red&quot;, &quot;green&quot;, &quot;red&quot;, &quot;red&quot;, NA, &quot;green&quot;, NA, &quot;blue&quot;, &quot;green&quot;, &quot;green&quot;, &quot;red&quot;, &quot;green&quot;, &quot;blue&quot;, NA) mtcars1 &lt;- cbind(mtcars1, col) class(mtcars1$col) #&gt; [1] &quot;character&quot; Close Solution × Hint col &lt;- c(NA, &quot;green&quot;, ......) mtcars1 &lt;- cbind(mtcars1, ___) class(mtcars1$___) Close Hint Update mtcars by adding column: col &lt;- c(NA, &quot;green&quot;, &quot;blue&quot;, &quot;red&quot;, NA, &quot;blue&quot;, &quot;green&quot;, &quot;blue&quot;, &quot;red&quot;, &quot;red&quot;, &quot;blue&quot;, &quot;green&quot;, &quot;blue&quot;, &quot;blue&quot;, &quot;green&quot;, &quot;red&quot;, &quot;red&quot;, NA, NA, &quot;red&quot;, &quot;green&quot;, &quot;red&quot;, &quot;red&quot;, NA, &quot;green&quot;, NA, &quot;blue&quot;, &quot;green&quot;, &quot;green&quot;, &quot;red&quot;, &quot;green&quot;, &quot;blue&quot;, NA) What class is column col? × Solution mtcars1[mtcars1$vs == 0,] #&gt; mpg cyl disp hp drat wt qsec vs am gear carb col #&gt; Mazda RX4 21.0 6 160 110 3.90 2.62 16.5 0 1 4 4 &lt;NA&gt; #&gt; Mazda RX4 Wag 21.0 6 160 110 3.90 2.88 17.0 0 1 4 4 green #&gt; Hornet Sportabout 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 &lt;NA&gt; #&gt; Duster 360 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 green #&gt; Merc 450SE 16.4 8 276 180 3.07 4.07 17.4 0 0 3 3 green #&gt; Merc 450SL 17.3 8 276 180 3.07 3.73 17.6 0 0 3 3 blue #&gt; Merc 450SLC 15.2 8 276 180 3.07 3.78 18.0 0 0 3 3 blue #&gt; Cadillac Fleetwood 10.4 8 472 205 2.93 5.25 18.0 0 0 3 4 green #&gt; Lincoln Continental 10.4 8 460 215 3.00 5.42 17.8 0 0 3 4 red #&gt; Chrysler Imperial 14.7 8 440 230 3.23 5.34 17.4 0 0 3 4 red #&gt; Dodge Challenger 15.5 8 318 150 2.76 3.52 16.9 0 0 3 2 red #&gt; AMC Javelin 15.2 8 304 150 3.15 3.44 17.3 0 0 3 2 red #&gt; Camaro Z28 13.3 8 350 245 3.73 3.84 15.4 0 0 3 4 &lt;NA&gt; #&gt; Pontiac Firebird 19.2 8 400 175 3.08 3.85 17.1 0 0 3 2 green #&gt; Porsche 914-2 26.0 4 120 91 4.43 2.14 16.7 0 1 5 2 blue #&gt; Ford Pantera L 15.8 8 351 264 4.22 3.17 14.5 0 1 5 4 green #&gt; Ferrari Dino 19.7 6 145 175 3.62 2.77 15.5 0 1 5 6 red #&gt; Maserati Bora 15.0 8 301 335 3.54 3.57 14.6 0 1 5 8 green Close Solution × Hint mtcars1[mtcars1$___ == 0,] Close Hint Select cars with a V-shaped engine. 8.7.7 Exercise (lists) Solve this exercise using a script file. Lists are general containers that can be used to store a set of different objects under one name (that is, the name of the list) in an ordered way. These objects can be matrices, vectors, data frames, even other lists, etc. Let us define a list: lst &lt;- list(45, &quot;Lars&quot;, TRUE, 80.5) lst #&gt; [[1]] #&gt; [1] 45 #&gt; #&gt; [[2]] #&gt; [1] &quot;Lars&quot; #&gt; #&gt; [[3]] #&gt; [1] TRUE #&gt; #&gt; [[4]] #&gt; [1] 80.5 Elements can be accessed using brackets: x &lt;- lst[2] x #&gt; [[1]] #&gt; [1] &quot;Lars&quot; y &lt;- lst[[2]] y #&gt; [1] &quot;Lars&quot; × Solution class(x) #&gt; [1] &quot;list&quot; class(y) #&gt; [1] &quot;character&quot; Close Solution × Hint class(___) class(___) Close Hint What is the class of the two objects x and y? What is the difference between using one or two brackets? × Solution names(lst) &lt;- c(&quot;age&quot;, &quot;name&quot;, &quot;male&quot;, &quot;weight&quot;) lst #&gt; $age #&gt; [1] 45 #&gt; #&gt; $name #&gt; [1] &quot;Lars&quot; #&gt; #&gt; $male #&gt; [1] TRUE #&gt; #&gt; $weight #&gt; [1] 80.5 Close Solution × Hint names(lst) &lt;- c(&quot;age&quot;, ___, ___, ___) lst Close Hint Add names age, name, male and weight to the 4 components of the list. × Solution lst$name #&gt; [1] &quot;Lars&quot; Close Solution Extract the name component using the $ operator. You can add/change/remove components using: lst$height &lt;- 173 # add component lst$name &lt;- list(first = &quot;Lars&quot;, last = &quot;Nielsen&quot;) # change the name component lst$male &lt;- NULL # remove male component lst #&gt; $age #&gt; [1] 45 #&gt; #&gt; $name #&gt; $name$first #&gt; [1] &quot;Lars&quot; #&gt; #&gt; $name$last #&gt; [1] &quot;Nielsen&quot; #&gt; #&gt; #&gt; $weight #&gt; [1] 80.5 #&gt; #&gt; $height #&gt; [1] 173 × Solution lst$name$last #&gt; [1] &quot;Nielsen&quot; Close Solution × Hint lst$name$___ Close Hint Extract the last name component using the $ operator. 8.7.8 Exercise (string management) Strings in R can be defined using single or double quotes: str1 &lt;- &quot;Business Analytics (BA) refers to the scientific process of transforming data into insight for making better decisions in business.&quot; str2 &lt;- &#39;BA can both be seen as the complete decision making process for solving a business problem or as a set of methodologies that enable the creation of business value.&#39; str3 &lt;- c(str1, str2) # vector of strings The stringr package in tidyverse provides many useful functions for string manipulation. We will consider a few. str4 &lt;- str_c(str1, str2, &quot;As a process it can be characterized by descriptive, predictive, and prescriptive model building using data sources.&quot;, sep = &quot; &quot;) # join strings str4 #&gt; [1] &quot;Business Analytics (BA) refers to the scientific process of transforming data into insight for making better decisions in business. BA can both be seen as the complete decision making process for solving a business problem or as a set of methodologies that enable the creation of business value. As a process it can be characterized by descriptive, predictive, and prescriptive model building using data sources.&quot; str_c(str3, collapse = &quot; &quot;) # collapse vector to a string #&gt; [1] &quot;Business Analytics (BA) refers to the scientific process of transforming data into insight for making better decisions in business. BA can both be seen as the complete decision making process for solving a business problem or as a set of methodologies that enable the creation of business value.&quot; str_replace(str2, &quot;BA&quot;, &quot;Business Analytics&quot;) # replace first occurrence #&gt; [1] &quot;Business Analytics can both be seen as the complete decision making process for solving a business problem or as a set of methodologies that enable the creation of business value.&quot; str_replace_all(str2, &quot;the&quot;, &quot;a&quot;) # replace all occurrences #&gt; [1] &quot;BA can both be seen as a complete decision making process for solving a business problem or as a set of methodologies that enable a creation of business value.&quot; str_remove(str1, &quot; for making better decisions in business&quot;) #&gt; [1] &quot;Business Analytics (BA) refers to the scientific process of transforming data into insight.&quot; str_detect(str2, &quot;BA&quot;) # detect a pattern #&gt; [1] TRUE × Solution str_detect(str1, &quot;Business&quot;) #&gt; [1] TRUE str_detect(str2, &quot;Business&quot;) #&gt; [1] FALSE Close Solution × Hint str_detect(str1, ___) str_detect(___, ___) Close Hint Is Business (case sensitive) contained in str1 and str2? × Solution str5 &lt;- str_replace(str2, &quot;BA&quot;, &quot;Business Analytics&quot;) str5 #&gt; [1] &quot;Business Analytics can both be seen as the complete decision making process for solving a business problem or as a set of methodologies that enable the creation of business value.&quot; Close Solution × Hint str5 &lt;- str_replace(str2, ___, ___) Close Hint Define a new string that replace BA with Business Analytics in str2 × Solution str5 &lt;- str_remove(str5, &quot; or as a set of methodologies that enable the creation of business value&quot;) str5 #&gt; [1] &quot;Business Analytics can both be seen as the complete decision making process for solving a business problem.&quot; Close Solution × Hint str5 &lt;- str_remove(str5, ___) Close Hint In the string from Question 2, remove or as a set of methodologies that enable the creation of business value. × Solution str5 &lt;- str_c(str5, &quot;This course will focus on programming and descriptive analytics.&quot;, sep= &quot; &quot;) str5 #&gt; [1] &quot;Business Analytics can both be seen as the complete decision making process for solving a business problem. This course will focus on programming and descriptive analytics.&quot; Close Solution × Hint str5 &lt;- str_c(str5, ___, sep= ___) Close Hint In the string from Question 3, add This course will focus on programming and descriptive analytics.. × Solution str5 &lt;- str_replace(str5, &quot;analytics&quot;, &quot;business analytics&quot;) str5 #&gt; [1] &quot;Business Analytics can both be seen as the complete decision making process for solving a business problem. This course will focus on programming and descriptive business analytics.&quot; Close Solution × Hint str5 &lt;- str_replace(str5, ___, ___) Close Hint In the string from Question 4, replace analytics with business analytics. × Solution str_replace(str2, &quot;BA&quot;, &quot;Business Analytics&quot;) |&gt; str_remove(&quot; or as a set of methodologies that enable the creation of business value&quot;) |&gt; str_c(&quot;This course will focus on programming and descriptive analytics.&quot;, sep= &quot; &quot;) |&gt; str_replace(&quot;analytics&quot;, &quot;business analytics&quot;) #&gt; [1] &quot;Business Analytics can both be seen as the complete decision making process for solving a business problem. This course will focus on programming and descriptive business analytics.&quot; Close Solution × Hint str_replace(str2, ___, ___) |&gt; str_remove(___) |&gt; str_c(___) |&gt; str_replace(___) Close Hint Do all calculations in Question 2-5 using pipes. References Wickham, H. 2017. R for Data Science. O’Reilly. https://r4ds.had.co.nz/. "],["mod-r-loops-cond.html", "Module 9 Loops and conditionals 9.1 Learning outcomes 9.2 Conditionals and control flow 9.3 Loops 9.4 Recap 9.5 Exercises", " Module 9 Loops and conditionals This module considers programming with loops and conditional statements in R. A template project for this module is given on Posit Cloud (open it and use it while reading the notes). Learning path diagram It is recommended that you follow the green learning path; however, you may like a different learning style. In the learning path diagram, there are links to alternative online content (video or reading). Note this is an alternative to the standard learning path that you may use instead (you should not do both). The learning path may also have extra content, that is NOT a part of syllabus (only look at it if you want more info)! 9.1 Learning outcomes By the end of this module, you are expected to be able to: Formulate conditional statements. Use functions any and all. Formulate loops in R using for and while statements. Use function if_else. The learning outcomes relate to the overall learning goals number 2, 4 and 10 of the course. 9.2 Conditionals and control flow An excellent introduction to conditionals and if statements is given in Chapter 1 of the interactive DataCamp course Intermediate R. Please complete the chapter before continuing. Some functions are also useful for comparing logical data types. Consider this example: x &lt;- c(1, 3, 5, 10, 2, 17, 11, NA, 4) x &gt; 10 # are the elements greater that 10 #&gt; [1] FALSE FALSE FALSE FALSE FALSE TRUE TRUE NA FALSE any(x &gt; 10) # are any of the elements greater that 10 #&gt; [1] TRUE all(x &gt; 10) # are all of the elements greater that 10 #&gt; [1] FALSE all(x &lt; 20) # are all of the elements greater that 20 #&gt; [1] NA all(x &lt; 20, na.rm = TRUE) # are all of the elements greater that 20 #&gt; [1] TRUE That is, functions any and all can be used to join logical values in vectors. Some if statements can be written alternatively using function if_else: if_else(condition, true, false, missing = NULL) For example: x &lt;- c(-5:5, NA) x #&gt; [1] -5 -4 -3 -2 -1 0 1 2 3 4 5 NA ## using if and for res &lt;- rep(&quot;&quot;, length(x)) for (i in seq_along(x)) { if (is.na(x[i])) res[i] &lt;- &quot;missing&quot; else if (x[i] &lt; 0) res[i] &lt;- &quot;negative&quot; else res[i] &lt;- &quot;positive&quot; } res #&gt; [1] &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;positive&quot; &quot;positive&quot; &quot;positive&quot; #&gt; [9] &quot;positive&quot; &quot;positive&quot; &quot;positive&quot; &quot;missing&quot; ## implicit if statement res &lt;- rep(&quot;&quot;, length(x)) res #&gt; [1] &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; res[x &lt; 0] &lt;- &quot;negative&quot; res[x &gt;= 0] &lt;- &quot;positive&quot; res[is.na(x)] &lt;- &quot;missing&quot; res #&gt; [1] &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;positive&quot; &quot;positive&quot; &quot;positive&quot; #&gt; [9] &quot;positive&quot; &quot;positive&quot; &quot;positive&quot; &quot;missing&quot; ## using if_else res &lt;- if_else(x &lt; 0, &quot;negative&quot;, &quot;positive&quot;, &quot;missing&quot;) res #&gt; [1] &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;positive&quot; &quot;positive&quot; &quot;positive&quot; #&gt; [9] &quot;positive&quot; &quot;positive&quot; &quot;positive&quot; &quot;missing&quot; 9.3 Loops An excellent introduction to conditionals and if statements is given in Chapter 2 of the interactive DataCamp course Intermediate R. Please complete the chapter before continuing (stop when Chapter 2 finishes). Loops in R may be slow. However, not if you follow some golden rules: Do not use a loop when a vectorized alternative exists. Do not grow objects (via c, cbind, etc) during the loop - R has to create a new object and copy across the information just to add a new element or row/column. Instead, allocate an object to hold the results and fill it in during the loop. As an example, consider the for loop with 4 iterations: i_val &lt;- c(1,2,6,9) res &lt;- rep(NA,4) res #&gt; [1] NA NA NA NA for (idx in 1:length(i_val)) { res[idx] &lt;- 6 * i_val[idx] + 9 } res #&gt; [1] 15 21 45 63 Note we allocate memory for the result vector before the loop so we do not have to grow the result object. Next, we calculate results \\(6i+9\\) using a loop. Be careful here! This is not the same: res &lt;- rep(NA,4) for (i in i_val) { res[i] &lt;- 6 * i + 9 } res #&gt; [1] 15 21 NA NA NA 45 NA NA 63 In this example, however, we can use a vectorized alternative: res &lt;- 6 * i_val + 9 res #&gt; [1] 15 21 45 63 where the operation is applied to each element in the vector. Nested for loops is also possible. A simple example of a nested loop: for (i in 1:3) { for (j in 1:2) { cat(str_c(&quot;i =&quot;, i, &quot; j = &quot;,j, &quot;\\n&quot;)) } } #&gt; i =1 j = 1 #&gt; i =1 j = 2 #&gt; i =2 j = 1 #&gt; i =2 j = 2 #&gt; i =3 j = 1 #&gt; i =3 j = 2 We here use the function cat to print out a string (\\n indicates new line). Note how the nested loops are executed: Set i = 1 (outer loop) Set j = 1 (inner loop), i stays 1 Set j = 2 (inner loop), i stays 1 Inner loop finishes, proceed with outer loop. Increase i = 2 (outer loop) Set j = 1 (inner loop), i stays 2 Set j = 2 (inner loop), i stays 2 Inner loop finishes, proceed with outer loop. Increase i = 3 (outer loop) Set j = 1 (inner loop), i stays 3 Set j = 2 (inner loop), i stays 3 Inner loop finishes, proceed with outer loop. Outer loop finishes as well (we looped over i in 1:3). Job done. Nested loops can be used to iterate over matrices or data frames: mat &lt;- matrix(NA, nrow = 2, ncol = 3) mat #&gt; [,1] [,2] [,3] #&gt; [1,] NA NA NA #&gt; [2,] NA NA NA for (i in 1:nrow(mat)) { for (j in 1:ncol(mat)) { mat[i,j] &lt;- (i-1)*ncol(mat) + j cat(str_c(&quot;Entry (&quot;, i, &quot;, &quot;, j, &quot;) = &quot;, mat[i,j], &quot;\\n&quot;)) } } #&gt; Entry (1, 1) = 1 #&gt; Entry (1, 2) = 2 #&gt; Entry (1, 3) = 3 #&gt; Entry (2, 1) = 4 #&gt; Entry (2, 2) = 5 #&gt; Entry (2, 3) = 6 mat #&gt; [,1] [,2] [,3] #&gt; [1,] 1 2 3 #&gt; [2,] 4 5 6 Often you can replace nested loops with a single loop by using expand_grid: library(tidyverse) # load function expand_grid mat &lt;- matrix(NA, nrow = 2, ncol = 3) ite &lt;- expand_grid(i = 1:2, j=1:3) ite #&gt; # A tibble: 6 × 2 #&gt; i j #&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 1 1 #&gt; 2 1 2 #&gt; 3 1 3 #&gt; 4 2 1 #&gt; 5 2 2 #&gt; 6 2 3 for (r in 1:nrow(ite)) { # iterate over rows i &lt;- ite$i[r] j &lt;- ite$j[r] mat[i,j] &lt;- (i-1)*ncol(mat) + j cat(str_c(&quot;Entry (&quot;, i, &quot;, &quot;, j, &quot;) = &quot;, mat[i,j], &quot;\\n&quot;)) } #&gt; Entry (1, 1) = 1 #&gt; Entry (1, 2) = 2 #&gt; Entry (1, 3) = 3 #&gt; Entry (2, 1) = 4 #&gt; Entry (2, 2) = 5 #&gt; Entry (2, 3) = 6 mat #&gt; [,1] [,2] [,3] #&gt; [1,] 1 2 3 #&gt; [2,] 4 5 6 Note expand_grid creates a data frame with all combinations. This way of looping is a more flexible approach since you can nest more loops by adding more columns to ite, add different values in each column. For instance, if you only want to calculate values for row 2 and columns 1 and 3 the code becomes: mat &lt;- matrix(NA, nrow = 2, ncol = 3) ite &lt;- expand_grid(i = 2, j = c(1,3)) ite #&gt; # A tibble: 2 × 2 #&gt; i j #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2 1 #&gt; 2 2 3 for (r in 1:nrow(ite)) { # iterate over rows i &lt;- ite$i[r] j &lt;- ite$j[r] mat[i,j] &lt;- (i-1)*ncol(mat) + j cat(str_c(&quot;Entry (&quot;, i, &quot;, &quot;, j, &quot;) = &quot;, mat[i,j], &quot;\\n&quot;)) } #&gt; Entry (2, 1) = 4 #&gt; Entry (2, 3) = 6 mat #&gt; [,1] [,2] [,3] #&gt; [1,] NA NA NA #&gt; [2,] 4 NA 6 9.4 Recap Comparison/relational operators known to R are: &lt; for less than, &gt; for greater than, &lt;= for less than or equal to, &gt;= for greater than or equal to, == for equal to each other (and not = which is typically used for assignment!), != not equal to each other. Logical operators known to R are: &amp; and, | or, ! not. If you use &amp;&amp; and || only the first element in vectors are compared. In general this is used rarely. Useful functions that return a logical are any and all which can be used to join logical values in vectors. Conditional Statements can be constructed using for instance if and while statements. Moreover, function if_else is a vectorized alternative. Loops can be created using for and while statements. You can break out of a loop using break and jump to the next iteration (skipping the remainder of the code in the loop) using next. Do not use a loop when a vectorized alternative exists. Do not grow objects during the loop. Instead, allocate an object to hold the results and fill it in during the loop. Nested loops are possible in R. However, often they can be converted into a single loop by defining a data frame having the values of the nested loops in each row. Here function expand_grid may be useful to create the data frame. You may also have a look at the slides for this module . 9.5 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Some of the solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up too early. Put some effort into finding a solution! Always practice using shortcuts in RStudio (see Tools &gt; Keyboard Shortcuts Help). Go to the Tools for Analytics workspace and download/export the TM9 project. Open it on your laptop and have a look at the files in the exercises folder which can be used as a starting point. 9.5.1 Exercise (conditional expressions) Solve this exercise using a script file Consider object x: x &lt;- c(1,2,-3,4) What will this conditional expression return? if(all(x&gt;0)){ print(&quot;All Postives&quot;) } else { print(&quot;Not all positives&quot;) } What will the following expressions return? x &lt;- c(TRUE, FALSE, TRUE, TRUE) all(x) any(x) any(!x) all(!x) Which of the expressions above is always FALSE when at least one entry of a logical vector x is TRUE? Consider vector: library(tidyverse) x &lt;- 1:15 x #&gt; [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 × Solution if_else(x &lt; 7, as.integer(0), x) #&gt; [1] 0 0 0 0 0 0 7 8 9 10 11 12 13 14 15 Close Solution × Hint if_else(x &lt; 7, as.integer(___), ___) Close Hint Use the if_else function to set elements with value below 7 to 0. × Solution if_else(x &lt; 7 | x &gt; 10, NA_integer_, x) #&gt; [1] NA NA NA NA NA NA 7 8 9 10 NA NA NA NA NA Close Solution × Hint if_else(___, NA_integer_, ___) Close Hint Use the if_else function to set elements with value below 7 or above 10 to NA_integer_ (which is the NA/missing value of an integer). × Solution x &lt;- sample(c(1:10,NA,5.5), 1) if (is.na(x)) { y &lt;- &quot;missing&quot; } else if (x %% 2 == 0) { y &lt;- &quot;even&quot; } else if (x %% 2 == 1) { y &lt;- &quot;odd&quot; } else if (x %% 1 &gt; 0) { y &lt;- &quot;decimal&quot; } x #&gt; [1] 5.5 y #&gt; [1] &quot;decimal&quot; Close Solution × Hint x &lt;- sample(c(1:10,NA,5.5), 1) if (is.na(x)) { y &lt;- ___ } else if (x %% 2 == 0) { ___ } else if (___) { ___ } else if (___) { y &lt;- &quot;decimal&quot; } x y Close Hint Consider code x &lt;- sample(c(1:10,NA,5.5), 1) x #&gt; [1] 7 which generates a number from the vector c(1:10,NA,5.5). Write code which set object y equal to “even” if x is even, “odd” if x is odd, “decimal” if x has a decimal not zero and “missing” if x is NA. Hint: have a look at ?'%%' (the modulo operator). 9.5.2 Exercise (loops) × Solution x &lt;- rep(NA,4) for (i in 1:4) { x[i] &lt;- 2 * i + 4 } x #&gt; [1] 6 8 10 12 Close Solution × Hint x &lt;- rep(NA,4) for (i in 1:4) { x[i] &lt;- ___ } x Close Hint Using a for loop, create a vector having values \\(2i + 4\\) given \\(i=1\\ldots 4\\). × Solution i_val &lt;- c(2, 5, 6, 12) x &lt;- rep(NA, length(i_val)) for (idx in 1:length(i_val)) { x[idx] &lt;- 2 * i_val[idx] + 4 } Close Solution × Hint i_val &lt;- c(2, 5, 6, 12) x &lt;- rep(NA, length(i_val)) for (idx in 1:length(i_val)) { x[idx] &lt;- ___ } Close Hint Using a for loop, create a vector having values \\(2i + 4\\) given \\(i=2,5,6,12\\). × Solution i_val &lt;- c(2, 5, 6, 12) x &lt;- rep(NA, length(i_val)) idx &lt;- 1 while (idx &lt; 5) { x[idx] &lt;- 2 * i_val[idx] + 4 idx &lt;- idx + 1 } Close Solution × Hint i_val &lt;- c(2, 5, 6, 12) x &lt;- rep(NA, length(i_val)) idx &lt;- 1 while (idx &lt; 5) { x[idx] &lt;- ___ idx &lt;- ___ } Close Hint Solve Question 2 using a while loop. × Solution 2 * 1:4 + 4 # Q1 #&gt; [1] 6 8 10 12 2* c(2, 5, 6, 12) + 4 # Q2 #&gt; [1] 8 14 16 28 Close Solution × Hint 2 * ___ + 4 # Q1 ___ # Q2 Close Hint Solve Questions 1 and 2 using a vectorized alternative. 9.5.3 Exercise (search vector) This exercise is a slightly modified version an exam assignment (reexam 2021-A1). Consider the vector: v &lt;- c(9, 19, 2, 8, NA, 12, 9, 23, NA, 34) v #&gt; [1] 9 19 2 8 NA 12 9 23 NA 34 × Solution any(v &lt;= 2) #&gt; [1] TRUE Yes since the vector contains 2. Close Solution Is any of the entries in v below or equal to 2? × Solution all(v &gt;= 2) #&gt; [1] NA We don’t know since we have missing values. Close Solution Is all of the entries in v above or equal to 2? × Solution any(is.na(v)) #&gt; [1] TRUE Yes, since v contains NA values. Close Solution Does v have missing values? × Solution which(v &gt; 10) #&gt; [1] 2 6 8 10 The indicies are show above. Close Solution Which entries in v are above 10? You must return the indices, e.g. the index of v[3] is 3. × Solution res &lt;- if_else(v &lt; 10, v, 0, 0) res #&gt; [1] 9 0 2 8 0 0 9 0 0 0 We use if_else to set values. Close Solution Create a vector res where res[i] is equal to v[i] if v[i] is less than 10 and otherwise zero (also if v[i] is NA). 9.5.4 Exercise (calculating distances) Consider zip codes in Jutland: # remotes::install_github(&quot;bss-osca/tfa-package&quot;, upgrade = FALSE) # run to upgrade library(tidyverse) data(zips, package = &quot;tfa&quot;) # load the zips data from the tfa package zips #&gt; postal_code place_name latitude longitude #&gt; 1 1050 København K 55.7 12.59 #&gt; 2 1051 København K 55.7 12.59 #&gt; 3 1052 København K 55.7 12.59 #&gt; 4 1053 København K 55.7 12.59 #&gt; 5 1054 København K 55.7 12.59 #&gt; 6 1055 København K 55.7 12.59 #&gt; 7 1056 København K 55.7 12.59 #&gt; 8 1057 København K 55.7 12.59 #&gt; 9 1058 København K 55.7 12.59 #&gt; 10 1059 København K 55.7 12.59 #&gt; 11 1060 København K 55.7 12.59 #&gt; 12 1061 København K 55.7 12.58 #&gt; 13 1062 København K 55.7 12.58 #&gt; 14 1063 København K 55.7 12.58 #&gt; 15 1064 København K 55.7 12.58 #&gt; 16 1065 København K 55.7 12.58 #&gt; 17 1066 København K 55.7 12.58 #&gt; 18 1067 København K 55.7 12.58 #&gt; 19 1068 København K 55.7 12.58 #&gt; 20 1069 København K 55.7 12.58 #&gt; 21 1070 København K 55.7 12.58 #&gt; 22 1071 København K 55.7 12.58 #&gt; 23 1072 København K 55.7 12.58 #&gt; 24 1073 København K 55.7 12.58 #&gt; 25 1074 København K 55.7 12.58 #&gt; 26 1100 København K 55.7 12.58 #&gt; 27 1101 København K 55.7 12.58 #&gt; 28 1102 København K 55.7 12.58 #&gt; 29 1103 København K 55.7 12.58 #&gt; 30 1104 København K 55.7 12.58 #&gt; 31 1105 København K 55.7 12.58 #&gt; 32 1106 København K 55.7 12.58 #&gt; 33 1107 København K 55.7 12.58 #&gt; 34 1110 København K 55.7 12.58 #&gt; 35 1111 København K 55.7 12.58 #&gt; 36 1112 København K 55.7 12.58 #&gt; 37 1113 København K 55.7 12.58 #&gt; 38 1114 København K 55.7 12.58 #&gt; 39 1115 København K 55.7 12.58 #&gt; 40 1116 København K 55.7 12.58 #&gt; 41 1117 København K 55.7 12.58 #&gt; 42 1118 København K 55.7 12.58 #&gt; 43 1119 København K 55.7 12.58 #&gt; 44 1120 København K 55.7 12.58 #&gt; 45 1121 København K 55.7 12.58 #&gt; 46 1122 København K 55.7 12.58 #&gt; 47 1123 København K 55.7 12.58 #&gt; 48 1124 København K 55.7 12.58 #&gt; 49 1125 København K 55.7 12.58 #&gt; 50 1126 København K 55.7 12.58 #&gt; 51 1127 København K 55.7 12.58 #&gt; 52 1128 København K 55.7 12.57 #&gt; 53 1129 København K 55.7 12.57 #&gt; 54 1130 København K 55.7 12.57 #&gt; 55 1131 København K 55.7 12.57 #&gt; 56 1150 København K 55.7 12.58 #&gt; 57 1151 København K 55.7 12.58 #&gt; 58 1152 København K 55.7 12.58 #&gt; 59 1153 København K 55.7 12.58 #&gt; 60 1154 København K 55.7 12.58 #&gt; 61 1155 København K 55.7 12.58 #&gt; 62 1156 København K 55.7 12.58 #&gt; 63 1157 København K 55.7 12.58 #&gt; 64 1158 København K 55.7 12.57 #&gt; 65 1159 København K 55.7 12.57 #&gt; 66 1160 København K 55.7 12.58 #&gt; 67 1161 København K 55.7 12.57 #&gt; 68 1162 København K 55.7 12.57 #&gt; 69 1164 København K 55.7 12.57 #&gt; 70 1165 København K 55.7 12.57 #&gt; 71 1166 København K 55.7 12.57 #&gt; 72 1167 København K 55.7 12.57 #&gt; 73 1168 København K 55.7 12.57 #&gt; 74 1169 København K 55.7 12.57 #&gt; 75 1170 København K 55.7 12.57 #&gt; 76 1171 København K 55.7 12.57 #&gt; 77 1172 København K 55.7 12.57 #&gt; 78 1173 København K 55.7 12.57 #&gt; 79 1174 København K 55.7 12.57 #&gt; 80 1175 København K 55.7 12.57 #&gt; 81 1200 København K 55.7 12.58 #&gt; 82 1201 København K 55.7 12.58 #&gt; 83 1202 København K 55.7 12.58 #&gt; 84 1203 København K 55.7 12.58 #&gt; 85 1204 København K 55.7 12.58 #&gt; 86 1205 København K 55.7 12.58 #&gt; 87 1206 København K 55.7 12.58 #&gt; 88 1207 København K 55.7 12.58 #&gt; 89 1208 København K 55.7 12.58 #&gt; 90 1209 København K 55.7 12.58 #&gt; 91 1210 København K 55.7 12.57 #&gt; 92 1211 København K 55.7 12.57 #&gt; 93 1212 København K 55.7 12.58 #&gt; 94 1213 København K 55.7 12.58 #&gt; 95 1214 København K 55.7 12.58 #&gt; 96 1215 København K 55.7 12.58 #&gt; 97 1216 København K 55.7 12.58 #&gt; 98 1218 København K 55.7 12.58 #&gt; 99 1219 København K 55.7 12.58 #&gt; 100 1220 København K 55.7 12.58 #&gt; 101 1221 København K 55.7 12.58 #&gt; 102 1250 København K 55.7 12.59 #&gt; 103 1251 København K 55.7 12.59 #&gt; 104 1252 København K 55.7 12.60 #&gt; 105 1253 København K 55.7 12.59 #&gt; 106 1254 København K 55.7 12.59 #&gt; 107 1255 København K 55.7 12.59 #&gt; 108 1256 København K 55.7 12.59 #&gt; 109 1257 København K 55.7 12.59 #&gt; 110 1259 København K 55.7 12.60 #&gt; 111 1260 København K 55.7 12.59 #&gt; 112 1261 København K 55.7 12.59 #&gt; 113 1263 København K 55.7 12.59 #&gt; 114 1264 København K 55.7 12.59 #&gt; 115 1265 København K 55.7 12.59 #&gt; 116 1266 København K 55.7 12.59 #&gt; 117 1267 København K 55.7 12.59 #&gt; 118 1268 København K 55.7 12.59 #&gt; 119 1270 København K 55.7 12.59 #&gt; 120 1271 København K 55.7 12.59 #&gt; 121 1300 København K 55.7 12.59 #&gt; 122 1301 København K 55.7 12.59 #&gt; 123 1302 København K 55.7 12.59 #&gt; 124 1303 København K 55.7 12.59 #&gt; 125 1304 København K 55.7 12.58 #&gt; 126 1306 København K 55.7 12.58 #&gt; 127 1307 København K 55.7 12.58 #&gt; 128 1308 København K 55.7 12.58 #&gt; 129 1309 København K 55.7 12.58 #&gt; 130 1310 København K 55.7 12.59 #&gt; 131 1311 København K 55.7 12.59 #&gt; 132 1312 København K 55.7 12.59 #&gt; 133 1313 København K 55.7 12.59 #&gt; 134 1314 København K 55.7 12.59 #&gt; 135 1315 København K 55.7 12.59 #&gt; 136 1316 København K 55.7 12.58 #&gt; 137 1317 København K 55.7 12.58 #&gt; 138 1318 København K 55.7 12.58 #&gt; 139 1319 København K 55.7 12.59 #&gt; 140 1320 København K 55.7 12.59 #&gt; 141 1321 København K 55.7 12.59 #&gt; 142 1322 København K 55.7 12.59 #&gt; 143 1323 København K 55.7 12.59 #&gt; 144 1324 København K 55.7 12.59 #&gt; 145 1325 København K 55.7 12.59 #&gt; 146 1326 København K 55.7 12.59 #&gt; 147 1327 København K 55.7 12.59 #&gt; 148 1328 København K 55.7 12.59 #&gt; 149 1329 København K 55.7 12.59 #&gt; 150 1350 København K 55.7 12.58 #&gt; 151 1352 København K 55.7 12.57 #&gt; 152 1353 København K 55.7 12.57 #&gt; 153 1354 København K 55.7 12.57 #&gt; 154 1355 København K 55.7 12.57 #&gt; 155 1356 København K 55.7 12.57 #&gt; 156 1357 København K 55.7 12.57 #&gt; 157 1358 København K 55.7 12.57 #&gt; 158 1359 København K 55.7 12.57 #&gt; 159 1360 København K 55.7 12.57 #&gt; 160 1361 København K 55.7 12.57 #&gt; 161 1362 København K 55.7 12.57 #&gt; 162 1363 København K 55.7 12.57 #&gt; 163 1364 København K 55.7 12.57 #&gt; 164 1365 København K 55.7 12.56 #&gt; 165 1366 København K 55.7 12.56 #&gt; 166 1367 København K 55.7 12.56 #&gt; 167 1368 København K 55.7 12.56 #&gt; 168 1369 København K 55.7 12.56 #&gt; 169 1370 København K 55.7 12.56 #&gt; 170 1371 København K 55.7 12.57 #&gt; 171 1400 København K 55.7 12.59 #&gt; 172 1401 København K 55.7 12.59 #&gt; 173 1402 København K 55.7 12.59 #&gt; 174 1403 København K 55.7 12.59 #&gt; 175 1406 København K 55.7 12.59 #&gt; 176 1407 København K 55.7 12.59 #&gt; 177 1408 København K 55.7 12.59 #&gt; 178 1409 København K 55.7 12.59 #&gt; 179 1410 København K 55.7 12.59 #&gt; 180 1411 København K 55.7 12.58 #&gt; 181 1412 København K 55.7 12.59 #&gt; 182 1413 København K 55.7 12.59 #&gt; 183 1414 København K 55.7 12.59 #&gt; 184 1415 København K 55.7 12.59 #&gt; 185 1416 København K 55.7 12.59 #&gt; 186 1417 København K 55.7 12.59 #&gt; 187 1418 København K 55.7 12.59 #&gt; 188 1419 København K 55.7 12.59 #&gt; 189 1420 København K 55.7 12.59 #&gt; 190 1421 København K 55.7 12.59 #&gt; 191 1422 København K 55.7 12.60 #&gt; 192 1423 København K 55.7 12.59 #&gt; 193 1424 København K 55.7 12.59 #&gt; 194 1425 København K 55.7 12.59 #&gt; 195 1426 København K 55.7 12.60 #&gt; 196 1427 København K 55.7 12.60 #&gt; 197 1428 København K 55.7 12.60 #&gt; 198 1429 København K 55.7 12.60 #&gt; 199 1430 København K 55.7 12.60 #&gt; 200 1432 København K 55.7 12.61 #&gt; 201 1433 København K 55.7 12.70 #&gt; 202 1434 København K 55.7 12.60 #&gt; 203 1435 København K 55.7 12.61 #&gt; 204 1436 København K 55.7 12.60 #&gt; 205 1437 København K 55.7 12.60 #&gt; 206 1438 København K 55.7 12.60 #&gt; 207 1439 København K 55.7 12.61 #&gt; 208 1440 København K 55.7 12.60 #&gt; 209 1441 København K 55.7 12.61 #&gt; 210 1450 København K 55.7 12.57 #&gt; 211 1451 København K 55.7 12.57 #&gt; 212 1452 København K 55.7 12.57 #&gt; 213 1453 København K 55.7 12.57 #&gt; 214 1454 København K 55.7 12.57 #&gt; 215 1455 København K 55.7 12.57 #&gt; 216 1456 København K 55.7 12.57 #&gt; 217 1457 København K 55.7 12.57 #&gt; 218 1458 København K 55.7 12.57 #&gt; 219 1459 København K 55.7 12.57 #&gt; 220 1460 København K 55.7 12.57 #&gt; 221 1461 København K 55.7 12.57 #&gt; 222 1462 København K 55.7 12.57 #&gt; 223 1463 København K 55.7 12.57 #&gt; 224 1464 København K 55.7 12.57 #&gt; 225 1465 København K 55.7 12.57 #&gt; 226 1466 København K 55.7 12.57 #&gt; 227 1467 København K 55.7 12.57 #&gt; 228 1468 København K 55.7 12.57 #&gt; 229 1470 København K 55.7 12.57 #&gt; 230 1471 København K 55.7 12.58 #&gt; 231 1472 København K 55.7 12.58 #&gt; 232 1473 København K 55.7 12.58 #&gt; 233 1550 København V 55.7 12.57 #&gt; 234 1551 København V 55.7 12.57 #&gt; 235 1552 København V 55.7 12.57 #&gt; 236 1553 København V 55.7 12.57 #&gt; 237 1554 København V 55.7 12.57 #&gt; 238 1555 København V 55.7 12.57 #&gt; 239 1556 København V 55.7 12.57 #&gt; 240 1557 København V 55.7 12.57 #&gt; 241 1558 København V 55.7 12.58 #&gt; 242 1559 København V 55.7 12.58 #&gt; 243 1560 København V 55.7 12.57 #&gt; 244 1561 København V 55.7 12.56 #&gt; 245 1562 København V 55.7 12.57 #&gt; 246 1563 København V 55.7 12.57 #&gt; 247 1564 København V 55.7 12.58 #&gt; 248 1567 København V 55.7 12.57 #&gt; 249 1568 København V 55.7 12.57 #&gt; 250 1569 København V 55.7 12.57 #&gt; 251 1570 København V 55.7 12.56 #&gt; 252 1571 København V 55.7 12.57 #&gt; 253 1572 København V 55.7 12.57 #&gt; 254 1573 København V 55.7 12.57 #&gt; 255 1574 København V 55.7 12.57 #&gt; 256 1575 København V 55.7 12.57 #&gt; 257 1576 København V 55.7 12.57 #&gt; 258 1577 København V 55.7 12.57 #&gt; 259 1600 København V 55.7 12.56 #&gt; 260 1601 København V 55.7 12.56 #&gt; 261 1602 København V 55.7 12.56 #&gt; 262 1603 København V 55.7 12.56 #&gt; 263 1604 København V 55.7 12.56 #&gt; 264 1605 København V 55.7 12.56 #&gt; 265 1606 København V 55.7 12.56 #&gt; 266 1607 København V 55.7 12.56 #&gt; 267 1608 København V 55.7 12.57 #&gt; 268 1609 København V 55.7 12.56 #&gt; 269 1610 København V 55.7 12.55 #&gt; 270 1611 København V 55.7 12.56 #&gt; 271 1612 København V 55.7 12.56 #&gt; 272 1613 København V 55.7 12.56 #&gt; 273 1614 København V 55.7 12.56 #&gt; 274 1615 København V 55.7 12.56 #&gt; 275 1616 København V 55.7 12.56 #&gt; 276 1617 København V 55.7 12.55 #&gt; 277 1618 København V 55.7 12.55 #&gt; 278 1619 København V 55.7 12.55 #&gt; 279 1620 København V 55.7 12.55 #&gt; 280 1621 København V 55.7 12.55 #&gt; 281 1622 København V 55.7 12.55 #&gt; 282 1623 København V 55.7 12.55 #&gt; 283 1624 København V 55.7 12.55 #&gt; 284 1631 København V 55.7 12.56 #&gt; 285 1632 København V 55.7 12.55 #&gt; 286 1633 København V 55.7 12.56 #&gt; 287 1634 København V 55.7 12.56 #&gt; 288 1635 København V 55.7 12.56 #&gt; 289 1650 København V 55.7 12.55 #&gt; 290 1651 København V 55.7 12.56 #&gt; 291 1652 København V 55.7 12.56 #&gt; 292 1653 København V 55.7 12.56 #&gt; 293 1654 København V 55.7 12.56 #&gt; 294 1655 København V 55.7 12.56 #&gt; 295 1656 København V 55.7 12.56 #&gt; 296 1657 København V 55.7 12.56 #&gt; 297 1658 København V 55.7 12.55 #&gt; 298 1659 København V 55.7 12.55 #&gt; 299 1660 København V 55.7 12.55 #&gt; 300 1661 København V 55.7 12.55 #&gt; 301 1662 København V 55.7 12.55 #&gt; 302 1663 København V 55.7 12.55 #&gt; 303 1664 København V 55.7 12.55 #&gt; 304 1665 København V 55.7 12.55 #&gt; 305 1666 København V 55.7 12.55 #&gt; 306 1667 København V 55.7 12.55 #&gt; 307 1668 København V 55.7 12.55 #&gt; 308 1669 København V 55.7 12.55 #&gt; 309 1670 København V 55.7 12.55 #&gt; 310 1671 København V 55.7 12.55 #&gt; 311 1672 København V 55.7 12.55 #&gt; 312 1673 København V 55.7 12.55 #&gt; 313 1674 København V 55.7 12.54 #&gt; 314 1675 København V 55.7 12.55 #&gt; 315 1676 København V 55.7 12.55 #&gt; 316 1677 København V 55.7 12.55 #&gt; 317 1699 København V 55.7 12.56 #&gt; 318 1700 København V 55.7 12.56 #&gt; 319 1701 København V 55.7 12.56 #&gt; 320 1702 København V 55.7 12.56 #&gt; 321 1703 København V 55.7 12.56 #&gt; 322 1704 København V 55.7 12.57 #&gt; 323 1705 København V 55.7 12.55 #&gt; 324 1706 København V 55.7 12.56 #&gt; 325 1707 København V 55.7 12.56 #&gt; 326 1708 København V 55.7 12.56 #&gt; 327 1709 København V 55.7 12.55 #&gt; 328 1710 København V 55.7 12.56 #&gt; 329 1711 København V 55.7 12.56 #&gt; 330 1712 København V 55.7 12.56 #&gt; 331 1714 København V 55.7 12.56 #&gt; 332 1715 København V 55.7 12.56 #&gt; 333 1716 København V 55.7 12.56 #&gt; 334 1717 København V 55.7 12.56 #&gt; 335 1718 København V 55.7 12.56 #&gt; 336 1719 København V 55.7 12.56 #&gt; 337 1720 København V 55.7 12.55 #&gt; 338 1721 København V 55.7 12.55 #&gt; 339 1722 København V 55.7 12.55 #&gt; 340 1723 København V 55.7 12.55 #&gt; 341 1724 København V 55.7 12.55 #&gt; 342 1725 København V 55.7 12.55 #&gt; 343 1726 København V 55.7 12.55 #&gt; 344 1727 København V 55.7 12.55 #&gt; 345 1728 København V 55.7 12.55 #&gt; 346 1729 København V 55.7 12.55 #&gt; 347 1730 København V 55.7 12.55 #&gt; 348 1731 København V 55.7 12.55 #&gt; 349 1732 København V 55.7 12.55 #&gt; 350 1733 København V 55.7 12.54 #&gt; 351 1734 København V 55.7 12.55 #&gt; 352 1735 København V 55.7 12.55 #&gt; 353 1736 København V 55.7 12.54 #&gt; 354 1737 København V 55.7 12.54 #&gt; 355 1738 København V 55.7 12.54 #&gt; 356 1739 København V 55.7 12.54 #&gt; 357 1749 København V 55.7 12.54 #&gt; 358 1750 København V 55.7 12.54 #&gt; 359 1751 København V 55.7 12.54 #&gt; 360 1752 København V 55.7 12.54 #&gt; 361 1753 København V 55.7 12.54 #&gt; 362 1754 København V 55.7 12.54 #&gt; 363 1755 København V 55.7 12.54 #&gt; 364 1756 København V 55.7 12.54 #&gt; 365 1757 København V 55.7 12.54 #&gt; 366 1758 København V 55.7 12.54 #&gt; 367 1759 København V 55.7 12.54 #&gt; 368 1760 København V 55.7 12.54 #&gt; 369 1761 København V 55.7 12.54 #&gt; 370 1762 København V 55.7 12.54 #&gt; 371 1763 København V 55.7 12.54 #&gt; 372 1764 København V 55.7 12.54 #&gt; 373 1765 København V 55.7 12.54 #&gt; 374 1766 København V 55.7 12.54 #&gt; 375 1770 København V 55.7 12.54 #&gt; 376 1771 København V 55.7 12.54 #&gt; 377 1772 København V 55.7 12.54 #&gt; 378 1773 København V 55.7 12.54 #&gt; 379 1774 København V 55.7 12.54 #&gt; 380 1775 København V 55.7 12.54 #&gt; 381 1777 København V 55.7 12.54 #&gt; 382 1799 København V 55.7 12.53 #&gt; 383 2100 København Ø 55.7 12.57 #&gt; 384 2150 Nordhavn 55.7 12.60 #&gt; 385 2200 København N 55.7 12.55 #&gt; 386 2300 København S 55.7 12.60 #&gt; 387 2400 København NV 55.7 12.53 #&gt; 388 2450 København SV 55.6 12.54 #&gt; 389 2500 Valby 55.7 12.50 #&gt; 390 2700 Brønshøj 55.7 12.48 #&gt; 391 2720 Vanløse 55.7 12.49 #&gt; 392 1800 Frederiksberg C 55.7 12.53 #&gt; 393 1801 Frederiksberg C 55.7 12.53 #&gt; 394 1802 Frederiksberg C 55.7 12.53 #&gt; 395 1803 Frederiksberg C 55.7 12.53 #&gt; 396 1804 Frederiksberg C 55.7 12.53 #&gt; 397 1805 Frederiksberg C 55.7 12.53 #&gt; 398 1806 Frederiksberg C 55.7 12.53 #&gt; 399 1807 Frederiksberg C 55.7 12.53 #&gt; 400 1808 Frederiksberg C 55.7 12.53 #&gt; 401 1809 Frederiksberg C 55.7 12.54 #&gt; 402 1810 Frederiksberg C 55.7 12.54 #&gt; 403 1811 Frederiksberg C 55.7 12.54 #&gt; 404 1812 Frederiksberg C 55.7 12.54 #&gt; 405 1813 Frederiksberg C 55.7 12.54 #&gt; 406 1814 Frederiksberg C 55.7 12.54 #&gt; 407 1815 Frederiksberg C 55.7 12.54 #&gt; 408 1816 Frederiksberg C 55.7 12.54 #&gt; 409 1817 Frederiksberg C 55.7 12.54 #&gt; 410 1818 Frederiksberg C 55.7 12.54 #&gt; 411 1819 Frederiksberg C 55.7 12.55 #&gt; 412 1820 Frederiksberg C 55.7 12.54 #&gt; 413 1822 Frederiksberg C 55.7 12.55 #&gt; 414 1823 Frederiksberg C 55.7 12.55 #&gt; 415 1824 Frederiksberg C 55.7 12.55 #&gt; 416 1825 Frederiksberg C 55.7 12.55 #&gt; 417 1826 Frederiksberg C 55.7 12.54 #&gt; 418 1827 Frederiksberg C 55.7 12.54 #&gt; 419 1828 Frederiksberg C 55.7 12.54 #&gt; 420 1829 Frederiksberg C 55.7 12.54 #&gt; 421 1850 Frederiksberg C 55.7 12.54 #&gt; 422 1851 Frederiksberg C 55.7 12.54 #&gt; 423 1852 Frederiksberg C 55.7 12.54 #&gt; 424 1853 Frederiksberg C 55.7 12.54 #&gt; 425 1854 Frederiksberg C 55.7 12.53 #&gt; 426 1855 Frederiksberg C 55.7 12.54 #&gt; 427 1856 Frederiksberg C 55.7 12.54 #&gt; 428 1857 Frederiksberg C 55.7 12.54 #&gt; 429 1860 Frederiksberg C 55.7 12.54 #&gt; 430 1861 Frederiksberg C 55.7 12.54 #&gt; 431 1862 Frederiksberg C 55.7 12.54 #&gt; 432 1863 Frederiksberg C 55.7 12.54 #&gt; 433 1864 Frederiksberg C 55.7 12.54 #&gt; 434 1865 Frederiksberg C 55.7 12.54 #&gt; 435 1866 Frederiksberg C 55.7 12.54 #&gt; 436 1867 Frederiksberg C 55.7 12.54 #&gt; 437 1868 Frederiksberg C 55.7 12.54 #&gt; 438 1870 Frederiksberg C 55.7 12.54 #&gt; 439 1871 Frederiksberg C 55.7 12.54 #&gt; 440 1872 Frederiksberg C 55.7 12.55 #&gt; 441 1873 Frederiksberg C 55.7 12.54 #&gt; 442 1874 Frederiksberg C 55.7 12.55 #&gt; 443 1875 Frederiksberg C 55.7 12.55 #&gt; 444 1876 Frederiksberg C 55.7 12.54 #&gt; 445 1877 Frederiksberg C 55.7 12.54 #&gt; 446 1878 Frederiksberg C 55.7 12.54 #&gt; 447 1879 Frederiksberg C 55.7 12.55 #&gt; 448 1900 Frederiksberg C 55.7 12.55 #&gt; 449 1901 Frederiksberg C 55.7 12.55 #&gt; 450 1902 Frederiksberg C 55.7 12.55 #&gt; 451 1903 Frederiksberg C 55.7 12.55 #&gt; 452 1904 Frederiksberg C 55.7 12.55 #&gt; 453 1905 Frederiksberg C 55.7 12.55 #&gt; 454 1906 Frederiksberg C 55.7 12.55 #&gt; 455 1908 Frederiksberg C 55.7 12.55 #&gt; 456 1909 Frederiksberg C 55.7 12.55 #&gt; 457 1910 Frederiksberg C 55.7 12.55 #&gt; 458 1911 Frederiksberg C 55.7 12.55 #&gt; 459 1912 Frederiksberg C 55.7 12.55 #&gt; 460 1913 Frederiksberg C 55.7 12.55 #&gt; 461 1914 Frederiksberg C 55.7 12.55 #&gt; 462 1915 Frederiksberg C 55.7 12.55 #&gt; 463 1916 Frederiksberg C 55.7 12.56 #&gt; 464 1917 Frederiksberg C 55.7 12.56 #&gt; 465 1920 Frederiksberg C 55.7 12.55 #&gt; 466 1921 Frederiksberg C 55.7 12.55 #&gt; 467 1922 Frederiksberg C 55.7 12.55 #&gt; 468 1923 Frederiksberg C 55.7 12.55 #&gt; 469 1924 Frederiksberg C 55.7 12.55 #&gt; 470 1925 Frederiksberg C 55.7 12.55 #&gt; 471 1926 Frederiksberg C 55.7 12.56 #&gt; 472 1927 Frederiksberg C 55.7 12.56 #&gt; 473 1928 Frederiksberg C 55.7 12.56 #&gt; 474 1950 Frederiksberg C 55.7 12.54 #&gt; 475 1951 Frederiksberg C 55.7 12.54 #&gt; 476 1952 Frederiksberg C 55.7 12.54 #&gt; 477 1953 Frederiksberg C 55.7 12.54 #&gt; 478 1954 Frederiksberg C 55.7 12.54 #&gt; 479 1955 Frederiksberg C 55.7 12.54 #&gt; 480 1956 Frederiksberg C 55.7 12.54 #&gt; 481 1957 Frederiksberg C 55.7 12.54 #&gt; 482 1958 Frederiksberg C 55.7 12.54 #&gt; 483 1959 Frederiksberg C 55.7 12.54 #&gt; 484 1960 Frederiksberg C 55.7 12.55 #&gt; 485 1961 Frederiksberg C 55.7 12.55 #&gt; 486 1962 Frederiksberg C 55.7 12.55 #&gt; 487 1963 Frederiksberg C 55.7 12.55 #&gt; 488 1964 Frederiksberg C 55.7 12.55 #&gt; 489 1965 Frederiksberg C 55.7 12.55 #&gt; 490 1966 Frederiksberg C 55.7 12.55 #&gt; 491 1967 Frederiksberg C 55.7 12.55 #&gt; 492 1970 Frederiksberg C 55.7 12.55 #&gt; 493 1971 Frederiksberg C 55.7 12.55 #&gt; 494 1972 Frederiksberg C 55.7 12.55 #&gt; 495 1973 Frederiksberg C 55.7 12.55 #&gt; 496 1974 Frederiksberg C 55.7 12.55 #&gt; 497 2000 Frederiksberg 55.7 12.52 #&gt; 498 2740 Skovlunde 55.7 12.40 #&gt; 499 2750 Ballerup 55.7 12.36 #&gt; 500 2760 Måløv 55.8 12.32 #&gt; 501 2605 Brøndby 55.7 12.41 #&gt; 502 2660 Brøndby Strand 55.6 12.42 #&gt; 503 2791 Dragør 55.6 12.65 #&gt; 504 2820 Gentofte 55.8 12.53 #&gt; 505 2870 Dyssegård 55.7 12.53 #&gt; 506 2900 Hellerup 55.7 12.56 #&gt; 507 2920 Charlottenlund 55.8 12.57 #&gt; 508 2930 Klampenborg 55.8 12.59 #&gt; 509 2860 Søborg 55.7 12.48 #&gt; 510 2880 Bagsværd 55.8 12.46 #&gt; 511 2600 Glostrup 55.7 12.40 #&gt; 512 2730 Herlev 55.7 12.43 #&gt; 513 2620 Albertslund 55.7 12.35 #&gt; 514 2650 Hvidovre 55.6 12.47 #&gt; 515 2630 Taastrup 55.6 12.29 #&gt; 516 2640 Hedehusene 55.7 12.20 #&gt; 517 2800 Kongens Lyngby 55.8 12.51 #&gt; 518 2830 Virum 55.8 12.47 #&gt; 519 2610 Rødovre 55.7 12.45 #&gt; 520 2635 Ishøj 55.6 12.34 #&gt; 521 2770 Kastrup 55.6 12.61 #&gt; 522 2625 Vallensbæk 55.6 12.36 #&gt; 523 2665 Vallensbæk Strand 55.6 12.39 #&gt; 524 3500 Værløse 55.8 12.36 #&gt; 525 3520 Farum 55.8 12.37 #&gt; 526 3450 Allerød 55.9 12.35 #&gt; 527 3540 Lynge 55.8 12.28 #&gt; 528 2980 Kokkedal 55.9 12.49 #&gt; 529 2990 Nivå 55.9 12.50 #&gt; 530 3050 Humlebæk 56.0 12.52 #&gt; 531 3480 Fredensborg 56.0 12.41 #&gt; 532 3000 Helsingør 56.0 12.59 #&gt; 533 3060 Espergærde 56.0 12.54 #&gt; 534 3070 Snekkersten 56.0 12.58 #&gt; 535 3080 Tikøb 56.0 12.45 #&gt; 536 3100 Hornbæk 56.1 12.45 #&gt; 537 3140 Ålsgårde 56.1 12.53 #&gt; 538 3150 Hellebæk 56.1 12.56 #&gt; 539 3490 Kvistgård 56.0 12.50 #&gt; 540 3320 Skævinge 55.9 12.15 #&gt; 541 3330 Gørløse 55.9 12.20 #&gt; 542 3400 Hillerød 55.9 12.29 #&gt; 543 2960 Rungsted Kyst 55.9 12.53 #&gt; 544 2970 Hørsholm 55.9 12.50 #&gt; 545 2840 Holte 55.8 12.49 #&gt; 546 2850 Nærum 55.8 12.53 #&gt; 547 2942 Skodsborg 55.8 12.57 #&gt; 548 2950 Vedbæk 55.8 12.55 #&gt; 549 3460 Birkerød 55.8 12.43 #&gt; 550 2765 Smørum 55.7 12.30 #&gt; 551 3650 Ølstykke 55.8 12.16 #&gt; 552 3660 Stenløse 55.8 12.22 #&gt; 553 3670 Veksø Sjælland 55.8 12.24 #&gt; 554 3550 Slangerup 55.8 12.17 #&gt; 555 3600 Frederikssund 55.8 12.07 #&gt; 556 3630 Jægerspris 55.9 11.96 #&gt; 557 4050 Skibby 55.8 11.96 #&gt; 558 3300 Frederiksværk 56.0 12.02 #&gt; 559 3310 Ølsted 55.9 12.06 #&gt; 560 3360 Liseleje 56.0 11.97 #&gt; 561 3370 Melby 56.0 11.97 #&gt; 562 3390 Hundested 56.0 11.88 #&gt; 563 3120 Dronningmølle 56.1 12.38 #&gt; 564 3200 Helsinge 56.0 12.18 #&gt; 565 3210 Vejby 56.1 12.14 #&gt; 566 3220 Tisvildeleje 56.1 12.09 #&gt; 567 3230 Græsted 56.1 12.26 #&gt; 568 3250 Gilleleje 56.1 12.29 #&gt; 569 3700 Rønne 55.1 14.72 #&gt; 570 3720 Aakirkeby 55.1 14.93 #&gt; 571 3730 Nexø 55.0 15.11 #&gt; 572 3740 Svaneke 55.1 15.13 #&gt; 573 3751 Østermarie 55.1 15.02 #&gt; 574 3760 Gudhjem 55.2 14.95 #&gt; 575 3770 Allinge 55.3 14.80 #&gt; 576 3782 Klemensker 55.2 14.81 #&gt; 577 3790 Hasle 55.2 14.72 #&gt; 578 8700 Horsens 55.9 9.85 #&gt; 579 8732 Hovedgård 55.9 9.96 #&gt; 580 8740 Brædstrup 56.0 9.62 #&gt; 581 8751 Gedved 55.9 9.85 #&gt; 582 8752 Østbirk 56.0 9.75 #&gt; 583 8789 Endelave 55.8 10.28 #&gt; 584 6933 Kibæk 56.0 8.87 #&gt; 585 6973 Ørnhøj 56.2 8.57 #&gt; 586 7270 Stakroge 55.9 8.85 #&gt; 587 7280 Sønder Felding 55.9 8.78 #&gt; 588 7400 Herning 56.1 8.97 #&gt; 589 7451 Sunds 56.2 9.02 #&gt; 590 7480 Vildbjerg 56.2 8.77 #&gt; 591 7490 Aulum 56.3 8.80 #&gt; 592 7540 Haderup 56.4 8.97 #&gt; 593 7550 Sørvad 56.3 8.66 #&gt; 594 6990 Ulfborg 56.3 8.22 #&gt; 595 7500 Holstebro 56.4 8.63 #&gt; 596 7570 Vemb 56.3 8.36 #&gt; 597 7830 Vinderup 56.5 8.80 #&gt; 598 7620 Lemvig 56.5 8.29 #&gt; 599 7650 Bøvlingbjerg 56.4 8.21 #&gt; 600 7660 Bækmarksbro 56.4 8.32 #&gt; 601 7673 Harboøre 56.6 8.16 #&gt; 602 7680 Thyborøn 56.7 8.21 #&gt; 603 7560 Hjerm 56.4 8.65 #&gt; 604 7600 Struer 56.5 8.57 #&gt; 605 7790 Thyholm 56.6 8.55 #&gt; 606 8400 Ebeltoft 56.2 10.67 #&gt; 607 8410 Rønde 56.3 10.47 #&gt; 608 8420 Knebel 56.2 10.47 #&gt; 609 8444 Balle 56.3 10.79 #&gt; 610 8543 Hornslet 56.3 10.31 #&gt; 611 8544 Mørke 56.4 10.34 #&gt; 612 8550 Ryomgård 56.4 10.48 #&gt; 613 8560 Kolind 56.4 10.59 #&gt; 614 8581 Nimtofte 56.4 10.58 #&gt; 615 8500 Grenaa 56.4 10.87 #&gt; 616 8570 Trustrup 56.4 10.76 #&gt; 617 8585 Glesborg 56.5 10.67 #&gt; 618 8586 Ørum Djurs 56.4 10.66 #&gt; 619 8592 Anholt 56.7 11.54 #&gt; 620 8950 Ørsted 56.5 10.33 #&gt; 621 8961 Allingåbro 56.5 10.42 #&gt; 622 8963 Auning 56.4 10.38 #&gt; 623 8370 Hadsten 56.3 10.07 #&gt; 624 8382 Hinnerup 56.3 10.07 #&gt; 625 8450 Hammel 56.3 9.87 #&gt; 626 8472 Sporup 56.2 9.83 #&gt; 627 8860 Ulstrup 56.4 9.79 #&gt; 628 8881 Thorsø 56.3 9.79 #&gt; 629 8300 Odder 56.0 10.18 #&gt; 630 8350 Hundslund 55.9 10.06 #&gt; 631 8799 Tunø 56.0 10.44 #&gt; 632 8870 Langå 56.4 9.92 #&gt; 633 8900 Randers C 56.5 10.03 #&gt; 634 8920 Randers NV 56.5 9.98 #&gt; 635 8930 Randers NØ 56.5 10.08 #&gt; 636 8940 Randers SV 56.4 10.03 #&gt; 637 8960 Randers SØ 56.4 10.11 #&gt; 638 8970 Havndal 56.6 10.23 #&gt; 639 8981 Spentrup 56.5 10.04 #&gt; 640 8983 Gjerlev J 56.6 10.14 #&gt; 641 8990 Fårup 56.5 9.88 #&gt; 642 8600 Silkeborg 56.2 9.56 #&gt; 643 8620 Kjellerup 56.3 9.41 #&gt; 644 8632 Lemming 56.2 9.54 #&gt; 645 8641 Sorring 56.2 9.78 #&gt; 646 8643 Ans By 56.3 9.60 #&gt; 647 8653 Them 56.1 9.55 #&gt; 648 8654 Bryrup 56.0 9.52 #&gt; 649 8882 Fårvang 56.3 9.71 #&gt; 650 8883 Gjern 56.2 9.74 #&gt; 651 8305 Samsø 55.9 10.59 #&gt; 652 8362 Hørning 56.1 10.03 #&gt; 653 8464 Galten 56.2 9.93 #&gt; 654 8660 Skanderborg 56.0 9.93 #&gt; 655 8670 Låsby 56.2 9.81 #&gt; 656 8680 Ry 56.1 9.76 #&gt; 657 8000 Aarhus C 56.2 10.20 #&gt; 658 8200 Aarhus N 56.2 10.19 #&gt; 659 8210 Aarhus V 56.2 10.16 #&gt; 660 8220 Brabrand 56.2 10.11 #&gt; 661 8230 Åbyhøj 56.2 10.16 #&gt; 662 8240 Risskov 56.2 10.23 #&gt; 663 8250 Egå 56.2 10.29 #&gt; 664 8260 Viby J 56.1 10.14 #&gt; 665 8270 Højbjerg 56.1 10.19 #&gt; 666 8310 Tranbjerg J 56.1 10.13 #&gt; 667 8320 Mårslet 56.1 10.16 #&gt; 668 8330 Beder 56.1 10.22 #&gt; 669 8340 Malling 56.0 10.21 #&gt; 670 8355 Solbjerg 56.0 10.09 #&gt; 671 8361 Hasselager 56.1 10.09 #&gt; 672 8380 Trige 56.3 10.15 #&gt; 673 8381 Tilst 56.2 10.11 #&gt; 674 8462 Harlev J 56.1 10.00 #&gt; 675 8471 Sabro 56.2 10.04 #&gt; 676 8520 Lystrup 56.2 10.23 #&gt; 677 8530 Hjortshøj 56.3 10.25 #&gt; 678 8541 Skødstrup 56.3 10.31 #&gt; 679 7330 Brande 55.9 9.11 #&gt; 680 7361 Ejstrupholm 56.0 9.29 #&gt; 681 7362 Hampen 56.0 9.36 #&gt; 682 7430 Ikast 56.1 9.16 #&gt; 683 7441 Bording 56.2 9.27 #&gt; 684 7442 Engesvang 56.2 9.34 #&gt; 685 8765 Klovborg 55.9 9.49 #&gt; 686 8766 Nørre Snede 56.0 9.40 #&gt; 687 6880 Tarm 55.9 8.51 #&gt; 688 6893 Hemmet 55.8 8.31 #&gt; 689 6900 Skjern 56.0 8.50 #&gt; 690 6920 Videbæk 56.1 8.66 #&gt; 691 6940 Lem St 56.0 8.39 #&gt; 692 6950 Ringkøbing 56.1 8.21 #&gt; 693 6960 Hvide Sande 56.0 8.14 #&gt; 694 6971 Spjald 56.1 8.50 #&gt; 695 6980 Tim 56.2 8.29 #&gt; 696 7130 Juelsminde 55.8 10.00 #&gt; 697 7140 Stouby 55.7 9.80 #&gt; 698 7150 Barrit 55.7 9.89 #&gt; 699 7160 Tørring 55.9 9.50 #&gt; 700 7171 Uldum 55.8 9.59 #&gt; 701 8721 Daugård 55.7 9.71 #&gt; 702 8722 Hedensted 55.8 9.70 #&gt; 703 8723 Løsning 55.8 9.70 #&gt; 704 8762 Flemming 55.9 9.66 #&gt; 705 8763 Rask Mølle 55.9 9.61 #&gt; 706 8781 Stenderup 55.8 9.81 #&gt; 707 8783 Hornsyld 55.8 9.85 #&gt; 708 7800 Skive 56.6 9.02 #&gt; 709 7840 Højslev 56.6 9.17 #&gt; 710 7860 Spøttrup 56.6 8.82 #&gt; 711 7870 Roslev 56.7 8.99 #&gt; 712 7884 Fur 56.8 9.02 #&gt; 713 7470 Karup J 56.3 9.20 #&gt; 714 7850 Stoholm Jyll 56.5 9.14 #&gt; 715 8800 Viborg 56.4 9.39 #&gt; 716 8830 Tjele 56.5 9.61 #&gt; 717 8831 Løgstrup 56.5 9.32 #&gt; 718 8832 Skals 56.6 9.37 #&gt; 719 8840 Rødkærsbro 56.4 9.51 #&gt; 720 8850 Bjerringbro 56.4 9.65 #&gt; 721 9632 Møldrup 56.6 9.50 #&gt; 722 7900 Nykøbing M 56.8 8.83 #&gt; 723 7950 Erslev 56.8 8.71 #&gt; 724 7960 Karby 56.8 8.58 #&gt; 725 7970 Redsted M 56.7 8.65 #&gt; 726 7980 Vils 56.8 8.73 #&gt; 727 7990 Øster Assels 56.7 8.72 #&gt; 728 7700 Thisted 57.0 8.63 #&gt; 729 7730 Hanstholm 57.1 8.64 #&gt; 730 7741 Frøstrup 57.1 8.98 #&gt; 731 7742 Vesløs 57.0 8.97 #&gt; 732 7752 Snedsted 56.9 8.50 #&gt; 733 7755 Bedsted Thy 56.8 8.40 #&gt; 734 7760 Hurup Thy 56.7 8.41 #&gt; 735 7770 Vestervig 56.8 8.28 #&gt; 736 9320 Hjallerup 57.2 10.15 #&gt; 737 9330 Dronninglund 57.2 10.30 #&gt; 738 9340 Asaa 57.1 10.39 #&gt; 739 9700 Brønderslev 57.3 9.95 #&gt; 740 9740 Jerslev J 57.3 10.11 #&gt; 741 9300 Sæby 57.3 10.50 #&gt; 742 9352 Dybvad 57.3 10.33 #&gt; 743 9750 Østervrå 57.3 10.26 #&gt; 744 9900 Frederikshavn 57.4 10.50 #&gt; 745 9970 Strandby 57.5 10.49 #&gt; 746 9981 Jerup 57.5 10.44 #&gt; 747 9982 Ålbæk 57.6 10.40 #&gt; 748 9990 Skagen 57.7 10.56 #&gt; 749 9600 Aars 56.8 9.50 #&gt; 750 9620 Aalestrup 56.7 9.49 #&gt; 751 9631 Gedsted 56.7 9.34 #&gt; 752 9640 Farsø 56.8 9.29 #&gt; 753 9670 Løgstør 56.9 9.27 #&gt; 754 9681 Ranum 56.9 9.20 #&gt; 755 9940 Læsø 57.3 11.01 #&gt; 756 9520 Skørping 56.8 9.91 #&gt; 757 9530 Støvring 56.9 9.82 #&gt; 758 9541 Suldrup 56.8 9.69 #&gt; 759 9574 Bælum 56.8 10.12 #&gt; 760 9575 Terndrup 56.8 10.06 #&gt; 761 9610 Nørager 56.7 9.67 #&gt; 762 9500 Hobro 56.6 9.80 #&gt; 763 9510 Arden 56.8 9.89 #&gt; 764 9550 Mariager 56.7 10.01 #&gt; 765 9560 Hadsund 56.8 10.21 #&gt; 766 9440 Aabybro 57.1 9.74 #&gt; 767 9460 Brovst 57.1 9.52 #&gt; 768 9490 Pandrup 57.2 9.64 #&gt; 769 9492 Blokhus 57.3 9.60 #&gt; 770 9493 Saltum 57.3 9.66 #&gt; 771 9690 Fjerritslev 57.1 9.26 #&gt; 772 9000 Aalborg 57.0 9.91 #&gt; 773 9200 Aalborg SV 57.0 9.87 #&gt; 774 9210 Aalborg SØ 57.0 9.94 #&gt; 775 9220 Aalborg Øst 57.0 9.99 #&gt; 776 9230 Svenstrup J 57.0 9.85 #&gt; 777 9240 Nibe 57.0 9.62 #&gt; 778 9260 Gistrup 57.0 9.99 #&gt; 779 9270 Klarup 57.0 10.05 #&gt; 780 9280 Storvorde 57.0 10.17 #&gt; 781 9293 Kongerslev 56.9 10.12 #&gt; 782 9310 Vodskov 57.1 10.07 #&gt; 783 9362 Gandrup 57.1 10.19 #&gt; 784 9370 Hals 57.0 10.33 #&gt; 785 9380 Vestbjerg 57.1 9.96 #&gt; 786 9381 Sulsted 57.2 9.96 #&gt; 787 9382 Tylstrup 57.2 9.94 #&gt; 788 9400 Nørresundby 57.1 9.92 #&gt; 789 9430 Vadum 57.1 9.86 #&gt; 790 9480 Løkken 57.4 9.74 #&gt; 791 9760 Vrå 57.4 9.95 #&gt; 792 9800 Hjørring 57.5 9.97 #&gt; 793 9830 Tårs 57.4 10.13 #&gt; 794 9850 Hirtshals 57.6 9.97 #&gt; 795 9870 Sindal 57.5 10.24 #&gt; 796 9881 Bindslev 57.6 10.20 #&gt; 797 2670 Greve 55.6 12.30 #&gt; 798 2690 Karlslunde 55.6 12.25 #&gt; 799 4030 Tune 55.6 12.19 #&gt; 800 4140 Borup 55.5 11.98 #&gt; 801 4600 Køge 55.5 12.17 #&gt; 802 4623 Lille Skensved 55.5 12.10 #&gt; 803 4632 Bjæverskov 55.5 12.04 #&gt; 804 4681 Herfølge 55.4 12.14 #&gt; 805 4682 Tureby 55.4 12.08 #&gt; 806 4000 Roskilde 55.7 12.10 #&gt; 807 4040 Jyllinge 55.8 12.11 #&gt; 808 4130 Viby Sjælland 55.5 12.02 #&gt; 809 4621 Gadstrup 55.6 12.10 #&gt; 810 2680 Solrød Strand 55.5 12.21 #&gt; 811 4622 Havdrup 55.5 12.12 #&gt; 812 4500 Nykøbing Sj 55.9 11.64 #&gt; 813 4534 Hørve 55.8 11.43 #&gt; 814 4540 Fårevejle 55.8 11.43 #&gt; 815 4550 Asnæs 55.8 11.50 #&gt; 816 4560 Vig 55.9 11.56 #&gt; 817 4571 Grevinge 55.8 11.59 #&gt; 818 4572 Nørre Asmindrup 55.9 11.62 #&gt; 819 4573 Højby 55.9 11.55 #&gt; 820 4581 Rørvig 55.9 11.75 #&gt; 821 4583 Sjællands Odde 56.0 11.36 #&gt; 822 4300 Holbæk 55.7 11.71 #&gt; 823 4305 Orø 55.8 11.81 #&gt; 824 4340 Tølløse 55.6 11.73 #&gt; 825 4350 Ugerløse 55.6 11.65 #&gt; 826 4360 Kirke Eskilstrup 55.6 11.77 #&gt; 827 4370 Store Merløse 55.5 11.72 #&gt; 828 4390 Vipperød 55.7 11.74 #&gt; 829 4420 Regstrup 55.7 11.62 #&gt; 830 4440 Mørkøv 55.7 11.51 #&gt; 831 4450 Jyderup 55.7 11.41 #&gt; 832 4520 Svinninge 55.7 11.48 #&gt; 833 4532 Gislinge 55.7 11.55 #&gt; 834 4640 Faxe 55.2 12.12 #&gt; 835 4653 Karise 55.3 12.20 #&gt; 836 4654 Faxe Ladeplads 55.2 12.16 #&gt; 837 4683 Rønnede 55.3 12.03 #&gt; 838 4690 Haslev 55.3 11.97 #&gt; 839 4270 Høng 55.5 11.30 #&gt; 840 4281 Gørlev 55.5 11.18 #&gt; 841 4400 Kalundborg 55.7 11.08 #&gt; 842 4460 Snertinge 55.7 11.38 #&gt; 843 4470 Svebølle 55.7 11.29 #&gt; 844 4480 Store Fuglede 55.6 11.17 #&gt; 845 4490 Jerslev Sjælland 55.6 11.23 #&gt; 846 4591 Føllenslev 55.7 11.33 #&gt; 847 4592 Sejerø 55.9 11.13 #&gt; 848 4593 Eskebjerg 55.7 11.27 #&gt; 849 4100 Ringsted 55.4 11.81 #&gt; 850 4174 Jystrup Midtsj 55.5 11.86 #&gt; 851 4200 Slagelse 55.4 11.34 #&gt; 852 4220 Korsør 55.3 11.15 #&gt; 853 4230 Skælskør 55.3 11.30 #&gt; 854 4241 Vemmelev 55.4 11.26 #&gt; 855 4242 Boeslunde 55.3 11.27 #&gt; 856 4243 Rude 55.2 11.49 #&gt; 857 4244 Agersø 55.2 11.19 #&gt; 858 4245 Omø 55.2 11.15 #&gt; 859 4261 Dalmose 55.3 11.42 #&gt; 860 4652 Hårlev 55.4 12.23 #&gt; 861 4660 Store Heddinge 55.3 12.38 #&gt; 862 4671 Strøby 55.4 12.30 #&gt; 863 4672 Klippinge 55.4 12.33 #&gt; 864 4673 Rødvig Stevns 55.3 12.37 #&gt; 865 4173 Fjenneslev 55.4 11.66 #&gt; 866 4180 Sorø 55.4 11.56 #&gt; 867 4190 Munke Bjergby 55.5 11.53 #&gt; 868 4291 Ruds Vedby 55.5 11.38 #&gt; 869 4293 Dianalund 55.5 11.49 #&gt; 870 4295 Stenlille 55.5 11.58 #&gt; 871 4296 Nyrup 55.5 11.65 #&gt; 872 4060 Kirke Såby 55.6 11.86 #&gt; 873 4070 Kirke Hyllinge 55.7 11.89 #&gt; 874 4320 Lejre 55.6 11.97 #&gt; 875 4330 Hvalsø 55.6 11.86 #&gt; 876 4895 Errindlev 54.7 11.50 #&gt; 877 4900 Nakskov 54.8 11.13 #&gt; 878 4912 Harpelunde 54.9 11.07 #&gt; 879 4913 Horslunde 54.9 11.21 #&gt; 880 4920 Søllested 54.8 11.28 #&gt; 881 4930 Maribo 54.8 11.50 #&gt; 882 4941 Bandholm 54.8 11.47 #&gt; 883 4942 Askø 54.9 11.50 #&gt; 884 4943 Torrig L 54.9 11.32 #&gt; 885 4944 Fejø 54.9 11.41 #&gt; 886 4945 Femø 55.0 11.54 #&gt; 887 4951 Nørreballe 54.8 11.43 #&gt; 888 4952 Stokkemarke 54.8 11.37 #&gt; 889 4953 Vesterborg 54.9 11.30 #&gt; 890 4960 Holeby 54.7 11.48 #&gt; 891 4970 Rødby 54.7 11.36 #&gt; 892 4983 Dannemare 54.7 11.19 #&gt; 893 4160 Herlufmagle 55.3 11.75 #&gt; 894 4171 Glumsø 55.4 11.69 #&gt; 895 4250 Fuglebjerg 55.3 11.55 #&gt; 896 4262 Sandved 55.3 11.52 #&gt; 897 4684 Holmegaard 55.3 11.83 #&gt; 898 4700 Næstved 55.2 11.76 #&gt; 899 4733 Tappernøje 55.2 11.97 #&gt; 900 4736 Karrebæksminde 55.2 11.65 #&gt; 901 4800 Nykøbing F 54.8 11.88 #&gt; 902 4840 Nørre Alslev 54.9 11.85 #&gt; 903 4850 Stubbekøbing 54.9 12.04 #&gt; 904 4862 Guldborg 54.9 11.73 #&gt; 905 4863 Eskilstrup 54.9 11.88 #&gt; 906 4871 Horbelev 54.8 12.06 #&gt; 907 4872 Idestrup 54.7 11.98 #&gt; 908 4873 Væggerløse 54.7 11.95 #&gt; 909 4874 Gedser 54.6 11.94 #&gt; 910 4880 Nysted 54.7 11.73 #&gt; 911 4891 Toreby L 54.8 11.78 #&gt; 912 4892 Kettinge 54.7 11.75 #&gt; 913 4894 Øster Ulslev 54.7 11.61 #&gt; 914 4990 Sakskøbing 54.8 11.65 #&gt; 915 4720 Præstø 55.1 12.06 #&gt; 916 4735 Mern 55.0 12.07 #&gt; 917 4750 Lundby 55.1 11.84 #&gt; 918 4760 Vordingborg 55.0 11.92 #&gt; 919 4771 Kalvehave 55.0 12.15 #&gt; 920 4772 Langebæk 55.0 12.08 #&gt; 921 4773 Stensved 55.0 12.03 #&gt; 922 4780 Stege 55.0 12.29 #&gt; 923 4791 Borre 55.0 12.47 #&gt; 924 4792 Askeby 54.9 12.16 #&gt; 925 4793 Bogø By 54.9 12.05 #&gt; 926 5463 Harndrup 55.5 10.02 #&gt; 927 5464 Brenderup Fyn 55.5 9.97 #&gt; 928 5466 Asperup 55.5 9.90 #&gt; 929 5500 Middelfart 55.5 9.76 #&gt; 930 5580 Nørre Aaby 55.5 9.87 #&gt; 931 5591 Gelsted 55.4 9.96 #&gt; 932 5592 Ejby 55.4 9.92 #&gt; 933 5492 Vissenbjerg 55.4 10.14 #&gt; 934 5560 Aarup 55.4 10.05 #&gt; 935 5610 Assens 55.3 9.92 #&gt; 936 5620 Glamsbjerg 55.3 10.09 #&gt; 937 5631 Ebberup 55.2 9.99 #&gt; 938 5683 Haarby 55.2 10.11 #&gt; 939 5690 Tommerup 55.3 10.20 #&gt; 940 5600 Faaborg 55.1 10.25 #&gt; 941 5601 Lyø 55.0 10.15 #&gt; 942 5602 Avernakø 55.0 10.28 #&gt; 943 5603 Bjørnø 55.1 10.25 #&gt; 944 5642 Millinge 55.1 10.17 #&gt; 945 5672 Broby 55.2 10.26 #&gt; 946 5750 Ringe 55.2 10.46 #&gt; 947 5772 Kværndrup 55.2 10.53 #&gt; 948 5792 Årslev 55.3 10.44 #&gt; 949 5854 Gislev 55.2 10.60 #&gt; 950 5856 Ryslinge 55.2 10.54 #&gt; 951 5863 Ferritslev Fyn 55.3 10.58 #&gt; 952 5290 Marslev 55.4 10.52 #&gt; 953 5300 Kerteminde 55.5 10.65 #&gt; 954 5330 Munkebo 55.5 10.55 #&gt; 955 5350 Rynkeby 55.4 10.61 #&gt; 956 5370 Mesinge 55.5 10.63 #&gt; 957 5380 Dalby 55.5 10.67 #&gt; 958 5390 Martofte 55.6 10.63 #&gt; 959 5550 Langeskov 55.4 10.59 #&gt; 960 5540 Ullerslev 55.4 10.66 #&gt; 961 5800 Nyborg 55.3 10.78 #&gt; 962 5853 Ørbæk 55.3 10.66 #&gt; 963 5871 Frørup 55.2 10.76 #&gt; 964 5000 Odense C 55.4 10.39 #&gt; 965 5200 Odense V 55.4 10.33 #&gt; 966 5210 Odense NV 55.4 10.31 #&gt; 967 5220 Odense SØ 55.4 10.46 #&gt; 968 5230 Odense M 55.4 10.40 #&gt; 969 5240 Odense NØ 55.4 10.44 #&gt; 970 5250 Odense SV 55.4 10.34 #&gt; 971 5260 Odense S 55.3 10.39 #&gt; 972 5270 Odense N 55.4 10.36 #&gt; 973 5320 Agedrup 55.4 10.48 #&gt; 974 5491 Blommenslyst 55.4 10.25 #&gt; 975 5700 Svendborg 55.1 10.61 #&gt; 976 5762 Vester Skerninge 55.1 10.46 #&gt; 977 5771 Stenstrup 55.1 10.51 #&gt; 978 5874 Hesselager 55.2 10.77 #&gt; 979 5881 Skårup Fyn 55.1 10.70 #&gt; 980 5882 Vejstrup 55.1 10.71 #&gt; 981 5883 Oure 55.1 10.72 #&gt; 982 5884 Gudme 55.1 10.70 #&gt; 983 5892 Gudbjerg Sydfyn 55.2 10.66 #&gt; 984 5400 Bogense 55.6 10.09 #&gt; 985 5450 Otterup 55.5 10.40 #&gt; 986 5462 Morud 55.4 10.19 #&gt; 987 5471 Søndersø 55.5 10.20 #&gt; 988 5474 Veflinge 55.5 10.15 #&gt; 989 5485 Skamby 55.5 10.28 #&gt; 990 5900 Rudkøbing 54.9 10.74 #&gt; 991 5932 Humble 54.8 10.69 #&gt; 992 5935 Bagenkop 54.8 10.69 #&gt; 993 5943 Strynø 54.9 10.61 #&gt; 994 5953 Tranekær 55.1 10.88 #&gt; 995 5960 Marstal 54.9 10.51 #&gt; 996 5965 Birkholm 54.9 10.50 #&gt; 997 5970 Ærøskøbing 54.9 10.39 #&gt; 998 5985 Søby Ærø 54.9 10.27 #&gt; 999 6100 Haderslev 55.2 9.52 #&gt; 1000 6500 Vojens 55.2 9.30 #&gt; 1001 6510 Gram 55.3 9.03 #&gt; 1002 6541 Bevtoft 55.2 9.20 #&gt; 1003 6560 Sommersted 55.3 9.28 #&gt; 1004 6623 Vorbasse 55.6 9.08 #&gt; 1005 7190 Billund 55.7 9.12 #&gt; 1006 7200 Grindsted 55.8 8.92 #&gt; 1007 7250 Hejnsvig 55.7 8.98 #&gt; 1008 7260 Sønder Omme 55.8 8.90 #&gt; 1009 6300 Gråsten 54.9 9.57 #&gt; 1010 6310 Broager 54.9 9.68 #&gt; 1011 6320 Egernsund 54.9 9.62 #&gt; 1012 6400 Sønderborg 54.9 9.78 #&gt; 1013 6430 Nordborg 55.0 9.79 #&gt; 1014 6440 Augustenborg 55.0 9.92 #&gt; 1015 6470 Sydals 54.9 9.96 #&gt; 1016 6240 Løgumkloster 55.1 8.98 #&gt; 1017 6261 Bredebro 55.1 8.77 #&gt; 1018 6270 Tønder 54.9 8.87 #&gt; 1019 6280 Højer 55.0 8.70 #&gt; 1020 6520 Toftlund 55.2 9.04 #&gt; 1021 6534 Agerskov 55.1 9.14 #&gt; 1022 6535 Branderup J 55.1 9.06 #&gt; 1023 6780 Skærbæk 55.2 8.78 #&gt; 1024 6792 Rømø 55.1 8.54 #&gt; 1025 6690 Gørding 55.5 8.80 #&gt; 1026 6700 Esbjerg 55.5 8.46 #&gt; 1027 6705 Esbjerg Ø 55.5 8.50 #&gt; 1028 6710 Esbjerg V 55.5 8.39 #&gt; 1029 6715 Esbjerg N 55.5 8.46 #&gt; 1030 6731 Tjæreborg 55.5 8.59 #&gt; 1031 6740 Bramming 55.5 8.71 #&gt; 1032 6760 Ribe 55.3 8.77 #&gt; 1033 6771 Gredstedbro 55.4 8.75 #&gt; 1034 6720 Fanø 55.4 8.40 #&gt; 1035 6753 Agerbæk 55.6 8.80 #&gt; 1036 6800 Varde 55.6 8.50 #&gt; 1037 6818 Årre 55.6 8.67 #&gt; 1038 6823 Ansager 55.7 8.75 #&gt; 1039 6830 Nørre Nebel 55.8 8.27 #&gt; 1040 6840 Oksbøl 55.6 8.27 #&gt; 1041 6851 Janderup Vestj 55.6 8.37 #&gt; 1042 6852 Billum 55.6 8.33 #&gt; 1043 6853 Vejers Strand 55.6 8.13 #&gt; 1044 6854 Henne 55.7 8.21 #&gt; 1045 6855 Outrup 55.7 8.35 #&gt; 1046 6857 Blåvand 55.6 8.15 #&gt; 1047 6862 Tistrup 55.7 8.61 #&gt; 1048 6870 Ølgod 55.8 8.62 #&gt; 1049 6600 Vejen 55.5 9.14 #&gt; 1050 6621 Gesten 55.5 9.20 #&gt; 1051 6622 Bække 55.6 9.15 #&gt; 1052 6630 Rødding 55.4 9.11 #&gt; 1053 6650 Brørup 55.5 9.02 #&gt; 1054 6660 Lintrup 55.4 8.98 #&gt; 1055 6670 Holsted 55.5 8.91 #&gt; 1056 6682 Hovborg 55.6 8.94 #&gt; 1057 6683 Føvling 55.4 8.91 #&gt; 1058 6752 Glejbjerg 55.6 8.83 #&gt; 1059 6200 Aabenraa 55.0 9.44 #&gt; 1060 6210 Barsø 55.1 9.56 #&gt; 1061 6230 Rødekro 55.1 9.32 #&gt; 1062 6330 Padborg 54.8 9.35 #&gt; 1063 6340 Kruså 54.9 9.44 #&gt; 1064 6360 Tinglev 54.9 9.24 #&gt; 1065 6372 Bylderup-Bov 55.0 9.10 #&gt; 1066 6392 Bolderslev 55.0 9.27 #&gt; 1067 7000 Fredericia 55.6 9.72 #&gt; 1068 6000 Kolding 55.5 9.48 #&gt; 1069 6051 Almind 55.6 9.48 #&gt; 1070 6052 Viuf 55.6 9.49 #&gt; 1071 6064 Jordrup 55.6 9.31 #&gt; 1072 6070 Christiansfeld 55.4 9.47 #&gt; 1073 6091 Bjert 55.5 9.57 #&gt; 1074 6092 Sønder Stenderup 55.5 9.62 #&gt; 1075 6093 Sjølund 55.4 9.56 #&gt; 1076 6094 Hejls 55.4 9.60 #&gt; 1077 6580 Vamdrup 55.4 9.31 #&gt; 1078 6640 Lunderskov 55.5 9.31 #&gt; 1079 6040 Egtved 55.6 9.35 #&gt; 1080 7080 Børkop 55.6 9.67 #&gt; 1081 7100 Vejle 55.7 9.52 #&gt; 1082 7120 Vejle Øst 55.7 9.61 #&gt; 1083 7173 Vonge 55.9 9.42 #&gt; 1084 7182 Bredsten 55.7 9.36 #&gt; 1085 7183 Randbøl 55.7 9.26 #&gt; 1086 7184 Vandel 55.7 9.21 #&gt; 1087 7300 Jelling 55.8 9.43 #&gt; 1088 7321 Gadbjerg 55.8 9.31 #&gt; 1089 7323 Give 55.9 9.25 #&gt; 1090 9100 Aalborg 57.0 9.92 #&gt; 1091 8100 Aarhus C 56.2 10.21 #&gt; 1092 8245 Risskov Ø 56.2 10.25 #&gt; 1093 5100 Odense C 55.4 10.39 #&gt; 1094 6701 Esbjerg 55.5 8.45 #&gt; 1095 7007 Fredericia 55.6 9.75 #&gt; 1096 900 København C 57.0 9.92 #&gt; 1097 960 Udland 56.8 9.51 #&gt; 1098 999 København C 57.7 10.58 #&gt; 1099 1001 København K 55.7 12.57 #&gt; 1100 1002 København K 55.7 12.57 #&gt; 1101 1003 København K 55.7 12.57 #&gt; 1102 1004 København K 55.7 12.57 #&gt; 1103 1005 København K 55.7 12.57 #&gt; 1104 1006 København K 55.7 12.57 #&gt; 1105 1007 København K 55.7 12.57 #&gt; 1106 1008 København K 55.7 12.57 #&gt; 1107 1009 København K 55.7 12.57 #&gt; 1108 1010 København K 55.7 12.57 #&gt; 1109 1011 København K 55.7 12.57 #&gt; 1110 1012 København K 55.7 12.57 #&gt; 1111 1013 København K 55.7 12.57 #&gt; 1112 1014 København K 55.7 12.57 #&gt; 1113 1015 København K 55.7 12.57 #&gt; 1114 1016 København K 55.7 12.57 #&gt; 1115 1017 København K 55.7 12.57 #&gt; 1116 1018 København K 55.7 12.57 #&gt; 1117 1019 København K 55.7 12.57 #&gt; 1118 1020 København K 55.7 12.57 #&gt; 1119 1021 København K 55.7 12.57 #&gt; 1120 1022 København K 55.7 12.57 #&gt; 1121 1023 København K 55.7 12.57 #&gt; 1122 1024 København K 55.7 12.57 #&gt; 1123 1025 København K 55.7 12.57 #&gt; 1124 1026 København K 55.7 12.57 #&gt; 1125 1092 København K 55.7 12.57 #&gt; 1126 1093 København K 55.7 12.57 #&gt; 1127 1095 København K 55.7 12.57 #&gt; 1128 1098 København K 55.7 12.57 #&gt; 1129 1140 København K 55.7 12.57 #&gt; 1130 1147 København K 55.7 12.57 #&gt; 1131 1148 København K 55.7 12.57 #&gt; 1132 1217 København K 55.7 12.57 #&gt; 1133 1240 København K 55.7 12.57 #&gt; 1134 1448 København K 55.7 12.57 #&gt; 1135 1500 København V 55.7 12.57 #&gt; 1136 1501 København V 55.7 12.57 #&gt; 1137 1502 København V 55.7 12.57 #&gt; 1138 1503 København V 55.7 12.57 #&gt; 1139 1504 København V 55.7 12.57 #&gt; 1140 1505 København V 55.7 12.57 #&gt; 1141 1506 København V 55.7 12.57 #&gt; 1142 1507 København V 55.7 12.57 #&gt; 1143 1508 København V 55.7 12.57 #&gt; 1144 1509 København V 55.7 12.57 #&gt; 1145 1510 København V 55.7 12.57 #&gt; 1146 1513 Centraltastning 55.7 12.57 #&gt; 1147 1592 København V 55.7 12.57 #&gt; 1148 1599 København V 55.7 12.57 #&gt; 1149 1630 København V 55.7 12.57 #&gt; 1150 1780 København V 55.7 12.57 #&gt; 1151 1785 København V 55.7 12.57 #&gt; 1152 1786 København V 55.7 12.57 #&gt; 1153 1787 København V 55.7 12.57 #&gt; 1154 1790 København V 55.7 12.57 #&gt; 1155 1835 Frederiksberg C 55.7 12.53 #&gt; 1156 917 Københavns Pakkecent 55.7 12.57 #&gt; 1157 800 Høje Taastrup 55.6 12.27 #&gt; 1158 1532 København V 55.7 12.57 #&gt; 1159 1533 København V 55.7 12.57 We want to calculate distances between a subset of zip areas: idx &lt;- sample(1:nrow(zips), 5, replace = F) dat &lt;- zips[idx,] dat #&gt; postal_code place_name latitude longitude #&gt; 962 5853 Ørbæk 55.3 10.7 #&gt; 425 1854 Frederiksberg C 55.7 12.5 #&gt; 815 4550 Asnæs 55.8 11.5 #&gt; 220 1460 København K 55.7 12.6 #&gt; 887 4951 Nørreballe 54.8 11.4 distanceMat &lt;- matrix(NA, nrow = length(idx), ncol = length(idx)) colnames(distanceMat) &lt;- str_c(dat$postal_code, dat$place_name, sep = &quot; &quot;) rownames(distanceMat) &lt;- colnames(distanceMat) distanceMat #&gt; 5853 Ørbæk 1854 Frederiksberg C 4550 Asnæs 1460 København K 4951 Nørreballe #&gt; 5853 Ørbæk NA NA NA NA NA #&gt; 1854 Frederiksberg C NA NA NA NA NA #&gt; 4550 Asnæs NA NA NA NA NA #&gt; 1460 København K NA NA NA NA NA #&gt; 4951 Nørreballe NA NA NA NA NA We can find average distances between two zip codes in dat using function: library(geodist) getDist &lt;- function(i, j) { return(geodist(dat[i, ], dat[j, ], measure = &quot;haversine&quot;) / 1000) # convert to km (return in meters) } getDist(1, 3) # distance between row 1 and 3 #&gt; [,1] #&gt; [1,] 81.8 × Solution for(i in 1:nrow(distanceMat)) { for(j in 1:ncol(distanceMat)) { if (i&gt;j) {distanceMat[i,j] &lt;- distanceMat[j,i]; next} # assume symmetric distances if (!is.na(distanceMat[i,j])) next # value already calculated if (i==j) {distanceMat[i,j] &lt;- 0; next} distanceMat[i,j] &lt;- getDist(i, j) } } distanceMat #&gt; 5853 Ørbæk 1854 Frederiksberg C 4550 Asnæs 1460 København K 4951 Nørreballe #&gt; 5853 Ørbæk 0.0 126.80 81.8 128.98 70.4 #&gt; 1854 Frederiksberg C 126.8 0.00 67.0 2.29 119.3 #&gt; 4550 Asnæs 81.8 66.99 0.0 69.17 113.2 #&gt; 1460 København K 129.0 2.29 69.2 0.00 120.7 #&gt; 4951 Nørreballe 70.4 119.26 113.2 120.73 0.0 Close Solution × Hint for(i in 1:nrow(distanceMat)) { for(j in 1:ncol(distanceMat)) { if (i&gt;j) {__} # assume symmetric distances if (!is.na(distanceMat[i,j])) next # value already calculated if (i==j) {__; next} __ } } distanceMat Close Hint Use nested for loops to fill distanceMat with distances. Assume that the distance from a to b is the same as from b to a. That is, you only have to call the function once for two zip codes. 9.5.5 Exercise (expand_grid) × Solution ite &lt;- expand_grid(i = c(1,5), j = 2:3) ite #&gt; # A tibble: 4 × 2 #&gt; i j #&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 1 2 #&gt; 2 1 3 #&gt; 3 5 2 #&gt; 4 5 3 distanceMat &lt;- matrix(NA, nrow = length(idx), ncol = length(idx)) for(r in 1:nrow(ite)) { i &lt;- ite$i[r] j &lt;- ite$j[r] if (!is.na(distanceMat[j,i])) {distanceMat[i,j] &lt;- distanceMat[j,i]; next} # assume symmetric distances if (!is.na(distanceMat[i,j])) next # value already calculated if (i==j) {distanceMat[i,j] &lt;- 0; next} distanceMat[i,j] &lt;- getDist(i, j) } distanceMat #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] NA 127 81.8 NA NA #&gt; [2,] NA NA NA NA NA #&gt; [3,] NA NA NA NA NA #&gt; [4,] NA NA NA NA NA #&gt; [5,] NA 119 113.2 NA NA Close Solution × Hint ite &lt;- expand_grid(i = __, j = __) ite distanceMat &lt;- matrix(NA, nrow = length(idx), ncol = length(idx)) for(r in 1:nrow(ite)) { i &lt;- ite$i[r] j &lt;- __ if (!is.na(distanceMat[j,i])) {__; next} # assume symmetric distances if (!is.na(distanceMat[i,j])) next # value already calculated if (i==j) {distanceMat[i,j] &lt;- 0; next} distanceMat[i,j] &lt;- __ } distanceMat Close Hint Consider the solution of Exercise 9.5.4 and assume that you only want to calculate the distance from rows 1 and 5 to rows 2 and 3 in dat. Modify the solution using expand_grid so only one loop is used. "],["mod-r-functions.html", "Module 10 Functions 10.1 Learning outcomes 10.2 DataCamp course 10.3 Functions returning multiple objects 10.4 The ... argument 10.5 Documenting your functions 10.6 Example - Job sequencing 10.7 Recap 10.8 Exercises", " Module 10 Functions To understand computations in R, two slogans are helpful: Everything that exists is an object. Everything that happens is a function call. John Chambers Writing functions is a core activity of an R programmer. It represents the key step of the transition from a user to a programmer. Functions have inputs and outputs. Functions (and control structures) are what makes your code more dynamic. Functions are often used to encapsulate a sequence of expressions that needs to be executed numerous times, perhaps under slightly different conditions. In programming, functional programming is a programming paradigm, a style of how code is written. Rather than repeating the code, functions and control structures allow one to build code in blocks. As a result, your code becomes more structured, more readable and much easier to maintain and debug (find errors). A template project for this module is given on Posit Cloud (open it and use it while reading the notes). Learning path diagram It is recommended that you follow the green learning path; however, you may like a different learning style. In the learning path diagram, there are links to alternative online content (video or reading). Note this is an alternative to the standard learning path that you may use instead (you should not do both). The learning path may also have extra content, that is NOT a part of syllabus (only look at it if you want more info)! 10.1 Learning outcomes By the end of this module, you are expected to be able to: Call a function. Formulate a function with different input arguments. Describe why functions are important in R. Set defaults for input arguments. Return values from functions. Explain how variable scope and precedence works. Document functions. The learning outcomes relate to the overall learning goals number 2, 3, 4 and 10 of the course. 10.2 DataCamp course An excellent introduction to functions is given in Chapter 3 in the DataCamp course Intermediate R. Please complete the chapter before continuing. 10.3 Functions returning multiple objects Functions in R only return a single object. However, note that the object may be a list. That is, if you want to return multiple arguments, store them in a list. A simple example: test &lt;- function() { # the function does some stuff and calculate some results res1 &lt;- 45 res2 &lt;- &quot;Success&quot; res3 &lt;- c(4, 7, 9) res4 &lt;- list(cost = 23, profit = 200) lst &lt;- list(days = res1, run = res2, id = res3, money = res4) return(lst) } test() #&gt; $days #&gt; [1] 45 #&gt; #&gt; $run #&gt; [1] &quot;Success&quot; #&gt; #&gt; $id #&gt; [1] 4 7 9 #&gt; #&gt; $money #&gt; $money$cost #&gt; [1] 23 #&gt; #&gt; $money$profit #&gt; [1] 200 10.4 The ... argument The special argument ... indicates a variable number of arguments and is usually used to pass arguments to nested functions used inside the function. Consider example: my_name &lt;- function(first = &quot;Lars&quot;, last = &quot;Nielsen&quot;) { str_c(first, last, sep = &quot; &quot;) } my_name() #&gt; [1] &quot;Lars Nielsen&quot; cite_text &lt;- function(text, ...) { str_c(text, &#39;, -&#39;, my_name(...)) } cite_text(&quot;Learning by doing is the best way to learn how to program!&quot;) #&gt; [1] &quot;Learning by doing is the best way to learn how to program!, -Lars Nielsen&quot; cite_text(&quot;Learning by doing is the best way to learn how to program!&quot;, last = &quot;Relund&quot;) #&gt; [1] &quot;Learning by doing is the best way to learn how to program!, -Lars Relund&quot; cite_text(&quot;To be or not to be&quot;, first = &quot;Shakespeare&quot;, last = &quot;&quot;) #&gt; [1] &quot;To be or not to be, -Shakespeare &quot; Note in the first function run, we use the defaults in my_name. In the second run, we change the default last name and in the last run, we change both arguments. If you need to retrieve/capture the content of the ... argument, put it in a list: test &lt;- function(...) { return(list(...)) } test(x = 4, y = &quot;hey&quot;, z = 1:5) #&gt; $x #&gt; [1] 4 #&gt; #&gt; $y #&gt; [1] &quot;hey&quot; #&gt; #&gt; $z #&gt; [1] 1 2 3 4 5 10.5 Documenting your functions It is always a good idea to document your functions. This is in fact always done in functions of a package. For instance try ?mutate and see the documentation in the Help tab. Assume that you have written a function subtract &lt;- function(x, y) { return(x-y) } In RStudio you can insert a Roxygen documentation skeleton by having the cursor at the first line of the function and go to Code &gt; Insert Roxygen Skeleton (Ctrl+Alt+Shift+R): #&#39; Title #&#39; #&#39; @param x #&#39; @param y #&#39; @return #&#39; @export #&#39; @examples subtract &lt;- function(x, y) { return(x-y) } You now can modify your documentation to #&#39; Subtract two vectors #&#39; #&#39; @param x First vector. #&#39; @param y Vector to be subtracted. #&#39; @return The difference. #&#39; @export #&#39; @examples #&#39; subtract(x = c(5,5), y = c(2,3)) subtract &lt;- function(x, y) { return(x-y) } Note Parameters/function arguments are documented using the @param tag. Return value is documented using the @return tag. Under the @examples tag you can insert some examples. Ignore the @export tag. This is used if you include your function in your own package. Package development is beyond the scope of this course. If you are interested, have a look at the book Hadley Wickham (2015). A list of further tags can be seen in the vignette Rd (documentation) tags. 10.6 Example - Job sequencing Recall the job sequencing problem in Section 5.8 that consider a problem of determining the best sequencing of jobs on a machine. A set of startup costs are given for 5 machines: startup_costs &lt;- c(27, 28, 32, 35, 26) startup_costs #&gt; [1] 27 28 32 35 26 Moreover, when changing from one job to another job, the setup costs are given as: setup_costs &lt;- matrix(c( NA, 35, 22, 44, 12, 49, NA, 46, 38, 17, 46, 12, NA, 29, 41, 23, 37, 31, NA, 26, 17, 23, 28, 34, NA), byrow = T, nrow = 5) setup_costs #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] NA 35 22 44 12 #&gt; [2,] 49 NA 46 38 17 #&gt; [3,] 46 12 NA 29 41 #&gt; [4,] 23 37 31 NA 26 #&gt; [5,] 17 23 28 34 NA For instance, the setup cost from Job 2 to Job 4 is 38. The goal of the problem is to determine a sequence of jobs which minimizes the total setup cost including the startup cost. One possible way to find a sequence is the use a greedy strategy: Greedy Algorithm Step 0: Start with the job which has minimal startup cost. Step 1: Select the next job as the job not already done with minimal setup cost given current job. Step 2: Set next job in Step 1 to current job and go to Step 1 if not all jobs are done. In R the greedy algorithm can be implemented as: #&#39; Calculate a job sequence based on a greedy algorithm #&#39; #&#39; @param startup Startup costs. #&#39; @param setup Setup costs. #&#39; @return A list with the job sequence and total setup costs. greedy &lt;- function(startup, setup) { jobs &lt;- nrow(setup) cur_job &lt;- which.min(startup) cost &lt;- startup[cur_job] # cat(&quot;Start job:&quot;, cur_job, &quot;\\n&quot;) job_seq &lt;- cur_job setup[, cur_job] &lt;- NA for (i in 1:(jobs-1)) { next_job &lt;- which.min(setup[cur_job, ]) # cat(&quot;Next job:&quot;, next_job, &quot;\\n&quot;) cost &lt;- cost + setup[cur_job, next_job] job_seq &lt;- c(job_seq, next_job) cur_job &lt;- next_job setup[, cur_job] &lt;- NA } # print(setup) return(list(seq = job_seq, cost = cost)) } greedy(startup_costs, setup_costs) #&gt; $seq #&gt; [1] 5 1 3 2 4 #&gt; #&gt; $cost #&gt; [1] 115 First, the job with minimum startup cost is found using function which.min and we define cost as the startup cost. We use cat to make some debugging statements and initialize job_seq with the first job. Next, we have to find a way of ignoring jobs already done. We do that here by setting the columns of setup cost equal to NA for jobs already done. Hence, they will not be selected by which.min. The for loop runs 4 times and selects jobs and accumulate the total cost. Finally, the job sequence and the total cost is returned as a list. A well-known better strategy is to: Better Algorithm Step 0: Subtract minimum of startup and setup cost for each job from setup and startup costs (that is columnwise) Step 1: Call the greedy algorithm with the modified costs. Note that the total cost returned has to be modified a bit. The better strategy implemented in R: #&#39; Calculate a job sequence based on a better (greedy) algorithm #&#39; #&#39; @param startup Startup costs. #&#39; @param setup Setup costs. #&#39; @return A list with the job sequence and total setup costs. better &lt;- function(startup, setup) { jobs &lt;- nrow(setup) min_col_val &lt;- apply(rbind(startup, setup), 2, min, na.rm = T) startup &lt;- startup - min_col_val min_mat &lt;- matrix(rep(min_col_val, jobs), ncol = jobs, byrow = T) setup &lt;- setup - min_mat lst &lt;- greedy(startup, setup) lst$cost &lt;- lst$cost + sum(min_col_val) return(lst) } better(startup_costs, setup_costs) #&gt; $seq #&gt; [1] 4 1 3 2 5 #&gt; #&gt; $cost #&gt; [1] 109 First the number of jobs are identified. Next, we need to find the minimum value in each column. Here we use the apply function. The first argument is the setup matrix with the startup costs added as a row. The second argument is 2 indicating that we should apply the third argument to each column (if was equal 1 then to each row). The third argument is the function to apply to each column (here min). The last argument is an optional argument passed to the min function. With the current values min_col_val equals 17, 12, 22, 29, and 12. Afterwards the minimum values are subtracted in each column. Note for subtracting the minimum values from the setup cost, we first need to create a matrix with the minimum values (min_mat). Finally, we call the greedy algorithm with the new costs and correct the returned result with the minimum values. 10.7 Recap Writing functions is a core activity of an R programmer. It represents the key step of the transition from a user to a programmer. Functions have inputs and outputs. Functions (and control structures) are what makes your code more dynamic. Functions are often used to encapsulate a sequence of expressions that need to be executed numerous times, perhaps under slightly different conditions. In programming, functional programming is a programming paradigm, a style of how code is written. Rather than repeating the code, functions and control structures allow one to build code in blocks. As a result, your code becomes more structured, more readable and much easier to maintain and debug (find errors). Functions can be defined using the function() directive. The named arguments (input values) can have default values. Moreover, R passes arguments by value. That is, an R function cannot change the variable that you input to that function. A function can be called using its name and its arguments can be specified by name or by position in the argument list. Functions always return the last expression evaluated in the function body or when you use the return flow control statement (good coding practice). Scoping refers to the rules R use to look up the value of variables. A function will first look inside the body of the function to identify all the variables. If all variables exist, no further search is required. Otherwise, R will look one level up to see if the variable exists. Functions can be assigned to R objects just like any other R object. Document your functions using the Roxygen skeleton! You may also have a look at the slides for this module . 10.8 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Some of the solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up too early. Put some effort into finding a solution! Always practice using shortcuts in RStudio (see Tools &gt; Keyboard Shortcuts Help). Go to the Tools for Analytics workspace and download/export the TM10 project. Open it on your laptop and have a look at the files in the exercises folder which can be used as a starting point. 10.8.1 Exercise (defining functions) Solve this exercise using a script file. × Solution #&#39; Computes the sum of the integers from 1 to n (inclusive). #&#39; #&#39; @param n Max value in the sum. #&#39; #&#39; @return Sum of the integers from 1 to n. #&#39; #&#39; @examples #&#39; sum_n(30) sum_n &lt;- function(n) { return(sum(1:n)) } sum_n(5000) #&gt; [1] 12502500 Close Solution × Hint #&#39; Computes the sum of the integers from 1 to n (inclusive). #&#39; #&#39; @param n Max value in the sum. #&#39; #&#39; @return Sum of the integers from 1 to n. #&#39; #&#39; @examples #&#39; sum_n(30) sum_n &lt;- function(n) { return(___) } sum_n(5000) Close Hint Create a function sum_n that for any given value, say \\(n\\), computes the sum of the integers from 1 to n (inclusive). Use the function to determine the sum of integers from 1 to 5000. Document your function too. × Solution #&#39; Computes the sum S_n = 1^2 + 2^2 + 3^2 + ... + n^2 #&#39; #&#39; @param n Max input in sum. #&#39; #&#39; @return S_n compute_s_n &lt;- function(n) { return(sum((1:n)^2)) } compute_s_n(10) #&gt; [1] 385 Close Solution Write a function compute_s_n that for any given \\(n\\) computes the sum \\(S_n = 1^2 + 2^2 + 3^2 + \\dots + n^2\\). Report the value of the sum when \\(n=10\\). × Solution 1 s_n &lt;- vector(&#39;numeric&#39;, 25) for (n in 1:25) { s_n[n] &lt;- compute_s_n(n) } s_n #&gt; [1] 1 5 14 30 55 91 140 204 285 385 506 650 819 1015 1240 1496 1785 2109 2470 #&gt; [20] 2870 3311 3795 4324 4900 5525 Close Solution 1 × Hint 1 s_n &lt;- vector(&#39;numeric&#39;, 25) for (n in 1:25) { s_n[n] &lt;- ___ } s_n Close Hint 1 × Solution 2 compute_s_n_alt &lt;- function(n) { return(n*(n+1)*(2*n+1)/6) } for (n in 1:25) { if (s_n[n] != compute_s_n_alt(n)) { cat(&#39;Error!&#39;) break } } Close Solution 2 × Hint 2 compute_s_n_alt &lt;- function(n) { return(n*(n+1)*___) } for (n in 1:25) { if (s_n[n] != ___) { cat(&#39;Error!&#39;) break } } Close Hint 2 Define an empty numerical vector s_n of size 25 using s_n &lt;- vector(\"numeric\", 25) and store in the results of \\(S_1, S_2, \\dots S_{25}\\) using a for-loop. Confirm that the formula for the sum is \\(S_n= n(n+1)(2n+1)/6\\) for \\(n = 1, \\ldots, 25\\). × Solution biggest &lt;- function(a, b) { if (a &gt; b) return(1) return(0) } biggest(3,4) #&gt; [1] 0 biggest(3,3) #&gt; [1] 0 biggest(8,2) #&gt; [1] 1 Close Solution × Hint biggest &lt;- function(a, b) { if (a &gt; b) ___ return(0) } Close Hint Write a function biggest which takes two integers as arguments. Let the function return 1 if the first argument is larger than the second and return 0 otherwise. × Solution shipping_cost &lt;- function(total) { return(0.1 * total) } shipping_cost(450) #&gt; [1] 45 Close Solution × Hint shipping_cost &lt;- function(total) { return(___) } Close Hint Write a function that returns the shipping cost as 10% of the total cost of an order (input argument). × Solution shipping_cost &lt;- function(total, pct = 0.1) { return(pct * total) } shipping_cost(450) #&gt; [1] 45 shipping_cost(450, pct = 0.2) #&gt; [1] 90 Close Solution × Hint shipping_cost &lt;- function(total, pct = ___) { ___ } Close Hint Given Question 5, rewrite the function so the percentage is an input argument with a default of 10%. × Solution shipping_cost &lt;- function(total) { return(0.1 * total) } gasoline_cost &lt;- function(total) { return(shipping_cost(total) * 0.5) } gasoline_cost(450) #&gt; [1] 22.5 Close Solution × Hint gasoline_cost &lt;- function(total) { return(shipping_cost(___) * ___) } Close Hint Given Question 5, the shipping cost can be split into parts. One part is gasoline which is 50% of the shipping cost. Write a function that has total cost as input argument and calculate the gasoline cost and use the function defined in Question 5 inside it. × Solution shipping_cost &lt;- function(total, pct = 0.1) { return(pct * total) } gasoline_cost &lt;- function(total, ...) { return(shipping_cost(total, ...) * 0.5) } gasoline_cost(450) #&gt; [1] 22.5 gasoline_cost(450, pct = 0.2) #&gt; [1] 45 Close Solution × Hint gasoline_cost &lt;- function(total, ...) { return(shipping_cost(___) * ___) } Close Hint Given Question 6, the shipping cost can be split into parts. One part is gasoline which is 50% of the shipping cost. Write a function that has total cost a input argument and calculate the gasoline cost and use the function defined in Question 6 inside it. Hint: Use the ... argument to pass arguments to shipping_cost. × Solution shipping_cost &lt;- function(total, pct = 0.1) { return(pct * total) } gasoline_cost &lt;- function(total, ...) { return(shipping_cost(total, ...) * 0.5) } costs &lt;- function(total, ...) { lst &lt;- list(total = total, shipping = shipping_cost(total, ...), gasoline = gasoline_cost(total, ...)) return(lst) } costs(450) #&gt; $total #&gt; [1] 450 #&gt; #&gt; $shipping #&gt; [1] 45 #&gt; #&gt; $gasoline #&gt; [1] 22.5 costs(450, pct = 0.15) #&gt; $total #&gt; [1] 450 #&gt; #&gt; $shipping #&gt; [1] 67.5 #&gt; #&gt; $gasoline #&gt; [1] 33.8 Close Solution × Hint shipping_cost &lt;- function(total, pct = 0.1) { return(pct * total) } gasoline_cost &lt;- function(total, ...) { return(shipping_cost(total, ...) * 0.5) } costs &lt;- function(total, ...) { lst &lt;- list(total = ___, shipping = ___, gasoline = ___) return(lst) } Close Hint Given Question 8, write a function costs that, given total cost, returns the total cost, shipping cost and gasoline cost. 10.8.2 Exercise (euclidean distances) This exercise is a slightly modified version an exam assignment (exam 2021-A1). The euclidean distance between two points \\(p = (p_1,p_2)\\) and \\(q = (q_1,q_2)\\) can be calculated using formula \\[ d(p,q) = \\sqrt{(p_1-q_1)^2 + (p_2-q_2)^2}.\\] × Solution p &lt;- c(10,10) q &lt;- c(4,3) sqrt((p[1] - q[1])^2 + (p[2] - q[2])^2) #&gt; [1] 9.22 The distance is 9.22. Close Solution Calculate the distance between points \\(p = (10,10)\\) and \\(q = (4,3)\\) using the formula. × Solution d_mat = matrix(NA, nrow = nrow(p_mat), ncol = nrow(p_mat)) for (i in 1:nrow(d_mat)) { for (j in 1:ncol(d_mat)) { # if (i&gt;j) {d_mat[i,j] &lt;- d_mat[j,i]; next} # assume symmetric distances # if (!is.na(d_mat[i,j])) next # value already calculated if (i==j) {d_mat[i,j] &lt;- 0; next} d_mat[i,j] &lt;- sqrt((p_mat[i,1] - p_mat[j,1])^2 + (p_mat[i,2] - p_mat[j,2])^2) } } d_mat #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 0.00 9.22 8.25 2.83 #&gt; [2,] 9.22 0.00 8.06 6.40 #&gt; [3,] 8.25 8.06 0.00 7.21 #&gt; [4,] 2.83 6.40 7.21 0.00 The distance matrix is given above. Close Solution Consider 4 points in a matrix (one in each row): p_mat &lt;- matrix(c(0, 7, 8, 2, 10, 16, 8, 12), nrow = 4) p_mat #&gt; [,1] [,2] #&gt; [1,] 0 10 #&gt; [2,] 7 16 #&gt; [3,] 8 8 #&gt; [4,] 2 12 The distance matrix of p_mat is a 4 times 4 matrix where entry (i,j) contains the distance from the point in row i to the point in row j. Calculate the distance matrix of p_mat. × Solution calc_distances &lt;- function(p_mat, from = 1:nrow(p_mat), to = 1:nrow(p_mat)) { d_mat &lt;- matrix(NA, nrow = nrow(p_mat), ncol = nrow(p_mat)) ite &lt;- expand_grid(from = from, to = to) for (r in 1:nrow(ite)) { i &lt;- ite$from[r] j &lt;- ite$to[r] if (!is.na(d_mat[i,j])) next # value already calculated if (i==j) {d_mat[i,j] &lt;- 0; next} d_mat[i,j] &lt;- sqrt((p_mat[i,1] - p_mat[j,1])^2 + (p_mat[i,2] - p_mat[j,2])^2) } return(d_mat) } p_mat &lt;- matrix(c(10, 9, 15, 15, 11, 19, 12, 11, 7, 15), nrow = 5) calc_distances(p_mat) #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] 0.00 7.07 9.43 13.00 4.12 #&gt; [2,] 7.07 0.00 6.08 7.81 3.61 #&gt; [3,] 9.43 6.08 0.00 4.00 5.66 #&gt; [4,] 13.00 7.81 4.00 0.00 8.94 #&gt; [5,] 4.12 3.61 5.66 8.94 0.00 calc_distances(p_mat, to = 3:4) #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] NA NA 9.43 13.00 NA #&gt; [2,] NA NA 6.08 7.81 NA #&gt; [3,] NA NA 0.00 4.00 NA #&gt; [4,] NA NA 4.00 0.00 NA #&gt; [5,] NA NA 5.66 8.94 NA calc_distances(p_mat, from = c(1, nrow(p_mat)), to = 3:4) #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] NA NA 9.43 13.00 NA #&gt; [2,] NA NA NA NA NA #&gt; [3,] NA NA NA NA NA #&gt; [4,] NA NA NA NA NA #&gt; [5,] NA NA 5.66 8.94 NA The function with test are given above. Close Solution × Hint calc_distances &lt;- function(p_mat, from = 1:nrow(p_mat), to = 1:nrow(p_mat)) { d_mat &lt;- matrix(NA, nrow = ___, ncol = ___) ite &lt;- expand_grid(___) for (r in 1:nrow(ite)) { i &lt;- ___ j &lt;- ___ if (!is.na(d_mat[i,j])) next # value already calculated if (i==j) {d_mat[i,j] &lt;- 0; next} d_mat[i,j] &lt;- ___ } return(d_mat) } Close Hint Create a function calc_distances with the following features (implement as many as you can): Takes a matrix p_mat with a point in each row as input argument. Takes two additional input arguments from and to with default values 1:nrow(p_mat) Return the distance matrix with values calculated for rows in the from input argument and columns in the to input argument. The other entries equals NA. The function should work for different p_mat (you may assume that the matrix always have two columns). You may test your code using: p_mat &lt;- matrix(c(10, 9, 15, 15, 11, 19, 12, 11, 7, 15), nrow = 5) calc_distances(p_mat) calc_distances(p_mat, to = 3:4) calc_distances(p_mat, from = c(1, nrow(p_mat)), to = 3:4) 10.8.3 Exercise (scope) × Solution That value is still 3 since x defined inside the function is a local variable. Close Solution After running the code below, what is the value of variable x? x &lt;- 3 my_func &lt;- function(y){ x &lt;- 5 return(y + 5) } my_func(7) × Solution The code runs. But it is not good coding practice to call global variables inside a function (x). Instead x should have been an argument to the function. Close Solution Is there any problems with the following code? x &lt;- 3 my_func &lt;- function(y){ return(y + x) } my_func(7) × Solution That value is still 3 since my_func has not been called yet. Close Solution Have a look at the documentation for operator &lt;&lt;- (run ?'&lt;&lt;-'). After running the code below, what is the value of variable x? x &lt;- 3 my_func &lt;- function(y){ x &lt;- 4 x &lt;&lt;- 5 return(y + 5) } × Solution That value of x is 5 since &lt;&lt;- is used to look at the parent environment. The function call returns 11 since the x used is the local variable. In general avoid using &lt;&lt;- and give local variables different names compared to global ones. Close Solution After running the code below, what is the value of variable x and output of the function call? x &lt;- 3 my_func &lt;- function(y){ x &lt;- 4 x &lt;&lt;- 5 return(y + x) } my_func(7) 10.8.4 Exercise (time conversion) This exercise is a slightly modified version an exam assignment (exam 2022-A1). × Solution SecToMin &lt;- function(sec) { return(sec / 60) } SecToHours &lt;- function(sec) { return(sec / 60 / 60) } MinToSec &lt;- function(min) { return(min * 60) } MinToHours &lt;- function(min) { return(min / 60) } HoursToMin &lt;- function(hours) { return(hours * 60) } HoursToSec &lt;- function(hours) { return(hours * 60 * 60) } Close Solution Make functions: SecToMin which takes an input argument sec in seconds and return the number converted to minutes. SecToHours which takes an input argument sec in seconds and return the number converted to hours. MinToSec which takes an input argument min in minutes and return the number converted to seconds. MinToHours which takes an input argument min in minutes and return the number converted to hours. HoursToMin which takes an input argument hours in hours and return the number converted to minutes. HoursToSec which takes an input argument hours in hours and return the number converted to seconds. All numbers may be decimal numbers, e.g. 90 seconds is 1.5 minutes and 1.5 hours is 90 minutes. × Solution ConvertTime &lt;- function(val, unit) { if (unit == &quot;sec&quot;) { return(c(sec = val, min = SecToMin(val), hours = SecToHours(val))) } if (unit == &quot;min&quot;) { return(c(sec = MinToSec(val), min = val, hours = MinToHours(val))) } if (unit == &quot;hours&quot;) { return(c(sec = HoursToSec(val), min = HoursToMin(val), hours = val)) } return(NA) } ## We test the function: ConvertTime(val = 1.5, unit = &quot;min&quot;) #&gt; sec min hours #&gt; 90.000 1.500 0.025 ConvertTime(val = 1.5, unit = &quot;hours&quot;) #&gt; sec min hours #&gt; 5400.0 90.0 1.5 ConvertTime(val = 1.5, unit = &quot;kr&quot;) #&gt; [1] NA Close Solution Make a function ConvertTime which takes two input arguments: val A number. unit A string that can take values “sec”, “min” and “hours”. The function should return val converted to seconds, minutes and hours with features: works for all possible values for unit, uses the functions in Question 1, returns a vector with 3 numbers (seconds, minutes and hours) or NA if unit does not equals “sec”, “min” or “hours”. References Wickham, Hadley. 2015. R Packages: Organize, Test, Document, and Share Your Code. O’Reilly Media. http://r-pkgs.had.co.nz/. "],["mod-r-tidyverse-intro.html", "Module 11 Introduction to tidyverse and RMarkdown 11.1 Learning outcomes 11.2 The tidyverse package 11.3 Writing reproducible reports 11.4 Tibbles 11.5 Recap 11.6 Exercises", " Module 11 Introduction to tidyverse and RMarkdown The tidyverse is a collection of R packages designed for data science. RMarkdown documents support the concept of literate programming where you weave R code together with text (written in Markdown) to produce elegantly formatted documents. A template project for this module is given on Posit Cloud (open it and use it while reading the notes). Learning path diagram It is recommended that you follow the green learning path; however, you may like a different learning style. In the learning path diagram, there are links to alternative online content (video or reading). Note this is an alternative to the standard learning path that you may use instead (you should not do both). The learning path may also have extra content, that is NOT a part of syllabus (only look at it if you want more info)! 11.1 Learning outcomes By the end of this module, you are expected to be able to: Describe what the tidyverse package is. Explain the ideas behind reproducible reports and literal programming. Create your first RMarkdown document and add some code and text. The learning outcomes relate to the overall learning goals number 7, 17 and 18 of the course. 11.2 The tidyverse package The tidyverse is a collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. The core tidyverse includes the packages that you are likely to use in everyday data analyses. In tidyverse 1.3.0, the following packages are included in the core tidyverse: dplyr provides a grammar of data manipulation, providing a consistent set of verbs that solve the most common data manipulation challenges. We are going to use dplyr in Module 13. ggplot2 is a system for declaratively creating graphics, based on The Grammar of Graphics. You provide the data, tell ggplot2 how to map variables to aesthetics, what graphical primitives to use, and it takes care of the details. We are going to use ggplot in Module 14. tidyr provides a set of functions that help you get to tidy data. Tidy data is data with a consistent form: in brief, every variable goes in a column, and every column is a variable. readr provides a fast and friendly way to read rectangular data (like csv, tsv, and fwf). It is designed to flexibly parse many types of data found in the wild, while still cleanly failing when data unexpectedly changes. We are going to use dplyr in Module 12. purrr enhances R’s functional programming (FP) toolkit by providing a complete and consistent set of tools for working with functions and vectors. Once you master the basic concepts, purrr allows you to replace many for loops with code that is easier to write and more expressive. This package is not covered in this course. tibble is a modern re-imagining of the data frame, keeping what time has proven to be effective, and throwing out what has not. Tibbles are data frames that are lazy and surly: they do less and complain more forcing you to confront problems earlier, typically leading to cleaner, more expressive code. We are going to use tibbles in Module 13. stringr provides a cohesive set of functions designed to make working with strings as easy as possible. You have already worked a bit with stringr in Exercise 8.7.8 forcats provides a suite of useful tools that solve common problems with factors. R uses factors to handle categorical variables, variables that have a fixed and known set of possible values. This package is not covered in this course. Small introductions (with examples) to the packages are given on their documentation pages (follow the links above). The tidyverse also includes many other packages with more specialized usage. They are not loaded automatically with library(tidyverse), so you will need to load each one with its own call to library(). 11.3 Writing reproducible reports The concept of literate programming was originally introduced by Donald Knuth in 1984. In a nutshell, Knuth envisioned a new programming paradigm where computer scientists focus on weaving code together with text as documentation. That is, when we do an Analytics project, we are interested in writing reports containing both R code for importing data, wrangling and analysis. Moreover, at the same time, the document should contain our comments about the code, plots, analysis, results, etc. The document is then rendered to an output format such as html, pdf or Word which is presented to the decision maker. Note the document can be seen as the “the source code” for the report communicated to the decision maker. Some developers have created tools to enable others to write better literate programs. They use a markup language made for authoring. We are going to focus on RMarkdown. In RMarkdown documents you can weave R code together with text (written in Markdown) to produce elegantly formatted output. In fact this book is written in RMarkdown by using a set of RMarkdown documents bound together as a collection using the bookdown package, rendered to a web page using RStudio, shared on GitHub, built by GitHub Actions, and published on GitHub Pages. This may seem complicated at first. However, after setup, it makes life much easier, since we can update the book easier, share and collaborate on the book easier, update the web page automatically, keep history of the book source, keep the book source at a single location. RMarkdown documents are reproducible. Anybody who works with data has at some point heard a colleague say ‘Well, it works on my computer’, expressing dismay at the fact that you cannot reproduce their results. Ultimately, reproducible means that the results can be reproduced given access to the original data, software, and code. In practice it may be hard to make your project totally reproducible. For instance, people may be using a different operating system, other versions of the software, etc. That is, there are different levels of reproducibility. In this course, we will focus on RMarkdown only. See Module 11 for more info about levels of reproducibility. An introduction to RMarkdown is given in Chapters 3 and 4 of the DataCamp course Communicating with Data in the Tidyverse. Note that you may skip Chapters 1 and 2 and still understand most of the questions in Chapters 3 and 4 (otherwise just see the solution). You are expected to have completed the chapters before continuing this module! The RMarkdown cheatsheet may be useful. Find the newest version in RStudio Help &gt; Cheatsheets. All chunk options for R code can be seen here. 11.4 Tibbles Tibbles are a modern data frame, keeping what time has proven to be effective, and throwing out what is not. Tibbles are more strict compared to data frames e.g. they do not change variable names or types, do not do partial matching and complain more e.g. when a variable does not exist. This forces you to confront problems earlier, typically leading to cleaner, more expressive code. Moreover, tibbles have an enhanced print method and can have columns that are lists. Let us see a few examples: tbl1 &lt;- tibble(name = c(&quot;Lars&quot;, &quot;Susan&quot;, &quot;Hans&quot;), age = c(23, 56, 45)) tbl1 #&gt; # A tibble: 3 × 2 #&gt; name age #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Lars 23 #&gt; 2 Susan 56 #&gt; 3 Hans 45 tbl2 &lt;- tibble(x = 1:3, y = list(1:5, 1:10, 1:20)) tbl2 #&gt; # A tibble: 3 × 2 #&gt; x y #&gt; &lt;int&gt; &lt;list&gt; #&gt; 1 1 &lt;int [5]&gt; #&gt; 2 2 &lt;int [10]&gt; #&gt; 3 3 &lt;int [20]&gt; tbl3 &lt;- as_tibble(mtcars) tbl3 #&gt; # A tibble: 32 × 11 #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 #&gt; 2 21 6 160 110 3.9 2.88 17.0 0 1 4 4 #&gt; 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 #&gt; 4 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 #&gt; 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 #&gt; 6 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 #&gt; 7 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 #&gt; 8 24.4 4 147. 62 3.69 3.19 20 1 0 4 2 #&gt; 9 22.8 4 141. 95 3.92 3.15 22.9 1 0 4 2 #&gt; 10 19.2 6 168. 123 3.92 3.44 18.3 1 0 4 4 #&gt; # ℹ 22 more rows tbl4 &lt;- tribble( ~x, ~y, ~z, #--|--|---- &quot;a&quot;, 2, 3.6, &quot;b&quot;, 1, 8.5 ) tbl4 #&gt; # A tibble: 2 × 3 #&gt; x y z #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 a 2 3.6 #&gt; 2 b 1 8.5 Note that we can always coerce a data frame to a tibble (tbl3) or create it directly using tibble. Another way to create a tibble is with tribble. Here column headings are defined by formulas (i.e. they start with ~), and entries are separated by commas. This makes it possible to lay out small amounts of data in easy to read form. Tibbles have a refined print method that shows only the first 10 rows along with the number of columns that will fit on your screen. This makes it much easier to work with large data. In addition to its name, each column reports its type. Hence, your console is not overwhelmed with data. To see a full view of the data, you can use RStudio’s built-in data viewer: View(tbl3) 11.5 Recap tidyverse is a collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. RMarkdown is an example of literate programming. The core tidyverse includes the packages that you are likely to use in everyday data analyses. The concept of literate programming is a programming paradigm which focuses on weaving code together with text as documentation. That is, we are interested in writing reports containing both text and R code for importing data, wrangling and analysis. Reproducibility means that the results can be reproduced given access to the original data, software, and code. In practice it may be hard to make your project totally reproducible. That is, there are different levels of reproducibility. RMarkdown documents are an attempt to make reproducible documents and combine R code and markdown text. All chunk options for R code in RMarkdown documents can be seen here. The RMarkdown cheatsheet may be useful. Find the newest version in RStudio Help &gt; Cheatsheets. For Markdown syntax see Help &gt; Markdown Quick Reference. Tibbles are a modern data frame, keeping what time has proven to be effective, and throwing out what is not. Tibbles are more strict compared to data frames e.g. they do not change variable names or types, do not do partial matching and complain more e.g. when a variable does not exist. Tibbles have an enhanced print method and can have columns that are lists. You may also have a look at the slides for this module . 11.6 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Some of the solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up too early. Put some effort into finding a solution! Always practice using shortcuts in RStudio (see Tools &gt; Keyboard Shortcuts Help). Go to the Tools for Analytics workspace and download/export the TM11 project. Open it on your laptop and have a look at the files in the exercises folder which can be used as a starting point. 11.6.1 Exercise (your first RMarkdown exercise) Load the tfa package: # If tfa package is not installed then run # install.packages(&quot;remotes&quot;) # remotes::install_github(&quot;bss-osca/tfa-package&quot;, upgrade = FALSE) library(tfa) The package contains templates for exercises etc. Go to File &gt; New File &gt; R Markdown…. In the pop-up box select From template in the left column and then TFA Exercise. Press Ok and a new RMarkdown document will be opened. Change the meta text (e.g. the title and add your name) in the yaml. Render/compile the document by pressing the Knit button (or Ctrl+Shift+K). × Solution All the code is now hidden. But not the output. Close Solution Change echo = TRUE to echo = FALSE in the first chunk setup and render the document. What has happened? You can easily go to a chunk using the navigation in the bottom left of the source window. Try to change fig.asp = 0.25 to e.g. 0.5 in Chunk 10 (and set eval = TRUE). What happens? Note: You may need to call install.packages(\"ggraph\") if get Error in library(ggraph) : there is no package called 'ggraph'. Create a new section ## Question 4 and add text in italic: What is the sum of all setup costs? × Solution total &lt;- sum(setup_costs) Close Solution Add a code chunk solving Question 4 above. × Solution The sum of all setup costs are ̀r total ̀. Close Solution Add a line of text with the result. 11.6.2 Exercise (tibbles) Solve this exercise using an R script file. × Solution airquality |&gt; as_tibble() #&gt; # A tibble: 153 × 6 #&gt; Ozone Solar.R Wind Temp Month Day #&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 41 190 7.4 67 5 1 #&gt; 2 36 118 8 72 5 2 #&gt; 3 12 149 12.6 74 5 3 #&gt; 4 18 313 11.5 62 5 4 #&gt; 5 NA NA 14.3 56 5 5 #&gt; 6 28 NA 14.9 66 5 6 #&gt; 7 23 299 8.6 65 5 7 #&gt; 8 19 99 13.8 59 5 8 #&gt; 9 8 19 20.1 61 5 9 #&gt; 10 NA 194 8.6 69 5 10 #&gt; # ℹ 143 more rows Close Solution Convert the dataset airquality to a tibble. × Solution airquality |&gt; as_tibble() #&gt; # A tibble: 153 × 6 #&gt; Ozone Solar.R Wind Temp Month Day #&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 41 190 7.4 67 5 1 #&gt; 2 36 118 8 72 5 2 #&gt; 3 12 149 12.6 74 5 3 #&gt; 4 18 313 11.5 62 5 4 #&gt; 5 NA NA 14.3 56 5 5 #&gt; 6 28 NA 14.9 66 5 6 #&gt; 7 23 299 8.6 65 5 7 #&gt; 8 19 99 13.8 59 5 8 #&gt; 9 8 19 20.1 61 5 9 #&gt; 10 NA 194 8.6 69 5 10 #&gt; # ℹ 143 more rows airquality #&gt; Ozone Solar.R Wind Temp Month Day #&gt; 1 41 190 7.4 67 5 1 #&gt; 2 36 118 8.0 72 5 2 #&gt; 3 12 149 12.6 74 5 3 #&gt; 4 18 313 11.5 62 5 4 #&gt; 5 NA NA 14.3 56 5 5 #&gt; 6 28 NA 14.9 66 5 6 #&gt; 7 23 299 8.6 65 5 7 #&gt; 8 19 99 13.8 59 5 8 #&gt; 9 8 19 20.1 61 5 9 #&gt; 10 NA 194 8.6 69 5 10 #&gt; 11 7 NA 6.9 74 5 11 #&gt; 12 16 256 9.7 69 5 12 #&gt; 13 11 290 9.2 66 5 13 #&gt; 14 14 274 10.9 68 5 14 #&gt; 15 18 65 13.2 58 5 15 #&gt; 16 14 334 11.5 64 5 16 #&gt; 17 34 307 12.0 66 5 17 #&gt; 18 6 78 18.4 57 5 18 #&gt; 19 30 322 11.5 68 5 19 #&gt; 20 11 44 9.7 62 5 20 #&gt; 21 1 8 9.7 59 5 21 #&gt; 22 11 320 16.6 73 5 22 #&gt; 23 4 25 9.7 61 5 23 #&gt; 24 32 92 12.0 61 5 24 #&gt; 25 NA 66 16.6 57 5 25 #&gt; 26 NA 266 14.9 58 5 26 #&gt; 27 NA NA 8.0 57 5 27 #&gt; 28 23 13 12.0 67 5 28 #&gt; 29 45 252 14.9 81 5 29 #&gt; 30 115 223 5.7 79 5 30 #&gt; 31 37 279 7.4 76 5 31 #&gt; 32 NA 286 8.6 78 6 1 #&gt; 33 NA 287 9.7 74 6 2 #&gt; 34 NA 242 16.1 67 6 3 #&gt; 35 NA 186 9.2 84 6 4 #&gt; 36 NA 220 8.6 85 6 5 #&gt; 37 NA 264 14.3 79 6 6 #&gt; 38 29 127 9.7 82 6 7 #&gt; 39 NA 273 6.9 87 6 8 #&gt; 40 71 291 13.8 90 6 9 #&gt; 41 39 323 11.5 87 6 10 #&gt; 42 NA 259 10.9 93 6 11 #&gt; 43 NA 250 9.2 92 6 12 #&gt; 44 23 148 8.0 82 6 13 #&gt; 45 NA 332 13.8 80 6 14 #&gt; 46 NA 322 11.5 79 6 15 #&gt; 47 21 191 14.9 77 6 16 #&gt; 48 37 284 20.7 72 6 17 #&gt; 49 20 37 9.2 65 6 18 #&gt; 50 12 120 11.5 73 6 19 #&gt; 51 13 137 10.3 76 6 20 #&gt; 52 NA 150 6.3 77 6 21 #&gt; 53 NA 59 1.7 76 6 22 #&gt; 54 NA 91 4.6 76 6 23 #&gt; 55 NA 250 6.3 76 6 24 #&gt; 56 NA 135 8.0 75 6 25 #&gt; 57 NA 127 8.0 78 6 26 #&gt; 58 NA 47 10.3 73 6 27 #&gt; 59 NA 98 11.5 80 6 28 #&gt; 60 NA 31 14.9 77 6 29 #&gt; 61 NA 138 8.0 83 6 30 #&gt; 62 135 269 4.1 84 7 1 #&gt; 63 49 248 9.2 85 7 2 #&gt; 64 32 236 9.2 81 7 3 #&gt; 65 NA 101 10.9 84 7 4 #&gt; 66 64 175 4.6 83 7 5 #&gt; 67 40 314 10.9 83 7 6 #&gt; 68 77 276 5.1 88 7 7 #&gt; 69 97 267 6.3 92 7 8 #&gt; 70 97 272 5.7 92 7 9 #&gt; 71 85 175 7.4 89 7 10 #&gt; 72 NA 139 8.6 82 7 11 #&gt; 73 10 264 14.3 73 7 12 #&gt; 74 27 175 14.9 81 7 13 #&gt; 75 NA 291 14.9 91 7 14 #&gt; 76 7 48 14.3 80 7 15 #&gt; 77 48 260 6.9 81 7 16 #&gt; 78 35 274 10.3 82 7 17 #&gt; 79 61 285 6.3 84 7 18 #&gt; 80 79 187 5.1 87 7 19 #&gt; 81 63 220 11.5 85 7 20 #&gt; 82 16 7 6.9 74 7 21 #&gt; 83 NA 258 9.7 81 7 22 #&gt; 84 NA 295 11.5 82 7 23 #&gt; 85 80 294 8.6 86 7 24 #&gt; 86 108 223 8.0 85 7 25 #&gt; 87 20 81 8.6 82 7 26 #&gt; 88 52 82 12.0 86 7 27 #&gt; 89 82 213 7.4 88 7 28 #&gt; 90 50 275 7.4 86 7 29 #&gt; 91 64 253 7.4 83 7 30 #&gt; 92 59 254 9.2 81 7 31 #&gt; 93 39 83 6.9 81 8 1 #&gt; 94 9 24 13.8 81 8 2 #&gt; 95 16 77 7.4 82 8 3 #&gt; 96 78 NA 6.9 86 8 4 #&gt; 97 35 NA 7.4 85 8 5 #&gt; 98 66 NA 4.6 87 8 6 #&gt; 99 122 255 4.0 89 8 7 #&gt; 100 89 229 10.3 90 8 8 #&gt; 101 110 207 8.0 90 8 9 #&gt; 102 NA 222 8.6 92 8 10 #&gt; 103 NA 137 11.5 86 8 11 #&gt; 104 44 192 11.5 86 8 12 #&gt; 105 28 273 11.5 82 8 13 #&gt; 106 65 157 9.7 80 8 14 #&gt; 107 NA 64 11.5 79 8 15 #&gt; 108 22 71 10.3 77 8 16 #&gt; 109 59 51 6.3 79 8 17 #&gt; 110 23 115 7.4 76 8 18 #&gt; 111 31 244 10.9 78 8 19 #&gt; 112 44 190 10.3 78 8 20 #&gt; 113 21 259 15.5 77 8 21 #&gt; 114 9 36 14.3 72 8 22 #&gt; 115 NA 255 12.6 75 8 23 #&gt; 116 45 212 9.7 79 8 24 #&gt; 117 168 238 3.4 81 8 25 #&gt; 118 73 215 8.0 86 8 26 #&gt; 119 NA 153 5.7 88 8 27 #&gt; 120 76 203 9.7 97 8 28 #&gt; 121 118 225 2.3 94 8 29 #&gt; 122 84 237 6.3 96 8 30 #&gt; 123 85 188 6.3 94 8 31 #&gt; 124 96 167 6.9 91 9 1 #&gt; 125 78 197 5.1 92 9 2 #&gt; 126 73 183 2.8 93 9 3 #&gt; 127 91 189 4.6 93 9 4 #&gt; 128 47 95 7.4 87 9 5 #&gt; 129 32 92 15.5 84 9 6 #&gt; 130 20 252 10.9 80 9 7 #&gt; 131 23 220 10.3 78 9 8 #&gt; 132 21 230 10.9 75 9 9 #&gt; 133 24 259 9.7 73 9 10 #&gt; 134 44 236 14.9 81 9 11 #&gt; 135 21 259 15.5 76 9 12 #&gt; 136 28 238 6.3 77 9 13 #&gt; 137 9 24 10.9 71 9 14 #&gt; 138 13 112 11.5 71 9 15 #&gt; 139 46 237 6.9 78 9 16 #&gt; 140 18 224 13.8 67 9 17 #&gt; 141 13 27 10.3 76 9 18 #&gt; 142 24 238 10.3 68 9 19 #&gt; 143 16 201 8.0 82 9 20 #&gt; 144 13 238 12.6 64 9 21 #&gt; 145 23 14 9.2 71 9 22 #&gt; 146 36 139 10.3 81 9 23 #&gt; 147 7 49 10.3 69 9 24 #&gt; 148 14 20 16.6 63 9 25 #&gt; 149 30 193 6.9 70 9 26 #&gt; 150 NA 145 13.2 77 9 27 #&gt; 151 14 191 14.3 75 9 28 #&gt; 152 18 131 8.0 76 9 29 #&gt; 153 20 223 11.5 68 9 30 Close Solution Print the tibble and the original data frame and compare the difference. × Solution # here misc is a list with lists dat &lt;- tibble(name = c(&quot;Hans&quot;, &quot;Ole&quot;), age = c(23, 45), misc = list( list(status = 1, comment = &quot;To young&quot;), list(comment = &quot;Potential candidate&quot;))) dat #&gt; # A tibble: 2 × 3 #&gt; name age misc #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;list&gt; #&gt; 1 Hans 23 &lt;named list [2]&gt; #&gt; 2 Ole 45 &lt;named list [1]&gt; dat$misc[[1]] #&gt; $status #&gt; [1] 1 #&gt; #&gt; $comment #&gt; [1] &quot;To young&quot; Close Solution Create a tibble with 3 columns of data type string/character, double and list. "],["mod-r-io.html", "Module 12 Importing and exporting data 12.1 Learning outcomes 12.2 CSV files 12.3 Excel 12.4 Google Sheets 12.5 Text files 12.6 R’s native binary format 12.7 Json 12.8 Recap 12.9 Exercises", " Module 12 Importing and exporting data For doing data driven analytics, you first must import some data. That is, take data from a database, file, web API etc. and transform it into a data frame/table. Moreover, after processing data, you often want to export or store some of the results. This module introduces you to different ways of importing and exporting data. A template project for this module is given on Posit Cloud (open it and use it while reading the notes). Learning path diagram It is recommended that you follow the green learning path; however, you may like a different learning style. In the learning path diagram, there are links to alternative online content (video or reading). Note this is an alternative to the standard learning path that you may use instead (you should not do both). The learning path may also have extra content, that is NOT a part of syllabus (only look at it if you want more info)! 12.1 Learning outcomes By the end of this module, you are expected to be able to: Import and export csv files in different formats. Import and export data from Excel. Import and export data from Google Sheets. Write to a text file. Save data using R’s native format. Read and write to a json file. The learning outcomes relate to the overall learning goals number 7 and 13 of the course. 12.2 CSV files CSV files contain comma separated values (csv) in plain text and are often named using the file suffix .csv. Each line of the file is a data record. Each record consists of one or more fields, separated by a common delimiter (e.g. ,, ; or _). The CSV file format is not fully standardized. Different delimiters may be used, fields may be surrounded by quotation marks, text may contain escape characters and the encoding of the file may not be known. Despite these problems, CSV files are commonly used since they are easy to exchange and read. We will use the readr package for reading and writing. An overview over the functions can be seen in the cheatsheet. 12.2.1 Reading a CSV file In general use the following functions read_csv: Read a file with delimiter ,. read_csv2: Read a file with delimiter ;. read_delim: Read a file with a delimiter set by you. 12.2.1.1 Reading an unknown CSV file For importing a CSV file properly, you need to know the delimiter, if the files has headers and the encoding. If you are not sure, you may have a look on the file by opening it in a text editor or try to read some lines: csv_file &lt;- readr_example(&quot;mtcars.csv&quot;) # csv file lines &lt;- read_lines(csv_file, n_max = 3) lines #&gt; [1] &quot;\\&quot;mpg\\&quot;,\\&quot;cyl\\&quot;,\\&quot;disp\\&quot;,\\&quot;hp\\&quot;,\\&quot;drat\\&quot;,\\&quot;wt\\&quot;,\\&quot;qsec\\&quot;,\\&quot;vs\\&quot;,\\&quot;am\\&quot;,\\&quot;gear\\&quot;,\\&quot;carb\\&quot;&quot; #&gt; [2] &quot;21,6,160,110,3.9,2.62,16.46,0,1,4,4&quot; #&gt; [3] &quot;21,6,160,110,3.9,2.875,17.02,0,1,4,4&quot; cat(lines, sep = &quot;\\n&quot;) #&gt; &quot;mpg&quot;,&quot;cyl&quot;,&quot;disp&quot;,&quot;hp&quot;,&quot;drat&quot;,&quot;wt&quot;,&quot;qsec&quot;,&quot;vs&quot;,&quot;am&quot;,&quot;gear&quot;,&quot;carb&quot; #&gt; 21,6,160,110,3.9,2.62,16.46,0,1,4,4 #&gt; 21,6,160,110,3.9,2.875,17.02,0,1,4,4 It seems that the delimiter is a , and we may try to read the file using read_csv: dat &lt;- read_csv(csv_file) head(dat) #&gt; # A tibble: 6 × 11 #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 #&gt; 2 21 6 160 110 3.9 2.88 17.0 0 1 4 4 #&gt; 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 #&gt; 4 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 #&gt; 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 #&gt; 6 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 CSV files should always be saved using encoding UTF-8. However, sometimes you may have encoding problems when you read a file: csv_file &lt;- system.file(&quot;extdata/persons.csv&quot;, package = &quot;tfa&quot;) read_csv(csv_file) #&gt; # A tibble: 3 × 2 #&gt; first last #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 &quot;Hans&quot; &quot;S\\xf8gaard&quot; #&gt; 2 &quot;\\xc5ge&quot; &quot;\\xd8kse&quot; #&gt; 3 &quot;Yvette&quot; &quot;L\\xe6ske&quot; Note that some of the characters are not converted correctly. This is usually because the file encoding is not UTF-8. In this case, try to guess the encoding using: guess_encoding(csv_file) #&gt; # A tibble: 1 × 2 #&gt; encoding confidence #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 ISO-8859-1 0.27 dat &lt;- read_csv(csv_file, locale = locale(encoding = &quot;ISO-8859-1&quot;)) dat #&gt; # A tibble: 3 × 2 #&gt; first last #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Hans Søgaard #&gt; 2 Åge Økse #&gt; 3 Yvette Læske 12.2.2 Writing to CSV files Given a tibble/data frame export it using write_csv: csv_file &lt;- &quot;testing.csv&quot; write_csv(dat, file = csv_file) write_csv2(dat, file = &quot;testing_semicolon.csv&quot;) # use a semicolon as delimitor You can now always import the data again using read_csv: read_csv(csv_file) #&gt; # A tibble: 3 × 2 #&gt; first last #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Hans Søgaard #&gt; 2 Åge Økse #&gt; 3 Yvette Læske guess_encoding(csv_file) #&gt; # A tibble: 3 × 2 #&gt; encoding confidence #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 UTF-8 1 #&gt; 2 windows-1252 0.31 #&gt; 3 windows-1250 0.25 Note that write_csv always saves the file using encoding UTF-8. In a few cases, you may need to save a CSV file that can be read by Excel. For this purpose use: write_excel_csv2(dat, csv_file) The CSV file can now be opened correctly in Excel. 12.3 Excel There are different packages in R for reading and writing to Excel. We will use the readxl package for reading Excel files which is a part of tidyverse. The package supports both the legacy .xls format and the modern xml-based .xlsx format. Let us use one of the example files provided by the package: xlsx_file &lt;- system.file(&quot;extdata/datasets.xlsx&quot;, package = &quot;readxl&quot;) It is always a good idea to have a look at the file before you import from it. You can open it from R by using: browseURL(xlsx_file) Data can be read using: library(readxl) xlsx &lt;- read_excel(xlsx_file) # reads the first sheet xlsx #&gt; # A tibble: 32 × 11 #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 #&gt; 2 21 6 160 110 3.9 2.88 17.0 0 1 4 4 #&gt; 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 #&gt; 4 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 #&gt; 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 #&gt; 6 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 #&gt; 7 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 #&gt; 8 24.4 4 147. 62 3.69 3.19 20 1 0 4 2 #&gt; 9 22.8 4 141. 95 3.92 3.15 22.9 1 0 4 2 #&gt; 10 19.2 6 168. 123 3.92 3.44 18.3 1 0 4 4 #&gt; # ℹ 22 more rows xlsx &lt;- read_excel(xlsx_file, sheet = 2) # reads the second sheet xlsx #&gt; # A tibble: 71 × 2 #&gt; weight feed #&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 179 horsebean #&gt; 2 160 horsebean #&gt; 3 136 horsebean #&gt; 4 227 horsebean #&gt; 5 217 horsebean #&gt; 6 168 horsebean #&gt; 7 108 horsebean #&gt; 8 124 horsebean #&gt; 9 143 horsebean #&gt; 10 140 horsebean #&gt; # ℹ 61 more rows xlsx &lt;- read_excel(xlsx_file, sheet = &quot;quakes&quot;) # reads a named sheet xlsx #&gt; # A tibble: 1,000 × 5 #&gt; lat long depth mag stations #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 -20.4 182. 562 4.8 41 #&gt; 2 -20.6 181. 650 4.2 15 #&gt; 3 -26 184. 42 5.4 43 #&gt; 4 -18.0 182. 626 4.1 19 #&gt; 5 -20.4 182. 649 4 11 #&gt; 6 -19.7 184. 195 4 12 #&gt; 7 -11.7 166. 82 4.8 43 #&gt; 8 -28.1 182. 194 4.4 15 #&gt; 9 -28.7 182. 211 4.7 35 #&gt; 10 -17.5 180. 622 4.3 19 #&gt; # ℹ 990 more rows xlsx &lt;- read_excel(xlsx_file, sheet = &quot;mtcars&quot;, range = &quot;A5:G11&quot;, col_names = F) # reads a range #&gt; New names: #&gt; • `` -&gt; `...1` #&gt; • `` -&gt; `...2` #&gt; • `` -&gt; `...3` #&gt; • `` -&gt; `...4` #&gt; • `` -&gt; `...5` #&gt; • `` -&gt; `...6` #&gt; • `` -&gt; `...7` colnames(xlsx) &lt;- read_excel(xlsx_file, sheet = &quot;mtcars&quot;, range = &quot;A1:G1&quot;, col_names = F) # reads the column names #&gt; New names: #&gt; • `` -&gt; `...1` #&gt; • `` -&gt; `...2` #&gt; • `` -&gt; `...3` #&gt; • `` -&gt; `...4` #&gt; • `` -&gt; `...5` #&gt; • `` -&gt; `...6` #&gt; • `` -&gt; `...7` xlsx #&gt; # A tibble: 7 × 7 #&gt; mpg cyl disp hp drat wt qsec #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 21.4 6 258 110 3.08 3.22 19.4 #&gt; 2 18.7 8 360 175 3.15 3.44 17.0 #&gt; 3 18.1 6 225 105 2.76 3.46 20.2 #&gt; 4 14.3 8 360 245 3.21 3.57 15.8 #&gt; 5 24.4 4 147. 62 3.69 3.19 20 #&gt; 6 22.8 4 141. 95 3.92 3.15 22.9 #&gt; 7 19.2 6 168. 123 3.92 3.44 18.3 Writing to an Excel file can be done using the openxlsx package. To write to a new file use: library(openxlsx) dat &lt;- trees # test dataset head(dat) #&gt; Girth Height Volume #&gt; 1 8.3 70 10.3 #&gt; 2 8.6 65 10.3 #&gt; 3 8.8 63 10.2 #&gt; 4 10.5 72 16.4 #&gt; 5 10.7 81 18.8 #&gt; 6 10.8 83 19.7 write.xlsx(dat, &quot;test1.xlsx&quot;, sheetName = &quot;trees&quot;) # start at cell A1 write.xlsx(dat, &quot;test2.xlsx&quot;, sheetName = &quot;trees&quot;, startCol = &quot;C&quot;, startRow = 3) If you want to append a sheet to a file use: xlsx_file &lt;- system.file(&quot;extdata/datasets.xlsx&quot;, package = &quot;tfa&quot;) file.copy(xlsx_file, &quot;test.xlsx&quot;) # copy the file so can make some tests #&gt; [1] TRUE wb &lt;- loadWorkbook(file = &quot;test.xlsx&quot;) # read the workbook addWorksheet(wb = wb, sheetName = &quot;trees&quot;) writeData(wb, sheet = &quot;trees&quot;, x = dat) saveWorkbook(wb, file = &quot;test.xlsx&quot;, overwrite = TRUE) 12.4 Google Sheets You can import and export to Google sheets using the googlesheets4 package in tidyverse. To read and write data, in general, you need to be logged in as a Google user. The package will ask you when needed. However, if you only want to read data from a public sheet, you can use gs4_deauth to skip this: library(googlesheets4) gs4_deauth() To read data use: url &lt;- &quot;https://docs.google.com/spreadsheets/d/1U6Cf_qEOhiR9AZqTqS3mbMF3zt2db48ZP5v3rkrAEJY/edit#gid=780868077&quot; read_sheet(url) read_sheet(url, sheet = 3) range_read(url, sheet = 2, n_max = 3) range_read(url, range = &quot;Africa!A5:C15&quot;) To write data to a new file use: gs4_auth() gs &lt;- gs4_create(&quot;test&quot;, sheets = c(&quot;Sheet 1&quot;, &quot;Sheet 2&quot;)) write_sheet(dat, ss = gs) range_write(gs, dat, sheet = &quot;Sheet 1&quot;, range = &quot;C4&quot;) gs4_browse(gs) # have a look at the file in a browser To see the results, have a look at your Google sheet test in your browser. 12.5 Text files You can read and write to plain text files using the readr package. However, mostly you want to write to a text file because you want to save some kind of log file when you run your script. Here sink is an excellent function to use, since it redirects your R output. To see the output without messages, errors and warnings use: sink(file = &quot;ex1.log&quot;, split = TRUE) # open the file for output cat(&quot;This is a string\\n... and on a new line\\n\\n&quot;) print(&quot;This is another string&quot;) head(mtcars) rep(1, 4) message(&quot;A message.&quot;) warning(&quot;A warning.&quot;) rep(3, f) # a error cat(&quot;\\nLast line\\n&quot;) sink() # close the file again # file.show(&quot;ex1.log&quot;) # to view in external viewer Let us have a look at the content of the file (run cat(read_file(\"ex1.log\"))): This is a string ... and on a new line [1] &quot;This is another string&quot; mpg cyl disp hp drat wt qsec vs am gear carb Mazda RX4 21.0 6 160 110 3.90 2.62 16.5 0 1 4 4 Mazda RX4 Wag 21.0 6 160 110 3.90 2.88 17.0 0 1 4 4 Datsun 710 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 Hornet 4 Drive 21.4 6 258 110 3.08 3.21 19.4 1 0 3 1 Hornet Sportabout 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 Valiant 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 [1] 1 1 1 1 Last line Note that messages, errors and warnings are not included in the output. If you want to include it use: zz &lt;- file(&quot;ex2.log&quot;, open = &quot;wt&quot;) sink(zz, type = &quot;output&quot;) # open the file for output sink(zz, type = &quot;message&quot;) # open the same file for messages, errors and warnings cat(&quot;This is a string\\n... and on a new line\\n\\n&quot;) print(&quot;This is another string&quot;) head(mtcars) rep(1, 4) message(&quot;A message.&quot;) warning(&quot;A warning.&quot;) rep(3, f) # a error cat(&quot;\\nLast line\\n&quot;) sink() # close the file for output sink() # close the file for messages, errors and warnings That is, we call sink two times. Let us have a look at the content of the file: This is a string ... and on a new line [1] &quot;This is another string&quot; mpg cyl disp hp drat wt qsec vs am gear carb Mazda RX4 21.0 6 160 110 3.90 2.62 16.5 0 1 4 4 Mazda RX4 Wag 21.0 6 160 110 3.90 2.88 17.0 0 1 4 4 Datsun 710 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 Hornet 4 Drive 21.4 6 258 110 3.08 3.21 19.4 1 0 3 1 Hornet Sportabout 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 Valiant 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 [1] 1 1 1 1 A message. Warning message: A warning. Error: object &#39;f&#39; not found Last line Warning message: In sink() : no sink to remove ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. Error: unexpected symbol in &quot;By the&quot; Error: unexpected &#39;*&#39; in &quot;*&quot; Error: unexpected &#39;*&#39; in &quot;*&quot; Error: unexpected &#39;*&#39; in &quot;*&quot; Error: unexpected &#39;*&#39; in &quot;*&quot; Error: unexpected &#39;*&#39; in &quot;*&quot; Error: unexpected symbol in &quot;The learning&quot; Error: unexpected &#39;&lt;&#39; in &quot;&lt;&quot; Error: unexpected &#39;&lt;&#39; in &quot;&lt;&quot; Error: unexpected &#39;&lt;&#39; in &quot;&lt;&quot; Error: unexpected &#39;&lt;&#39; in &quot;&lt;&quot; Error: unexpected symbol in &quot;An excellent&quot; Error: unexpected &#39;&lt;&#39; in &quot;&lt;&quot; Error: unexpected &#39;&lt;&#39; in &quot;&lt;&quot; Error: unexpected &#39;&lt;&#39; in &quot;&lt;&quot; Error: unexpected &#39;&lt;&#39; in &quot;&lt;&quot; Error: unexpected &#39;&lt;&#39; in &quot;&lt;&quot; Error: unexpected symbol in &quot;Mutating joins&quot; Error: attempt to use zero-length variable name Error in curl::curl_fetch_memory(url, handle = handle) : Error in the HTTP2 framing layer ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. x Request failed [429]. Retry 1 happens in 3.5 seconds ... x Request failed [429]. Retry 2 happens in 3.5 seconds ... x Request failed [429]. Retry 3 happens in 8.2 seconds ... x Request failed [429]. Retry 1 happens in 2.5 seconds ... x Request failed [429]. Retry 2 happens in 1.9 seconds ... x Request failed [429]. Retry 3 happens in 26 seconds ... x Request failed [429]. Retry 1 happens in 4.2 seconds ... ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. ✓ Reading from &quot;learning_paths&quot;. ✓ Range &#39;&#39;r-transform&#39;&#39;. 12.6 R’s native binary format In general, we can differ between two main types of data/files. Information is either binary encoded (basically just 0’s and 1’s) or stored as text files. What we have considered so far is storing data in text files. Text files can be read by humans and computers alike. The great thing about plain text is their simplicity and their ease of use: any programming language can read a plain text file. Text files are good for storing tabular data but lacks type-safety, and has limited precision for numeric values. Binary file formats cannot be read by humans but allow space-efficient data compression. Furthermore, binary formats may be difficult to read and write using other programs. As most other programming languages, R comes with its own binary format. We will focus on the Rds data format which is optimized for speed and compression ratios. To save and read an R object use: dat &lt;- list(x = c(2, 5, 6), y = &quot;A string&quot;, z = mtcars) saveRDS(dat, file = &quot;test.rds&quot;) readRDS(&quot;test.rds&quot;) #&gt; $x #&gt; [1] 2 5 6 #&gt; #&gt; $y #&gt; [1] &quot;A string&quot; #&gt; #&gt; $z #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; Mazda RX4 21.0 6 160.0 110 3.90 2.62 16.5 0 1 4 4 #&gt; Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.88 17.0 0 1 4 4 #&gt; Datsun 710 22.8 4 108.0 93 3.85 2.32 18.6 1 1 4 1 #&gt; Hornet 4 Drive 21.4 6 258.0 110 3.08 3.21 19.4 1 0 3 1 #&gt; Hornet Sportabout 18.7 8 360.0 175 3.15 3.44 17.0 0 0 3 2 #&gt; Valiant 18.1 6 225.0 105 2.76 3.46 20.2 1 0 3 1 #&gt; Duster 360 14.3 8 360.0 245 3.21 3.57 15.8 0 0 3 4 #&gt; Merc 240D 24.4 4 146.7 62 3.69 3.19 20.0 1 0 4 2 #&gt; Merc 230 22.8 4 140.8 95 3.92 3.15 22.9 1 0 4 2 #&gt; Merc 280 19.2 6 167.6 123 3.92 3.44 18.3 1 0 4 4 #&gt; Merc 280C 17.8 6 167.6 123 3.92 3.44 18.9 1 0 4 4 #&gt; Merc 450SE 16.4 8 275.8 180 3.07 4.07 17.4 0 0 3 3 #&gt; Merc 450SL 17.3 8 275.8 180 3.07 3.73 17.6 0 0 3 3 #&gt; Merc 450SLC 15.2 8 275.8 180 3.07 3.78 18.0 0 0 3 3 #&gt; Cadillac Fleetwood 10.4 8 472.0 205 2.93 5.25 18.0 0 0 3 4 #&gt; Lincoln Continental 10.4 8 460.0 215 3.00 5.42 17.8 0 0 3 4 #&gt; Chrysler Imperial 14.7 8 440.0 230 3.23 5.34 17.4 0 0 3 4 #&gt; Fiat 128 32.4 4 78.7 66 4.08 2.20 19.5 1 1 4 1 #&gt; Honda Civic 30.4 4 75.7 52 4.93 1.61 18.5 1 1 4 2 #&gt; Toyota Corolla 33.9 4 71.1 65 4.22 1.83 19.9 1 1 4 1 #&gt; Toyota Corona 21.5 4 120.1 97 3.70 2.46 20.0 1 0 3 1 #&gt; Dodge Challenger 15.5 8 318.0 150 2.76 3.52 16.9 0 0 3 2 #&gt; AMC Javelin 15.2 8 304.0 150 3.15 3.44 17.3 0 0 3 2 #&gt; Camaro Z28 13.3 8 350.0 245 3.73 3.84 15.4 0 0 3 4 #&gt; Pontiac Firebird 19.2 8 400.0 175 3.08 3.85 17.1 0 0 3 2 #&gt; Fiat X1-9 27.3 4 79.0 66 4.08 1.94 18.9 1 1 4 1 #&gt; Porsche 914-2 26.0 4 120.3 91 4.43 2.14 16.7 0 1 5 2 #&gt; Lotus Europa 30.4 4 95.1 113 3.77 1.51 16.9 1 1 5 2 #&gt; Ford Pantera L 15.8 8 351.0 264 4.22 3.17 14.5 0 1 5 4 #&gt; Ferrari Dino 19.7 6 145.0 175 3.62 2.77 15.5 0 1 5 6 #&gt; Maserati Bora 15.0 8 301.0 335 3.54 3.57 14.6 0 1 5 8 #&gt; Volvo 142E 21.4 4 121.0 109 4.11 2.78 18.6 1 1 4 2 Note we here have saved a non tabular R object (a list). 12.7 Json JavaScript Object Notation (json) is an open standard text file format, and data interchange format, that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and array data types. It can be used to store non tabular data in text format. It is often used for data-exchange in web-apis. Let us try to read and write to a json file using the jsonlite package. library(jsonlite) dat &lt;- list(x = c(2, 5, 6), y = &quot;A string&quot;, z = head(mtcars)) write_json(dat, &quot;test.json&quot;, pretty = T) lst &lt;- read_json(&quot;test.json&quot;, simplifyDataFrame = T, simplifyVector = T) lst #&gt; $x #&gt; [1] 2 5 6 #&gt; #&gt; $y #&gt; [1] &quot;A string&quot; #&gt; #&gt; $z #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; Mazda RX4 21.0 6 160 110 3.90 2.62 16.5 0 1 4 4 #&gt; Mazda RX4 Wag 21.0 6 160 110 3.90 2.88 17.0 0 1 4 4 #&gt; Datsun 710 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 #&gt; Hornet 4 Drive 21.4 6 258 110 3.08 3.21 19.4 1 0 3 1 #&gt; Hornet Sportabout 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 #&gt; Valiant 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 The content of the json file look likes: { &quot;x&quot;: [2, 5, 6], &quot;y&quot;: [&quot;A string&quot;], &quot;z&quot;: [ { &quot;mpg&quot;: 21, &quot;cyl&quot;: 6, &quot;disp&quot;: 160, &quot;hp&quot;: 110, &quot;drat&quot;: 3.9, &quot;wt&quot;: 2.62, &quot;qsec&quot;: 16.46, &quot;vs&quot;: 0, &quot;am&quot;: 1, &quot;gear&quot;: 4, &quot;carb&quot;: 4, &quot;_row&quot;: &quot;Mazda RX4&quot; }, { &quot;mpg&quot;: 21, &quot;cyl&quot;: 6, &quot;disp&quot;: 160, &quot;hp&quot;: 110, &quot;drat&quot;: 3.9, &quot;wt&quot;: 2.875, &quot;qsec&quot;: 17.02, &quot;vs&quot;: 0, &quot;am&quot;: 1, &quot;gear&quot;: 4, &quot;carb&quot;: 4, &quot;_row&quot;: &quot;Mazda RX4 Wag&quot; }, { &quot;mpg&quot;: 22.8, &quot;cyl&quot;: 4, &quot;disp&quot;: 108, &quot;hp&quot;: 93, &quot;drat&quot;: 3.85, &quot;wt&quot;: 2.32, &quot;qsec&quot;: 18.61, &quot;vs&quot;: 1, &quot;am&quot;: 1, &quot;gear&quot;: 4, &quot;carb&quot;: 1, &quot;_row&quot;: &quot;Datsun 710&quot; }, { &quot;mpg&quot;: 21.4, &quot;cyl&quot;: 6, &quot;disp&quot;: 258, &quot;hp&quot;: 110, &quot;drat&quot;: 3.08, &quot;wt&quot;: 3.215, &quot;qsec&quot;: 19.44, &quot;vs&quot;: 1, &quot;am&quot;: 0, &quot;gear&quot;: 3, &quot;carb&quot;: 1, &quot;_row&quot;: &quot;Hornet 4 Drive&quot; }, { &quot;mpg&quot;: 18.7, &quot;cyl&quot;: 8, &quot;disp&quot;: 360, &quot;hp&quot;: 175, &quot;drat&quot;: 3.15, &quot;wt&quot;: 3.44, &quot;qsec&quot;: 17.02, &quot;vs&quot;: 0, &quot;am&quot;: 0, &quot;gear&quot;: 3, &quot;carb&quot;: 2, &quot;_row&quot;: &quot;Hornet Sportabout&quot; }, { &quot;mpg&quot;: 18.1, &quot;cyl&quot;: 6, &quot;disp&quot;: 225, &quot;hp&quot;: 105, &quot;drat&quot;: 2.76, &quot;wt&quot;: 3.46, &quot;qsec&quot;: 20.22, &quot;vs&quot;: 1, &quot;am&quot;: 0, &quot;gear&quot;: 3, &quot;carb&quot;: 1, &quot;_row&quot;: &quot;Valiant&quot; } ] } 12.8 Recap For doing data driven analytics you first must import some data. That is, take data from a database, file, web API etc. and transform it into a data frame/table. CSV files contain delimiter separated values in plain text and are often named using the file suffix .csv. Each line of a csv file is a data record. Each record consists of one or more fields, separated by a common delimiter (e.g. ,, ; or _). The readxl package can be used to read Excel files. Writing to an Excel file can be done using the openxlsx package. You can import and export to Google sheets using the googlesheets4 package in tidyverse. Use sink to save output of you R script. There are two main types of data files. Information is either binary encoded or stored as text files. Text files can be read by humans and computers alike. The great thing about plain text is their simplicity and their ease of use: any programming language can read a plain text file. Text files are good for storing tabular data but lacks type-safety, and has limited precision for numeric values. Binary file formats cannot be read by humans but allow space-efficient data compression. Moreover they can be used to save non tabular data. As most other programming languages, R comes with its own binary format. We will focus on the Rds data format which are optimized for speed and compression ratios. Json is an open standard text file format, and data interchange format. It can be used to store non tabular data in text format. It is often used for data-exchange in web-api’s. You may also have a look at the slides for this module . 12.9 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Some of the solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up too early. Put some effort into finding a solution! Always practice using shortcuts in RStudio (see Tools &gt; Keyboard Shortcuts Help). Go to the Tools for Analytics workspace and download/export the TM12 project. Open it on your laptop and have a look at the files in the exercises folder which can be used as a starting point. 12.9.1 Exercise (Statistikbanken) Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). You can use the API from Statistikbanken to download a lot of data sets. Let us consider airports in Denmark (data set with table id FLYV41): url &lt;- &quot;https://api.statbank.dk/v1/data/FLYV41/CSV?lang=en&amp;LUFTHAVN=*&amp;Tid=*&amp;Transport=*&quot; Use cat(read_lines(url, n_max = 3), sep = \"\\n\") to have a look at the delimiter used. × Solution url &lt;- &#39;https://api.statbank.dk/v1/data/FLYV41/CSV?lang=en&amp;LUFTHAVN=*&amp;Tid=*&amp;Transport=*&#39; dat &lt;- read_csv2(url) dat Close Solution Import the csv file. Try to retrieve information and get an overview over the data by running: library(jsonlite) url &lt;- &quot;https://api.statbank.dk/v1/tableinfo/FLYV41?lang=en&quot; lst &lt;- read_json(url, simplifyVector = T) View(lst) Note the data returned is in json format, so we use read_json to read the data into a list. × Solution info &lt;- function(tab_id) { url &lt;- str_c(&quot;https://api.statbank.dk/v1/tableinfo/&quot;, tab_id, &quot;?lang=en&quot;) lst &lt;- read_json(url, simplifyVector = T) return(list(description = lst$description, unit = lst$unit, variables = lst$variables[,1:2])) } info(&quot;FLYV41&quot;) Close Solution × Hint 2 info &lt;- function(tab_id) { url &lt;- str_c(___) lst &lt;- read_json(___) return(list(description = lst$___, unit = ___, ___)) } info(&quot;FLYV41&quot;) Close Hint 2 × Hint 1 You can modify the code in Question 3 to return only parts of the list. Close Hint 1 Create a function info(tab_id) that returns a list with components description, unit and variables from the information for a data set with table id tab_id. Information about all the data sets can be retrieved using: url &lt;- &quot;https://api.statbank.dk/v1/tables?lang=en&quot; lst &lt;- jsonlite::read_json(url, simplifyVector = T) View(lst) Have a look at the row for FLYV41. × Solution get_data &lt;- function(tab_id, col_id = NULL) { url &lt;- str_c(&quot;https://api.statbank.dk/v1/tableinfo/&quot;, tab_id, &quot;?lang=en&quot;) lst &lt;- read_json(url, simplifyVector = T) cols &lt;- lst$variables$id if (!is.null(col_id)) cols &lt;- cols[col_id] url &lt;- str_c(&quot;https://api.statbank.dk/v1/data/&quot;, tab_id, &quot;/CSV?lang=en&amp;&quot;, str_c(cols, collapse = &quot;=*&amp;&quot;), &quot;=*&quot;) |&gt; URLencode() dat &lt;- read_csv2(url) return(dat) } get_data(&quot;FLYV41&quot;, 3) get_data(&quot;FLYV41&quot;, 1:2) get_data(&quot;FLYV41&quot;) Close Solution × Hint get_data &lt;- function(tab_id, col_id = NULL) { url &lt;- ___ lst &lt;- ___ cols &lt;- lst$variables$id if (!is.null(col_id)) cols &lt;- cols[___] url &lt;- ___ dat &lt;- ___ return(dat) } get_data(&quot;FLYV41&quot;, 3) get_data(&quot;FLYV41&quot;, 1:2) get_data(&quot;FLYV41&quot;) Close Hint Given the information about variables in a data set we can construct the url to retrieve the data in csv format: tab_id &lt;- &quot;FLYV41&quot; url &lt;- str_c(&quot;https://api.statbank.dk/v1/tableinfo/&quot;, tab_id, &quot;?lang=en&quot;) lst &lt;- read_json(url, simplifyVector = T) col_id &lt;- c(1,3) # column ids in lst$variables$id cols &lt;- lst$variables$id[col_id] url &lt;- str_c(&quot;https://api.statbank.dk/v1/data/&quot;, tab_id, &quot;/CSV?lang=en&amp;&quot;, str_c(cols, collapse = &quot;=*&amp;&quot;), &quot;=*&quot;) |&gt; URLencode() url #&gt; [1] &quot;https://api.statbank.dk/v1/data/FLYV41/CSV?lang=en&amp;LUFTHAVN=*&amp;Tid=*&quot; Create a function get_data(tab_id, col_id) that retrieve a data set. × Solution dat &lt;- get_data(&quot;FOLK1A&quot;, c(2, 3, 5)) dat write_csv(dat, &quot;test.csv&quot;) Close Solution Use the function get_data to retrieve data for tab_id = \"FOLK1A\" and col_id = c(2, 3, 5) and save it as a csv file with a comma as delimiter. × Solution library(openxlsx) write.xlsx(dat, &quot;test.xlsx&quot;, sheetName = &quot;FOLK1A&quot;) library(googlesheets4) gs &lt;- gs4_create(&quot;test&quot;) write_sheet(dat, ss = gs, sheet = &quot;FOLK1A&quot;) gs4_browse(gs) Close Solution × Hint library(openxlsx) write.xlsx(___) library(googlesheets4) gs &lt;- gs4_create(&quot;test&quot;) write_sheet(___, ss = ___, sheet = &quot;FOLK1A&quot;) gs4_browse(gs) Close Hint Save the data in an Excel file and a Google sheet. 12.9.2 Exercise (tuples in OPL) In the algebraic modeling language OPL (Optimization Programming Language) used by IBM ILOG CPLEX Optimization Studio, you can define tuples to contain various information. For example consider tuples defined as: tuple nurse { string name; int experience; // higest best } tuple shift { string departmentName; string day; int startTime; int endTime; } A nurse tuple is then defined as &lt;\"Anne\", 11&gt; and a shift tuple as `&lt;“Consultation”, “Monday” 12, 18&gt;. A set of tuples can be defined using: {nurse} nurses = ...; {shift} shifts = ...; where the ... operator means that the sets are read from a data text file: nurses = { &lt;&quot;Anne&quot;, 11&gt;, &lt;&quot;Bethanie&quot;, 4&gt;, &lt;&quot;Betsy&quot;, 2&gt; }; shifts = { &lt;&quot;Emergency&quot;, &quot;Monday&quot;, 2, 8&gt;, &lt;&quot;Emergency&quot;, Monday 8 12 4 7&gt;, &lt;&quot;Emergency&quot;, &quot;Monday&quot; 12 18 2 5&gt; }; You can now use the sets to define decision variables \\(x_{ns}\\) equal one if nurse \\(n\\) is assigned to shift \\(s\\). In this exercise we will try to generate the data text file given tibbles with data. × Solution file = &quot;test.dat&quot; write_lines(&quot;nurses = {&quot;, file) write_lines(&#39; &lt;&quot;Anne&quot;, 11&gt;&#39;, file, append = TRUE) write_lines(&#39;};&#39;, file, append = TRUE) cat(read_file(&quot;test.dat&quot;)) #&gt; nurses = { #&gt; &lt;&quot;Anne&quot;, 11&gt; #&gt; }; Close Solution × Hint file = &quot;test.dat&quot; write_lines(&quot;nurses = {&quot;, file) write_lines(___, ___, append = TRUE) write_lines(___, ___, append = TRUE) cat(read_file(&quot;test.dat&quot;)) # to have a look Close Hint Try to generate a text file named test.dat using function write_lines with content nurses = { &lt;&quot;Anne&quot;, 11&gt; }; Load datasets # remotes::install_github(&quot;bss-osca/tfa-package&quot;, dependencies = FALSE) # if tfa not installed library(tfa) library(tidyverse) nurses &lt;- read_csv(system.file(&quot;extdata/nurses.csv&quot;, package = &quot;tfa&quot;)) shifts &lt;- read_csv(system.file(&quot;extdata/shifts.csv&quot;, package = &quot;tfa&quot;)) × Solution nurses |&gt; mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) #&gt; # A tibble: 32 × 2 #&gt; name experience #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 &quot;\\&quot;Anne\\&quot;&quot; 11 #&gt; 2 &quot;\\&quot;Bethanie\\&quot;&quot; 4 #&gt; 3 &quot;\\&quot;Betsy\\&quot;&quot; 2 #&gt; 4 &quot;\\&quot;Cathy\\&quot;&quot; 2 #&gt; 5 &quot;\\&quot;Cecilia\\&quot;&quot; 9 #&gt; 6 &quot;\\&quot;Chris\\&quot;&quot; 11 #&gt; 7 &quot;\\&quot;Cindy\\&quot;&quot; 5 #&gt; 8 &quot;\\&quot;David\\&quot;&quot; 1 #&gt; 9 &quot;\\&quot;Debbie\\&quot;&quot; 7 #&gt; 10 &quot;\\&quot;Dee\\&quot;&quot; 3 #&gt; # ℹ 22 more rows Close Solution × Hint 2 nurses |&gt; mutate(across(where(___), ~str_c(&#39;___&#39;, .x, &#39;___&#39;))) Close Hint 2 × Hint 1 v &lt;- c(&quot;foo&quot;, &quot;bar&quot;) str_c(&#39;&quot;&#39;, v, &#39;&quot;&#39;) # use of str_c to add &quot; #&gt; [1] &quot;\\&quot;foo\\&quot;&quot; &quot;\\&quot;bar\\&quot;&quot; str_c(v, collapse = &quot;, &quot;) # collapsing a vector #&gt; [1] &quot;foo, bar&quot; tbl &lt;- tribble( ~name, ~experience, &quot;Anne&quot;, 11, &quot;Bethanie&quot;, 4 ) tbl #&gt; # A tibble: 2 × 2 #&gt; name experience #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Anne 11 #&gt; 2 Bethanie 4 tbl |&gt; mutate(across(where(is.character), # use across to find all character columns ~str_c(&#39;(&#39;, .x, &#39;)&#39;))) # str_c is applied to each column where .x is the column values #&gt; # A tibble: 2 × 2 #&gt; name experience #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 (Anne) 11 #&gt; 2 (Bethanie) 4 Close Hint 1 Transform all character columns in nurses so they start and end with \". Some hints are given in Hint 1. × Solution nurses |&gt; mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) |&gt; unite(&quot;tuple&quot;, everything(), sep = &quot;, &quot;, remove = FALSE) #&gt; # A tibble: 32 × 3 #&gt; tuple name experience #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 &quot;\\&quot;Anne\\&quot;, 11&quot; &quot;\\&quot;Anne\\&quot;&quot; 11 #&gt; 2 &quot;\\&quot;Bethanie\\&quot;, 4&quot; &quot;\\&quot;Bethanie\\&quot;&quot; 4 #&gt; 3 &quot;\\&quot;Betsy\\&quot;, 2&quot; &quot;\\&quot;Betsy\\&quot;&quot; 2 #&gt; 4 &quot;\\&quot;Cathy\\&quot;, 2&quot; &quot;\\&quot;Cathy\\&quot;&quot; 2 #&gt; 5 &quot;\\&quot;Cecilia\\&quot;, 9&quot; &quot;\\&quot;Cecilia\\&quot;&quot; 9 #&gt; 6 &quot;\\&quot;Chris\\&quot;, 11&quot; &quot;\\&quot;Chris\\&quot;&quot; 11 #&gt; 7 &quot;\\&quot;Cindy\\&quot;, 5&quot; &quot;\\&quot;Cindy\\&quot;&quot; 5 #&gt; 8 &quot;\\&quot;David\\&quot;, 1&quot; &quot;\\&quot;David\\&quot;&quot; 1 #&gt; 9 &quot;\\&quot;Debbie\\&quot;, 7&quot; &quot;\\&quot;Debbie\\&quot;&quot; 7 #&gt; 10 &quot;\\&quot;Dee\\&quot;, 3&quot; &quot;\\&quot;Dee\\&quot;&quot; 3 #&gt; # ℹ 22 more rows Close Solution × Hint nurses |&gt; mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) |&gt; unite(&quot;tuple&quot;, everything(), sep = ___, remove = ___) Close Hint Unite all columns into a new column named tuple where each column is separated with ,. Hint: have a look at the unite function. All columns can be selected using everything(). × Solution nurses |&gt; mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) |&gt; unite(&quot;tuple&quot;, everything(), sep = &quot;, &quot;, remove = FALSE) |&gt; mutate(tuple = str_c(&quot;&lt;&quot;, tuple, &quot;&gt;&quot;)) #&gt; # A tibble: 32 × 3 #&gt; tuple name experience #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 &quot;&lt;\\&quot;Anne\\&quot;, 11&gt;&quot; &quot;\\&quot;Anne\\&quot;&quot; 11 #&gt; 2 &quot;&lt;\\&quot;Bethanie\\&quot;, 4&gt;&quot; &quot;\\&quot;Bethanie\\&quot;&quot; 4 #&gt; 3 &quot;&lt;\\&quot;Betsy\\&quot;, 2&gt;&quot; &quot;\\&quot;Betsy\\&quot;&quot; 2 #&gt; 4 &quot;&lt;\\&quot;Cathy\\&quot;, 2&gt;&quot; &quot;\\&quot;Cathy\\&quot;&quot; 2 #&gt; 5 &quot;&lt;\\&quot;Cecilia\\&quot;, 9&gt;&quot; &quot;\\&quot;Cecilia\\&quot;&quot; 9 #&gt; 6 &quot;&lt;\\&quot;Chris\\&quot;, 11&gt;&quot; &quot;\\&quot;Chris\\&quot;&quot; 11 #&gt; 7 &quot;&lt;\\&quot;Cindy\\&quot;, 5&gt;&quot; &quot;\\&quot;Cindy\\&quot;&quot; 5 #&gt; 8 &quot;&lt;\\&quot;David\\&quot;, 1&gt;&quot; &quot;\\&quot;David\\&quot;&quot; 1 #&gt; 9 &quot;&lt;\\&quot;Debbie\\&quot;, 7&gt;&quot; &quot;\\&quot;Debbie\\&quot;&quot; 7 #&gt; 10 &quot;&lt;\\&quot;Dee\\&quot;, 3&gt;&quot; &quot;\\&quot;Dee\\&quot;&quot; 3 #&gt; # ℹ 22 more rows Close Solution × Hint nurses |&gt; mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) |&gt; unite(&quot;tuple&quot;, everything(), sep = &quot;, &quot;, remove = FALSE) |&gt; mutate(tuple = str_c(___, tuple, ___)) Close Hint Add &lt; and &gt; the start and end of the tuple column. × Solution nurses |&gt; mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) |&gt; unite(&quot;tuple&quot;, everything(), sep = &quot;, &quot;, remove = FALSE) |&gt; mutate(tuple = str_c(&quot;&lt;&quot;, tuple, &quot;&gt;&quot;)) |&gt; pull(tuple) |&gt; str_c(collapse = &quot;,\\n&quot;) #&gt; [1] &quot;&lt;\\&quot;Anne\\&quot;, 11&gt;,\\n&lt;\\&quot;Bethanie\\&quot;, 4&gt;,\\n&lt;\\&quot;Betsy\\&quot;, 2&gt;,\\n&lt;\\&quot;Cathy\\&quot;, 2&gt;,\\n&lt;\\&quot;Cecilia\\&quot;, 9&gt;,\\n&lt;\\&quot;Chris\\&quot;, 11&gt;,\\n&lt;\\&quot;Cindy\\&quot;, 5&gt;,\\n&lt;\\&quot;David\\&quot;, 1&gt;,\\n&lt;\\&quot;Debbie\\&quot;, 7&gt;,\\n&lt;\\&quot;Dee\\&quot;, 3&gt;,\\n&lt;\\&quot;Gloria\\&quot;, 8&gt;,\\n&lt;\\&quot;Isabelle\\&quot;, 3&gt;,\\n&lt;\\&quot;Jane\\&quot;, 3&gt;,\\n&lt;\\&quot;Janelle\\&quot;, 4&gt;,\\n&lt;\\&quot;Janice\\&quot;, 2&gt;,\\n&lt;\\&quot;Jemma\\&quot;, 2&gt;,\\n&lt;\\&quot;Joan\\&quot;, 5&gt;,\\n&lt;\\&quot;Joyce\\&quot;, 8&gt;,\\n&lt;\\&quot;Jude\\&quot;, 4&gt;,\\n&lt;\\&quot;Julie\\&quot;, 6&gt;,\\n&lt;\\&quot;Juliet\\&quot;, 7&gt;,\\n&lt;\\&quot;Kate\\&quot;, 5&gt;,\\n&lt;\\&quot;Nancy\\&quot;, 8&gt;,\\n&lt;\\&quot;Nathalie\\&quot;, 9&gt;,\\n&lt;\\&quot;Nicole\\&quot;, 0&gt;,\\n&lt;\\&quot;Patricia\\&quot;, 1&gt;,\\n&lt;\\&quot;Patrick\\&quot;, 6&gt;,\\n&lt;\\&quot;Roberta\\&quot;, 3&gt;,\\n&lt;\\&quot;Suzanne\\&quot;, 5&gt;,\\n&lt;\\&quot;Vickie\\&quot;, 7&gt;,\\n&lt;\\&quot;Wendie\\&quot;, 5&gt;,\\n&lt;\\&quot;Zoe\\&quot;, 8&gt;&quot; Close Solution × Hint nurses |&gt; mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) |&gt; unite(&quot;tuple&quot;, everything(), sep = &quot;, &quot;, remove = FALSE) |&gt; mutate(tuple = str_c(&quot;&lt;&quot;, tuple, &quot;&gt;&quot;)) |&gt; pull(___) |&gt; str_c(___) Close Hint Extract the tuple column and transform it into a string with collapse = \",\\n\". × Solution write_tuple &lt;- function(dat, file) { write_lines(&quot;nurses = {&quot;, file, sep = &quot;\\n &quot;) tuples &lt;- dat |&gt; mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) |&gt; unite(&quot;tuple&quot;, everything(), sep = &quot;, &quot;, remove = FALSE) |&gt; mutate(tuple = str_c(&quot;&lt;&quot;, tuple, &quot;&gt;&quot;)) |&gt; pull(tuple) |&gt; str_c(collapse = &quot;,\\n &quot;) write_lines(tuples, file, append = TRUE) write_lines(&quot;};&quot;, file, append = TRUE) } file &lt;- &quot;test.dat&quot; write_tuple(nurses, file) cat(read_file(&quot;test.dat&quot;)) # to have a look #&gt; nurses = { #&gt; &lt;&quot;Anne&quot;, 11&gt;, #&gt; &lt;&quot;Bethanie&quot;, 4&gt;, #&gt; &lt;&quot;Betsy&quot;, 2&gt;, #&gt; &lt;&quot;Cathy&quot;, 2&gt;, #&gt; &lt;&quot;Cecilia&quot;, 9&gt;, #&gt; &lt;&quot;Chris&quot;, 11&gt;, #&gt; &lt;&quot;Cindy&quot;, 5&gt;, #&gt; &lt;&quot;David&quot;, 1&gt;, #&gt; &lt;&quot;Debbie&quot;, 7&gt;, #&gt; &lt;&quot;Dee&quot;, 3&gt;, #&gt; &lt;&quot;Gloria&quot;, 8&gt;, #&gt; &lt;&quot;Isabelle&quot;, 3&gt;, #&gt; &lt;&quot;Jane&quot;, 3&gt;, #&gt; &lt;&quot;Janelle&quot;, 4&gt;, #&gt; &lt;&quot;Janice&quot;, 2&gt;, #&gt; &lt;&quot;Jemma&quot;, 2&gt;, #&gt; &lt;&quot;Joan&quot;, 5&gt;, #&gt; &lt;&quot;Joyce&quot;, 8&gt;, #&gt; &lt;&quot;Jude&quot;, 4&gt;, #&gt; &lt;&quot;Julie&quot;, 6&gt;, #&gt; &lt;&quot;Juliet&quot;, 7&gt;, #&gt; &lt;&quot;Kate&quot;, 5&gt;, #&gt; &lt;&quot;Nancy&quot;, 8&gt;, #&gt; &lt;&quot;Nathalie&quot;, 9&gt;, #&gt; &lt;&quot;Nicole&quot;, 0&gt;, #&gt; &lt;&quot;Patricia&quot;, 1&gt;, #&gt; &lt;&quot;Patrick&quot;, 6&gt;, #&gt; &lt;&quot;Roberta&quot;, 3&gt;, #&gt; &lt;&quot;Suzanne&quot;, 5&gt;, #&gt; &lt;&quot;Vickie&quot;, 7&gt;, #&gt; &lt;&quot;Wendie&quot;, 5&gt;, #&gt; &lt;&quot;Zoe&quot;, 8&gt; #&gt; }; Close Solution × Hint 2 write_tuple &lt;- function(dat, file) { write_lines(&quot;nurses = {&quot;, file, sep = &quot;\\n &quot;) tuples &lt;- dat |&gt; ___ write_lines(tuples, file, append = TRUE) write_lines(&quot;};&quot;, file, append = TRUE) } file &lt;- &quot;test.dat&quot; write_tuple(nurses, file) cat(read_file(&quot;test.dat&quot;)) # to have a look Close Hint 2 × Hint 1 write_tuple &lt;- function(dat, file) { write_lines(___) ___ write_lines(&quot;};&quot;, ___, ___) } file &lt;- &quot;test.dat&quot; write_tuple(nurses, file) cat(read_file(&quot;test.dat&quot;)) # to have a look Close Hint 1 Create a function write_tuple that takes nurses as input and write the tuples to a file. The name of an object can be extracted as a string using deparse(substitute(nurses)) #&gt; [1] &quot;nurses&quot; × Solution write_tuple &lt;- function(dat, file) { name &lt;- deparse(substitute(dat)) write_lines(str_c(name, &quot; = {&quot;), file, sep = &quot;\\n &quot;) tuples &lt;- dat |&gt; mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) |&gt; unite(&quot;tuple&quot;, everything(), sep = &quot;, &quot;, remove = FALSE) |&gt; mutate(tuple = str_c(&quot;&lt;&quot;, tuple, &quot;&gt;&quot;)) |&gt; pull(tuple) |&gt; str_c(collapse = &quot;,\\n &quot;) write_lines(tuples, file, append = TRUE) write_lines(&quot;};&quot;, file, append = TRUE) } file &lt;- &quot;test.dat&quot; write_tuple(shifts, file) cat(read_file(&quot;test.dat&quot;)) # to have a look #&gt; shifts = { #&gt; &lt;&quot;Emergency&quot;, &quot;Monday&quot;, 2, 8&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Monday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Monday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Monday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Monday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Monday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Tuesday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Tuesday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Tuesday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Tuesday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Tuesday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Wednesday&quot;, 2, 8&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Wednesday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Wednesday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Wednesday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Wednesday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Wednesday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Thursday&quot;, 2, 8&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Thursday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Thursday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Thursday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Thursday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Thursday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Friday&quot;, 2, 8&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Friday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Friday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Friday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Friday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Friday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Saturday&quot;, 2, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Saturday&quot;, 12, 20&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Saturday&quot;, 20, 2&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Sunday&quot;, 2, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Sunday&quot;, 12, 20&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Sunday&quot;, 20, 2&gt; #&gt; }; Close Solution Modify write_tuple so it works if shifts are given as input instead of nurses. × Solution write_tuple &lt;- function(dat, file, append = FALSE) { name &lt;- deparse(substitute(dat)) write_lines(str_c(&quot;\\n&quot;, name, &quot; = {&quot;), file, sep = &quot;\\n &quot;, append = append) tuples &lt;- dat |&gt; mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) |&gt; unite(&quot;tuple&quot;, everything(), sep = &quot;, &quot;, remove = FALSE) |&gt; mutate(tuple = str_c(&quot;&lt;&quot;, tuple, &quot;&gt;&quot;)) |&gt; pull(tuple) |&gt; str_c(collapse = &quot;,\\n &quot;) write_lines(tuples, file, append = TRUE) write_lines(&quot;};&quot;, file, append = TRUE) } Close Solution Modify write_tuple with a new input argument append which is false by default. If true, then then the file is not overwritten. × Solution file &lt;- &quot;test.dat&quot; write_tuple(nurses, file) write_tuple(shifts, file, append = TRUE) cat(read_file(&quot;test.dat&quot;)) # to have a look #&gt; #&gt; nurses = { #&gt; &lt;&quot;Anne&quot;, 11&gt;, #&gt; &lt;&quot;Bethanie&quot;, 4&gt;, #&gt; &lt;&quot;Betsy&quot;, 2&gt;, #&gt; &lt;&quot;Cathy&quot;, 2&gt;, #&gt; &lt;&quot;Cecilia&quot;, 9&gt;, #&gt; &lt;&quot;Chris&quot;, 11&gt;, #&gt; &lt;&quot;Cindy&quot;, 5&gt;, #&gt; &lt;&quot;David&quot;, 1&gt;, #&gt; &lt;&quot;Debbie&quot;, 7&gt;, #&gt; &lt;&quot;Dee&quot;, 3&gt;, #&gt; &lt;&quot;Gloria&quot;, 8&gt;, #&gt; &lt;&quot;Isabelle&quot;, 3&gt;, #&gt; &lt;&quot;Jane&quot;, 3&gt;, #&gt; &lt;&quot;Janelle&quot;, 4&gt;, #&gt; &lt;&quot;Janice&quot;, 2&gt;, #&gt; &lt;&quot;Jemma&quot;, 2&gt;, #&gt; &lt;&quot;Joan&quot;, 5&gt;, #&gt; &lt;&quot;Joyce&quot;, 8&gt;, #&gt; &lt;&quot;Jude&quot;, 4&gt;, #&gt; &lt;&quot;Julie&quot;, 6&gt;, #&gt; &lt;&quot;Juliet&quot;, 7&gt;, #&gt; &lt;&quot;Kate&quot;, 5&gt;, #&gt; &lt;&quot;Nancy&quot;, 8&gt;, #&gt; &lt;&quot;Nathalie&quot;, 9&gt;, #&gt; &lt;&quot;Nicole&quot;, 0&gt;, #&gt; &lt;&quot;Patricia&quot;, 1&gt;, #&gt; &lt;&quot;Patrick&quot;, 6&gt;, #&gt; &lt;&quot;Roberta&quot;, 3&gt;, #&gt; &lt;&quot;Suzanne&quot;, 5&gt;, #&gt; &lt;&quot;Vickie&quot;, 7&gt;, #&gt; &lt;&quot;Wendie&quot;, 5&gt;, #&gt; &lt;&quot;Zoe&quot;, 8&gt; #&gt; }; #&gt; #&gt; shifts = { #&gt; &lt;&quot;Emergency&quot;, &quot;Monday&quot;, 2, 8&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Monday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Monday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Monday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Monday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Monday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Tuesday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Tuesday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Tuesday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Tuesday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Tuesday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Wednesday&quot;, 2, 8&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Wednesday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Wednesday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Wednesday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Wednesday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Wednesday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Thursday&quot;, 2, 8&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Thursday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Thursday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Thursday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Thursday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Thursday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Friday&quot;, 2, 8&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Friday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Friday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Friday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Friday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Friday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Saturday&quot;, 2, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Saturday&quot;, 12, 20&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Saturday&quot;, 20, 2&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Sunday&quot;, 2, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Sunday&quot;, 12, 20&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Sunday&quot;, 20, 2&gt; #&gt; }; Close Solution Write nurses and shifts to a single data file. "],["mod-r-transform.html", "Module 13 Transforming data 13.1 Learning outcomes 13.2 Working with data in the tidyverse 13.3 Mutating joins 13.4 Recap 13.5 Exercises", " Module 13 Transforming data In this module, we consider transformation of data. In general raw data may be messy and need to be structured in a tidy way. Tidying your data means storing it in a structured form suitable for analysis. This is done using a tibble (data frame) where each column is a variable, and each row is an observation. Tidy data is important because the consistent structure lets you focus your struggle on questions about the data. Given a raw dataset the first step is to clean it and and transform it to a tidy format. Given tidy data, you next often need to transform it. Transformation includes narrowing in on observations of interest (e.g. only observations from a specific year or warehouse), creating new variables based on existing variables (like the cost of using the machine that day given idle time). Together, tidying and transforming are called wrangling, because it can be a hard process to get your data in the right form. In this chapter, you will learn how to work with tibbles using the dplyr package which is a part of the tidyverse. A template project for this module is given on Posit Cloud (open it and use it while reading the notes). Learning path diagram It is recommended that you follow the green learning path; however, you may like a different learning style. In the learning path diagram, there are links to alternative online content (video or reading). Note this is an alternative to the standard learning path that you may use instead (you should not do both). The learning path may also have extra content, that is NOT a part of syllabus (only look at it if you want more info)! 13.1 Learning outcomes By the end of this module, you are expected to be able to: Describe what tidy and wangling is. Apply the most common string functions. Apply tidy operations to data. Transform data. Clean data. The learning outcomes relate to the overall learning goals number 7, 11-14 and 18 of the course. 13.2 Working with data in the tidyverse An excellent introduction on how to transform data using the tidyverse is given in the interactive DataCamp course Data Manipulation with dplyr. Please complete the course before continuing. 13.3 Mutating joins Mutating joins allow you to combine variables from multiple tables. There are four types of mutating join, which differ in their behavior when a match is not found. We’ll illustrate each with a simple example: df1 &lt;- tibble(x = c(1, 2), y = 2:1) df2 &lt;- tibble(x = c(3, 1), a = 10, b = &quot;a&quot;) df1 #&gt; # A tibble: 2 × 2 #&gt; x y #&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 1 2 #&gt; 2 2 1 df2 #&gt; # A tibble: 2 × 3 #&gt; x a b #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 3 10 a #&gt; 2 1 10 a Note that column x is present in both tables and used when joining them. inner_join(df1, df2) only includes observations that match in both df1 and df2. df1 |&gt; inner_join(df2) #&gt; Joining with `by = join_by(x)` #&gt; # A tibble: 1 × 4 #&gt; x y a b #&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 1 2 10 a left_join(df1, df2) includes all observations in df1, regardless of whether they match or not. This is the most commonly used join because it ensures that you don’t lose observations from your primary table. df1 |&gt; left_join(df2) #&gt; Joining with `by = join_by(x)` #&gt; # A tibble: 2 × 4 #&gt; x y a b #&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 1 2 10 a #&gt; 2 2 1 NA &lt;NA&gt; right_join(df1, df2) includes all observations in df2. It’s equivalent to left_join(df2, df1), but the columns and rows will be ordered differently. df1 |&gt; right_join(df2) #&gt; Joining with `by = join_by(x)` #&gt; # A tibble: 2 × 4 #&gt; x y a b #&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 1 2 10 a #&gt; 2 3 NA 10 a df2 |&gt; left_join(df1) #&gt; Joining with `by = join_by(x)` #&gt; # A tibble: 2 × 4 #&gt; x a b y #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 3 10 a NA #&gt; 2 1 10 a 2 full_join() includes all observations from df1 and df2. df1 |&gt; full_join(df2) #&gt; Joining with `by = join_by(x)` #&gt; # A tibble: 3 × 4 #&gt; x y a b #&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 1 2 10 a #&gt; 2 2 1 NA &lt;NA&gt; #&gt; 3 3 NA 10 a The left, right and full joins are collectively know as outer joins. When a row doesn’t match in an outer join, the new variables are filled in with missing values. While mutating joins are primarily used to add new variables, they can also generate new observations. If a match is not unique, a join will add all possible combinations (the Cartesian product) of the matching observations: df1 &lt;- tibble(x = c(1, 1, 2), y = 1:3) df2 &lt;- tibble(x = c(1, 1, 2), z = c(&quot;a&quot;, &quot;b&quot;, &quot;a&quot;)) df1 |&gt; left_join(df2, relationship = &quot;many-to-many&quot;) #&gt; Joining with `by = join_by(x)` #&gt; # A tibble: 5 × 3 #&gt; x y z #&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; #&gt; 1 1 1 a #&gt; 2 1 1 b #&gt; 3 1 2 a #&gt; 4 1 2 b #&gt; 5 2 3 a Filtering joins match observations in the same way as mutating joins, but affect the observations, not the variables. There are two types: semi_join(df1, df2) keeps all observations in df1 that have a match in df2. anti_join(df1, df2) drops all observations in df1 that have a match in df2. These are most useful for diagnosing join mismatches. If you’re worried about what observations your joins will match, start with a semi_join() or anti_join(). semi_join() and anti_join() never duplicate; they only remove observations. df1 &lt;- tibble(x = c(1, 1, 3, 4), y = 1:4) df2 &lt;- tibble(x = c(1, 1, 2), z = c(&quot;a&quot;, &quot;b&quot;, &quot;a&quot;)) # Four rows to start with: df1 |&gt; nrow() #&gt; [1] 4 # And we get four rows after the join df1 |&gt; inner_join(df2, by = &quot;x&quot;, relationship = &quot;many-to-many&quot;) |&gt; nrow() #&gt; [1] 4 # But only two rows actually match df1 |&gt; semi_join(df2, by = &quot;x&quot;) |&gt; nrow() #&gt; [1] 2 13.4 Recap We consider transformation of tidy data where data are stored using a tibble (data frame) where each column is a variable, and each row is an observation/case. Tidy data is important because the consistent structure lets you focus your struggle on questions about the data. Transformation includes narrowing in on observations of interest (e.g. only observations from a specific year or warehouse), creating new variables based on existing variables (like the cost of using the machine that day given idle time). Tidying and transforming are called wrangling, because it can be a hard process to get your data in the right form. The package dplyr provides a consistent set of verbs that helps you solve the most common data manipulation challenges: The filter function chooses rows (cases/observations) that meet a specific criteria. The select function chooses columns (variables) based on their names. The arrange function reorders the rows. The transmute function adds/modifies columns (variables) and drops existing ones. The mutate function adds/modifies columns (variables). The group_by function groups variables for groupwise operations. The ungroup function removes the current grouping. The count function counts rows based on a grouping. The summarise function reduces multiple values down to a single summary. The distinct function selects unique/distinct rows. The pull function can be used to extract columns as vectors (it is similar to $). Some nice to know functions to use inside e.g. summarise or mutate are The n() function counts the number of rows in a group. The n_distinct counts the number of unique rows in a group. The first function considers the first row in a group (remember to order it as needed). The slice_min and slice_max functions select rows with highest or lowest values of a variable. The across function makes it easy to apply the same transformation to multiple columns. Use print(n = Inf) in a pipe to print all rows. Use the pipe operator |&gt; to connect operations. Use functions glimpse, tail, head, View to have a look at the data. The skim function in the skimr package provides an approach to summary statistics. Use as.character, as.numeric, etc. to convert data to a different type. Use nrow and ncol functions to get the number of rows and columns of the data. The ‘Data transformation with dplyr’ cheatsheet is very useful. Find the newest version in RStudio Help &gt; Cheatsheets. You may also have a look at the slides for this module . 13.5 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Some of the solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up too early. Put some effort into finding a solution! Always practice using shortcuts in RStudio (see Tools &gt; Keyboard Shortcuts Help). Go to the Tools for Analytics workspace and download/export the TM13 project. Open it on your laptop and have a look at the files in the exercises folder which can be used as a starting point. 13.5.1 Exercise (gapminder) Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). The gapminder data set provides values for life expectancy, GDP per capita, and population, every five years, from 1952 to 2007 for 142 countries. The data can be loaded using the gapminder package: library(gapminder) data(gapminder, package = &quot;gapminder&quot;) gapminder #&gt; # A tibble: 1,704 × 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. #&gt; 2 Afghanistan Asia 1957 30.3 9240934 821. #&gt; 3 Afghanistan Asia 1962 32.0 10267083 853. #&gt; 4 Afghanistan Asia 1967 34.0 11537966 836. #&gt; 5 Afghanistan Asia 1972 36.1 13079460 740. #&gt; 6 Afghanistan Asia 1977 38.4 14880372 786. #&gt; 7 Afghanistan Asia 1982 39.9 12881816 978. #&gt; 8 Afghanistan Asia 1987 40.8 13867957 852. #&gt; 9 Afghanistan Asia 1992 41.7 16317921 649. #&gt; 10 Afghanistan Asia 1997 41.8 22227415 635. #&gt; # ℹ 1,694 more rows Let us try to examine the dataset (use pipes |&gt; as much as possible). × Solution gapminder |&gt; glimpse() #&gt; Rows: 1,704 #&gt; Columns: 6 #&gt; $ country &lt;fct&gt; &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afgh… #&gt; $ continent &lt;fct&gt; Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Europe, … #&gt; $ year &lt;int&gt; 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 2007, 1952, 19… #&gt; $ lifeExp &lt;dbl&gt; 28.8, 30.3, 32.0, 34.0, 36.1, 38.4, 39.9, 40.8, 41.7, 41.8, 42.1, 43.8, 55.2, 59… #&gt; $ pop &lt;int&gt; 8425333, 9240934, 10267083, 11537966, 13079460, 14880372, 12881816, 13867957, 16… #&gt; $ gdpPercap &lt;dbl&gt; 779, 821, 853, 836, 740, 786, 978, 852, 649, 635, 727, 975, 1601, 1942, 2313, 27… gapminder |&gt; summary() #&gt; country continent year lifeExp pop #&gt; Afghanistan: 12 Africa :624 Min. :1952 Min. :23.6 Min. :6.00e+04 #&gt; Albania : 12 Americas:300 1st Qu.:1966 1st Qu.:48.2 1st Qu.:2.79e+06 #&gt; Algeria : 12 Asia :396 Median :1980 Median :60.7 Median :7.02e+06 #&gt; Angola : 12 Europe :360 Mean :1980 Mean :59.5 Mean :2.96e+07 #&gt; Argentina : 12 Oceania : 24 3rd Qu.:1993 3rd Qu.:70.8 3rd Qu.:1.96e+07 #&gt; Australia : 12 Max. :2007 Max. :82.6 Max. :1.32e+09 #&gt; (Other) :1632 #&gt; gdpPercap #&gt; Min. : 241 #&gt; 1st Qu.: 1202 #&gt; Median : 3532 #&gt; Mean : 7215 #&gt; 3rd Qu.: 9325 #&gt; Max. :113523 #&gt; gapminder |&gt; tail() #&gt; # A tibble: 6 × 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Zimbabwe Africa 1982 60.4 7636524 789. #&gt; 2 Zimbabwe Africa 1987 62.4 9216418 706. #&gt; 3 Zimbabwe Africa 1992 60.4 10704340 693. #&gt; 4 Zimbabwe Africa 1997 46.8 11404948 792. #&gt; 5 Zimbabwe Africa 2002 40.0 11926563 672. #&gt; 6 Zimbabwe Africa 2007 43.5 12311143 470. Close Solution Use glimpse, summary and tail to examine the data. Use count to count the number of × Solution gapminder |&gt; count(country) |&gt; nrow() #&gt; [1] 142 Close Solution         a) countries, × Solution gapminder |&gt; count(continent) |&gt; nrow() #&gt; [1] 5 Close Solution         b) continents, × Solution gapminder |&gt; count(continent, country) |&gt; count(continent) # or #&gt; # A tibble: 5 × 2 #&gt; continent n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Africa 52 #&gt; 2 Americas 25 #&gt; 3 Asia 33 #&gt; 4 Europe 30 #&gt; 5 Oceania 2 gapminder |&gt; distinct(continent, country) |&gt; count(continent) #&gt; # A tibble: 5 × 2 #&gt; continent n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Africa 52 #&gt; 2 Americas 25 #&gt; 3 Asia 33 #&gt; 4 Europe 30 #&gt; 5 Oceania 2 Close Solution         c) countries per continent. × Solution gapminder |&gt; distinct(continent) |&gt; pull(continent) |&gt; as.character() #&gt; [1] &quot;Asia&quot; &quot;Europe&quot; &quot;Africa&quot; &quot;Americas&quot; &quot;Oceania&quot; Close Solution × Hint gapminder |&gt; distinct(___) |&gt; pull(___) |&gt; as.character() Close Hint Retrieve a vector with all distinct continent values. Subset rows to find: × Solution gapminder |&gt; filter(lifeExp &lt; 29) #&gt; # A tibble: 2 × 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. #&gt; 2 Rwanda Africa 1992 23.6 7290203 737. Close Solution         a) all rows with life expectancy less that 29 years, × Solution gapminder |&gt; filter(country == &quot;Rwanda&quot;, year &gt; 1979) #&gt; # A tibble: 6 × 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Rwanda Africa 1982 46.2 5507565 882. #&gt; 2 Rwanda Africa 1987 44.0 6349365 848. #&gt; 3 Rwanda Africa 1992 23.6 7290203 737. #&gt; 4 Rwanda Africa 1997 36.1 7212583 590. #&gt; 5 Rwanda Africa 2002 43.4 7852401 786. #&gt; 6 Rwanda Africa 2007 46.2 8860588 863. Close Solution         b) all rows for Rwanda after year 1979, × Solution gapminder |&gt; filter(country %in% c(&quot;Rwanda&quot;, &quot;Afghanistan&quot;, &quot;France&quot;)) #&gt; # A tibble: 36 × 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. #&gt; 2 Afghanistan Asia 1957 30.3 9240934 821. #&gt; 3 Afghanistan Asia 1962 32.0 10267083 853. #&gt; 4 Afghanistan Asia 1967 34.0 11537966 836. #&gt; 5 Afghanistan Asia 1972 36.1 13079460 740. #&gt; 6 Afghanistan Asia 1977 38.4 14880372 786. #&gt; 7 Afghanistan Asia 1982 39.9 12881816 978. #&gt; 8 Afghanistan Asia 1987 40.8 13867957 852. #&gt; 9 Afghanistan Asia 1992 41.7 16317921 649. #&gt; 10 Afghanistan Asia 1997 41.8 22227415 635. #&gt; # ℹ 26 more rows Close Solution         c) all rows for Rwanda, Afghanistan or France. Select columns × Solution gapminder |&gt; select(year, lifeExp) #&gt; # A tibble: 1,704 × 2 #&gt; year lifeExp #&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1952 28.8 #&gt; 2 1957 30.3 #&gt; 3 1962 32.0 #&gt; 4 1967 34.0 #&gt; 5 1972 36.1 #&gt; 6 1977 38.4 #&gt; 7 1982 39.9 #&gt; 8 1987 40.8 #&gt; 9 1992 41.7 #&gt; 10 1997 41.8 #&gt; # ℹ 1,694 more rows Close Solution         a) year and life expectancy, × Solution gapminder |&gt; select(country, gdpPercap) #&gt; # A tibble: 1,704 × 2 #&gt; country gdpPercap #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 Afghanistan 779. #&gt; 2 Afghanistan 821. #&gt; 3 Afghanistan 853. #&gt; 4 Afghanistan 836. #&gt; 5 Afghanistan 740. #&gt; 6 Afghanistan 786. #&gt; 7 Afghanistan 978. #&gt; 8 Afghanistan 852. #&gt; 9 Afghanistan 649. #&gt; 10 Afghanistan 635. #&gt; # ℹ 1,694 more rows Close Solution         b) country and GDP per capita. × Solution gapminder |&gt; filter((gdpPercap &gt; 40000 &amp; continent == &quot;Europe&quot;) | (gdpPercap &lt; 500 &amp; continent == &quot;Africa&quot;)) |&gt; # print(n=Inf) |&gt; # if want to see the intermediate results select(continent, country, gdpPercap) # |&gt; print(n=Inf) #&gt; # A tibble: 51 × 3 #&gt; continent country gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 Africa Burundi 339. #&gt; 2 Africa Burundi 380. #&gt; 3 Africa Burundi 355. #&gt; 4 Africa Burundi 413. #&gt; 5 Africa Burundi 464. #&gt; 6 Africa Burundi 463. #&gt; 7 Africa Burundi 446. #&gt; 8 Africa Burundi 430. #&gt; 9 Africa Congo, Dem. Rep. 458. #&gt; 10 Africa Congo, Dem. Rep. 312. #&gt; # ℹ 41 more rows Close Solution × Hint gapminder |&gt; filter((gdpPercap &gt; ___ &amp; continent == ___) | (___)) |&gt; # print(n=Inf) |&gt; # if want to see the intermediate results select(continent, ___, ___) # |&gt; print(n=Inf) Close Hint Subset your data set to find all rows with GDP per capita greater than 40000 in Europe or with GDP per capita less than 500 in Africa. × Solution gapminder |&gt; mutate(gdp = pop * gdpPercap) #&gt; # A tibble: 1,704 × 7 #&gt; country continent year lifeExp pop gdpPercap gdp #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. 6567086330. #&gt; 2 Afghanistan Asia 1957 30.3 9240934 821. 7585448670. #&gt; 3 Afghanistan Asia 1962 32.0 10267083 853. 8758855797. #&gt; 4 Afghanistan Asia 1967 34.0 11537966 836. 9648014150. #&gt; 5 Afghanistan Asia 1972 36.1 13079460 740. 9678553274. #&gt; 6 Afghanistan Asia 1977 38.4 14880372 786. 11697659231. #&gt; 7 Afghanistan Asia 1982 39.9 12881816 978. 12598563401. #&gt; 8 Afghanistan Asia 1987 40.8 13867957 852. 11820990309. #&gt; 9 Afghanistan Asia 1992 41.7 16317921 649. 10595901589. #&gt; 10 Afghanistan Asia 1997 41.8 22227415 635. 14121995875. #&gt; # ℹ 1,694 more rows Close Solution Use mutate to calculate each country’s GDP (population times GDP per capita). In general GDP numbers are large and abstract. Let us try to calculate relative numbers. × Solution mean_dk &lt;- gapminder |&gt; filter(country == &quot;Denmark&quot;) |&gt; pull(gdpPercap) |&gt; mean() dat &lt;- gapminder |&gt; mutate(gdpPercapRel = gdpPercap/mean_dk) The relative GDP per capita numbers are, in general, well below 1. We see that most of the countries covered by this dataset have substantially lower GDP per capita, relative to Denmark, across the entire time period. Close Solution × Hint 2 dat &lt;- gapminder |&gt; mutate(gdpPercapRel = ___) Close Hint 2 × Hint 1 mean_dk &lt;- gapminder |&gt; filter(country == &quot;Denmark&quot;) |&gt; pull(___) |&gt; mean() First you must calculate the mean of Danish gdpPercap and next use that to add a new column gdpPercapRel. Close Hint 1 Use mutate to calculate GDP per capita relative to mean GDP per capita in Denmark over the whole period (gdpPercap divided by the mean of Danish gdpPercap). Have a look at the calculated data. Does the numbers seem reasonable? I perceive Denmark to be a “high GDP” country, so I predict that the distribution of gdpPercapRel is located below 1, possibly even well below. Use arrange to order × Solution gapminder |&gt; arrange(year, country) #&gt; # A tibble: 1,704 × 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. #&gt; 2 Albania Europe 1952 55.2 1282697 1601. #&gt; 3 Algeria Africa 1952 43.1 9279525 2449. #&gt; 4 Angola Africa 1952 30.0 4232095 3521. #&gt; 5 Argentina Americas 1952 62.5 17876956 5911. #&gt; 6 Australia Oceania 1952 69.1 8691212 10040. #&gt; 7 Austria Europe 1952 66.8 6927772 6137. #&gt; 8 Bahrain Asia 1952 50.9 120447 9867. #&gt; 9 Bangladesh Asia 1952 37.5 46886859 684. #&gt; 10 Belgium Europe 1952 68 8730405 8343. #&gt; # ℹ 1,694 more rows Close Solution         a) data by year then country, as opposed to current by country then year, × Solution gapminder |&gt; filter(year == 2007) |&gt; arrange(lifeExp) #&gt; # A tibble: 142 × 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Swaziland Africa 2007 39.6 1133066 4513. #&gt; 2 Mozambique Africa 2007 42.1 19951656 824. #&gt; 3 Zambia Africa 2007 42.4 11746035 1271. #&gt; 4 Sierra Leone Africa 2007 42.6 6144562 863. #&gt; 5 Lesotho Africa 2007 42.6 2012649 1569. #&gt; 6 Angola Africa 2007 42.7 12420476 4797. #&gt; 7 Zimbabwe Africa 2007 43.5 12311143 470. #&gt; 8 Afghanistan Asia 2007 43.8 31889923 975. #&gt; 9 Central African Republic Africa 2007 44.7 4369038 706. #&gt; 10 Liberia Africa 2007 45.7 3193942 415. #&gt; # ℹ 132 more rows Close Solution         b) data from 2007, sorted on life expectancy, × Solution gapminder |&gt; filter(year == 2007) |&gt; arrange(desc(lifeExp)) #&gt; # A tibble: 142 × 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Japan Asia 2007 82.6 127467972 31656. #&gt; 2 Hong Kong, China Asia 2007 82.2 6980412 39725. #&gt; 3 Iceland Europe 2007 81.8 301931 36181. #&gt; 4 Switzerland Europe 2007 81.7 7554661 37506. #&gt; 5 Australia Oceania 2007 81.2 20434176 34435. #&gt; 6 Spain Europe 2007 80.9 40448191 28821. #&gt; 7 Sweden Europe 2007 80.9 9031088 33860. #&gt; 8 Israel Asia 2007 80.7 6426679 25523. #&gt; 9 France Europe 2007 80.7 61083916 30470. #&gt; 10 Canada Americas 2007 80.7 33390141 36319. #&gt; # ℹ 132 more rows Close Solution         c) data from 2007, sorted on life expectancy in descending order. Hint: use desc() inside arrange. Use select to × Solution gapminder |&gt; select(yr = year, everything()) #&gt; # A tibble: 1,704 × 6 #&gt; yr country continent lifeExp pop gdpPercap #&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1952 Afghanistan Asia 28.8 8425333 779. #&gt; 2 1957 Afghanistan Asia 30.3 9240934 821. #&gt; 3 1962 Afghanistan Asia 32.0 10267083 853. #&gt; 4 1967 Afghanistan Asia 34.0 11537966 836. #&gt; 5 1972 Afghanistan Asia 36.1 13079460 740. #&gt; 6 1977 Afghanistan Asia 38.4 14880372 786. #&gt; 7 1982 Afghanistan Asia 39.9 12881816 978. #&gt; 8 1987 Afghanistan Asia 40.8 13867957 852. #&gt; 9 1992 Afghanistan Asia 41.7 16317921 649. #&gt; 10 1997 Afghanistan Asia 41.8 22227415 635. #&gt; # ℹ 1,694 more rows Close Solution         a) rename year to yr and keep all other columns (the select helper everything may be used), × Solution gapminder |&gt; select(-pop) #&gt; # A tibble: 1,704 × 5 #&gt; country continent year lifeExp gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 779. #&gt; 2 Afghanistan Asia 1957 30.3 821. #&gt; 3 Afghanistan Asia 1962 32.0 853. #&gt; 4 Afghanistan Asia 1967 34.0 836. #&gt; 5 Afghanistan Asia 1972 36.1 740. #&gt; 6 Afghanistan Asia 1977 38.4 786. #&gt; 7 Afghanistan Asia 1982 39.9 978. #&gt; 8 Afghanistan Asia 1987 40.8 852. #&gt; 9 Afghanistan Asia 1992 41.7 649. #&gt; 10 Afghanistan Asia 1997 41.8 635. #&gt; # ℹ 1,694 more rows Close Solution         b) remove pop, × Solution gapminder |&gt; select(year, pop, everything()) #&gt; # A tibble: 1,704 × 6 #&gt; year pop country continent lifeExp gdpPercap #&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1952 8425333 Afghanistan Asia 28.8 779. #&gt; 2 1957 9240934 Afghanistan Asia 30.3 821. #&gt; 3 1962 10267083 Afghanistan Asia 32.0 853. #&gt; 4 1967 11537966 Afghanistan Asia 34.0 836. #&gt; 5 1972 13079460 Afghanistan Asia 36.1 740. #&gt; 6 1977 14880372 Afghanistan Asia 38.4 786. #&gt; 7 1982 12881816 Afghanistan Asia 39.9 978. #&gt; 8 1987 13867957 Afghanistan Asia 40.8 852. #&gt; 9 1992 16317921 Afghanistan Asia 41.7 649. #&gt; 10 1997 22227415 Afghanistan Asia 41.8 635. #&gt; # ℹ 1,694 more rows Close Solution         c) reorder columns in order year, pop, … (remaining). Use group_by and summarize to find the × Solution gapminder |&gt; group_by(continent) |&gt; summarize(n = n()) #&gt; # A tibble: 5 × 2 #&gt; continent n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Africa 624 #&gt; 2 Americas 300 #&gt; 3 Asia 396 #&gt; 4 Europe 360 #&gt; 5 Oceania 24 Close Solution         a) number of observations per continent, × Solution gapminder |&gt; group_by(continent) |&gt; summarize(n = n(), n_countries = n_distinct(country)) #&gt; # A tibble: 5 × 3 #&gt; continent n n_countries #&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Africa 624 52 #&gt; 2 Americas 300 25 #&gt; 3 Asia 396 33 #&gt; 4 Europe 360 30 #&gt; 5 Oceania 24 2 Close Solution         b) number of countries per continent (use n_distinct inside summarize to count the number of distinct observations), × Solution gapminder |&gt; group_by(continent) |&gt; summarize(avg_lifeExp = mean(lifeExp)) #&gt; # A tibble: 5 × 2 #&gt; continent avg_lifeExp #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 Africa 48.9 #&gt; 2 Americas 64.7 #&gt; 3 Asia 60.1 #&gt; 4 Europe 71.9 #&gt; 5 Oceania 74.3 Close Solution         c) average life expectancy by continent, × Solution gapminder |&gt; filter(continent == &quot;Asia&quot;) |&gt; group_by(year) |&gt; summarize(min_lifeExp = min(lifeExp), max_lifeExp = max(lifeExp)) #&gt; # A tibble: 12 × 3 #&gt; year min_lifeExp max_lifeExp #&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1952 28.8 65.4 #&gt; 2 1957 30.3 67.8 #&gt; 3 1962 32.0 69.4 #&gt; 4 1967 34.0 71.4 #&gt; 5 1972 36.1 73.4 #&gt; 6 1977 31.2 75.4 #&gt; 7 1982 39.9 77.1 #&gt; 8 1987 40.8 78.7 #&gt; 9 1992 41.7 79.4 #&gt; 10 1997 41.8 80.7 #&gt; 11 2002 42.1 82 #&gt; 12 2007 43.8 82.6 Close Solution         d) minimum and maximum life expectancies seen by year in Asia. × Solution gapminder |&gt; group_by(country) |&gt; # group by country select(country, year, lifeExp) |&gt; # select relevant columns arrange(year, .by_group = TRUE) |&gt; # make sure that data is sorted correct mutate(lifeExp_gain = lifeExp - first(lifeExp)) |&gt; filter(year &lt; 1963) # just for nice printing #&gt; # A tibble: 426 × 4 #&gt; # Groups: country [142] #&gt; country year lifeExp lifeExp_gain #&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Afghanistan 1952 28.8 0 #&gt; 2 Afghanistan 1957 30.3 1.53 #&gt; 3 Afghanistan 1962 32.0 3.20 #&gt; 4 Albania 1952 55.2 0 #&gt; 5 Albania 1957 59.3 4.05 #&gt; 6 Albania 1962 64.8 9.59 #&gt; 7 Algeria 1952 43.1 0 #&gt; 8 Algeria 1957 45.7 2.61 #&gt; 9 Algeria 1962 48.3 5.23 #&gt; 10 Angola 1952 30.0 0 #&gt; # ℹ 416 more rows Close Solution × Hint gapminder |&gt; group_by(country) |&gt; # group by country select(country, year, lifeExp) |&gt; # select relevant columns arrange(year, .by_group = TRUE) |&gt; # make sure that data is sorted correct mutate(lifeExp_gain = ___) |&gt; # define new variable filter(year &lt; 1963) # just for nice printing The first function may be helpful to extract the first value from a vector in each group. Close Hint Sometimes you do not want to collapse the \\(n\\) rows for each group into one row. That is, you do not want to use summarize but mutate within your groups. Try to make a new variable that is the years of life expectancy gained (lost) relative to 1952, for each individual country. × Solution gapminder |&gt; select(country, year, continent, lifeExp) |&gt; group_by(continent, country) |&gt; mutate(le_delta = lifeExp - lag(lifeExp)) |&gt; summarize(worst_le_delta = min(le_delta, na.rm = TRUE)) |&gt; slice_min(worst_le_delta) |&gt; arrange(worst_le_delta) #&gt; # A tibble: 5 × 3 #&gt; # Groups: continent [5] #&gt; continent country worst_le_delta #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 Africa Rwanda -20.4 #&gt; 2 Asia Cambodia -9.10 #&gt; 3 Americas El Salvador -1.51 #&gt; 4 Europe Montenegro -1.46 #&gt; 5 Oceania Australia 0.170 Mostly you are seeing what genocide looks like in dry statistics on average life expectancy. Close Solution × Hint gapminder |&gt; select(country, year, continent, lifeExp) |&gt; # select relevant columns group_by(continent, country) |&gt; # group mutate(le_delta = ___) |&gt; # within country, take (lifeExp in year i) - (lifeExp in year i - 1) summarize(worst_le_delta = min(___, na.rm = TRUE)) |&gt; # find lowest value slice_min(worst_le_delta) |&gt; # find min in each continent arrange(worst_le_delta) # arrange The lag function is useful to select the value in the previous row. Positive values of le_delta means lifeExp went up, negative means it went down. Break the code into pieces, starting at the top, and inspect the intermediate results. These commands are built up gradually, with lots of errors and refinements along the way. Close Hint Which country experienced the sharpest 5-year drop in life expectancy in each continent? Recall that the Gapminder data only has data every five years, e.g. for 1952, 1957, etc. So this really means looking at life expectancy changes between adjacent timepoints. 13.5.2 Exercise (babynames) Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). The package babynames contains the dataset babynames provided by the U.S. Social Security Administration. For each year from 1880 to 2017, the number of children of each sex given each name. All names with more than 5 uses are given (source: http://www.ssa.gov/oact/babynames/limits.html). Install it using install.packages(&quot;babynames&quot;) We will use the skimr package to get an overview over babynames: library(babynames) library(skimr) skim(babynames) Table 13.1: Data summary Name babynames Number of rows 1924665 Number of columns 5 _______________________ Column type frequency: character 2 numeric 3 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace sex 0 1 1 1 0 2 0 name 0 1 2 15 0 97310 0 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist year 0 1 1975 34 1880 1951 1985 2003 2017.00 ▁▂▃▅▇ n 0 1 181 1533 5 7 12 32 99686.00 ▇▁▁▁▁ prop 0 1 0 0 0 0 0 0 0.08 ▇▁▁▁▁ × Solution The last line only selects the n column. Close Solution Which of these is NOT a way to select the name and n columns together? select(babynames, -c(year, sex, prop)) select(babynames, name:n) select(babynames, starts_with(&quot;n&quot;)) select(babynames, ends_with(&quot;n&quot;)) Use filter and the logical operators to find: × Solution babynames |&gt; filter(prop &gt;= 0.08) #&gt; # A tibble: 3 × 5 #&gt; year sex name n prop #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1880 M John 9655 0.0815 #&gt; 2 1880 M William 9532 0.0805 #&gt; 3 1881 M John 8769 0.0810 Close Solution         a) all of the names where prop is greater than or equal to 0.08, × Solution babynames |&gt; filter(name == &quot;Sea&quot;) #&gt; # A tibble: 4 × 5 #&gt; year sex name n prop #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1982 F Sea 5 0.00000276 #&gt; 2 1985 M Sea 6 0.00000312 #&gt; 3 1986 M Sea 5 0.0000026 #&gt; 4 1998 F Sea 5 0.00000258 Close Solution         b) all of the children named “Sea”. Use Boolean operators to return only the rows that contain: × Solution babynames |&gt; filter(name == &quot;Sue&quot;, sex == &quot;M&quot;) #&gt; # A tibble: 52 × 5 #&gt; year sex name n prop #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1917 M Sue 7 0.0000073 #&gt; 2 1927 M Sue 5 0.0000043 #&gt; 3 1928 M Sue 5 0.00000438 #&gt; 4 1930 M Sue 5 0.00000443 #&gt; 5 1931 M Sue 6 0.00000561 #&gt; 6 1932 M Sue 7 0.00000652 #&gt; 7 1933 M Sue 7 0.00000686 #&gt; 8 1934 M Sue 14 0.0000132 #&gt; 9 1935 M Sue 13 0.0000122 #&gt; 10 1936 M Sue 9 0.00000846 #&gt; # ℹ 42 more rows Close Solution         a) boys named Sue, × Solution babynames |&gt; filter(year == 1880, n == 5 | n == 6) #&gt; # A tibble: 455 × 5 #&gt; year sex name n prop #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1880 F Abby 6 0.0000615 #&gt; 2 1880 F Aileen 6 0.0000615 #&gt; 3 1880 F Alba 6 0.0000615 #&gt; 4 1880 F Alda 6 0.0000615 #&gt; 5 1880 F Alla 6 0.0000615 #&gt; 6 1880 F Alverta 6 0.0000615 #&gt; 7 1880 F Ara 6 0.0000615 #&gt; 8 1880 F Ardelia 6 0.0000615 #&gt; 9 1880 F Ardella 6 0.0000615 #&gt; 10 1880 F Arrie 6 0.0000615 #&gt; # ℹ 445 more rows Close Solution         b) names that were used by exactly 5 or 6 children in 1880, × Solution babynames |&gt; filter(name %in% c(&quot;Acura&quot;, &quot;Lexus&quot;, &quot;Yugo&quot;)) #&gt; # A tibble: 57 × 5 #&gt; year sex name n prop #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1990 F Lexus 36 0.0000175 #&gt; 2 1990 M Lexus 12 0.00000558 #&gt; 3 1991 F Lexus 102 0.0000502 #&gt; 4 1991 M Lexus 16 0.00000755 #&gt; 5 1992 F Lexus 193 0.0000963 #&gt; 6 1992 M Lexus 25 0.0000119 #&gt; 7 1993 F Lexus 285 0.000145 #&gt; 8 1993 M Lexus 30 0.0000145 #&gt; 9 1994 F Lexus 381 0.000195 #&gt; 10 1994 F Acura 6 0.00000308 #&gt; # ℹ 47 more rows Close Solution         c) names that are one of Acura, Lexus, or Yugo. × Solution min(babynames$n) #&gt; [1] 5 max(babynames$n) #&gt; [1] 99686 Close Solution What is the smallest value of n? What is the largest? × Solution babynames |&gt; filter(sex == &quot;F&quot;, year == 2017) |&gt; select(name, n) |&gt; arrange(desc(n)) #&gt; # A tibble: 18,309 × 2 #&gt; name n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Emma 19738 #&gt; 2 Olivia 18632 #&gt; 3 Ava 15902 #&gt; 4 Isabella 15100 #&gt; 5 Sophia 14831 #&gt; 6 Mia 13437 #&gt; 7 Charlotte 12893 #&gt; 8 Amelia 11800 #&gt; 9 Evelyn 10675 #&gt; 10 Abigail 10551 #&gt; # ℹ 18,299 more rows Close Solution × Hint babynames |&gt; filter(___) |&gt; select(name, n) |&gt; arrange(desc(___)) Close Hint Write a sequence of functions that filters babynames to just the girls that were born in 2017, then select the name and n columns, then arrange the results so that the most popular names are near the top. × Solution # for instance babynames |&gt; filter(sex == &quot;M&quot;, name == &quot;Lars&quot;) #&gt; # A tibble: 112 × 5 #&gt; year sex name n prop #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1883 M Lars 7 0.0000622 #&gt; 2 1884 M Lars 5 0.0000407 #&gt; 3 1886 M Lars 5 0.000042 #&gt; 4 1887 M Lars 5 0.0000457 #&gt; 5 1897 M Lars 5 0.000041 #&gt; 6 1901 M Lars 8 0.0000692 #&gt; 7 1912 M Lars 6 0.0000133 #&gt; 8 1913 M Lars 6 0.0000112 #&gt; 9 1914 M Lars 16 0.0000234 #&gt; 10 1915 M Lars 17 0.0000193 #&gt; # ℹ 102 more rows Close Solution Trim babynames to just the rows that contain your name and your sex. × Solution babynames |&gt; filter(name == &quot;Khaleesi&quot;) |&gt; summarise(total = sum(n), first = min(year)) #&gt; # A tibble: 1 × 2 #&gt; total first #&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1964 2011 Close Solution × Hint babynames ___ filter(____) ___ ____(total = ___, first = ___) Close Hint Extract the rows where name == \"Khaleesi\". Then use summarise() to find the total number of children named Khaleesi and the first year Khaleesi appeared in the data. × Solution babynames |&gt; group_by(name, sex) |&gt; summarize(total = sum(n)) |&gt; arrange(desc(total)) #&gt; # A tibble: 107,973 × 3 #&gt; # Groups: name [97,310] #&gt; name sex total #&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 James M 5150472 #&gt; 2 John M 5115466 #&gt; 3 Robert M 4814815 #&gt; 4 Michael M 4350824 #&gt; 5 Mary F 4123200 #&gt; 6 William M 4102604 #&gt; 7 David M 3611329 #&gt; 8 Joseph M 2603445 #&gt; 9 Richard M 2563082 #&gt; 10 Charles M 2386048 #&gt; # ℹ 107,963 more rows Close Solution × Hint babynames |&gt; _______(name, sex) |&gt; _______(total = _____(n)) |&gt; _______(desc(_____)) Close Hint Use group_by(), summarise(), and arrange() to display the ten most popular names. Compute popularity as the total number of children of a single gender given a name. × Solution babynames |&gt; group_by(year) |&gt; summarise(total = sum(n)) #&gt; # A tibble: 138 × 2 #&gt; year total #&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 1880 201484 #&gt; 2 1881 192696 #&gt; 3 1882 221533 #&gt; 4 1883 216946 #&gt; 5 1884 243462 #&gt; 6 1885 240854 #&gt; 7 1886 255317 #&gt; 8 1887 247394 #&gt; 9 1888 299473 #&gt; 10 1889 288946 #&gt; # ℹ 128 more rows Close Solution Use group_by() to calculate the total number of children born each year over time. × Solution babynames |&gt; group_by(year, sex) |&gt; mutate(rank = min_rank(desc(n))) |&gt; arrange(year, sex, desc(prop)) #&gt; # A tibble: 1,924,665 × 6 #&gt; # Groups: year, sex [276] #&gt; year sex name n prop rank #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 1880 F Mary 7065 0.0724 1 #&gt; 2 1880 F Anna 2604 0.0267 2 #&gt; 3 1880 F Emma 2003 0.0205 3 #&gt; 4 1880 F Elizabeth 1939 0.0199 4 #&gt; 5 1880 F Minnie 1746 0.0179 5 #&gt; 6 1880 F Margaret 1578 0.0162 6 #&gt; 7 1880 F Ida 1472 0.0151 7 #&gt; 8 1880 F Alice 1414 0.0145 8 #&gt; 9 1880 F Bertha 1320 0.0135 9 #&gt; 10 1880 F Sarah 1288 0.0132 10 #&gt; # ℹ 1,924,655 more rows The same results if you use n since in the same order. Close Solution × Hint babynames |&gt; group_by(___, ___) |&gt; ___(rank = ___(desc(___))) |&gt; arrange(year, sex, desc(prop)) Close Hint Column prop denotes the proportion given year and sex. Use mutate() and min_rank() to rank each row in babynames from largest prop to lowest prop given year and sex. What happens if you do the same using the n column? × Solution babynames |&gt; group_by(year, sex) |&gt; mutate(rank = min_rank(desc(n))) |&gt; filter(rank == 1, year &gt; 2009) #&gt; # A tibble: 16 × 6 #&gt; # Groups: year, sex [16] #&gt; year sex name n prop rank #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 2010 F Isabella 22905 0.0117 1 #&gt; 2 2010 M Jacob 22117 0.0108 1 #&gt; 3 2011 F Sophia 21837 0.0113 1 #&gt; 4 2011 M Jacob 20365 0.0100 1 #&gt; 5 2012 F Sophia 22304 0.0115 1 #&gt; 6 2012 M Jacob 19069 0.00941 1 #&gt; 7 2013 F Sophia 21213 0.0110 1 #&gt; 8 2013 M Noah 18241 0.00904 1 #&gt; 9 2014 F Emma 20924 0.0107 1 #&gt; 10 2014 M Noah 19286 0.00943 1 #&gt; 11 2015 F Emma 20435 0.0105 1 #&gt; 12 2015 M Noah 19613 0.00962 1 #&gt; 13 2016 F Emma 19471 0.0101 1 #&gt; 14 2016 M Noah 19082 0.00946 1 #&gt; 15 2017 F Emma 19738 0.0105 1 #&gt; 16 2017 M Liam 18728 0.00954 1 Close Solution Filter the results to find all names with rank == 1 after 2009. 13.5.3 Exercise (profit) Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). Consider the dataset profit containing quarterly financial records for each costumer, product, etc.: library(skimr) path &lt;- system.file(&quot;extdata/profit_raw.csv&quot;, package = &quot;tfa&quot;) profit &lt;- read_csv(path) skim(profit) Table 13.2: Data summary Name profit Number of rows 24546 Number of columns 9 _______________________ Column type frequency: character 9 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace Quarter 0 1 1 2 0 12 0 Channel 0 1 3 3 0 10 0 Customer ID 0 1 3 3 0 18 0 Country 0 1 3 14 0 47 0 Product Line 0 1 14 25 0 6 0 Revenue 63 1 1 7 0 1210 0 Product Cost 61 1 3 6 0 1139 0 Customer Service Cost 10 1 1 6 0 464 0 Profit 0 1 3 7 0 966 0 Note that it seems that the dataset need to be cleaned. All columns are strings (some should be numbers) and there seems to be missing values. You may start by having a view of the dataset using: View(profit) First focus on column Quarter which currently has 12 distinct values: profit |&gt; distinct(Quarter) #&gt; # A tibble: 12 × 1 #&gt; Quarter #&gt; &lt;chr&gt; #&gt; 1 Q3 #&gt; 2 1 #&gt; 3 Q4 #&gt; 4 Q1 #&gt; 5 Q2 #&gt; 6 2 #&gt; 7 4 #&gt; 8 q1 #&gt; 9 q4 #&gt; 10 q3 #&gt; 11 q2 #&gt; 12 3 You would like it to be a numeric with values 1-4. × Solution profit &lt;- profit |&gt; mutate(Quarter = str_remove(Quarter, &quot;q&quot;) |&gt; str_remove(&quot;Q&quot;) |&gt; as.numeric()) profit |&gt; distinct(Quarter) #&gt; # A tibble: 4 × 1 #&gt; Quarter #&gt; &lt;dbl&gt; #&gt; 1 3 #&gt; 2 1 #&gt; 3 4 #&gt; 4 2 Close Solution × Hint profit &lt;- profit |&gt; mutate(Quarter = str_remove(___, &quot;q&quot;) |&gt; str_remove(___) |&gt; as.numeric()) profit |&gt; distinct(Quarter) Close Hint Use mutate, str_remove and as.numeric to convert the column to a numeric by removing all ‘q’ and ‘Q’ values. Let us look at the next columns: profit |&gt; distinct(Channel) |&gt; pull() #&gt; [1] &quot;ATM&quot; &quot;BRH&quot; &quot;INT&quot; &quot;MAL&quot; &quot;EML&quot; &quot;CCT&quot; &quot;TEL&quot; &quot;MOP&quot; &quot;DSA&quot; &quot;EVE&quot; profit |&gt; distinct(`Customer ID`) |&gt; pull() #&gt; [1] &quot;FRT&quot; &quot;MRT&quot; &quot;PBI&quot; &quot;MAM&quot; &quot;EBP&quot; &quot;RPB&quot; &quot;WEB&quot; &quot;WEM&quot; &quot;HEC&quot; &quot;STF&quot; &quot;IAS&quot; &quot;CRE&quot; &quot;INB&quot; &quot;CAM&quot; &quot;AGR&quot; &quot;SBE&quot; #&gt; [17] &quot;AFF&quot; &quot;MFN&quot; profit |&gt; distinct(Country) |&gt; pull() #&gt; [1] &quot;USA&quot; &quot;Canada&quot; &quot;Great Britain&quot; &quot;Finland&quot; &quot;New Zealand&quot; #&gt; [6] &quot;Brazil&quot; &quot;Mexico&quot; &quot;Germany&quot; &quot;Puerto Rico&quot; &quot;Hong Kong&quot; #&gt; [11] &quot;Japan&quot; &quot;Columbia&quot; &quot;Switzerland&quot; &quot;Uruguay&quot; &quot;Netherlands&quot; #&gt; [16] &quot;Korea&quot; &quot;Venezuela&quot; &quot;Panama&quot; &quot;Sweden&quot; &quot;China&quot; #&gt; [21] &quot;Guatemala&quot; &quot;South Africa&quot; &quot;Malaysia&quot; &quot;Nigeria&quot; &quot;Denmark&quot; #&gt; [26] &quot;France&quot; &quot;India&quot; &quot;Taiwan&quot; &quot;Norway&quot; &quot;Chile&quot; #&gt; [31] &quot;Indonesia&quot; &quot;Ireland&quot; &quot;Thailand&quot; &quot;Peru&quot; &quot;Spain&quot; #&gt; [36] &quot;Belgium&quot; &quot;Poland&quot; &quot;Ecuador&quot; &quot;Costa Rica&quot; &quot;Australia&quot; #&gt; [41] &quot;Israel&quot; &quot;Guam&quot; &quot;Oman&quot; &quot;Singapore&quot; &quot;Argentina&quot; #&gt; [46] &quot;Czechoslovakia&quot; &quot;Philippines&quot; profit |&gt; distinct(`Product Line`) |&gt; pull() #&gt; [1] &quot;Credit Products&quot; &quot;Deposit Products&quot; &quot;Revolving Credit Products&quot; #&gt; [4] &quot;Other Products&quot; &quot;Third Party Products&quot; &quot;Fee Based Products&quot; These seem to be okay. The last columns should be numbers. Let us consider Revenue. profit |&gt; distinct(Revenue) |&gt; pull() |&gt; head(n = 100) #&gt; [1] &quot;$ 6044&quot; &quot;$ 4686&quot; &quot;$ 6063&quot; &quot;$ 4682&quot; &quot;$ 6320&quot; &quot;$ 2993&quot; &quot;$ 3355&quot; &quot;$ 5716&quot; &quot;$ 3347&quot; #&gt; [10] &quot;$ 2624&quot; &quot;$ 3629&quot; &quot;$ 5612&quot; &quot;$ 4618&quot; &quot;$ 2080&quot; &quot;$ 2788&quot; &quot;$ 2829&quot; &quot;$ 2898&quot; &quot;$ 5232&quot; #&gt; [19] &quot;$ 2949&quot; &quot;$ 5565&quot; &quot;$ 2153&quot; &quot;$ 3097&quot; &quot;$ 1920&quot; &quot;$ 4041&quot; &quot;$ 5931&quot; &quot;$ 1605&quot; &quot;$ 2026&quot; #&gt; [28] &quot;$ 1687&quot; &quot;$ 5075&quot; &quot;$ 4223&quot; &quot;$ 2456&quot; &quot;$ 1924&quot; &quot;$ 1578&quot; &quot;$ 3235&quot; &quot;$ 5123&quot; &quot;$ 1560&quot; #&gt; [37] &quot;$ 1945&quot; &quot;$ 6060&quot; &quot;$ 1222&quot; &quot;$ 1660&quot; &quot;$ 3000&quot; &quot;$ 2970&quot; &quot;$ 1631&quot; &quot;$ 1215&quot; &quot;$ 1759&quot; #&gt; [46] &quot;$ 3285&quot; &quot;$ 2048&quot; &quot;$ 2173&quot; &quot;$ 3353&quot; &quot;$ 1162&quot; &quot;$ 1232&quot; &quot;$ 1561&quot; &quot;$ 1123&quot; &quot;$ 1794&quot; #&gt; [55] &quot;$ 1202&quot; &quot;$ 1510&quot; &quot;$ 4472&quot; &quot;$ 2370&quot; &quot;$ 2581&quot; &quot;$ 2761&quot; &quot;$ 6371&quot; &quot;$ 1972&quot; &quot;$ 1562&quot; #&gt; [64] &quot;$ 2742&quot; &quot;$ 4598&quot; &quot;$ 5322&quot; &quot;$ 3411&quot; NA &quot;$ 1569&quot; &quot;$ 2852&quot; &quot;$ 1622&quot; &quot;$ 2505&quot; #&gt; [73] &quot;$ 1596&quot; &quot;$ 1447&quot; &quot;$ 1690&quot; &quot;$ 2448&quot; &quot;$ 1593&quot; &quot;$ 1876&quot; &quot;$ 6591&quot; &quot;$ 1611&quot; &quot;$ 1254&quot; #&gt; [82] &quot;Unknown&quot; &quot;$ 842&quot; &quot;$ 1529&quot; &quot;$ 1439&quot; &quot;$ 762&quot; &quot;$ 1959&quot; &quot;$ 4382&quot; &quot;$ 1407&quot; &quot;$ 909&quot; #&gt; [91] &quot;$ 1549&quot; &quot;$ 2161&quot; &quot;$ 1331&quot; &quot;$ 727&quot; &quot;$ 1462&quot; &quot;$ 1067&quot; &quot;$ 833&quot; &quot;$ 1675&quot; &quot;$ 1524&quot; #&gt; [100] &quot;$ 1285&quot; Most values start with a dollar sign. Let us have a look at the other ones: profit |&gt; filter(!str_starts(Revenue, fixed(&quot;$&quot;))) #&gt; # A tibble: 95 × 9 #&gt; Quarter Channel `Customer ID` Country `Product Line` Revenue `Product Cost` #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 3 INT MAM USA Deposit Products Unknown $ 1008 #&gt; 2 3 MAL RPB USA Credit Products ? $ 1420 #&gt; 3 1 MAL WEM Great Britain Other Products ? $ 87 #&gt; 4 3 ATM MFN Germany Fee Based Products unknown $ 47 #&gt; 5 3 ATM PBI Costa Rica Third Party Products Unknown $ 51 #&gt; 6 1 ATM PBI Chile Deposit Products Unknown $ 58 #&gt; 7 4 CCT MRT Great Britain Revolving Credit Products ? $ 27 #&gt; 8 4 ATM MAM Taiwan Third Party Products unknown $ 55 #&gt; 9 4 MAL WEB Japan Other Products unknown $ 40 #&gt; 10 2 CCT MAM Netherlands Credit Products unknown $ 14 #&gt; # ℹ 85 more rows #&gt; # ℹ 2 more variables: `Customer Service Cost` &lt;chr&gt;, Profit &lt;chr&gt; na_values &lt;- profit |&gt; filter(!str_starts(Revenue, fixed(&quot;$&quot;))) |&gt; distinct(Revenue) |&gt; pull(Revenue) na_values #&gt; [1] &quot;Unknown&quot; &quot;?&quot; &quot;unknown&quot; The expression is a bit complex. Let us break it up. Function fixed just returns the fixed string ‘$’. This is necessary since the dollar sign has a special meaning in regular expressions (beyond the scope here). Function str_starts checks if the string starts with a dollar sign. We use the logical negation (NOT) to find the complementary set. Note that different strings have been used to indicate NA values (Unknown, ?, unknown). Let us first use a single value to indicate NA (a question mark): profit &lt;- profit |&gt; mutate(Revenue = str_replace_all(Revenue, c(&quot;unknown&quot; = &quot;?&quot;, &quot;Unknown&quot; = &quot;?&quot;))) Next, we replace all ? with NA: profit &lt;- profit |&gt; mutate(Revenue = na_if(Revenue, &quot;?&quot;)) profit |&gt; # check filter(!str_starts(Revenue, fixed(&quot;$&quot;))) #&gt; # A tibble: 0 × 9 #&gt; # ℹ 9 variables: Quarter &lt;dbl&gt;, Channel &lt;chr&gt;, Customer ID &lt;chr&gt;, Country &lt;chr&gt;, #&gt; # Product Line &lt;chr&gt;, Revenue &lt;chr&gt;, Product Cost &lt;chr&gt;, Customer Service Cost &lt;chr&gt;, #&gt; # Profit &lt;chr&gt; Finally, we remove all dollar signs: profit &lt;- profit |&gt; mutate(Revenue = str_remove(Revenue, fixed(&quot;$ &quot;)) |&gt; as.numeric()) profit #&gt; # A tibble: 24,546 × 9 #&gt; Quarter Channel `Customer ID` Country `Product Line` Revenue `Product Cost` #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 3 ATM FRT USA Credit Products 6044 $ 3998 #&gt; 2 1 ATM MRT USA Credit Products 4686 $ 3229 #&gt; 3 4 ATM PBI USA Deposit Products 6063 $ 7440 #&gt; 4 1 ATM PBI USA Deposit Products 4682 $ 6127 #&gt; 5 4 ATM MRT USA Deposit Products 6320 $ 7913 #&gt; 6 3 BRH MAM USA Deposit Products 2993 $ 1034 #&gt; 7 4 BRH PBI USA Revolving Credit Products 3355 $ 4355 #&gt; 8 3 ATM FRT USA Revolving Credit Products 5716 $ 5617 #&gt; 9 4 BRH PBI USA Deposit Products 3347 $ 4229 #&gt; 10 1 BRH PBI USA Credit Products 2624 $ 1960 #&gt; # ℹ 24,536 more rows #&gt; # ℹ 2 more variables: `Customer Service Cost` &lt;chr&gt;, Profit &lt;chr&gt; As one pipe: profit &lt;- profit |&gt; mutate(Revenue = str_replace_all(Revenue, c(&quot;unknown&quot; = &quot;?&quot;, &quot;Unknown&quot; = &quot;?&quot;))) |&gt; mutate(Revenue = na_if(Revenue, &quot;?&quot;)) |&gt; mutate(Revenue = str_remove(Revenue, fixed(&quot;$ &quot;)) |&gt; as.numeric()) Convert the remaining columns to numeric like shown for Revenue above. × Solution profit &lt;- read_csv(path) profit &lt;- profit |&gt; mutate(across(Revenue:Profit, ~str_replace_all(.x, c(&quot;unknown&quot; = &quot;?&quot;, &quot;Unknown&quot; = &quot;?&quot;)) )) |&gt; mutate(across(Revenue:Profit, ~na_if(.x, &quot;?&quot;) )) |&gt; mutate(across(Revenue:Profit, ~str_remove(.x, fixed(&quot;$ &quot;)) |&gt; as.numeric() )) profit #&gt; # A tibble: 24,546 × 9 #&gt; Quarter Channel `Customer ID` Country `Product Line` Revenue `Product Cost` #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Q3 ATM FRT USA Credit Products 6044 3998 #&gt; 2 1 ATM MRT USA Credit Products 4686 3229 #&gt; 3 Q4 ATM PBI USA Deposit Products 6063 7440 #&gt; 4 Q1 ATM PBI USA Deposit Products 4682 6127 #&gt; 5 Q4 ATM MRT USA Deposit Products 6320 7913 #&gt; 6 Q3 BRH MAM USA Deposit Products 2993 1034 #&gt; 7 Q4 BRH PBI USA Revolving Credit Products 3355 4355 #&gt; 8 Q3 ATM FRT USA Revolving Credit Products 5716 5617 #&gt; 9 Q4 BRH PBI USA Deposit Products 3347 4229 #&gt; 10 Q1 BRH PBI USA Credit Products 2624 1960 #&gt; # ℹ 24,536 more rows #&gt; # ℹ 2 more variables: `Customer Service Cost` &lt;dbl&gt;, Profit &lt;dbl&gt; Close Solution × Hint profit &lt;- read_csv(path) |&gt; mutate(across(___:___, ~str_replace_all(.x, c(&quot;unknown&quot; = &quot;?&quot;, &quot;Unknown&quot; = &quot;?&quot;)) )) |&gt; mutate(across(___:___, ~na_if(.x, &quot;?&quot;) )) |&gt; mutate(across(___:___, ~str_remove(.x, fixed(&quot;$ &quot;)) |&gt; as.numeric() )) profit Close Hint Use the across function to apply the operations in Question 2 for a set of columns. Hint: see the examples on the help page of across. × Solution profit &lt;- read_csv(path) |&gt; mutate(Quarter = str_remove(Quarter, &quot;q&quot;) |&gt; str_remove(&quot;Q&quot;) |&gt; as.numeric()) |&gt; mutate(across(Revenue:Profit, ~str_replace_all(.x, c(&quot;unknown&quot; = &quot;?&quot;, &quot;Unknown&quot; = &quot;?&quot;)) )) |&gt; mutate(across(Revenue:Profit, ~na_if(.x, &quot;?&quot;) )) |&gt; mutate(across(Revenue:Profit, ~str_remove(.x, fixed(&quot;$ &quot;)) |&gt; as.numeric() )) skim(profit) Table 13.3: Data summary Name profit Number of rows 24546 Number of columns 9 _______________________ Column type frequency: character 4 numeric 5 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace Channel 0 1 3 3 0 10 0 Customer ID 0 1 3 3 0 18 0 Country 0 1 3 14 0 47 0 Product Line 0 1 14 25 0 6 0 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist Quarter 0 1.00 2.50 1.12 1 2 2 3 4 ▇▇▁▇▇ Revenue 158 0.99 120.31 421.79 1 12 41 74 7540 ▇▁▁▁▁ Product Cost 61 1.00 100.04 375.58 0 9 29 68 9256 ▇▁▁▁▁ Customer Service Cost 96 1.00 17.41 67.50 0 1 5 12 1865 ▇▁▁▁▁ Profit 0 1.00 2.71 154.89 -4139 -7 0 9 3664 ▁▁▇▁▁ Close Solution Write one pipe that does all the cleaning. × Solution profit &lt;- profit |&gt; mutate(Profit_calc = Revenue - `Product Cost` - `Customer Service Cost`, Diff = abs(Profit - Profit_calc)) |&gt; mutate(Profit = if_else(Diff &gt; 0 &amp; Diff &lt;= 1, Profit_calc, Profit, missing = Profit) ) profit |&gt; filter(Diff == 1, is.na(Profit_calc)) # check #&gt; # A tibble: 0 × 11 #&gt; # ℹ 11 variables: Quarter &lt;dbl&gt;, Channel &lt;chr&gt;, Customer ID &lt;chr&gt;, Country &lt;chr&gt;, #&gt; # Product Line &lt;chr&gt;, Revenue &lt;dbl&gt;, Product Cost &lt;dbl&gt;, Customer Service Cost &lt;dbl&gt;, #&gt; # Profit &lt;dbl&gt;, Profit_calc &lt;dbl&gt;, Diff &lt;dbl&gt; Close Solution × Hint profit &lt;- profit |&gt; mutate(Profit_calc = Revenue - `Product Cost` - `Customer Service Cost`, Diff = abs(___)) |&gt; mutate(Profit = if_else(Diff &gt; 0 &amp; Diff &lt;= 1, ___, Profit, Profit) ) profit |&gt; filter(Diff == 1, is.na(Profit_calc)) # check Close Hint Validate that revenue - product costs - customer service cost equals profit. If you see small rounding errors (less than or equal one) then recalculate the profit. × Solution profit &lt;- profit |&gt; rowwise() |&gt; mutate(c_na = sum(is.na(c_across(Revenue:Profit)))) |&gt; mutate(Revenue = if_else(is.na(Revenue) &amp; c_na == 1, Profit + `Product Cost` + `Customer Service Cost`, Revenue, Revenue), `Product Cost` = if_else(is.na(`Product Cost`) &amp; c_na == 1, - Profit + Revenue - `Customer Service Cost`, `Product Cost`), `Customer Service Cost` = if_else(is.na(`Customer Service Cost`) &amp; c_na == 1, - Profit + Revenue - `Product Cost`, `Customer Service Cost`)) |&gt; select(Quarter:Profit) # check - do numbers match profit |&gt; mutate(Profit_calc = Revenue - `Product Cost` - `Customer Service Cost`, Diff = abs(Profit - Profit_calc)) |&gt; filter(Diff &gt; 0) #&gt; # A tibble: 0 × 11 #&gt; # Rowwise: #&gt; # ℹ 11 variables: Quarter &lt;dbl&gt;, Channel &lt;chr&gt;, Customer ID &lt;chr&gt;, Country &lt;chr&gt;, #&gt; # Product Line &lt;chr&gt;, Revenue &lt;dbl&gt;, Product Cost &lt;dbl&gt;, Customer Service Cost &lt;dbl&gt;, #&gt; # Profit &lt;dbl&gt;, Profit_calc &lt;dbl&gt;, Diff &lt;dbl&gt; # check - find NA values profit |&gt; rowwise() |&gt; mutate(c_na = sum(is.na(c_across(Revenue:Profit)))) |&gt; filter(c_na &gt; 0) #&gt; # A tibble: 3 × 10 #&gt; # Rowwise: #&gt; Quarter Channel `Customer ID` Country `Product Line` Revenue `Product Cost` Customer Service Cos…¹ #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 EML FRT France Revolving Cre… 3 NA NA #&gt; 2 2 BRH EBP Guam Fee Based Pro… NA NA 0 #&gt; 3 1 MAL MFN Japan Fee Based Pro… NA NA 5 #&gt; # ℹ abbreviated name: ¹​`Customer Service Cost` #&gt; # ℹ 2 more variables: Profit &lt;dbl&gt;, c_na &lt;int&gt; Close Solution × Hint 2 profit &lt;- profit |&gt; rowwise() |&gt; mutate(c_na = sum(is.na(c_across(Revenue:Profit)))) |&gt; mutate(Revenue = if_else(is.na(___) &amp; c_na == 1, ___, Revenue, Revenue), `Product Cost` = if_else(is.na(___) &amp; c_na == 1, ___, `Product Cost`), `Customer Service Cost` = if_else(is.na(___) &amp; c_na == 1, ___, `Customer Service Cost`)) |&gt; select(Quarter:Profit) You can check you calculations using your code from Question 5. Close Hint 2 × Hint 1 # To find the number of missing values (`NA`) you can create a new column # counting the number of missing values: profit &lt;- profit |&gt; rowwise() |&gt; mutate(ct_na = sum(is.na(c_across(Revenue:Profit)))) |&gt; ungroup() profit |&gt; filter(ct_na &gt;= 1) Recall that profit = revenue - product costs - customer service cost; that is, if a single value of these are missing then the value can be calculated using the other ones. Close Hint 1 Recalculate values in columns Revenue to Profit if possible. × Solution profit |&gt; group_by(Quarter) |&gt; slice_max(Profit, n = 2) #&gt; # A tibble: 8 × 9 #&gt; # Groups: Quarter [4] #&gt; Quarter Channel `Customer ID` Country `Product Line` Revenue `Product Cost` Customer Service Cos…¹ #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 ATM PBI USA Credit Produc… 4821 1808 233 #&gt; 2 1 ATM PBI USA Revolving Cre… 4268 1638 363 #&gt; 3 2 ATM FRT USA Credit Produc… 5931 3137 406 #&gt; 4 2 ATM RPB USA Deposit Produ… 4864 2156 533 #&gt; 5 3 ATM WEM USA Credit Produc… 5682 2112 454 #&gt; 6 3 ATM WEM USA Deposit Produ… 4850 2493 253 #&gt; 7 4 ATM MAM USA Revolving Cre… 6699 2506 530 #&gt; 8 4 ATM WEM USA Revolving Cre… 5836 2114 265 #&gt; # ℹ abbreviated name: ¹​`Customer Service Cost` #&gt; # ℹ 1 more variable: Profit &lt;dbl&gt; Close Solution Find the two best rows with highest profit in each quarter. × Solution profit |&gt; group_by(Quarter, `Customer ID`) |&gt; summarise(Profit = sum(Profit)) |&gt; slice_max(Profit, n = 2) #&gt; # A tibble: 8 × 3 #&gt; # Groups: Quarter [4] #&gt; Quarter `Customer ID` Profit #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 1 MRT 3925 #&gt; 2 1 WEB 3776 #&gt; 3 2 FRT 7272 #&gt; 4 2 MAM 6992 #&gt; 5 3 WEM 6616 #&gt; 6 3 RPB 3245 #&gt; 7 4 EBP 10093 #&gt; 8 4 WEM 8262 The results are not the same since use another group by. Close Solution × Hint profit |&gt; group_by(___, `Customer ID`) |&gt; summarise(Profit = ___) |&gt; slice_max(Profit, n = 2) Close Hint Find the two best customers with highest profit in each quarter. Is the result the same as in Question 7? × Solution profit |&gt; group_by(`Product Line`) |&gt; summarise(Profit = sum(Profit)) |&gt; slice_max(Profit) #&gt; # A tibble: 1 × 2 #&gt; `Product Line` Profit #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Credit Products 31022 # ... repeat # Using a function summarise_profit &lt;- function(data, group_var, summarise_var) { data |&gt; group_by(across({{ group_var }})) |&gt; summarise(across({{ summarise_var }}, sum)) |&gt; slice_max(Profit) } summarise_profit(profit, `Product Line`, Profit) #&gt; # A tibble: 1 × 2 #&gt; `Product Line` Profit #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Credit Products 31022 summarise_profit(profit, `Customer ID`, Profit) #&gt; # A tibble: 1 × 2 #&gt; `Customer ID` Profit #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 WEM 18942 # ... repeat # Using purrr package to get a single tibble (if interested in the purrr package) val &lt;- names(profit)[1:5] max_profit &lt;- map_df( val, ~{ tmp &lt;- profit |&gt; group_by(.data[[.x]]) |&gt; summarise(Profit = sum(Profit), .groups = &quot;drop&quot;) |&gt; slice_max(Profit) tibble(by = .x, best = as.character(tmp[[1,1]]), profit = tmp[[1,2]] ) } ) max_profit #&gt; # A tibble: 5 × 3 #&gt; by best profit #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Quarter 4 35268 #&gt; 2 Channel ATM 30433 #&gt; 3 Customer ID WEM 18942 #&gt; 4 Country USA 39693 #&gt; 5 Product Line Credit Products 31022 Close Solution × Hint profit |&gt; group_by(___) |&gt; summarise(Profit = ___) |&gt; slice_max(Profit) # ... repeat Close Hint Find the product line, customer, channel, country and quarter with the highest profit. × Solution profit |&gt; group_by(`Customer ID`) |&gt; distinct(Country) |&gt; count(`Customer ID`) #&gt; # A tibble: 18 × 2 #&gt; # Groups: Customer ID [18] #&gt; `Customer ID` n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 AFF 1 #&gt; 2 AGR 16 #&gt; 3 CAM 1 #&gt; 4 CRE 1 #&gt; 5 EBP 47 #&gt; 6 FRT 47 #&gt; 7 HEC 1 #&gt; 8 IAS 1 #&gt; 9 INB 1 #&gt; 10 MAM 47 #&gt; 11 MFN 30 #&gt; 12 MRT 47 #&gt; 13 PBI 47 #&gt; 14 RPB 47 #&gt; 15 SBE 1 #&gt; 16 STF 2 #&gt; 17 WEB 47 #&gt; 18 WEM 47 Close Solution Are there rows with the same customer in different countries? × Solution profit |&gt; arrange(desc(Profit), desc(Revenue)) #&gt; # A tibble: 24,546 × 9 #&gt; # Rowwise: #&gt; Quarter Channel `Customer ID` Country `Product Line` Revenue `Product Cost` #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 4 ATM MAM USA Revolving Credit Products 6699 2506 #&gt; 2 4 ATM WEM USA Revolving Credit Products 5836 2114 #&gt; 3 4 ATM MAM USA Credit Products 7540 3374 #&gt; 4 4 ATM MRT USA Credit Products 6419 2669 #&gt; 5 3 ATM WEM USA Credit Products 5682 2112 #&gt; 6 4 ATM WEB USA Deposit Products 5145 1907 #&gt; 7 1 ATM PBI USA Credit Products 4821 1808 #&gt; 8 4 ATM RPB USA Credit Products 5828 2727 #&gt; 9 2 ATM FRT USA Credit Products 5931 3137 #&gt; 10 1 ATM PBI USA Revolving Credit Products 4268 1638 #&gt; # ℹ 24,536 more rows #&gt; # ℹ 2 more variables: `Customer Service Cost` &lt;dbl&gt;, Profit &lt;dbl&gt; Close Solution Sort the data decreasing with respect to profit and next revenue. × Solution profit |&gt; group_by(`Product Line`) |&gt; summarise(cost = sum(`Product Cost` + `Customer Service Cost`)) |&gt; # print() |&gt; # if want a peek before slicing slice_max(cost) #&gt; # A tibble: 1 × 2 #&gt; `Product Line` cost #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Credit Products 820665 profit |&gt; group_by(`Product Line`) |&gt; summarise(cost = sum(`Product Cost`)) |&gt; slice_min(cost) #&gt; # A tibble: 1 × 2 #&gt; `Product Line` cost #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Third Party Products 91796 Close Solution × Hint profit |&gt; group_by(`Product Line`) |&gt; summarise(cost = sum(___)) |&gt; # print() |&gt; # if want a peek before slicing slice_max(___) profit |&gt; ___% slice_min(cost) Close Hint Which product line has the highest and lowest total cost? × Solution profit |&gt; mutate(cust_cost_new = `Customer Service Cost` * 1.05, profit_new = Revenue - cust_cost_new - `Product Cost`) |&gt; group_by(`Product Line`) |&gt; summarise(cust_cost = sum(`Customer Service Cost`), profit = sum(Profit), cust_cost_new = sum(cust_cost_new), profit_new = sum(profit_new), profit_decrease = profit_new - profit) #&gt; # A tibble: 6 × 6 #&gt; `Product Line` cust_cost profit cust_cost_new profit_new profit_decrease #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Credit Products 119612 31022 125593. 25041. -5981. #&gt; 2 Deposit Products 114526 5408 120252. -318. -5726. #&gt; 3 Fee Based Products 22900 4953 24045 NA NA #&gt; 4 Other Products 33282 7438 34946. 5774. -1664. #&gt; 5 Revolving Credit Products NA 15905 NA NA NA #&gt; 6 Third Party Products 15970 2264 16768. 1465. -799. Close Solution × Hint profit |&gt; mutate(cust_cost_new = ___ * 1.05, profit_new = ___) |&gt; group_by(`Product Line`) |&gt; summarise(cust_cost = sum(___), profit = sum(Profit), cust_cost_new = ___, profit_new = ___, profit_decrease = ___) Close Hint Assume that customer service cost increases with 5%. How will that affect the profit for each product line? rm(profit) 13.5.4 Exercise (fisheries) Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). The dataset called fisheries contains world fisheries harvest for 2005. The tonnage from capture and aquaculture is listed by country. You need the tidyverse package as usual: library(tidyverse) # install tfa package using remotes::install_github(&quot;bss-osca/tfa-package&quot;, upgrade = FALSE) We load the needed datasets: fisheries &lt;- read_csv(system.file(&quot;extdata/fisheries.csv&quot;, package = &quot;tfa&quot;)) fisheries #&gt; # A tibble: 216 × 4 #&gt; country capture aquaculture total #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Afghanistan 1000 1200 2200 #&gt; 2 Albania 7886 950 8836 #&gt; 3 Algeria 95000 1361 96361 #&gt; 4 American Samoa 3047 20 3067 #&gt; 5 Andorra 0 0 0 #&gt; 6 Angola 486490 655 487145 #&gt; 7 Antigua and Barbuda 3000 10 3010 #&gt; 8 Argentina 755226 3673 758899 #&gt; 9 Armenia 3758 16381 20139 #&gt; 10 Aruba 142 0 142 #&gt; # ℹ 206 more rows continents &lt;- read_csv(system.file(&quot;extdata/continents.csv&quot;, package = &quot;tfa&quot;)) continents #&gt; # A tibble: 247 × 2 #&gt; country continent #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Afghanistan Asia #&gt; 2 Åland Islands Europe #&gt; 3 Albania Europe #&gt; 4 Algeria Africa #&gt; 5 American Samoa Oceania #&gt; 6 Andorra Europe #&gt; 7 Angola Africa #&gt; 8 Anguilla Americas #&gt; 9 Antigua &amp; Barbuda Americas #&gt; 10 Argentina Americas #&gt; # ℹ 237 more rows Some mean statistics: fisheries |&gt; summarise(across(where(is.numeric), \\(x) mean(x, na.rm = TRUE))) #&gt; # A tibble: 1 × 3 #&gt; capture aquaculture total #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 421916. 508368. 930284. × Solution fisheries |&gt; anti_join(continents) # countries not belonging to a continent #&gt; Joining with `by = join_by(country)` #&gt; # A tibble: 20 × 4 #&gt; country capture aquaculture total #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Antigua and Barbuda 3000 10 3010 #&gt; 2 Bosnia and Herzegovina 305 4564 4869 #&gt; 3 Czech Republic 3507 20952 24459 #&gt; 4 Democratic Republic of the Congo 237372 3161 240533 #&gt; 5 Eswatini 65 100 165 #&gt; 6 Federated States of Micronesia 88397 0 88397 #&gt; 7 Ivory Coast 67500 4701 72201 #&gt; 8 Jersey and Guernsey 2985 1499 4484 #&gt; 9 Macao 1500 0 1500 #&gt; 10 Myanmar 2072390 1017644 3090034 #&gt; 11 North Macedonia 306 986 1292 #&gt; 12 Palestine 3306 280 3586 #&gt; 13 Republic of the Congo 86748 177 86925 #&gt; 14 Saint Kitts and Nevis 65734 1 65735 #&gt; 15 Saint Lucia 2097 32 2129 #&gt; 16 Saint Vincent and the Grenadines 23077 0 23077 #&gt; 17 São Tomé and Príncipe 11750 0 11750 #&gt; 18 Trinidad and Tobago 13027 11 13038 #&gt; 19 Turks and Caicos Islands 2780 0 2780 #&gt; 20 US Virgin Islands 551 8 559 fisheries &lt;- fisheries |&gt; print() |&gt; left_join(continents) |&gt; print() #&gt; # A tibble: 216 × 4 #&gt; country capture aquaculture total #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Afghanistan 1000 1200 2200 #&gt; 2 Albania 7886 950 8836 #&gt; 3 Algeria 95000 1361 96361 #&gt; 4 American Samoa 3047 20 3067 #&gt; 5 Andorra 0 0 0 #&gt; 6 Angola 486490 655 487145 #&gt; 7 Antigua and Barbuda 3000 10 3010 #&gt; 8 Argentina 755226 3673 758899 #&gt; 9 Armenia 3758 16381 20139 #&gt; 10 Aruba 142 0 142 #&gt; # ℹ 206 more rows #&gt; Joining with `by = join_by(country)` #&gt; # A tibble: 216 × 5 #&gt; country capture aquaculture total continent #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 Afghanistan 1000 1200 2200 Asia #&gt; 2 Albania 7886 950 8836 Europe #&gt; 3 Algeria 95000 1361 96361 Africa #&gt; 4 American Samoa 3047 20 3067 Oceania #&gt; 5 Andorra 0 0 0 Europe #&gt; 6 Angola 486490 655 487145 Africa #&gt; 7 Antigua and Barbuda 3000 10 3010 &lt;NA&gt; #&gt; 8 Argentina 755226 3673 758899 Americas #&gt; 9 Armenia 3758 16381 20139 Asia #&gt; 10 Aruba 142 0 142 Americas #&gt; # ℹ 206 more rows fisheries |&gt; filter(is.na(continent)) # same result - countries not belonging to a continent #&gt; # A tibble: 20 × 5 #&gt; country capture aquaculture total continent #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 Antigua and Barbuda 3000 10 3010 &lt;NA&gt; #&gt; 2 Bosnia and Herzegovina 305 4564 4869 &lt;NA&gt; #&gt; 3 Czech Republic 3507 20952 24459 &lt;NA&gt; #&gt; 4 Democratic Republic of the Congo 237372 3161 240533 &lt;NA&gt; #&gt; 5 Eswatini 65 100 165 &lt;NA&gt; #&gt; 6 Federated States of Micronesia 88397 0 88397 &lt;NA&gt; #&gt; 7 Ivory Coast 67500 4701 72201 &lt;NA&gt; #&gt; 8 Jersey and Guernsey 2985 1499 4484 &lt;NA&gt; #&gt; 9 Macao 1500 0 1500 &lt;NA&gt; #&gt; 10 Myanmar 2072390 1017644 3090034 &lt;NA&gt; #&gt; 11 North Macedonia 306 986 1292 &lt;NA&gt; #&gt; 12 Palestine 3306 280 3586 &lt;NA&gt; #&gt; 13 Republic of the Congo 86748 177 86925 &lt;NA&gt; #&gt; 14 Saint Kitts and Nevis 65734 1 65735 &lt;NA&gt; #&gt; 15 Saint Lucia 2097 32 2129 &lt;NA&gt; #&gt; 16 Saint Vincent and the Grenadines 23077 0 23077 &lt;NA&gt; #&gt; 17 São Tomé and Príncipe 11750 0 11750 &lt;NA&gt; #&gt; 18 Trinidad and Tobago 13027 11 13038 &lt;NA&gt; #&gt; 19 Turks and Caicos Islands 2780 0 2780 &lt;NA&gt; #&gt; 20 US Virgin Islands 551 8 559 &lt;NA&gt; Close Solution × Hint 2 fisheries |&gt; anti_join(___) # countries not belonging to a continent fisheries &lt;- fisheries |&gt; print() |&gt; left_join(___) |&gt; print() fisheries |&gt; filter(is.na(___)) # same result - countries not belonging to a continent Close Hint 2 × Hint 1 You could use anti_join to find missing values. Use left_join to join the datasets. Close Hint 1 Use a mutating join to add a continent column to the fisheries dataset. Are there some countries which do not belong to a continent? × Solution fisheries &lt;- fisheries |&gt; filter(total &gt; 100000) Close Solution × Hint fisheries &lt;- ___ |&gt; filter(___) Close Hint Filter out countries whose total harvest was less than 100,000 tons. × Solution fisheries |&gt; filter(is.na(continent)) #&gt; # A tibble: 2 × 5 #&gt; country capture aquaculture total continent #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 Democratic Republic of the Congo 237372 3161 240533 &lt;NA&gt; #&gt; 2 Myanmar 2072390 1017644 3090034 &lt;NA&gt; fisheries &lt;- fisheries |&gt; mutate(continent = case_when( country == &quot;Democratic Republic of the Congo&quot; ~ &quot;Africa&quot;, country == &quot;Hong Kong&quot; ~ &quot;Asia&quot;, country == &quot;Myanmar&quot; ~ &quot;Asia&quot;, TRUE ~ continent ) ) fisheries |&gt; filter(is.na(continent)) #&gt; # A tibble: 0 × 5 #&gt; # ℹ 5 variables: country &lt;chr&gt;, capture &lt;dbl&gt;, aquaculture &lt;dbl&gt;, total &lt;dbl&gt;, continent &lt;chr&gt; Close Solution × Hint fisheries |&gt; filter(is.na(continent)) fisheries &lt;- ___ |&gt; mutate(continent = case_when( country == ___ ~ &quot;Africa&quot;, country == ___ ~ &quot;Asia&quot;, country == ___ ~ &quot;Asia&quot;, TRUE ~ continent ) ) fisheries |&gt; filter(is.na(continent)) Close Hint If still any countries not belonging to a continent then add them to the closest continent. × Solution fisheries &lt;- fisheries |&gt; mutate(aquaculture_perc = aquaculture / total) The percentage of fish harvest done using aquaculture. Close Solution × Hint fisheries &lt;- ___ |&gt; mutate(___) Close Hint Add column aquaculture_perc = aquaculture / total and explain the variable. × Solution fisheries |&gt; group_by(continent) |&gt; summarize(mean_ap = mean(aquaculture_perc)) #&gt; # A tibble: 5 × 2 #&gt; continent mean_ap #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Africa 0.0943 #&gt; 2 Americas 0.192 #&gt; 3 Asia 0.367 #&gt; 4 Europe 0.165 #&gt; 5 Oceania 0.150 Close Solution × Hint fisheries |&gt; # start with the fisheries data frame ___ |&gt; # group by continent ___(mean_ap = ___) # calculate mean aquaculture Close Hint Calculate the mean aquaculture percentage (we’ll call it mean_ap for short) for continents in the fisheries data. × Solution fisheries_summary_continent &lt;- fisheries |&gt; group_by(continent) |&gt; summarize(mean_ap = mean(aquaculture_perc), min_ap = min(aquaculture_perc), max_ap = max(aquaculture_perc)) |&gt; print() #&gt; # A tibble: 5 × 4 #&gt; continent mean_ap min_ap max_ap #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Africa 0.0943 0 0.803 #&gt; 2 Americas 0.192 0 0.529 #&gt; 3 Asia 0.367 0 0.782 #&gt; 4 Europe 0.165 0.00682 0.618 #&gt; 5 Oceania 0.150 0.0197 0.357 Close Solution × Hint fisheries_summary_continent &lt;- fisheries |&gt; # start with the fisheries data frame ___ |&gt; # group by continent ___(mean_ap = ___, min_ap = ___, ___) # calculate mean aquaculture Close Hint Now expand your calculations to also calculate the minimum and maximum aquaculture percentage for continents in the fisheries data and store the summary table in a data frame called fisheries_summary_continent. × Solution fisheries_summary_continent |&gt; arrange(desc(mean_ap)) #&gt; # A tibble: 5 × 4 #&gt; continent mean_ap min_ap max_ap #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Asia 0.367 0 0.782 #&gt; 2 Americas 0.192 0 0.529 #&gt; 3 Europe 0.165 0.00682 0.618 #&gt; 4 Oceania 0.150 0.0197 0.357 #&gt; 5 Africa 0.0943 0 0.803 Close Solution × Hint fisheries_summary_continent |&gt; # start with the fisheries_summary_continent data frame ___ # order in descending order of mean_ap Close Hint Take the fisheries_summary_continent data frame and order the results in descending order of mean aquaculture percentage. × Solution ggplot(fisheries_summary_continent, aes(y = reorder(continent, mean_ap), x = mean_ap)) + geom_col() + labs( x = &quot;&quot;, y = &quot;&quot;, title = &quot;Average share of aquaculture by continent&quot;, subtitle = &quot;out of total fisheries harvest&quot;, caption = &quot;Source: bit.ly/2VrawTt&quot; ) An example plot Close Solution If you already have read the module about visualizations, then try to make some relevant plots. 13.5.5 Exercise (company ranking) This exercise is a slightly modified version an exam assignment (exam 2021-A2). Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). The dataset companies, in the tfa package, lists approx. 1000 of the world’s biggest companies, measured by sales, profits, assets and market value. The column/variables are: name: the name of the company. country: the country the company is situated in. category: the products the company produces. sales: the amount of sales of the company in billion USD. profits: the profit of the company in billion USD. assets: the assets of the company in billion USD. marketvalue: the market value of the company in billion USD. You can load the dataset using: # remotes::install_github(&quot;bss-osca/tfa-package&quot;, build = FALSE) # run if tfa not installed library(tidyverse) companies &lt;- read_csv(system.file(&quot;extdata/companies.csv&quot;, package = &quot;tfa&quot;)) Use the dplyr package in tidyverse to calculate relevant summary tables (data frames) and answer the following questions. × Solution companies #&gt; # A tibble: 1,002 × 7 #&gt; name country category sales profits assets marketvalue #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 General Electric United States Conglomerates 134. 15.6 627. 329. #&gt; 2 Microsoft United States Software &amp; services 34.3 8.88 85.9 287. #&gt; 3 Pfizer United States Drugs &amp; biotechnology 40.4 6.2 120. 285. #&gt; 4 ExxonMobil United States Oil &amp; gas operations 223. 21.0 167. 277. #&gt; 5 Citigroup United States Banking 94.7 17.8 1264. 255. #&gt; 6 Wal-Mart Stores United States Retailing 256. 9.05 105. 244. #&gt; 7 Intel United States Semiconductors 30.1 5.64 47.1 197. #&gt; 8 American Intl Group United States Insurance 76.7 6.46 648. 195. #&gt; 9 HSBC Group United Kingdom Banking 44.3 6.66 758. 178. #&gt; 10 Vodafone United Kingdom Telecommunications services 48.0 -15.5 256. 175. #&gt; # ℹ 992 more rows 1002 rows and 7 columns. Close Solution How many rows and columns do the dataset have? × Solution library(skimr) skim(companies) Table 13.4: Data summary Name companies Number of rows 1002 Number of columns 7 _______________________ Column type frequency: character 3 numeric 4 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace name 0 1 1 26 0 1002 0 country 0 1 5 14 0 42 0 category 0 1 5 32 0 27 0 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist sales 0 1 15.24 23.67 0.27 3.47 7.96 17.09 256 ▇▁▁▁▁ profits 2 1 0.71 2.41 -25.83 0.20 0.42 0.88 21 ▁▁▇▁▁ assets 0 1 57.34 136.14 0.75 6.74 15.03 39.63 1264 ▇▁▁▁▁ marketvalue 0 1 21.04 32.01 5.15 7.02 10.55 20.19 329 ▇▁▁▁▁ From the output we can see that there are 1002 different companies (one for each row) 27 different product categories and 42 different countries. Close Solution × Hint library(skimr) skim(___) Close Hint How many different companies are we considering, how many different product categories and how many different countries? Hint: the skimr package might be useful. × Solution dat &lt;- companies |&gt; arrange(desc(marketvalue)) |&gt; head(n = 3) |&gt; print() #&gt; # A tibble: 3 × 7 #&gt; name country category sales profits assets marketvalue #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 General Electric United States Conglomerates 134. 15.6 627. 329. #&gt; 2 Microsoft United States Software &amp; services 34.3 8.88 85.9 287. #&gt; 3 Pfizer United States Drugs &amp; biotechnology 40.4 6.2 120. 285. # or # companies |&gt; # slice_max(marketvalue, n = 3) The 3 biggest companies are listed in the name column. Close Solution × Hint companies |&gt; slice_max(___) Close Hint What are the 3 biggest companies with respect to market value? × Solution dat &lt;- companies |&gt; group_by(country) |&gt; slice_max(profits, n = 1) |&gt; print() #&gt; # A tibble: 42 × 7 #&gt; # Groups: country [42] #&gt; name country category sales profits assets marketvalue #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Natl Australia Bank Australia Banking 15.3 2.69 270. 36.5 #&gt; 2 Erste Bank Austria Banking 7.5 0.27 127. 8.12 #&gt; 3 Dexia Belgium Banking 19.6 1.36 368. 21.6 #&gt; 4 ACE Bermuda Insurance 10.7 1.39 49.5 12.6 #&gt; 5 Petrobras-Petrsleo Brasil Brazil Oil &amp; gas operations 22.6 2.29 27.1 35.5 #&gt; 6 Royal Bank of Canada Canada Banking 18.8 2.28 305. 31.8 #&gt; 7 Garmin Cayman Islands Technology hardware &amp; … 0.57 0.18 0.86 5.19 #&gt; 8 PetroChina China Oil &amp; gas operations 29.5 5.67 58.4 90.5 #&gt; 9 Den Danske Bank Denmark Banking 12.6 1.57 309. 16.4 #&gt; 10 Nokia Finland Technology hardware &amp; … 37.0 4.52 29.2 104. #&gt; # ℹ 32 more rows The company with highest profit for each country is listed above. In Denmark the company is Den Danske Bank. Close Solution × Hint dat &lt;- companies |&gt; group_by(___) |&gt; slice_max(___) |&gt; print() Close Hint For each country find the company with highest profit. What company has the highest profit in Denmark? × Solution dat &lt;- companies |&gt; group_by(category) |&gt; summarise(marketvalue = sum(marketvalue)) |&gt; slice_max(marketvalue, n = 4) |&gt; print() #&gt; # A tibble: 4 × 2 #&gt; category marketvalue #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Banking 2858. #&gt; 2 Oil &amp; gas operations 1748. #&gt; 3 Drugs &amp; biotechnology 1732. #&gt; 4 Telecommunications services 1415. The 4 product categories that have the highest total market value are given in the category column. Close Solution × Hint dat &lt;- companies |&gt; group_by(___) |&gt; summarise(__) |&gt; slice_max(___) |&gt; print() Close Hint Which 4 product categories have the highest total market value? × Solution dat &lt;- companies |&gt; filter(country == &quot;Denmark&quot;) |&gt; mutate(value = profits + assets + marketvalue) |&gt; select(name, category, value) |&gt; print() #&gt; # A tibble: 4 × 3 #&gt; name category value #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Moller-Maersk Transportation 63.3 #&gt; 2 Den Danske Bank Banking 327. #&gt; 3 Novo-Nordisk Drugs &amp; biotechnology 22.4 #&gt; 4 TDC Group Telecommunications services 22.4 The companies can be seen above. The company with lowest value is Novo-Nordisk (or TDC Group). Close Solution × Hint dat &lt;- companies |&gt; filter(___) |&gt; mutate(___) |&gt; select(___) |&gt; print() Close Hint Create a new data frame only containing rows from Denmark and with columns name, category and a column value which equals the sum of columns profits, assets and marketvalue. Which company have the lowest value? 13.5.6 Exercise (Titanic) This exercise is a slightly modified version an exam assignment (reexam 2021-A2). Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). The dataset titanic, given in the appendix, lists approx. 1300 passengers on Titanic. The column/variables are: pclass: Passenger class (1 = 1st; 2 = 2nd; 3 = 3rd). survived: Survival (0 = No; 1 = Yes). name: Name. sex: Sex. age: Age. fare: Passenger Fare. cabin: Cabin number. embarked: Port of embarkation (C = Cherbourg; Q = Queenstown; S = Southampton). boat: Lifeboat number. You can read the dataset file titanic.csv into the dataset dat using # remotes::install_github(&quot;bss-osca/tfa-package&quot;, build = FALSE) # run if tfa not installed library(tidyverse) dat &lt;- read_csv(system.file(&quot;extdata/titanic.csv&quot;, package = &quot;tfa&quot;)) Use the dplyr package in tidyverse to calculate relevant summary tables (data frames) and answer the following questions. × Solution dat &lt;- dat |&gt; mutate(male = if_else(sex == &quot;male&quot;, TRUE, FALSE)) dat #&gt; # A tibble: 1,309 × 10 #&gt; pclass survived name sex age fare cabin embarked boat male #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt; #&gt; 1 1 1 Allen, Miss. Elisabeth Walton fema… 29 211. B5 S 2 FALSE #&gt; 2 1 1 Allison, Master. Hudson Trevor male 0.92 152. C22 … S 11 TRUE #&gt; 3 1 0 Allison, Miss. Helen Loraine fema… 2 152. C22 … S &lt;NA&gt; FALSE #&gt; 4 1 0 Allison, Mr. Hudson Joshua Creighton male 30 152. C22 … S &lt;NA&gt; TRUE #&gt; 5 1 0 Allison, Mrs. Hudson J C (Bessie Wa… fema… 25 152. C22 … S &lt;NA&gt; FALSE #&gt; 6 1 1 Anderson, Mr. Harry male 48 26.6 E12 S 3 TRUE #&gt; 7 1 1 Andrews, Miss. Kornelia Theodosia fema… 63 78.0 D7 S 10 FALSE #&gt; 8 1 0 Andrews, Mr. Thomas Jr male 39 0 A36 S &lt;NA&gt; TRUE #&gt; 9 1 1 Appleton, Mrs. Edward Dale (Charlot… fema… 53 51.5 C101 S D FALSE #&gt; 10 1 0 Artagaveytia, Mr. Ramon male 71 49.5 &lt;NA&gt; C &lt;NA&gt; TRUE #&gt; # ℹ 1,299 more rows We use if_else to set the new column. Close Solution × Hint dat &lt;- dat |&gt; mutate(male = if_else(___)) dat Close Hint Create a new column named male which is true if the person is a male. × Solution library(skimr) skim(dat) Table 13.5: Data summary Name dat Number of rows 1309 Number of columns 10 _______________________ Column type frequency: character 5 logical 1 numeric 4 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace name 0 1.00 12 82 0 1307 0 sex 0 1.00 4 6 0 2 0 cabin 1014 0.23 1 15 0 186 0 embarked 2 1.00 1 1 0 3 0 boat 823 0.37 1 7 0 27 0 Variable type: logical skim_variable n_missing complete_rate mean count male 0 1 0.64 TRU: 843, FAL: 466 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist pclass 0 1.0 2.29 0.84 1.00 2.0 3.0 3.0 3 ▃▁▃▁▇ survived 0 1.0 0.38 0.49 0.00 0.0 0.0 1.0 1 ▇▁▁▁▅ age 263 0.8 29.88 14.41 0.17 21.0 28.0 39.0 80 ▂▇▅▂▁ fare 1 1.0 33.30 51.76 0.00 7.9 14.4 31.3 512 ▇▁▁▁▁ From the output we can consider 1309 persons of which approx 64% are males. Approx. 38% of the passangers survived. Close Solution × Hint library(skimr) ___ Close Hint How many persons are we considering, how many men (in percentage) and how many survived? × Solution dat |&gt; group_by(sex, survived) |&gt; count() |&gt; group_by(sex) |&gt; mutate(rate = n/sum(n)) #&gt; # A tibble: 4 × 4 #&gt; # Groups: sex [2] #&gt; sex survived n rate #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 female 0 127 0.273 #&gt; 2 female 1 339 0.727 #&gt; 3 male 0 682 0.809 #&gt; 4 male 1 161 0.191 # Alternatively res &lt;- dat |&gt; group_by(male) |&gt; summarise(survived = sum(survived)/n()) |&gt; print() #&gt; # A tibble: 2 × 2 #&gt; male survived #&gt; &lt;lgl&gt; &lt;dbl&gt; #&gt; 1 FALSE 0.727 #&gt; 2 TRUE 0.191 The survival rate for women and men are 73 and 19 percent, respectively. Close Solution × Hint dat |&gt; group_by(___) |&gt; count() |&gt; group_by(___) |&gt; mutate(rate = ___) Close Hint How many of the females survived in percent (and how many males)? × Solution res &lt;- dat |&gt; filter(age &lt; 19, survived == TRUE) |&gt; nrow() |&gt; print() #&gt; [1] 95 95 childern survived. Close Solution × Hint res &lt;- dat |&gt; filter(___) |&gt; nrow() |&gt; print() Close Hint Define children as people with age below 19. How many children survived? × Solution res &lt;- dat |&gt; group_by(pclass) |&gt; summarise(rate = sum(survived)/n()) |&gt; print() #&gt; # A tibble: 3 × 2 #&gt; pclass rate #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 0.619 #&gt; 2 2 0.430 #&gt; 3 3 0.255 There seems to be a big difference in survival rate between first class (62%) and third class (26%). Close Solution × Hint res &lt;- dat |&gt; group_by(___) |&gt; summarise(rate = ___) |&gt; print() Close Hint Did relatively more people survive at first class compared to third class? × Solution res &lt;- dat |&gt; filter(!is.na(boat)) |&gt; summarise(rate = 1-sum(survived)/n()) |&gt; print() #&gt; # A tibble: 1 × 1 #&gt; rate #&gt; &lt;dbl&gt; #&gt; 1 0.0185 The survival rate when entered the lifeboat was high. Only 1.85% died. Close Solution × Hint res &lt;- dat |&gt; filter(___) |&gt; summarise(rate = ___) |&gt; print() Close Hint How many persons that entered a lifeboat did die in percent? × Solution dat |&gt; filter(str_detect(name, &quot;Hansen&quot;)) #&gt; # A tibble: 6 × 10 #&gt; pclass survived name sex age fare cabin embarked boat male #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt; #&gt; 1 3 0 Hansen, Mr. Claus Peter male 41 14.1 &lt;NA&gt; S &lt;NA&gt; TRUE #&gt; 2 3 0 Hansen, Mr. Henrik Juul male 26 7.85 &lt;NA&gt; S &lt;NA&gt; TRUE #&gt; 3 3 0 Hansen, Mr. Henry Damsgaard male 21 7.85 &lt;NA&gt; S &lt;NA&gt; TRUE #&gt; 4 3 1 Hansen, Mrs. Claus Peter (Jennie L H… fema… 45 14.1 &lt;NA&gt; S 11 FALSE #&gt; 5 3 0 Moen, Mr. Sigurd Hansen male 25 7.65 F G73 S &lt;NA&gt; TRUE #&gt; 6 3 0 Nysveen, Mr. Johan Hansen male 61 6.24 &lt;NA&gt; S &lt;NA&gt; TRUE Only a single person survived. Close Solution × Hint dat |&gt; filter(str_detect(___)) Close Hint How many persons with Hansen in their name survived? 13.5.7 Exercise (covid) This exercise is a slightly modified version an exam assignment (reexam 2022-A2). Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). Consider COVID-19 data obtained from Our World in Data in the file covid.csv. The dataset contains data from different countries. Some of the columns/variables are: cases: New confirmed cases of COVID-19. deaths: New deaths attributed to COVID-19. icu_patients: Number of COVID-19 patients in intensive care units (ICUs) on a given day. hosp_patients: Number of COVID-19 patients in hospital on a given day. tests: Total tests for COVID-19. positive_rate: The share of COVID-19 tests that are positive, given as a rolling 7-day average. vac: Total number of people who received at least one vaccine dose. fully_vac: Total number of people who received all doses prescribed by the vaccination protocol. population: Country population. Other columns are date, country, month and year. You can read the dataset file using # remotes::install_github(&quot;bss-osca/tfa-package&quot;, build = FALSE) # run if tfa not installed library(tidyverse) dat &lt;- read_csv(system.file(&quot;extdata/covid.csv&quot;, package = &quot;tfa&quot;)) Use the dplyr package in tidyverse to calculate relevant summary tables (tibbles/data frames) and answer the following questions. × Solution res1 &lt;- dat |&gt; distinct(country) |&gt; print() #&gt; # A tibble: 4 × 1 #&gt; country #&gt; &lt;chr&gt; #&gt; 1 Denmark #&gt; 2 Germany #&gt; 3 Norway #&gt; 4 United Kingdom res2 &lt;- dat |&gt; ungroup() |&gt; summarise(start = min(date), end = max(date)) |&gt; print() #&gt; # A tibble: 1 × 2 #&gt; start end #&gt; &lt;date&gt; &lt;date&gt; #&gt; 1 2020-01-27 2021-11-24 We have a total of 4 countries with data from 2020-01-27 to 2021-11-24. Close Solution × Hint res1 &lt;- dat |&gt; distinct(___) |&gt; print() res2 &lt;- dat |&gt; ungroup() |&gt; summarise(start = ___, end = ___) |&gt; print() Close Hint Which countries are considered and what is the timespan of the data? × Solution res &lt;- dat |&gt; filter(country == &quot;Denmark&quot;, date == &quot;2021-11-22&quot;) |&gt; print() #&gt; # A tibble: 1 × 13 #&gt; date country cases deaths icu_patients hosp_patients tests positive_rate vac fully_vac #&gt; &lt;date&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2021-11-22 Denmark 3810 6 NA NA NA NA 4544857 4441376 #&gt; # ℹ 3 more variables: population &lt;dbl&gt;, month &lt;dbl&gt;, year &lt;dbl&gt; The number of confirmed cases was 3810. Close Solution × Hint res &lt;- dat |&gt; filter(___) |&gt; print() Close Hint What is the number of new confirmed cases November 22nd, 2021 in Denmark? × Solution res1 &lt;- dat |&gt; group_by(country) |&gt; mutate(total_cases = cumsum(replace_na(cases, 0)), total_deaths = cumsum(replace_na(deaths, 0))) |&gt; print() #&gt; # A tibble: 2,628 × 15 #&gt; # Groups: country [4] #&gt; date country cases deaths icu_patients hosp_patients tests positive_rate vac fully_vac #&gt; &lt;date&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2020-02-02 Denmark NA NA NA NA 1 NA NA NA #&gt; 2 2020-02-03 Denmark NA NA NA NA NA NA NA NA #&gt; 3 2020-02-04 Denmark NA NA NA NA NA NA NA NA #&gt; 4 2020-02-05 Denmark NA NA NA NA NA NA NA NA #&gt; 5 2020-02-06 Denmark NA NA NA NA NA NA NA NA #&gt; 6 2020-02-07 Denmark NA NA NA NA NA NA NA NA #&gt; 7 2020-02-08 Denmark NA NA NA NA NA NA NA NA #&gt; 8 2020-02-09 Denmark NA NA NA NA NA NA NA NA #&gt; 9 2020-02-10 Denmark NA NA NA NA NA NA NA NA #&gt; 10 2020-02-11 Denmark NA NA NA NA NA NA NA NA #&gt; # ℹ 2,618 more rows #&gt; # ℹ 5 more variables: population &lt;dbl&gt;, month &lt;dbl&gt;, year &lt;dbl&gt;, total_cases &lt;dbl&gt;, #&gt; # total_deaths &lt;dbl&gt; res2 &lt;- res1 |&gt; filter(country == &quot;Norway&quot;, date == &quot;2021-10-10&quot;) |&gt; select(contains(&quot;total&quot;)) |&gt; print() #&gt; Adding missing grouping variables: `country` #&gt; # A tibble: 1 × 3 #&gt; # Groups: country [1] #&gt; country total_cases total_deaths #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Norway 193562 871 The total number of deaths in Norway up to 10th October 2021 is 871. Close Solution × Hint res1 &lt;- dat |&gt; group_by(___) |&gt; mutate(total_cases = cumsum(replace_na(cases, 0)), total_deaths = ___) |&gt; print() res2 &lt;- res1 |&gt; filter(___) |&gt; select(contains(___)) |&gt; print() Close Hint Calculate the total number of confirmed cases and deaths. Hint: you may use the cumsum function to add all cases up until a given date. You may here consider NA values in the cases and deaths columns as equal to zero (e.g. using replace_na(cases, 0)). What is the total number of deaths in Norway up to October 10th, 2021? × Solution res1 &lt;- dat |&gt; group_by(country, month, year, population) |&gt; summarize(tests = max(tests, na.rm = TRUE) - min(tests, na.rm = TRUE)) |&gt; ungroup() |&gt; mutate(testsCap = tests/population) |&gt; arrange(desc(year), month) |&gt; print() #&gt; # A tibble: 90 × 6 #&gt; country month year population tests testsCap #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Denmark 1 2021 5813302 2863482 0.493 #&gt; 2 Germany 1 2021 83900471 4684292 0.0558 #&gt; 3 Norway 1 2021 5465629 581599 0.106 #&gt; 4 United Kingdom 1 2021 68207114 16382170 0.240 #&gt; 5 Denmark 2 2021 5813302 3357579 0.578 #&gt; 6 Germany 2 2021 83900471 3335631 0.0398 #&gt; 7 Norway 2 2021 5465629 429646 0.0786 #&gt; 8 United Kingdom 2 2021 68207114 15305191 0.224 #&gt; 9 Denmark 3 2021 5813302 4881781 0.840 #&gt; 10 Germany 3 2021 83900471 4068985 0.0485 #&gt; # ℹ 80 more rows res2 &lt;- res1 |&gt; filter(year == 2021, month == 3) |&gt; arrange(desc(testsCap)) |&gt; print() #&gt; # A tibble: 4 × 6 #&gt; country month year population tests testsCap #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Denmark 3 2021 5813302 4881781 0.840 #&gt; 2 United Kingdom 3 2021 68207114 33279694 0.488 #&gt; 3 Norway 3 2021 5465629 791345 0.145 #&gt; 4 Germany 3 2021 83900471 4068985 0.0485 The highest number of tests per capita in March 2021 was in Denmark. Close Solution × Hint res1 &lt;- dat |&gt; group_by(___) |&gt; summarize(tests = max(___, na.rm = TRUE) - min(___, na.rm = TRUE)) |&gt; ungroup() |&gt; mutate(testsCap = ___) |&gt; arrange(desc(___), month) |&gt; print() res2 &lt;- res1 |&gt; filter(___) |&gt; arrange(desc(___)) |&gt; print() Close Hint For each country calculate the number of tests done in each month in a given year. Which country had the highest number of tests per capita in March 2021? × Solution res &lt;- dat |&gt; filter(country == &quot;United Kingdom&quot;) |&gt; group_by(country, year, month) |&gt; summarize(icu = max(icu_patients, na.rm = TRUE)) |&gt; arrange(desc(icu)) |&gt; print() #&gt; Warning: There were 3 warnings in `summarize()`. #&gt; The first warning was: #&gt; ℹ In argument: `icu = max(icu_patients, na.rm = TRUE)`. #&gt; ℹ In group 1: `country = &quot;United Kingdom&quot;`, `year = 2020`, `month = 1`. #&gt; Caused by warning in `max()`: #&gt; ! no non-missing arguments to max; returning -Inf #&gt; ℹ Run `dplyr::last_dplyr_warnings()` to see the 2 remaining warnings. #&gt; # A tibble: 23 × 4 #&gt; # Groups: country, year [2] #&gt; country year month icu #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 United Kingdom 2021 1 4077 #&gt; 2 United Kingdom 2021 2 3726 #&gt; 3 United Kingdom 2020 4 3301 #&gt; 4 United Kingdom 2020 5 2178 #&gt; 5 United Kingdom 2020 12 2122 #&gt; 6 United Kingdom 2021 3 1806 #&gt; 7 United Kingdom 2020 11 1489 #&gt; 8 United Kingdom 2021 9 1081 #&gt; 9 United Kingdom 2021 11 1034 #&gt; 10 United Kingdom 2021 8 1014 #&gt; # ℹ 13 more rows The highest number of ICU patients on a given day was in January (4077 patients). Close Solution × Hint res &lt;- dat |&gt; filter(___) |&gt; group_by(___) |&gt; summarize(icu = max(___, na.rm = TRUE)) |&gt; arrange(desc(___)) |&gt; print() Close Hint Consider United Kingdom. Which month had the highest number of ICU patients on a given day? 13.5.8 Exercise (election) This exercise is a slightly modified version an exam assignment (exam 2022-A2). Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). The dataset in the file elections.csv lists election votes for municipal elections in Denmark. The column/variables are: area: municipality, party: political party, year: election year, validVotes: Number of (valid) votes, personalVotes: total number of personal votes, listedMen: men listed, listedWomen: women listed, electedMen: elected men, electedWomen: elected women. You can read the dataset file into the dataset dat using # remotes::install_github(&quot;bss-osca/tfa-package&quot;, build = FALSE) # run if tfa not installed library(tidyverse) dat &lt;- read_csv(system.file(&quot;extdata/elections.csv&quot;, package = &quot;tfa&quot;)) Use the dplyr package in tidyverse to calculate relevant summary tables (data frames) and answer the following questions. × Solution res &lt;- dat |&gt; filter(year == 2017) |&gt; distinct(area) |&gt; nrow() |&gt; print() #&gt; [1] 99 We have a total of 99 municipalities. Close Solution × Hint res &lt;- dat |&gt; filter(year == ___) |&gt; distinct(___) |&gt; nrow() |&gt; print() Close Hint How many different municipalities were there in Denmark in 2017? × Solution res &lt;- dat |&gt; group_by(year) |&gt; summarize(votes = sum(validVotes)) |&gt; arrange(desc(votes)) |&gt; print() #&gt; # A tibble: 4 × 2 #&gt; year votes #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2017 3176021 #&gt; 2 2013 3116083 #&gt; 3 2005 2880007 #&gt; 4 2009 2784466 The highest number of votes was in 2017. Close Solution × Hint res &lt;- dat |&gt; group_by(___) |&gt; summarize(votes = ___) |&gt; arrange(desc(votes)) |&gt; print() Close Hint In which election year was the total number of votes highest? × Solution res &lt;- dat |&gt; filter(year == 2017) |&gt; mutate(elected = electedMen + electedWomen) |&gt; group_by(party) |&gt; summarize(votes = sum(validVotes), elected = sum(elected)) |&gt; arrange(desc(votes)) |&gt; print() #&gt; # A tibble: 12 × 3 #&gt; party votes elected #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Social Democratic Party 1029326 842 #&gt; 2 Liberal Democratic Party 733484 688 #&gt; 3 Conservative Peoples Party 279041 225 #&gt; 4 Danish Peoples Party (1997-) 277656 223 #&gt; 5 Unity List 188987 102 #&gt; 6 Socialist Peoples Party 181591 126 #&gt; 7 Social Liberal Party 146707 80 #&gt; 8 Letters not reserved, total 124912 87 #&gt; 9 The Alternative 93426 20 #&gt; 10 Liberal Alliance 82110 28 #&gt; 11 Nye Borgerlige 29073 1 #&gt; 12 The Slesvig Party 9708 10 The highest number of votes was given to the Social Democratic Party (1029326 votes) who got 842 elected. Close Solution × Hint res &lt;- dat |&gt; filter(___) |&gt; mutate(elected = ___) |&gt; group_by(___) |&gt; summarize(___) |&gt; arrange(desc(___)) |&gt; print() Close Hint Consider the 2017 election. How many votes and elected candidates did the different parties get in total (sort your result descending by votes)? × Solution res &lt;- dat |&gt; group_by(year) |&gt; summarize(listedWomen = sum(listedWomen), listedMen = sum(listedMen)) |&gt; mutate(listedWomenPct = listedWomen/(listedMen + listedWomen)) |&gt; arrange(listedWomenPct) |&gt; print() #&gt; # A tibble: 4 × 4 #&gt; year listedWomen listedMen listedWomenPct #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2005 3374 8033 0.296 #&gt; 2 2013 2796 6287 0.308 #&gt; 3 2009 2810 6239 0.311 #&gt; 4 2017 3037 6519 0.318 The listed women is approx. 31. That is, listed women is lower than listed men. This percentage seems to be almost constant over the years (but increasing very slowly). Close Solution × Hint res &lt;- dat |&gt; group_by(___) |&gt; summarize(listedWomen = ___, listedMen = ___) |&gt; mutate(listedWomenPct = ___) |&gt; arrange(listedWomenPct) |&gt; print() Close Hint Calculate the percentage of females listed for each year. Are there on average more women than men listed? Is there any tendency over the years? × Solution res &lt;- dat |&gt; filter(year == 2017) |&gt; group_by(area) |&gt; mutate(votesPct = validVotes/sum(validVotes)) |&gt; filter(party == &quot;Liberal Democratic Party&quot;) |&gt; select(area, party, votesPct) |&gt; arrange(desc(votesPct)) |&gt; print() #&gt; # A tibble: 99 × 3 #&gt; # Groups: area [99] #&gt; area party votesPct #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Herning Liberal Democratic Party 0.556 #&gt; 2 Lemvig Liberal Democratic Party 0.487 #&gt; 3 Morsø Liberal Democratic Party 0.483 #&gt; 4 Nyborg Liberal Democratic Party 0.475 #&gt; 5 Jammerbugt Liberal Democratic Party 0.465 #&gt; 6 Kolding Liberal Democratic Party 0.464 #&gt; 7 Tønder Liberal Democratic Party 0.446 #&gt; 8 Assens Liberal Democratic Party 0.420 #&gt; 9 Varde Liberal Democratic Party 0.420 #&gt; 10 Nordfyns Liberal Democratic Party 0.401 #&gt; # ℹ 89 more rows The Liberal Democratic Party got must relative votes in Herning. Close Solution × Hint res &lt;- dat |&gt; filter(___) |&gt; group_by(___) |&gt; mutate(votesPct = ___) |&gt; filter(party == ___) |&gt; select(___) |&gt; arrange(desc(___)) |&gt; print() Close Hint Consider the 2017 election. In which municipality did the Liberal Democratic Party get the highest percentage of votes? 13.5.9 Exercise (orders) This exercise is a slightly modified version an exam assignment (reexam 2023-A1). Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). Consider the dataset in the file orders.csv with purchase orders for a group of ships. The dataset contains a row for each item used in an order. The columns/variables are: ship: The ship considered. order_id: Order id. An order is a group of items purchased in one batch from a single supplier. item_id: Item id. item_desc: Item description. quantity: Number of items ordered. price: Price per unit. order_date: Order date. delivery_date: Expected delivery date when order is made. delivery_place: Delivery place. recieved_date: Actual date the order is recieved. supplier: Supplier for the order. delivery_cost: Delivery cost. order_year: Year the order was placed. You can read the dataset file into the dataset dat using # remotes::install_github(&quot;bss-osca/tfa-package&quot;, build = FALSE) # run if tfa not installed library(tidyverse) dat &lt;- read_csv(system.file(&quot;extdata/orders.csv&quot;, package = &quot;tfa&quot;)) Use the dplyr package in tidyverse to calculate relevant summary tables (tibbles/data frames) and answer/complete the following questions/tasks: × Solution # load packages library(tidyverse) library(skimr) skim(dat) Table 13.6: Data summary Name dat Number of rows 1989 Number of columns 13 _______________________ Column type frequency: character 5 Date 3 numeric 5 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace ship 0 1 6 7 0 9 0 item_id 0 1 11 11 0 550 0 item_desc 0 1 3 206 0 491 0 delivery_place 0 1 3 18 0 13 0 supplier 1 1 11 12 0 31 0 Variable type: Date skim_variable n_missing complete_rate min max median n_unique order_date 0 1.00 2015-01-09 2020-04-21 2018-01-15 315 delivery_date 0 1.00 2015-01-14 2020-07-29 2018-01-31 340 received_date 103 0.95 2015-01-23 2020-04-19 2018-04-06 266 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist order_id 0 1.00 3.67e+11 8.75e+09 3.56e+11 3.57e+11 3.68e+11 3.76e+11 3.77e+11 ▇▁▅▁▇ quantity 0 1.00 9.20e+00 1.05e+01 1.00e+00 2.00e+00 7.00e+00 1.00e+01 1.00e+02 ▇▁▁▁▁ price 0 1.00 2.95e+04 7.89e+04 2.46e+01 3.21e+02 3.58e+03 2.32e+04 1.62e+06 ▇▁▁▁▁ delivery_cost 1892 0.05 3.60e+04 5.23e+04 1.78e+02 1.12e+03 4.06e+03 5.92e+04 1.33e+05 ▇▁▁▁▂ order_year 0 1.00 2.02e+03 1.47e+00 2.02e+03 2.02e+03 2.02e+03 2.02e+03 2.02e+03 ▇▅▆▆▂ Orders are for 9 ships and from 31 suppliers. A total of 550 different items are considered. Close Solution × Hint Use the skim package. Close Hint How many ships, suppliers, and different items are considered? × Solution dat |&gt; count(order_id, supplier) |&gt; count(order_id) |&gt; filter(n &gt; 1) #&gt; # A tibble: 0 × 2 #&gt; # ℹ 2 variables: order_id &lt;dbl&gt;, n &lt;int&gt; dat |&gt; count(order_id, delivery_place) |&gt; count(order_id) |&gt; filter(n &gt; 1) #&gt; # A tibble: 0 × 2 #&gt; # ℹ 2 variables: order_id &lt;dbl&gt;, n &lt;int&gt; I count the number of suppliers per order id. Since there is only a single supplier per order id, orders are sent from a single supplier as expected. Similar for delivery place. Close Solution × Hint dat |&gt; count(order_id, supplier) |&gt; count(___) |&gt; filter(___) Close Hint Do all orders use a single supplier and delivery place? × Solution res &lt;- dat |&gt; group_by(order_id) |&gt; summarise( items = n(), quantity = sum(quantity, na.rm = T), price = sum(price * quantity, na.rm = T), delivery_cost = sum(delivery_cost, na.rm = T), year = first(order_year)) |&gt; arrange(desc(delivery_cost)) |&gt; print() #&gt; # A tibble: 423 × 6 #&gt; order_id items quantity price delivery_cost year #&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 356418604501 12 22 10353475. 1585508. 2018 #&gt; 2 376418011902 8 72 422047. 1065000 2018 #&gt; 3 367616617401 6 17 5499696. 355284 2016 #&gt; 4 356816627101 8 29 330429. 115162 2016 #&gt; 5 367615606001 1 5 864287. 88750 2015 #&gt; 6 356818622901 3 26 2393980. 71135. 2018 #&gt; 7 356716605702 1 1 1621285 54262. 2016 #&gt; 8 367515609001 2 30 85118. 34258. 2015 #&gt; 9 376316602501 10 21 1698994. 23962. 2016 #&gt; 10 356516614801 1 6 1427. 16323. 2016 #&gt; # ℹ 413 more rows The highest delivery cost is 1585508 for order 356418604501. Close Solution × Hint res &lt;- dat |&gt; group_by(order_id) |&gt; summarise( items = n(), ___) |&gt; arrange(___) |&gt; print() Close Hint For each order, calculate/find the number of different items, number of items, total price, total delivery cost, and order year (missing values are assumed zero). Which order has the highest delivery cost? × Solution res1 &lt;- dat |&gt; group_by(order_id) |&gt; summarise(supplier = first(supplier), delivery_place = first(delivery_place)) res2 &lt;- res1 |&gt; count(supplier, sort = T) |&gt; print() #&gt; # A tibble: 32 × 2 #&gt; supplier n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Supplier-447 325 #&gt; 2 Supplier-256 19 #&gt; 3 Supplier-703 14 #&gt; 4 Supplier-224 8 #&gt; 5 Supplier-428 7 #&gt; 6 Supplier-604 5 #&gt; 7 Supplier-373 4 #&gt; 8 Supplier-398 4 #&gt; 9 Supplier-400 4 #&gt; 10 Supplier-702 4 #&gt; # ℹ 22 more rows res3 &lt;- res1 |&gt; count(delivery_place, sort = T) |&gt; print() #&gt; # A tibble: 13 × 2 #&gt; delivery_place n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Delivery Place-105 338 #&gt; 2 Delivery Place-77 21 #&gt; 3 Delivery Place-84 18 #&gt; 4 Delivery Place-75 15 #&gt; 5 Delivery Place-78 13 #&gt; 6 Delivery Place-46 8 #&gt; 7 Delivery Place-107 2 #&gt; 8 Delivery Place-128 2 #&gt; 9 Delivery Place-81 2 #&gt; 10 #NA 1 #&gt; 11 Delivery Place-136 1 #&gt; 12 Delivery Place-177 1 #&gt; 13 Delivery Place-182 1 The supplier most used is Supplier-447. The delivery place used most is Delivery Place-105. Close Solution × Hint res1 &lt;- dat |&gt; group_by(order_id) |&gt; summarise( supplier = first___), delivery_place = first(___) ) res2 &lt;- res1 |&gt; count(___) |&gt; print() res3 &lt;- res1 |&gt; ___ Close Hint For each order, find the supplier and delivery place. Hint: The first function may be used to select the first item within a group. Which supplier and delivery place is used most? Add a column to the dataset equal the value of the items in a row calculated as the price times the quantity. Next, create a summary table named res1 that for each item id calculates the aggregated value and arrange them in descending order. × Solution res1 &lt;- dat |&gt; mutate(val = price * quantity) |&gt; group_by(item_id) |&gt; summarise(val = sum(val), item_desc = first(item_desc)) |&gt; arrange(desc(val)) |&gt; print() #&gt; # A tibble: 550 × 3 #&gt; item_id val item_desc #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 601.003.004 20301030 Cylinder Liner IMO Number 1848265-3 #&gt; 2 601.026.139 16083341. Spindle Guide, Compl #&gt; 3 601.004.008 15029349. Piston Crown IMO Number 1848264-1 #&gt; 4 601.002.078 12592313. DuraSpindle #&gt; 5 601.026.128 11675816. Fuel valve head #&gt; 6 601.004.010 8046002. Piston Rod IMO Effective Length=1812.5 +/- 0.2mm #&gt; 7 601.026.049 7654587. Pump barrel with plunger, compl. #&gt; 8 601.004.005 6631292. Piston ring, CPR-POP, H=9.5mm, alu-coat #&gt; 9 601.004.006 5946707. Piston Ring No. 2 &amp; 4 #&gt; 10 601.026.052 5436342. Suction valve #&gt; # ℹ 540 more rows The most costly item is 601.003.004 a Cylinder Liner IMO Number 1848265-3. Close Solution × Hint res1 &lt;- dat |&gt; mutate(val = ___) |&gt; group_by(___) |&gt; summarise(val = ___, item_desc = first(___)) |&gt; arrange(___) |&gt; print() Close Hint Which item is the most costly one with respect to the calculated value in res1? × Solution res1 &lt;- res1 |&gt; ungroup() |&gt; mutate(pct = val/sum(val), cum_pct = cumsum(pct)) |&gt; print() #&gt; # A tibble: 550 × 5 #&gt; item_id val item_desc pct cum_pct #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 601.003.004 20301030 Cylinder Liner IMO Number 1848265-3 0.104 0.104 #&gt; 2 601.026.139 16083341. Spindle Guide, Compl 0.0822 0.186 #&gt; 3 601.004.008 15029349. Piston Crown IMO Number 1848264-1 0.0768 0.263 #&gt; 4 601.002.078 12592313. DuraSpindle 0.0643 0.327 #&gt; 5 601.026.128 11675816. Fuel valve head 0.0596 0.387 #&gt; 6 601.004.010 8046002. Piston Rod IMO Effective Length=1812.5 +/- 0.2mm 0.0411 0.428 #&gt; 7 601.026.049 7654587. Pump barrel with plunger, compl. 0.0391 0.467 #&gt; 8 601.004.005 6631292. Piston ring, CPR-POP, H=9.5mm, alu-coat 0.0339 0.501 #&gt; 9 601.004.006 5946707. Piston Ring No. 2 &amp; 4 0.0304 0.531 #&gt; 10 601.026.052 5436342. Suction valve 0.0278 0.559 #&gt; # ℹ 540 more rows Close Solution × Hint res1 &lt;- res1 |&gt; ungroup() |&gt; mutate(pct = ___, cum_pct = cumsum(___)) |&gt; print() Close Hint Given the dataset res1, add two new columns: The relative value for each item as the ratio between the item’s value and the total value of all items. The cumulative relative value. Hint: You can use the cumsum function here. × Solution item &lt;- res1$item_id[1] res2 &lt;- dat |&gt; filter(item_id == item) |&gt; group_by(ship) |&gt; summarise(n = sum(quantity)) |&gt; arrange(desc(n)) |&gt; print() #&gt; # A tibble: 7 × 2 #&gt; ship n #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Ship-12 12 #&gt; 2 Ship-11 9 #&gt; 3 Ship-14 9 #&gt; 4 Ship-21 7 #&gt; 5 Ship-10 2 #&gt; 6 Ship-9 2 #&gt; 7 Ship-20 1 The item is used at 7 ships (most on ship Ship-12). Close Solution × Hint item &lt;- res1$item_id[1] res2 &lt;- dat |&gt; filter(___) |&gt; group_by(___) |&gt; summarise(__ |&gt; arrange(___ |&gt; print() Close Hint Consider the most costly item with respect to the calculated value in res1. At which ships is the item used and how many times? 13.5.10 Exercise (jobs) This exercise is a slightly modified version an exam assignment (exam 2023-A1). Consider the dataset in the file jobs.csv with engine maintenance jobs for a group of ships. The dataset contains a row for each item used. The columns/variables are: ship: The ship considered. job_id: Maintenance job id. A job is a collection of items replaced. job_desc: Job description. item_id: Item id. item_name: Item name. item_quantity: Number of items used. item_manufaturer: Item manufacturer. component_id: Engine component id. component_desc: Engine component description. done_date: Date the job finished. year: Year of done date. days: Days since the item was last used for maintenance on the ship. You can access the dataset file at location # remotes::install_github(&quot;bss-osca/tfa-package&quot;, build = FALSE) # run if tfa not installed path &lt;- system.file(&quot;extdata/jobs.csv&quot;, package = &quot;tfa&quot;) Use the dplyr package in tidyverse to calculate relevant summary tables (tibbles/data frames) and answer/complete the following questions/tasks. × Solution library(tidyverse) lines &lt;- read_lines(path, n_max = 3) lines #&gt; [1] &quot;ship,job_id,job_desc,item_id,item_name,item_quantity,item_manufaturer,component_id,component_desc,done_date,year,days&quot; #&gt; [2] &quot;Ship-20,2379,\\&quot;ME Exh. Gas outlet temp. cyl,#1 sensor pocket and wire cable\\&quot;,601.001.001,\\&quot;Thermocouple TC-87-02, Model: MPT 100K, Type: K, Temp :0-600 &#39;C, Class:B, Tube:\\&quot;,1,\\&quot;CMR KOREA CO.,LTD\\&quot;,601.001.01,Main Engine,2018-08-14,2018,NA&quot; #&gt; [3] &quot;Ship-21,1899,M.E cylinder no.4 exhaust gas temperature thermocouple replacement,601.001.001,\\&quot;Thermocouple TC-87-02, Model: MPT 100K, Type: K, Temp :0-600 &#39;C, Class:B, Tube:\\&quot;,1,\\&quot;CMR KOREA CO.,LTD\\&quot;,601.002.04,ME Cylinder Cover No 4,2016-12-20,2016,NA&quot; dat &lt;- read_csv(path) It can be seen that a comma (,) is used a delimiter. That is, the dataset is loaded using read_csv. Close Solution × Hint Use the read_lines function to have a look at the csv file. Close Hint Find the delimiter used in the csv file and load the file into a tibble/data frame called dat. × Solution library(skimr) skim(dat) Table 13.7: Data summary Name dat Number of rows 3106 Number of columns 12 _______________________ Column type frequency: character 7 Date 1 numeric 4 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace ship 0 1.00 6 7 0 9 0 job_desc 51 0.98 17 80 0 241 0 item_id 0 1.00 11 11 0 216 0 item_name 0 1.00 3 80 0 138 0 item_manufaturer 17 0.99 4 35 0 19 0 component_id 0 1.00 3 10 0 144 0 component_desc 53 0.98 9 51 0 214 0 Variable type: Date skim_variable n_missing complete_rate min max median n_unique done_date 0 1 2015-01-24 2020-04-21 2018-09-20 288 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist job_id 0 1.00 1344.58 1157.45 1 656 862 2010.0 6791 ▇▂▁▁▁ item_quantity 0 1.00 1.07 1.11 0 1 1 1.0 32 ▇▁▁▁▁ year 0 1.00 2018.05 1.16 2015 2017 2018 2019.0 2020 ▂▅▇▆▂ days 554 0.82 61.37 167.22 0 0 0 20.2 1625 ▇▁▁▁▁ We have a total of 3106 rows/observations for 9 ships over a period from 2015-01-24 to 2020-04-21. Close Solution × Hint Use the skimr package. Close Hint Provide a short overview of the data. How many rows are there in the data, what is the number of different ships, and what is the range of dates? × Solution res1 &lt;- dat |&gt; distinct(job_id) |&gt; nrow() |&gt; print() #&gt; [1] 463 res2 &lt;- dat |&gt; group_by(ship) |&gt; summarise(jobs = n_distinct(job_id)) |&gt; print() #&gt; # A tibble: 9 × 2 #&gt; ship jobs #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Ship-10 126 #&gt; 2 Ship-11 70 #&gt; 3 Ship-12 130 #&gt; 4 Ship-13 76 #&gt; 5 Ship-14 32 #&gt; 6 Ship-19 25 #&gt; 7 Ship-20 37 #&gt; 8 Ship-21 86 #&gt; 9 Ship-9 70 res3 &lt;- res2 |&gt; summarise(avg_jobs = mean(jobs)) |&gt; print() #&gt; # A tibble: 1 × 1 #&gt; avg_jobs #&gt; &lt;dbl&gt; #&gt; 1 72.4 We have a total of 463 jobs, the number of jobs for each ship can be seen using res2 with and average of 72.44 jobs per ship. Close Solution × Hint res1 &lt;- dat |&gt; distinct(___) |&gt; ___ |&gt; print() res2 &lt;- dat |&gt; group_by(ship) |&gt; summarise(___) |&gt; print() res3 &lt;- res2 |&gt; ___ Close Hint What is the total number of different jobs, number of different jobs per ship, and average number of jobs per ship? Hint: The function n_distinct may be used to find distinct values within a group. × Solution res1 &lt;- dat |&gt; distinct(job_id, item_id) |&gt; count(job_id) |&gt; summarise(min = min(n), avg = mean(n), max = max(n)) |&gt; print() #&gt; # A tibble: 1 × 3 #&gt; min avg max #&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 1 5.06 27 res2 &lt;- dat |&gt; group_by(job_id) |&gt; summarise(n = sum(item_quantity)) |&gt; summarise(min = min(n), avg = mean(n), max = max(n)) |&gt; print() #&gt; # A tibble: 1 × 3 #&gt; min avg max #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 0 7.17 53 The range and average of unique items considered can be seen using res1 and the range and average of items used can be seen using res2. Note some jobs don’t use the allocated item. Close Solution × Hint res1 &lt;- dat |&gt; distinct(___) |&gt; count(___) |&gt; summarise(___) |&gt; print() res2 &lt;- dat |&gt; group_by(___) |&gt; summarise(___) |&gt; summarise(___) |&gt; print() Close Hint What is the minimum, average, and maximum number of different items considered at each job? What is the minimum, average, and maximum number of items used for maintenance at each job? × Solution res &lt;- dat |&gt; filter(item_quantity == 0) |&gt; group_by(ship) |&gt; summarise(jobs = n_distinct(job_id)) |&gt; arrange(desc(jobs)) |&gt; print() #&gt; # A tibble: 7 × 2 #&gt; ship jobs #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Ship-10 84 #&gt; 2 Ship-14 9 #&gt; 3 Ship-9 8 #&gt; 4 Ship-20 4 #&gt; 5 Ship-21 3 #&gt; 6 Ship-12 2 #&gt; 7 Ship-19 1 Ship-10 have a lot of jobs where the items scheduled in a job, have not been used. Close Solution × Hint res &lt;- dat |&gt; filter(___) |&gt; group_by(__) |&gt; summarise(___) |&gt; arrange(___) |&gt; print() Close Hint It seems that some items considered in a job are not used anyway. Which ship has most jobs where an item should have been used, but has not (quantity is zero)? × Solution res &lt;- dat |&gt; group_by(item_id) |&gt; summarize(n = sum(item_quantity), item_name = first(item_name)) |&gt; arrange(desc(n)) |&gt; print() #&gt; # A tibble: 216 × 3 #&gt; item_id n item_name #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 601.003.013 281 Sealing Ring #&gt; 2 601.004.006 144 Piston Ring No. 2 And No. 4 #&gt; 3 601.026.128 107 O-Ring #&gt; 4 601.026.052 96 Suction Valve, Compl #&gt; 5 601.026.026 89 Back-Up Ring #&gt; 6 601.003.011 85 Packing #&gt; 7 601.003.007 83 O-Ring Modified No.5165541-1 #&gt; 8 601.026.139 81 Spindle Guide, Complete #&gt; 9 601.004.005 74 Piston Ring No. 1 #&gt; 10 601.003.014 72 Gasket #&gt; # ℹ 206 more rows Item 601.003.013 a Sealing Ring is used most Close Solution × Hint res &lt;- dat |&gt; group_by(___) |&gt; summarize(n = ___, item_name = first(___)) |&gt; arrange(___) |&gt; print() Close Hint Which item is the most used one for maintenance? "],["mod-r-plot.html", "Module 14 Data visualization using ggplot 14.1 Learning outcomes 14.2 Introduction to data visualization 14.3 Combining plots into one using patchwork 14.4 Saving graphics 14.5 Recap 14.6 Exercises", " Module 14 Data visualization using ggplot This module considers visualization of your data using the ggplot2 package which is a part of tidyverse. R has several systems for making plots, but ggplot2 is one of the most elegant and most versatile. Using ggplot2 you can make plots faster by learning one system and applying it in many different plot types. A template project for this module is given on Posit Cloud (open it and use it while reading the notes). Learning path diagram It is recommended that you follow the green learning path; however, you may like a different learning style. In the learning path diagram, there are links to alternative online content (video or reading). Note this is an alternative to the standard learning path that you may use instead (you should not do both). The learning path may also have extra content, that is NOT a part of syllabus (only look at it if you want more info)! 14.1 Learning outcomes By the end of this module, you are expected to: Know how to create basic plots using ggplot. Formulate the ideas behind the grammar of graphics. Explain the idea behind aesthetics such as color, fill, and line type. Add geometries to a plot such as a histogram, a boxplot, a barplot, a scatter plot, and a line. Understand how themes can be used to modify the overall look of a plot. Combine multiple plots into a single graphic. Save plots as variables and different image files. The learning outcomes relate to the overall learning goals number 7, 11-14 and 18 of the course. 14.2 Introduction to data visualization The package ggplot2 is a plotting package that makes it simple to create complex plots from data in a data frame. It provides an interface for specifying which variables to plot, how they are displayed, and general visual properties. Hence, only minimal changes are needed, if the underlying data change or if we decide to change from a bar plot to a scatterplot. The package implements the grammar of graphics, a coherent system for describing and building layered plots. A plot is built step by step by adding new layers. Adding layers in this fashion allows for extensive flexibility and customization of plots. An excellent introduction to data visualization using ggplot2 is given in the interactive DataCamp course Introduction to data visualization with ggplot2. Please complete the course before continuing. Note that there is a difference between using the pipe |&gt; operator which passes the output of the previous line of code as the first input of the next line of code and the + operator used between ggplot2 functions for “layering”. That is, you create the plot in layers, separated by +. 14.3 Combining plots into one using patchwork You can combine separate ggplots into the same graphic using the patchwork package. You can install patchwork from CRAN using install.packages('patchwork'). The usage is simple. Plots in two rows: library(ggplot2) library(patchwork) p1 &lt;- ggplot(mtcars) + geom_point(aes(mpg, disp)) p2 &lt;- ggplot(mtcars) + geom_boxplot(aes(gear, disp, group = gear)) p1 + p2 The package provides rich support for arbitrarily complex layouts. Code for nesting three plots on top of a third: p3 &lt;- ggplot(mtcars) + geom_smooth(aes(disp, qsec)) p4 &lt;- ggplot(mtcars) + geom_bar(aes(carb)) (p1 | p2 | p3) / p4 For further examples see the documentation pages. 14.4 Saving graphics In general, when you do analytics using R Markdown, there is no need to save your graphics. This is done automatically. However, in a few cases you may need to save you graphics in different formats. Let us consider a simple plot: library(tidyverse) p &lt;- ggplot(mpg, aes(displ, hwy, colour = class)) + geom_point() p # print it out To save the plot as a bitmap image (png, jpeg etc) have a look at the documentation (?png). Let us try to save the plot as a png file. png(&quot;test1.png&quot;) # open png device for writing p dev.off() # close device #&gt; png #&gt; 2 png(&quot;test2.png&quot;, width = 1200, height = 600) # use other output width and height in px p dev.off() #&gt; png #&gt; 2 png(&quot;test3.png&quot;, width = 1200, height = 900) # save a patchwork plot (p1 | p2 | p3) / p4 #&gt; `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; dev.off() #&gt; png #&gt; 2 # browseURL(&quot;test1.png&quot;) # to have a look at the file # browseURL(&quot;test3.png&quot;) # to have a look at the file To save the plot as a pdf use pdf(&quot;test1.pdf&quot;) # open pdf device for writing p dev.off() # close device #&gt; png #&gt; 2 # browseURL(&quot;test1.pdf&quot;) # to have a look at the file If you use LaTeX you may use the tikzDevice package to save plots as TikZ. 14.5 Recap The tidyverse package ggplot2 is an R package for producing data visualizations. It is based on the Grammar of Graphics by Wilkinson (2005). The grammar of graphics is a coherent system for describing and building layered plots. Graphics are made by grammatical elements such as data, aesthetics, geometries, scales, facets, and themes. Plots are made though aesthetic mappings. That is, variables are mapped to x or y position using aesthetics attributes such as color, shape, or size. A plot is built step by step by adding new layers. Adding layers in this fashion allows for extensive flexibility and customization of plots. Together, the data, aesthetic mappings, and geometric object form a layer. A plot may have multiple layers, for example, when we overlay a scatterplot with a smoothed line. Aesthetics are add in ggplot using the aes function or alternatively in geom_ functions. Geometries (e.g. a boxplot or line) are added to a plot using the geom_ functions. Themes can be applied to the plot using the theme_ functions and control all the non-data ink used to modify the overall look of a plot. Separate ggplots can be combined into the same graphic using the patchwork package. Save plots as variables and different image files using the device functions such as png and pdf. The pipe |&gt; operator is used to “pipe” the output of the previous line of code as the first input of the next line of code. The + operator in ggplot2 functions is used for “layering”. This means you create the plot in layers, separated by +. The ‘Data visualization with ggplot2’ cheatsheet is very useful. Find the newest version in RStudio Help &gt; Cheatsheets. A good place to see examples are on the main reference page. Follow the link to the function of interest and have a look at the examples. You may also have a look at the slides for this module . 14.6 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Some of the solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up too early. Put some effort into finding a solution! Always practice using shortcuts in RStudio (see Tools &gt; Keyboard Shortcuts Help). Go to the Tools for Analytics workspace and download/export the TM14 project. Open it on your laptop and have a look at the files in the exercises folder which can be used as a starting point. 14.6.1 Exercise (gapminder) Use the exercise R Markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). In this exercise, we will demonstrate how relatively simple ggplot2 code can create insightful and aesthetically pleasing plots. As motivation we will create plots that help us better understand trends in world health and economics. Hans Rosling was the co-founder of the Gapminder Foundation, an organization dedicated to educating the public by using data to dispel common myths about the so-called developing world. Hans Rosling conveyed actual data-based trends in a dramatic way of his own, using effective data visualization. Here we will try to answer two questions: Is it a fair characterization of today’s world to say it is divided into Western rich nations and the developing world in Africa, Asia, and Latin America? Has income inequality across countries worsened during the last 40 years? To answer these questions, we will be using the gapminder dataset provided in the dslabs package. This dataset was created using a number of spreadsheets available from the Gapminder Foundation. You can access the table like this: library(tidyverse) library(dslabs) data(gapminder) gapminder |&gt; as_tibble() #&gt; # A tibble: 10,545 × 9 #&gt; country year infant_mortality life_expectancy fertility population gdp continent region #&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; #&gt; 1 Albania 1960 115. 62.9 6.19 1636054 NA Europe South… #&gt; 2 Algeria 1960 148. 47.5 7.65 11124892 1.38e10 Africa North… #&gt; 3 Angola 1960 208 36.0 7.32 5270844 NA Africa Middl… #&gt; 4 Antigua an… 1960 NA 63.0 4.43 54681 NA Americas Carib… #&gt; 5 Argentina 1960 59.9 65.4 3.11 20619075 1.08e11 Americas South… #&gt; 6 Armenia 1960 NA 66.9 4.55 1867396 NA Asia Weste… #&gt; 7 Aruba 1960 NA 65.7 4.82 54208 NA Americas Carib… #&gt; 8 Australia 1960 20.3 70.9 3.45 10292328 9.67e10 Oceania Austr… #&gt; 9 Austria 1960 37.3 68.8 2.7 7065525 5.24e10 Europe Weste… #&gt; 10 Azerbaijan 1960 NA 61.3 5.57 3897889 NA Asia Weste… #&gt; # ℹ 10,535 more rows We start by testing our knowledge regarding differences in child mortality across different countries. For each of the six pairs of countries below, which country do you think had the highest child mortality rates in 2015? Which pairs do you think are most similar? Sri Lanka or Turkey Poland or South Korea Malaysia or Russia Pakistan or Vietnam Thailand or South Africa When answering these questions without data, the non-European countries are typically picked as having higher child mortality rates: Sri Lanka over Turkey, South Korea over Poland, and Malaysia over Russia. It is also common to assume that countries considered to be part of the developing world: Pakistan, Vietnam, Thailand, and South Africa, have similarly high mortality rates. To answer these questions with data, we can use dplyr. For example, for the first comparison we see that: gapminder |&gt; filter(year == 2015 &amp; country %in% c(&quot;Sri Lanka&quot;,&quot;Turkey&quot;)) |&gt; select(country, infant_mortality) #&gt; country infant_mortality #&gt; 1 Sri Lanka 8.4 #&gt; 2 Turkey 11.6 Turkey has the higher infant mortality rate. We can use this code on all comparisons and find the following: #&gt; New names: #&gt; • `country` -&gt; `country...1` #&gt; • `infant_mortality` -&gt; `infant_mortality...2` #&gt; • `country` -&gt; `country...3` #&gt; • `infant_mortality` -&gt; `infant_mortality...4` country infant mortality country infant mortality Sri Lanka 8.4 Turkey 11.6 Poland 4.5 South Korea 2.9 Malaysia 6.0 Russia 8.2 Pakistan 65.8 Vietnam 17.3 Thailand 10.5 South Africa 33.6 We see that the European countries on this list have higher child mortality rates: Poland has a higher rate than South Korea, and Russia has a higher rate than Malaysia. We also see that Pakistan has a much higher rate than Vietnam, and South Africa has a much higher rate than Thailand. It turns out that when Hans Rosling gave this quiz to educated groups of people, the average score was less than 2.5 out of 5, worse than what they would have obtained had they guessed randomly. This implies that we are misinformed. We will try to use visualization to help us being more informed. The west vs. the developing world There is a preconceived notion that the world is divided into two groups: the Western world (Western Europe and North America), characterized by long life spans and small families, versus the developing world (Africa, Asia, and Latin America) characterized by short life spans and large families. But do the data support this dichotomous view? × Solution filter(gapminder, year == 1962) |&gt; ggplot( aes(fertility, life_expectancy, color = continent)) + geom_point() Most points fall into two distinct categories: Life expectancy around 70 years and 3 or fewer children per family. Life expectancy lower than 65 years and more than 5 children per family. Countries are from the regions we expect. Close Solution × Hint filter(gapminder, year == ___) |&gt; ggplot( aes(___, ___, color = ___)) + geom_point() Close Hint Make a scatterplot of life expectancy versus fertility rates (average number of children per woman) in 1962. Use continent as color aesthetic. × Solution filter(gapminder, year %in% c(1962, 2012)) |&gt; ggplot(aes(fertility, life_expectancy, col = continent)) + geom_point() + facet_grid(cols = vars(year)) This plot clearly shows that the majority of countries have moved from the developing world cluster to the western world one. In 2012, the western versus developing world view no longer makes sense. This is particularly clear when comparing Europe to Asia, the latter of which includes several countries that have made great improvements. Close Solution × Hint filter(gapminder, ___ %in% c(1962, 2012)) |&gt; ggplot(aes(___, ___, col = ___)) + geom_point() + facet_grid(cols = vars(___)) Close Hint In 1962, “the West versus developing world” view was grounded in some reality. Is this still the case 50 years later? We could easily plot the 2012 data in the same way we did for 1962. To make comparisons, side by side plots are preferable. In ggplot2, we can achieve this by faceting variables and making a plot for each year. That is, you must filter by years 1962 and 2012 and add the layer facet_grid, which automatically separates the plots. × Solution years &lt;- c(1962, 1970, 1980, 1990, 2000, 2012) continents &lt;- c(&quot;Europe&quot;, &quot;Asia&quot;) gapminder |&gt; filter(year %in% years &amp; continent %in% continents) |&gt; ggplot( aes(fertility, life_expectancy, col = continent)) + geom_point() + facet_wrap(vars(year)) The plot clearly shows how most Asian countries have improved at a much faster rate than European ones. Close Solution × Hint gapminder |&gt; filter(year %in% ___ &amp; continent %in% ___) |&gt; ggplot(aes(___)) + geom_point() + facet_wrap(___) Close Hint To explore the transformation through the years, make a plot for the years 1962, 1970, 1980, 1990, 2000, and 2012 considering Europe and Asia. How has Asia transformed through the years compared to Europe? Since we consider many years, we will not want all the plots on the same row. Instead, we will want to use multiple rows and columns. The function facet_wrap permits us to do this by automatically wrapping the series of plots. Infobox - Scales The default choice of the range of the axes is important. When not using facet, this range is determined by the data shown in the plot. When using facet, this range is determined by the data shown in all plots and therefore kept fixed across plots. This makes comparisons across plots much easier. For example, in the above plot, we can see that life expectancy has increased and the fertility has decreased across most countries. We see this because the cloud of points moves. This is not the case if we adjust the scales: In the plot above, we have to pay special attention to the range to notice that the plot on the right has a larger life expectancy. × Solution gapminder |&gt; filter(continent == &quot;Asia&quot;) |&gt; ggplot(aes(fertility, life_expectancy, col = year)) + geom_point() #&gt; Warning: Removed 47 rows containing missing values or values outside the scale range #&gt; (`geom_point()`). Close Solution × Hint gapminder |&gt; filter(___) |&gt; ggplot(aes(___)) + geom_point() Close Hint Illustrate the transformation for Asia using a single plot where year is used as color aesthetic. Time series plots The visualizations above effectively illustrate that data no longer supports the Western versus developing world view. Once we see these plots, new questions emerge. For example, which countries are improving more and which ones less? Was the improvement constant during the last 50 years or was it more accelerated during certain periods? For a closer look that may help answer these questions, we introduce time series plots. Time series plots have time in the x-axis and an outcome or measurement of interest on the y-axis. For example, here is a trend plot of United States fertility rates: gapminder |&gt; filter(country == &quot;United States&quot;) |&gt; ggplot(aes(year, fertility)) + geom_point() We see that the trend is not linear at all. Instead there is sharp drop during the 1960s and 1970s to below 2. Then the trend comes back to 2 and stabilizes during the 1990s. When the points are regularly and densely spaced, as they are here, we create curves by joining the points with lines, to convey that these data are from a single series, here a country. To do this, we use the geom_line function instead of geom_point. × Solution gapminder |&gt; filter(country == &quot;United States&quot;) |&gt; ggplot(aes(year, fertility)) + geom_line() #&gt; Warning: Removed 1 row containing missing values or values outside the scale range (`geom_line()`). Close Solution Make a lineplot showing the time series of fertility versus year for United States. × Solution countries &lt;- c(&quot;South Korea&quot;, &quot;Germany&quot;) gapminder |&gt; filter(country %in% countries) |&gt; ggplot(aes(year, fertility, col = country)) + geom_line() #&gt; Warning: Removed 2 rows containing missing values or values outside the scale range #&gt; (`geom_line()`). The plot clearly shows how South Korea’s fertility rate dropped drastically during the 1960s and 1970s, and by 1990 had a similar rate to that of Germany. Close Solution × Hint gapminder |&gt; filter(country %in% ___) |&gt; ggplot(aes(year, fertility, col = ___)) + geom_line() Close Hint Lineplots is particularly helpful when we look at more countries. Make a lineplot showing the time series of fertility versus year for South Korea and Germany. Use country as color aesthetic. × Solution gapminder |&gt; filter(country %in% countries) |&gt; ggplot(aes(year, life_expectancy, col = country)) + geom_line() The plot clearly shows how an improvement in life expectancy followed the drops in fertility rates. In 1960, Germans lived 15 years longer than South Koreans, although by 2010 the gap is completely closed. It exemplifies the improvement that many non-western countries have achieved in the last 40 years. Close Solution Make a lineplot showing the time series of life expectancy versus year for South Korea and Germany. Use country as color aesthetic. Data transformations We now shift our attention to the second question related to the commonly held notion that wealth distribution across the world has become worse during the last decades. When general audiences are asked if poor countries have become poorer and rich countries become richer, the majority answers yes. By using stratification, histograms, smooth densities, and boxplots, we will be able to understand if this is in fact the case. First we learn how transformations can sometimes help provide more informative summaries and plots. The gapminder data table includes a column with the countries’ gross domestic product (GDP). GDP measures the market value of goods and services produced by a country in a year. The GDP per person is often used as a rough summary of a country’s wealth. Here we divide this quantity by 365 to obtain the more interpretable measure dollars per day. Using current U.S. dollars as a unit, a person surviving on an income of less than $2 a day, is defined to be living in absolute poverty. We add this variable to the data table: gapminder &lt;- gapminder |&gt; mutate(dollars_per_day = gdp/population/365) The GDP values are adjusted for inflation and represent current U.S. dollar, so these values are meant to be comparable across the years. Of course, these are country averages and within each country there is much variability. All the graphs and insights described below relate to country averages and not to individuals. Here is a histogram of per day incomes from 1970: past_year &lt;- 1970 gapminder |&gt; filter(year == past_year &amp; !is.na(gdp)) |&gt; ggplot(aes(dollars_per_day)) + geom_histogram(binwidth = 1, color = &quot;black&quot;) We use the color = \"black\" argument to draw a boundary and clearly distinguish the bins. In this plot, we see that for the majority of countries, averages are below $10 a day. However, the majority of the x-axis is dedicated to the 35 countries with averages above $10. So the plot is not very informative about countries with values below $10 a day. It might be more informative to quickly be able to see how many countries have average daily incomes of about $1 (extremely poor), $2 (very poor), $4 (poor), $8 (middle), $16 (well off), $32 (rich), $64 (very rich) per day. These changes are multiplicative and log transformations convert multiplicative changes into additive ones: when using base 2, a doubling of a value turns into an increase by 1. × Solution gapminder |&gt; filter(year == past_year &amp; !is.na(gdp)) |&gt; ggplot(aes(log2(dollars_per_day))) + geom_histogram(binwidth = 1, color = &quot;black&quot;) This provides a close-up of the mid to lower income countries. Close Solution Make a histogram of log2(dollars_per_day) from 1970. Infobox - Which base? In the case above, we used base 2 in the log transformations. Other common choices are base \\(\\mathrm{e}\\) (the natural log) and base 10. In general, we do not recommend using the natural log for data exploration and visualization. This is because while \\(2^2, 2^3, 2^4, \\dots\\) or \\(10^2, 10^3, \\dots\\) are easy to compute in our heads, the same is not true for \\(\\mathrm{e}^2, \\mathrm{e}^3, \\dots\\), so the scale is not intuitive or easy to interpret. In the dollars per day example, we used base 2 instead of base 10 because the resulting range is easier to interpret. The range of the values being plotted is 0.327, 48.885. In base 10, this turns into a range that includes very few integers: just 0 and 1. With base two, our range includes -2, -1, 0, 1, 2, 3, 4, and 5. It is easier to compute \\(2^x\\) and \\(10^x\\) when \\(x\\) is an integer and between -10 and 10, so we prefer to have smaller integers in the scale. Another consequence of a limited range is that choosing the binwidth is more challenging. With log base 2, we know that a binwidth of 1 will translate to a bin with range \\(x\\) to \\(2x\\). For an example in which base 10 makes more sense, consider population sizes. A log base 10 is preferable since the range for these is: filter(gapminder, year == past_year) |&gt; summarize(min = min(population), max = max(population)) #&gt; min max #&gt; 1 46075 8.09e+08 Here is the histogram of the transformed values: gapminder |&gt; filter(year == past_year) |&gt; ggplot(aes(log10(population))) + geom_histogram(binwidth = 0.5, color = &quot;black&quot;) In the above, we quickly see that country populations range between ten thousand and ten billion. There are two ways we can use log transformations in plots. We can log the values before plotting them or use log scales on the axes. Both approaches are useful and have different strengths. If we log the data, we can more easily interpret intermediate values in the scale. For example, if we see: ----1----x----2--------3---- for log transformed data, we know that the value of \\(x\\) is about 1.5. If the scales are logged: ----1----x----10------100--- then, to determine x, we need to compute \\(10^{1.5}\\), which is not easy to do in our heads. The advantage of using logged scales is that we see the original values on the axes. However, the advantage of showing logged scales is that the original values are displayed in the plot, which are easier to interpret. For example, we would see “32 dollars a day” instead of “5 log base 2 dollars a day”. × Solution gapminder |&gt; filter(year == past_year &amp; !is.na(gdp)) |&gt; ggplot(aes(dollars_per_day)) + geom_histogram(binwidth = 1, color = &quot;black&quot;) + scale_x_continuous(trans = &quot;log2&quot;) The plot from Q8 is the same except the values on the x-axis. Close Solution Make a histogram of dollars_per_day from 1970 using a log2 scale on the x-axis. Compare it to the plot from Question 8. Hint: you can use the scale_x_continuous function with trans = \"log2\". The histograms in Questions 8 and 9 have two bumps: one at about 4 and another at about 32. In statistics these bumps are sometimes referred to as modes. The mode of a distribution is the value with the highest frequency. The mode of the normal distribution is the average. When a distribution, like the one above, does not monotonically decrease from the mode, we call the locations where it goes up and down again local modes and say that the distribution has multiple modes indicating different distributions for different groups. The histogram above suggests that the 1970 country income distribution has two modes: one at about 2 dollars per day (1 in the log 2 scale) and another at about 32 dollars per day (5 in the log 2 scale). However, the histogram does not show us if the two groups of countries are west versus the rest. Let us create the group column: gapminder &lt;- gapminder |&gt; mutate(group = case_when( region %in% c(&quot;Western Europe&quot;, &quot;Northern Europe&quot;,&quot;Southern Europe&quot;, &quot;Northern America&quot;, &quot;Australia and New Zealand&quot;) ~ &quot;West&quot;, TRUE ~ &quot;Rest&quot;)) |&gt; as_tibble() × Solution gapminder |&gt; filter(year == past_year &amp; !is.na(gdp)) |&gt; ggplot(aes(dollars_per_day)) + geom_histogram(binwidth = 1, color = &quot;black&quot;) + facet_grid(cols = vars(group)) + scale_x_continuous(trans = &quot;log2&quot;) The plot confirms the west vs the rest dichotomy. Close Solution × Hint gapminder |&gt; filter(year == past_year &amp; !is.na(gdp)) |&gt; ggplot(aes(dollars_per_day)) + geom_histogram(binwidth = 1, color = &quot;black&quot;) + facet_grid(cols = ___) + scale_x_continuous(trans = &quot;log2&quot;) Close Hint Make a histogram of dollars_per_day from 1970 using a log2 scale and facet it by group. Is there a west versus the rest dichotomy? The exploratory data analysis above has revealed two characteristics about average income distribution in 1970. Using a histogram, we found a bimodal distribution with the modes relating to poor and rich countries. We will try to visualize these summaries in one plot. × Solution gapminder |&gt; filter(year == past_year &amp; !is.na(gdp)) |&gt; ggplot(aes(group, dollars_per_day)) + geom_boxplot() + scale_y_continuous(trans = &quot;log2&quot;) + geom_point() Close Solution × Hint gapminder |&gt; filter(year == past_year &amp; !is.na(gdp)) |&gt; ggplot(aes(group, dollars_per_day)) + geom____() + scale_y_continuous(trans = &quot;log2&quot;) + geom____() Close Hint Make a boxplot (geom_boxplot) of dollars_per_day (y-axis) versus group (x-axis) from 1970 using a log2 scale. Also add a the data using geom_point(). Data exploration clearly shows that in 1970 there was a “west versus the rest” dichotomy. But does this dichotomy persist? We first have to be a little careful here since there are more countries represented in 2010 than in 1970: the total counts are larger. One reason for this is that several countries were founded after 1970. For example, the Soviet Union divided into several countries during the 1990s. Another reason is that data was available for more countries in 2010. Hence we only have to consider the countries with data available for both years: past_year &lt;- 1970 present_year &lt;- 2010 years &lt;- c(past_year, present_year) country_list_1 &lt;- gapminder |&gt; filter(year == past_year &amp; !is.na(dollars_per_day)) |&gt; pull(country) country_list_2 &lt;- gapminder |&gt; filter(year == present_year &amp; !is.na(dollars_per_day)) |&gt; pull(country) country_list &lt;- intersect(country_list_1, country_list_2) We can now filter the rows by years and country_list. × Solution gapminder |&gt; filter(year %in% years &amp; country %in% country_list) |&gt; ggplot(aes(dollars_per_day)) + geom_histogram(binwidth = 1, color = &quot;black&quot;) + scale_x_continuous(trans = &quot;log2&quot;) + facet_grid(year ~ group) The income gap between rich and poor countries has narrowed considerably during the last 40 years Close Solution × Hint gapminder |&gt; filter(year %in% ___ &amp; country %in% ___) |&gt; ggplot(aes(dollars_per_day)) + geom_histogram(binwidth = 1, color = &quot;black&quot;) + scale_x_continuous(trans = &quot;log2&quot;) + facet_grid(___) Close Hint Make a histogram of dollars_per_day from 1970 and 2010 using a log2 scale and facet it by group and year. Does the dichotomy persist? × Solution gapminder |&gt; filter(year %in% years &amp; country %in% country_list) |&gt; mutate(year = factor(year)) |&gt; ggplot(aes(group, dollars_per_day, fill = year)) + geom_boxplot() + scale_y_continuous(trans = &quot;log2&quot;) We now see that the rich countries have become a bit richer, but percentage-wise, the poor countries appear to have improved more. In particular, we see that the proportion of developing countries earning more than $16 a day increased substantially. Close Solution × Hint gapminder |&gt; filter(year %in% years &amp; country %in% country_list) |&gt; mutate(year = factor(___)) |&gt; ggplot(aes(group, dollars_per_day, fill = ___)) + geom_boxplot() + scale_y_continuous(trans = &quot;log2&quot;) Close Hint Make a boxplot of dollars_per_day versus group from 1970 and 2010 using a log2 scale. Use year as fill aesthetic. Hint: you must convert year to a factor using mutate(year = factor(year)). The previous data exploration suggested that the income gap between rich and poor countries has narrowed considerably during the last 40 years. We used a series of histograms and boxplots to see this. Let us now shift to density plots. Let us start by noting that density plots for income distribution in 1970 and 2010 deliver the message that the gap is closing: gapminder |&gt; filter(year %in% years &amp; country %in% country_list) |&gt; ggplot(aes(dollars_per_day)) + geom_density(fill = &quot;grey&quot;) + scale_x_continuous(trans = &quot;log2&quot;) + facet_grid(cols = vars(year)) In the 1970 plot, we see two clear modes: poor and rich countries. In 2010, it appears that some of the poor countries have shifted towards the right, closing the gap. The next message we need to convey is that the reason for this change in distribution is that several poor countries became richer, rather than some rich countries becoming poorer. To do this, we can assign a color to the groups we identified during data exploration. gapminder |&gt; filter(year %in% years &amp; country %in% country_list) |&gt; ggplot(aes(dollars_per_day, fill = group)) + scale_x_continuous(trans = &quot;log2&quot;) + geom_density(alpha = 0.2) + facet_grid(cols = vars(year)) Note the default is to have the area represented by each distribution add up to 1, regardless of the size of each group: the number of countries in the ‘west’ group is 21 and in the ‘rest’ group is 87. We may use count on the y-axis instead: p &lt;- gapminder |&gt; filter(year %in% years &amp; country %in% country_list) |&gt; ggplot(aes(dollars_per_day, y = ..count.., fill = group)) + scale_x_continuous(trans = &quot;log2&quot;, limit = c(0.125, 300)) + facet_grid(cols = vars(year)) p + geom_density(alpha = 0.2) #&gt; Warning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0. #&gt; ℹ Please use `after_stat(count)` instead. #&gt; This warning is displayed once every 8 hours. #&gt; Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. × Solution p + geom_density(alpha = 0.2, bw = 0.75) This plot now shows that the developing world distribution is changing. Close Solution To get densities smoother, use bw = 0.75 argument so that the same bandwidth is used in each density. Comment on the plot. As a final point, we note that in these distributions the weight of every country is the same. So if most of the population is improving, but living in a very large country, such as China, we might not appreciate this. We can actually weight the smooth densities using the weight mapping argument. We modify the dataset: gapminder &lt;- gapminder |&gt; filter(year %in% years &amp; country %in% country_list) |&gt; group_by(year) |&gt; mutate(weight = population/sum(population)*2) |&gt; ungroup() × Solution gapminder |&gt; ggplot(aes(dollars_per_day, fill = group, weight = weight)) + scale_x_continuous(trans = &quot;log2&quot;, limit = c(0.125, 300)) + geom_density(alpha = 0.2, bw = 0.75) + facet_grid(cols = vars(year)) We now see that the rich countries have become a bit richer, but percentage-wise, the poor countries appear to have improved more. In particular, we see that the proportion of developing countries earning more than $16 a day increased substantially. Close Solution × Hint gapminder |&gt; ggplot(aes(dollars_per_day, fill = group, weight = ___)) + scale_x_continuous(trans = &quot;log2&quot;, limit = c(0.125, 300)) + geom_density(alpha = 0.2, bw = 0.75) + facet_grid(cols = vars(year)) Close Hint Modify the ggplot function with a weight argument and plot the density (with area equal 1). 14.6.2 Exercise (profit) Use the exercise R Markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). Consider the dataset profit (provided by the tfa package) containing quarterly financial records for each costumer, product, etc.: # remotes::install_github(&quot;bss-osca/tfa-package&quot;, upgrade = FALSE) # upgrade first library(tfa) library(skimr) glimpse(profit) #&gt; Rows: 24,546 #&gt; Columns: 9 #&gt; $ Quarter &lt;dbl&gt; 3, 1, 4, 1, 4, 3, 4, 3, 4, 1, 1, 3, 3, 3, 2, 2, 1, 2, 3, 2, 2, 2, … #&gt; $ Channel &lt;chr&gt; &quot;ATM&quot;, &quot;ATM&quot;, &quot;ATM&quot;, &quot;ATM&quot;, &quot;ATM&quot;, &quot;BRH&quot;, &quot;BRH&quot;, &quot;ATM&quot;, &quot;BRH&quot;, &quot;BR… #&gt; $ `Customer ID` &lt;chr&gt; &quot;FRT&quot;, &quot;MRT&quot;, &quot;PBI&quot;, &quot;PBI&quot;, &quot;MRT&quot;, &quot;MAM&quot;, &quot;PBI&quot;, &quot;FRT&quot;, &quot;PBI&quot;, &quot;PB… #&gt; $ Country &lt;chr&gt; &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;US… #&gt; $ `Product Line` &lt;chr&gt; &quot;Credit Products&quot;, &quot;Credit Products&quot;, &quot;Deposit Products&quot;, &quot;Deposit… #&gt; $ Revenue &lt;dbl&gt; 6044, 4686, 6063, 4682, 6320, 2993, 3355, 5716, 3347, 2624, 3629, … #&gt; $ `Product Cost` &lt;dbl&gt; 3998, 3229, 7440, 6127, 7913, 1034, 4355, 5617, 4229, 1960, 4650, … #&gt; $ `Customer Service Cost` &lt;dbl&gt; 413, 643, 1842, 1118, 1854, 242, 1027, 876, 425, 264, 700, 1482, 4… #&gt; $ Profit &lt;dbl&gt; 1633, 815, -3219, -2563, -3447, 1718, -2027, -777, -1307, 401, -17… skim(profit) Table 14.1: Data summary Name profit Number of rows 24546 Number of columns 9 _______________________ Column type frequency: character 4 numeric 5 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace Channel 0 1 3 3 0 10 0 Customer ID 0 1 3 3 0 18 0 Country 0 1 3 14 0 47 0 Product Line 0 1 14 25 0 6 0 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist Quarter 0 1 2.50 1.12 1 2 2 3 4 ▇▇▁▇▇ Revenue 0 1 120.22 420.96 1 12 41 74 7540 ▇▁▁▁▁ Product Cost 0 1 100.07 375.51 0 9 29 68 9256 ▇▁▁▁▁ Customer Service Cost 0 1 17.42 67.43 0 1 5 12 1865 ▇▁▁▁▁ Profit 0 1 2.71 154.89 -4139 -7 0 9 3664 ▁▁▇▁▁ Make a barplot that shows the total profitability of the product lines. Use the following steps: × Solution profit &lt;- profit |&gt; mutate(across(where(is.character), as.factor)) Close Solution × Hint profit &lt;- profit |&gt; mutate(across(where(is.___), as.___)) Close Hint        a) Convert all character columns to factor columns. × Solution profit |&gt; group_by(`Product Line`) |&gt; summarise(Profit = sum(Profit)) |&gt; ggplot(aes(x = `Product Line`, y = Profit)) + geom_col() Close Solution × Hint profit |&gt; group_by(___) |&gt; summarise(Profit = sum(___)) |&gt; ggplot(aes(x = ___, y = ___)) + geom_col() Close Hint        b) Group by product line, calculate the total profit and plot profit for each product line. × Solution profit |&gt; group_by(`Product Line`) |&gt; summarise(Profit = sum(Profit)) |&gt; ggplot(aes(x = reorder(`Product Line`, Profit), y = Profit)) + geom_col() # Alternatively you can reorder the data frame before calling ggplot profit |&gt; group_by(`Product Line`) |&gt; summarise(Profit = sum(Profit)) |&gt; arrange(Profit) |&gt; mutate(`Product Line` = factor(`Product Line`, levels = `Product Line`, ordered = TRUE)) |&gt; ggplot(aes(x = reorder(`Product Line`, Profit), y = Profit)) + geom_col() + labs(title = &quot;Total profit for each product line&quot;) Close Solution × Hint 2 profit |&gt; group_by(`Product Line`) |&gt; summarise(Profit = sum(Profit)) |&gt; ggplot(aes(x = reorder(___), y = Profit)) + geom_col() Close Hint 2 × Hint 1 See the last section on this webpage. Close Hint 1        c) Plot profit for each product line where product line is reordered based on total profit. × Solution profit |&gt; group_by(`Product Line`) |&gt; summarise(Profit = sum(Profit)) |&gt; ggplot(aes(x = reorder(`Product Line`, Profit), y = Profit)) + geom_col() + labs(title = &quot;Total profit for each product line&quot;) Close Solution × Hint Try to google ‘ggplot add title’. Close Hint        d) Add a title to the plot using labs. × Solution profit |&gt; group_by(`Product Line`) |&gt; summarise(Profit = sum(Profit)) |&gt; ggplot(aes(x = reorder(`Product Line`, Profit), y = Profit)) + geom_col() + labs(title = &quot;Total profit for each product line&quot;) + xlab(&quot;Product line&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Solution × Hint Try to google ‘ggplot2 rotate axis labels’. Close Hint        e) Rotate the x-axis labels 90 degrees. × Solution dat &lt;- profit |&gt; group_by(`Product Line`) |&gt; summarise(Profit = sum(Profit)) dat |&gt; slice_min(Profit) #&gt; # A tibble: 1 × 2 #&gt; `Product Line` Profit #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 Third Party Products 2209 dat |&gt; slice_max(Profit) #&gt; # A tibble: 1 × 2 #&gt; `Product Line` Profit #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 Credit Products 31016 Close Solution × Hint dat &lt;- profit |&gt; group_by(`Product Line`) |&gt; summarise(Profit = sum(Profit)) dat |&gt; slice_min(___) dat |&gt; ___ Close Hint        f) Which product line is best and worst? × Solution profit |&gt; group_by(`Product Line`, Quarter) |&gt; summarise(Profit = sum(Profit)) |&gt; ggplot(aes(x = reorder(`Product Line`, Profit), y = Profit)) + geom_col() + facet_grid(cols = vars(Quarter)) + labs(title = &quot;Total profit for each product line&quot;) + xlab(&quot;Product Line&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Some product lines have quite different earnings in different quarters. Close Solution × Hint profit |&gt; group_by(`Product Line`, ___) |&gt; summarise(Profit = sum(Profit)) |&gt; ggplot(aes(x = reorder(`Product Line`, Profit), y = Profit)) + geom_col() + facet_grid(cols = vars(___)) + labs(title = &quot;Total profit for each product line&quot;) + xlab(&quot;Product Line&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Hint Make a barplot that shows the total profitability of the product lines in each quarter. Are there details we have missed in Question 1? × Solution profit |&gt; ggplot(aes(y = Profit, x = `Product Line`)) + geom_boxplot() + labs(title = &quot;Profit for each product line&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) The profit varies more for three of the product lines. Close Solution × Hint profit |&gt; ggplot(aes(y = ___, x = ___)) + geom_boxplot() + labs(title = &quot;Profit for each product line&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Hint Make a boxplot of profitability of the product lines. Any insight? × Solution profit |&gt; group_by(`Customer ID`) |&gt; summarise(Profit = sum(Profit)) |&gt; ggplot(aes(x = reorder(`Customer ID`, Profit), y = Profit)) + geom_col() + labs(title = &quot;Total profit for each customer&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Lowest and highest total profit is for PBI and WEM, respectively. Close Solution × Hint profit |&gt; group_by(___) |&gt; summarise(Profit = sum(___)) |&gt; ggplot(aes(x = reorder(___, ___), y = Profit)) + geom_col() + labs(title = &quot;Total profit for each customer&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Hint Make a barplot that shows the total profitability of the customers. Which customer is best and worst? × Solution profit |&gt; group_by(`Customer ID`) |&gt; summarise(Profit = mean(Profit)) |&gt; ggplot(aes(x = reorder(`Customer ID`, Profit), y = Profit)) + geom_col() + labs(title = &quot;Mean profit for each customer&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Since the number of transactions are not the same, the order of customers will not be the same. Close Solution × Hint profit |&gt; group_by(`Customer ID`) |&gt; summarise(Profit = ___) |&gt; ggplot(aes(x = reorder(`Customer ID`, Profit), y = Profit)) + geom_col() + labs(title = &quot;Mean profit for each customer&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Hint Make a barplot that shows the mean profitability of the customers. Which customer is best and worst? Compare against Question 4 and discuss. × Solution profit |&gt; group_by(`Customer ID`) |&gt; summarise(ctr = n(), `Total Profit` = sum(Profit)) |&gt; ggplot(aes(x = reorder(`Customer ID`, `Total Profit`), y = ctr, fill = `Total Profit`)) + geom_col() + labs(title = &quot;Number of transactions (rows) for each customer&quot;) + xlab(&quot;Customer&quot;) + ylab(&quot;Transactions&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Solution × Hint profit |&gt; group_by(`Customer ID`) |&gt; summarise(ctr = ___, `Total Profit` = sum(___)) |&gt; ggplot(aes(x = reorder(___, `Total Profit`), y = ctr, fill = ___)) + geom_col() + labs(title = &quot;Number of transactions (rows) for each customer&quot;) + xlab(&quot;Customer&quot;) + ylab(&quot;Transactions&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Hint Make a plot illustrating number of transactions for each customer. Use total profit as fill atheistic. × Solution profit |&gt; ggplot(aes(y = Profit, x = `Customer ID`)) + geom_boxplot() + labs(title = &quot;Profit for each customer&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Solution × Hint profit |&gt; ggplot(aes(y = ___, x = ___)) + geom_boxplot() + labs(title = &quot;Profit for each customer&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Hint Make a boxplot illustrating the profit for each customer. 14.6.3 Exercise (COVID-19) Use the exercise R Markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). Countries around the world are responding to an outbreak of respiratory illness caused by a novel corona virus, COVID-19. The outbreak first started in Wuhan, China, but cases have been identified in a growing number of other locations internationally, including the United States. In this report we explore how the trajectory of the cumulative deaths in a number of countries. The data come from the coronavirus package, which pulls data from the Johns Hopkins University Center for Systems Science and Engineering (JHU CCSE) Corona virus repository. The corona virus package provides a tidy format dataset of the 2019 Novel Corona virus COVID-19 (2019-nCoV) epidemic. The package is available on GitHub here and is updated daily. First load the following packages: library(tidyverse) library(lubridate) # package for handling dates The data frame called coronavirus in the coronavirus package provides a daily summary of the Corona virus (COVID-19) cases by country. Each row in the data frame represents a country (or, where relevant, state/province). Note that the data provided in this package provides daily number of deaths, confirmed cases, and recovered cases. Since we just need the dataset we load it using read_csv: coronavirus &lt;- read_csv( &quot;https://raw.githubusercontent.com/RamiKrispin/coronavirus/master/csv/coronavirus.csv&quot;, col_types = cols( date = col_date(format = &quot;&quot;), province = col_character(), country = col_character(), lat = col_double(), long = col_double(), type = col_character(), cases = col_double() ) ) We calculate the total number of cases per day, cumulative numbers and days since first record: dat &lt;- coronavirus |&gt; group_by(country, date, type) |&gt; summarise(tot_cases = sum(cases)) |&gt; group_by(country, type) |&gt; arrange(date) |&gt; mutate(cumulative_cases = cumsum(tot_cases)) |&gt; ungroup() |&gt; mutate( days_elapsed = as.numeric(date - min(date)), year = year(date) ) |&gt; print() #&gt; # A tibble: 650,637 × 7 #&gt; country date type tot_cases cumulative_cases days_elapsed year #&gt; &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Afghanistan 2020-01-22 confirmed 0 0 0 2020 #&gt; 2 Afghanistan 2020-01-22 death 0 0 0 2020 #&gt; 3 Afghanistan 2020-01-22 recovery 0 0 0 2020 #&gt; 4 Albania 2020-01-22 confirmed 0 0 0 2020 #&gt; 5 Albania 2020-01-22 death 0 0 0 2020 #&gt; 6 Albania 2020-01-22 recovery 0 0 0 2020 #&gt; 7 Algeria 2020-01-22 confirmed 0 0 0 2020 #&gt; 8 Algeria 2020-01-22 death 0 0 0 2020 #&gt; 9 Algeria 2020-01-22 recovery 0 0 0 2020 #&gt; 10 Andorra 2020-01-22 confirmed 0 0 0 2020 #&gt; # ℹ 650,627 more rows × Solution dat |&gt; group_by(date, type) |&gt; summarise(tot_cases = sum(tot_cases)) |&gt; print() |&gt; ggplot(aes(x = date, y = tot_cases)) + geom_col() + facet_grid(rows = vars(type), scales = &quot;free&quot;) + labs( title = &quot;Number of Covid 19 cases per day&quot;, y = &quot;cases&quot; ) #&gt; # A tibble: 3,237 × 3 #&gt; # Groups: date [1,079] #&gt; date type tot_cases #&gt; &lt;date&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 2020-01-22 confirmed 557 #&gt; 2 2020-01-22 death 17 #&gt; 3 2020-01-22 recovery 30 #&gt; 4 2020-01-23 confirmed 100 #&gt; 5 2020-01-23 death 1 #&gt; 6 2020-01-23 recovery 2 #&gt; 7 2020-01-24 confirmed 287 #&gt; 8 2020-01-24 death 8 #&gt; 9 2020-01-24 recovery 7 #&gt; 10 2020-01-25 confirmed 493 #&gt; # ℹ 3,227 more rows Close Solution × Hint 2 dat |&gt; group_by(date, type) |&gt; summarise(tot_cases = sum(tot_cases)) |&gt; print() |&gt; ggplot(aes(x = ___, y = ___)) + geom_col() + facet_grid(rows = vars(___), scales = &quot;___&quot;) + labs( title = &quot;___&quot;, y = &quot;___&quot; ) Close Hint 2 × Hint 1 dat |&gt; group_by(date, ___) |&gt; summarise(tot_cases = sum(___)) Note you must aggegrate the numbers for the countries. Close Hint 1 Calculate and plot the number of confirmed, death and recovered cases per day given date using facet_grid and geom_col. Consider the following set of countries: countries &lt;- c( &quot;China&quot;, &quot;France&quot;, &quot;Denmark&quot;, &quot;US&quot;, &quot;Italy&quot; ) × Solution dat |&gt; filter(type == &quot;death&quot;, country %in% countries) |&gt; ggplot(aes(x = days_elapsed, y = cumulative_cases, color = country)) + geom_line() + theme(legend.position = &quot;bottom&quot;) + labs( x = str_c(&quot;Days since &quot;, min(dat$date)), y = &quot;Cumulative number of deaths&quot;, title = &quot;Cumulative deaths from COVID-19, selected countries&quot; ) Close Solution × Hint 2 dat |&gt; filter(type == &quot;death&quot;, country %in% countries) |&gt; ggplot(aes(x = ___, y = ___, color = ___)) + geom_line() + theme(legend.position = &quot;bottom&quot;) + labs( x = str_c(&quot;Days since &quot;, min(dat$date)), y = &quot;___&quot;, title = &quot;Cumulative deaths from COVID-19, selected countries&quot; ) Close Hint 2 × Hint 1 dat |&gt; filter(type == &quot;___&quot;, country %in% ___) |&gt; First you have to filter type and country Close Hint 1 Plot a lineplot of the cumulative number of deaths as a function of days elapsed for the selected countries. Use country as color aesthetic. Since the countries have different population sizes, we would like to calculate some numbers relative to the population size. First we need population sizes for each country. They are given in the dataset world_pop in the tfa package: world_pop &lt;- tfa::world_pop |&gt; filter(country %in% countries) |&gt; print() #&gt; # A tibble: 1,505 × 3 #&gt; country year pop #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 China 1800 321675013 #&gt; 2 China 1801 324408862 #&gt; 3 China 1802 327165946 #&gt; 4 China 1803 329946461 #&gt; 5 China 1804 332750607 #&gt; 6 China 1805 335578586 #&gt; 7 China 1806 338430598 #&gt; 8 China 1807 341306850 #&gt; 9 China 1808 344207546 #&gt; 10 China 1809 347132894 #&gt; # ℹ 1,495 more rows We can join the datasets using: dat &lt;- dat |&gt; filter(country %in% countries) |&gt; left_join(world_pop) |&gt; print() #&gt; Joining with `by = join_by(country, year)` #&gt; # A tibble: 16,185 × 8 #&gt; country date type tot_cases cumulative_cases days_elapsed year pop #&gt; &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 China 2020-01-22 confirmed 548 548 0 2020 1424548266 #&gt; 2 China 2020-01-22 death 17 17 0 2020 1424548266 #&gt; 3 China 2020-01-22 recovery 28 28 0 2020 1424548266 #&gt; 4 Denmark 2020-01-22 confirmed 0 0 0 2020 5796800 #&gt; 5 Denmark 2020-01-22 death 0 0 0 2020 5796800 #&gt; 6 Denmark 2020-01-22 recovery 0 0 0 2020 5796800 #&gt; 7 France 2020-01-22 confirmed 0 0 0 2020 65721165 #&gt; 8 France 2020-01-22 death 0 0 0 2020 65721165 #&gt; 9 France 2020-01-22 recovery 0 0 0 2020 65721165 #&gt; 10 Italy 2020-01-22 confirmed 0 0 0 2020 59132073 #&gt; # ℹ 16,175 more rows any(is.na(dat)) # check if any missing values #&gt; [1] FALSE × Solution dat &lt;- dat |&gt; mutate(tot_cases_pop = 100000 * tot_cases/pop) Close Solution Calculate tot_cases_pop as number of cases per 100000 inhabitants. That is, total cases divided by population and multiplied by 100000. × Solution dat |&gt; filter(date &gt;= today() - days(21), type == &quot;confirmed&quot;) |&gt; ggplot(aes(x = date, y = tot_cases_pop, fill = country)) + geom_col(position = position_dodge2()) Close Solution × Hint 2 dat |&gt; filter(date &gt;= today() - days(21), type == ___) |&gt; ggplot(aes(x = date, y = ___, fill = ___)) + geom_col(position = position_dodge2()) Close Hint 2 × Hint 1 # Use this to find date 21 days ago today() - days(21) #&gt; [1] &quot;2025-07-15&quot; Close Hint 1 Plot the number of confirmed cases per 100000 inhabitants for the last 21 days. Use country as fill aesthetic. × Solution dat |&gt; filter(date &gt;= today() - days(14), country == &quot;Denmark&quot;, type == &quot;confirmed&quot;) |&gt; ggplot(aes(x = date, y = tot_cases_pop)) + geom_col() Close Solution × Hint dat |&gt; filter(date &gt;= ___, country == ___, type == ___) |&gt; ggplot(aes(x = date, y = tot_cases_pop)) + geom_col() Close Hint Plot the number of confirmed cases per 100000 inhabitants in Denmark for the last 14 days. 14.6.4 Exercise (Lego and sales) Use the exercise R Markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). Consider (simulated) data of Lego sales in 2018 for a sample of customers who bought Legos in the U.S. The dataset is called lego_sales. You can find descriptions of each of the variables in the help file for the dataset, which you can access by running ?lego_sales in your Console. You need the tidyverse package as usual and the dsbox package for the data. library(tidyverse) library(dsbox) # install using devtools::install_github(&quot;rstudio-education/dsbox&quot;) Answer the following questions using a table with numbers and try to visualize it. For each question, state your answer in a sentence, e.g. “The first three common names of purchasers are …”. What are the three most common first names of purchasers? What are the three most common themes of Lego sets purchased? Among the most common theme of Lego sets purchased, what is the most common subtheme? × Hint Use the case_when() function. Close Hint Create a new variable called age_group and group the ages into the following categories: “18 and under”, “19 - 25”, “26 - 35”, “36 - 50”, “51 and over”. × Hint You may need to consider quantity of purchases. Close Hint Which age group has purchased the highest number of Lego sets. × Hint Hint: You will need to consider quantity of purchases as well as price of Lego sets. Close Hint Which age group has spent the most money on Legos? Come up with a question you want to answer using these data, and write it down. Then, create a data visualization that answers the question, and explain how your visualization answers the question. 14.6.5 Exercise (company ranking) This exercise is a slightly modified version an exam assignment (exam 2021-A3). Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). The dataset companies, in the tfa package, lists approx. 1000 of the world’s biggest companies, measured by sales, profits, assets and market value. The column/variables are: name: the name of the company. country: the country the company is situated in. category: the products the company produces. sales: the amount of sales of the company in billion USD. profits: the profit of the company in billion USD. assets: the assets of the company in billion USD. marketvalue: the market value of the company in billion USD. You can load the dataset using: # remotes::install_github(&quot;bss-osca/tfa-package&quot;, build = FALSE) # run if tfa not installed library(tidyverse) companies &lt;- read_csv(system.file(&quot;extdata/companies.csv&quot;, package = &quot;tfa&quot;)) Answer this assignment using the ggplot2 package in tidyverse (you might need dplyr for preparing the datasets you want to plot). × Solution companies |&gt; count(category) |&gt; ggplot(aes(x = reorder(category, -n), y = n)) + geom_col() + labs(title = &quot;Number of companies in each product category&quot;, x = &quot;Product category&quot;, y = &quot;&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Based on the plot, the lowest number of companies are in the Trading companies category. Close Solution × Hint companies |&gt; count(___) |&gt; ggplot(aes(x = reorder(___, -n), y = n)) + geom_col() + labs(title = &quot;Number of companies in each product category&quot;, x = &quot;Product category&quot;, y = &quot;&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Hint Create a visualization showing the number of companies for each product category with the following features: Number of companies is represented using bars and sorted increasingly or decreasingly. Informative figure title and axis titles are given. The labels on the x-axis are rotated 90 degrees. What product category has the lowest number of companies? × Solution companies |&gt; filter(category %in% c(&quot;Drugs &amp; biotechnology&quot;, &quot;Media&quot;)) |&gt; ggplot(aes(x = sales, y = profits, color = category)) + geom_point() + geom_smooth() + labs(title = &quot;Profit given sales&quot;, x = &quot;Sales (billion USD)&quot;, y = &quot;Profit (billion USD)&quot;, color = &quot;Product Category&quot;) + theme(legend.position = &quot;bottom&quot;) #&gt; `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; Based on the plot the Drugs &amp; biotechnology product category gives the best profit. Close Solution × Hint companies |&gt; filter(category %in% c(___)) |&gt; ggplot(aes(x = ___, y = ___, color = ___)) + geom_point() + geom_smooth() + labs(title = &quot;Profit given sales&quot;, x = &quot;Sales (billion USD)&quot;, y = &quot;Profit (billion USD)&quot;, color = &quot;Product Category&quot;) + theme(legend.position = &quot;bottom&quot;) Close Hint Consider product categories Drugs &amp; biotechnology and Media. Create a visualization showing the profit given sales of each company with the following features: Different colors are used for each product category. Informative figure title and axis titles are given. A trend line for each category is added using geom_smooth. Based on the trend lines which product category gives the best profit? × Solution companies &lt;- companies |&gt; mutate(ratio = profits/sales) # Option 1 - Use a boxplot companies |&gt; filter(category %in% c(&quot;Banking&quot;, &quot;Aerospace &amp; defense&quot;)) |&gt; ggplot(aes(y = ratio, color = category)) + geom_boxplot() + labs(title = &quot;Ratio of profit/sales&quot;, x = &quot;&quot;, y = &quot;Profit/sales ratio&quot;, color = &quot;Product Category&quot;) + theme(legend.position = &quot;bottom&quot;) # Option 2 - Use a density plot companies |&gt; filter(category %in% c(&quot;Banking&quot;, &quot;Aerospace &amp; defense&quot;)) |&gt; ggplot(aes(x = ratio, fill = category)) + geom_density(alpha = 0.5) + labs(title = &quot;Ratio of profit/sales&quot;, y = &quot;Density&quot;, x = &quot;Profit/sales ratio&quot;, fill = &quot;Product Category&quot;) + theme(legend.position = &quot;bottom&quot;) Given the plot above, it can be seen that the highest ratio with respect to the mean and the median is for Banking. However, the variation is also highest here. Close Solution × Hint companies &lt;- companies |&gt; mutate(ratio = ___) companies |&gt; filter(category %in% c(___)) |&gt; ggplot(aes(y = ___, color = ___)) + geom_boxplot() + labs(title = &quot;Ratio of profit/sales&quot;, x = &quot;&quot;, y = &quot;Profit/sales ratio&quot;, color = &quot;Product Category&quot;) + theme(legend.position = &quot;bottom&quot;) Close Hint Consider product categories Banking and Aerospace &amp; defense. Let ratio denote a variable/column that equals profit divided by sales. Create a visualization showing the variation in ratio with the following features: Different colors are used for each product category. Informative figure title and axis titles are given. Based on the visualization comment on the variation and median. Which product category gives the highest ratio? × Solution continents &lt;- read_csv(system.file(&quot;extdata/continents.csv&quot;, package = &quot;tfa&quot;)) companies |&gt; left_join(continents) |&gt; filter(continent %in% c(&quot;Americas&quot;, &quot;Europe&quot;)) |&gt; filter(category %in% c(&quot;Banking&quot;, &quot;Aerospace &amp; defense&quot;, &quot;Telecommunications services&quot;, &quot;Semiconductors&quot;)) |&gt; ggplot(aes(x = marketvalue, y = assets, color = continent)) + geom_point() + geom_smooth(method = lm) + facet_wrap(vars(category), scales = &quot;free&quot;) + labs(title = &quot;Assets given market value&quot;, x = &quot;Market value (billion USD)&quot;, y = &quot;Assets (billion USD)&quot;, color = &quot;Continent&quot;) + theme(legend.position = &quot;bottom&quot;) #&gt; Joining with `by = join_by(country)` #&gt; `geom_smooth()` using formula = &#39;y ~ x&#39; By considering the trend lines for Banking, it seems that if compare companies with the same marketvalue, then companies in Europe have more assets. Close Solution × Hint continents &lt;- read_csv(system.file(&quot;extdata/continents.csv&quot;, package = &quot;tfa&quot;)) companies |&gt; left_join(___) |&gt; filter(continent %in% c(___)) |&gt; filter(category %in% c(___)) |&gt; ggplot(aes(x = ___, y = ___, color = ___)) + geom_point() + geom_smooth(method = lm) + facet_wrap(vars(___), scales = &quot;free&quot;) + labs(title = &quot;Assets given market value&quot;, x = &quot;Market value (billion USD)&quot;, y = &quot;Assets (billion USD)&quot;, color = &quot;Continent&quot;) + theme(legend.position = &quot;bottom&quot;) Close Hint The continents dataset matches countries to continents and contains two columns: country: the country. continent: the corresponding continent. You can load the dataset using: continents &lt;- read_csv(system.file(&quot;extdata/continents.csv&quot;, package = &quot;tfa&quot;)) Consider product categories Banking, Aerospace &amp; defense, Telecommunications services and Semiconductors. Create a visualization showing assets given market value for each company with the following features (hint: you may need to do a mutating join): Two continents Americas and Europe are considered. Different colors are used for each continent. A plot is given for each product category (facet). Informative figure title and axis titles are given. A trend line for each category is added using geom_smooth(method = lm). Based on the visualization consider the trend lines for Banking and comment. 14.6.6 Exercise (Titanic) This exercise is a slightly modified version an exam assignment (reexam 2021-A3). Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). The dataset titanic, given in the appendix, lists approx. 1300 passengers on Titanic. The column/variables are: pclass: Passenger class (1 = 1st; 2 = 2nd; 3 = 3rd). survived: Survival (0 = No; 1 = Yes). name: Name. sex: Sex. age: Age. fare: Passenger Fare. cabin: Cabin number. embarked: Port of embarkation (C = Cherbourg; Q = Queenstown; S = Southampton). boat: Lifeboat number. You can read the dataset file titanic.csv into the dataset dat using # remotes::install_github(&quot;bss-osca/tfa-package&quot;, build = FALSE) # run if tfa not installed library(tidyverse) dat &lt;- read_csv(system.file(&quot;extdata/titanic.csv&quot;, package = &quot;tfa&quot;)) Answer this assignment using the ggplot2 package in tidyverse (you might need dplyr for preparing the datasets you want to plot). × Solution dat &lt;- dat |&gt; mutate(harbor = case_when( embarked == &quot;C&quot; ~ &quot;Cherbourg&quot;, embarked == &quot;Q&quot; ~ &quot;Queenstown&quot;, embarked == &quot;S&quot; ~ &quot;Southampton&quot;, TRUE ~ NA_character_ )) dat |&gt; ggplot(aes(x = harbor)) + geom_bar() + labs(title = &quot;Number of persons embarking each departure harbor&quot;, x = &quot;Harbor&quot;, y = &quot;Persons&quot;) The main harbor was Southampton. Close Solution × Hint dat &lt;- dat |&gt; mutate(harbor = case_when( embarked == &quot;C&quot; ~ &quot;Cherbourg&quot;, embarked == &quot;Q&quot; ~ &quot;Queenstown&quot;, embarked == &quot;S&quot; ~ &quot;Southampton&quot;, TRUE ~ NA_character_ )) dat |&gt; ggplot(aes(x = ___)) + geom_bar() + labs(title = &quot;Number of persons embarking each departure harbor&quot;, x = &quot;Harbor&quot;, y = &quot;Persons&quot;) Close Hint Create a visualization showing the number of persons embarking the different harbors with the following features: Number of persons is represented using bars. Informative figure title and axis titles are given. The labels on the x-axis are the harbor names (not abbreviations). What harbor was the main departure harbor? × Solution dat |&gt; ggplot(aes(x = age)) + geom_histogram(binwidth = 2) + labs(title = &quot;Age distribution&quot;, x = &quot;Age&quot;, y = &quot;Persons&quot;) #&gt; Warning: Removed 263 rows containing non-finite outside the scale range (`stat_bin()`). There where most people in their twenties. Close Solution × Hint dat |&gt; ggplot(aes(x = ___)) + geom_histogram(binwidth = 2) + labs(title = &quot;Age distribution&quot;, x = &quot;Age&quot;, y = &quot;Persons&quot;) Close Hint Create a visualization showing the age distribution of the persons with the following features: Number of persons is represented using a histogram. Informative figure title and axis titles are given. Where there most people on board in their twenties or thirties? × Solution dat |&gt; ggplot(aes(x = age, y = fare, color = sex)) + geom_point() + geom_smooth() + labs(title = &quot;Fare prices given age&quot;, x = &quot;Age&quot;, y = &quot;Price&quot;, color = &quot;Sex&quot;) + theme(legend.position = &quot;bottom&quot;) #&gt; `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; #&gt; Warning: Removed 264 rows containing non-finite outside the scale range (`stat_smooth()`). #&gt; Warning: Removed 264 rows containing missing values or values outside the scale range #&gt; (`geom_point()`). Based on the trend lines females in general pays more than males. Close Solution × Hint dat |&gt; ggplot(aes(x = ___, y = ___, color = ___)) + geom_point() + geom_smooth() + labs(title = &quot;Fare prices given age&quot;, x = &quot;Age&quot;, y = &quot;Price&quot;, color = &quot;Sex&quot;) + theme(legend.position = &quot;bottom&quot;) Close Hint Create a visualization showing the fare as a function of age with the following features: Different colors are used for each sex. Informative figure title and axis titles are given. A trend line for each sex is added using geom_smooth. Based on the trend lines, do females in general pay more for a ticket? × Solution dat |&gt; ggplot(aes(x = pclass, fill = as.logical(survived))) + geom_bar(position=&quot;fill&quot;) + labs(title = &quot;Survival rate given passenger class&quot;, x = &quot;Class&quot;, y = &quot;&quot;, fill = &quot;Survived&quot;) + theme(legend.position = &quot;bottom&quot;) Based on the plot most people survived at first classs. Close Solution × Hint dat |&gt; ggplot(aes(x = ___, fill = as.logical(___))) + geom_bar(position=&quot;fill&quot;) + labs(title = &quot;Survival rate given passenger class&quot;, x = &quot;Class&quot;, y = &quot;&quot;, fill = &quot;Survived&quot;) + theme(legend.position = &quot;bottom&quot;) Close Hint Create a visualization showing the survival rate for each passenger class with the following features: Bars are used for each passenger class. All bars have same height (100 %). Colors are used to identify who survived and did not survived. Informative figure title and axis titles are given. Is the survival rate different on first and third class? × Solution dat &lt;- dat |&gt; mutate(level = str_sub(cabin, 1, 1)) dat |&gt; filter(!is.na(level)) |&gt; ggplot(aes(x = level, y = fare)) + geom_boxplot() Based on the plot the fare prices at B and C level are more or less the same. Close Solution × Hint dat &lt;- dat |&gt; mutate(level = str_sub(cabin, 1, 1)) dat |&gt; filter(!is.na(___)) |&gt; ggplot(aes(x = ___, y = ___)) + geom_boxplot() Close Hint Let column level denote the the first letter in cabin. Create a visualization showing the variance in fare prices with the following features: Ignore rows with missing level. Variation is shown using a boxplot. Informative figure title and axis titles are given. Is the fare price different at the B and C level? 14.6.7 Exercise (covid) This exercise is a slightly modified version an exam assignment (reexam 2022-A3). Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). Consider COVID-19 data obtained from Our World in Data in the file covid.csv. The dataset contains data from different countries. Some of the columns/variables are: cases: New confirmed cases of COVID-19. deaths: New deaths attributed to COVID-19. icu_patients: Number of COVID-19 patients in intensive care units (ICUs) on a given day. hosp_patients: Number of COVID-19 patients in hospital on a given day. tests: Total tests for COVID-19. positive_rate: The share of COVID-19 tests that are positive, given as a rolling 7-day average. vac: Total number of people who received at least one vaccine dose. fully_vac: Total number of people who received all doses prescribed by the vaccination protocol. population: Country population. Other columns are date, country, month and year. You can read the dataset file using # remotes::install_github(&quot;bss-osca/tfa-package&quot;, build = FALSE) # run if tfa not installed library(tidyverse) dat &lt;- read_csv(system.file(&quot;extdata/covid.csv&quot;, package = &quot;tfa&quot;)) Answer this assignment using the ggplot2 package in tidyverse (you may need dplyr for preparing the datasets you want to plot). × Solution dat |&gt; filter(country == &quot;Denmark&quot;, !is.na(cases)) |&gt; ggplot(aes(y = cases, x = date)) + geom_line(color = &quot;blue&quot;) + labs(title = &quot;Number of cases in Denmark&quot;, x = &quot;Date&quot;, y = &quot;Cases&quot; ) The number of cases in July 2020 are low. Close Solution × Hint dat |&gt; filter(___) |&gt; ggplot(aes(y = ___, x = ___)) + geom_line(color = &quot;blue&quot;) + labs(title = &quot;Number of cases in Denmark&quot;, x = &quot;Date&quot;, y = &quot;Cases&quot; ) Close Hint Create a visualization showing the number of cases for each date in Denmark with the following features: A blue line is used to visualize the data. Informative figure title and axis titles are given. Is the number of cases low or high in July 2020 in the plot? × Solution dat |&gt; group_by(country) |&gt; mutate(total_deaths = cumsum(replace_na(deaths, 0))) |&gt; mutate(total_deaths_cap = total_deaths/(population/100000)) |&gt; ggplot(aes(x = date, y = total_deaths_cap, color = country)) + geom_line() + labs(title = &quot;Total number of deaths per 100000&quot;, x = &quot;Date&quot;, y = &quot;Deaths per 100000 capita&quot;, color = &quot;Country&quot; ) + theme(legend.position = &quot;bottom&quot;) The highest relative number of deaths are for the United Kingdom. Close Solution × Hint dat |&gt; group_by(___) |&gt; mutate(total_deaths = cumsum(replace_na(deaths, 0))) |&gt; mutate(total_deaths_cap = ___) |&gt; ggplot(aes(x = ___, y = ___, color = ___)) + geom_line() + labs(title = &quot;Total number of deaths per 100000&quot;, x = &quot;Date&quot;, y = &quot;Deaths per 100000 capita&quot;, color = &quot;Country&quot; ) + theme(legend.position = &quot;bottom&quot;) Close Hint Create a visualization showing the total number of deaths per 100000 capita as a function of date with the following features: Different colours are used for each country. Lines are used to visualize the data. Legends are put at the bottom of the plot. Informative figure title and axis titles are given. Hint: you may use the cumsum function to add all deaths up until a given date. You may here consider NA values in the deaths column as equal to zero (e.g. using replace_na(deaths, 0)). Which country has the highest relative number of deaths in general? × Solution dat |&gt; filter(year == 2021) |&gt; mutate(partly = vac/population, full = fully_vac/population) |&gt; pivot_longer(cols = c(partly, full)) |&gt; ggplot() + geom_line(aes(x = date, y = value, color = name)) + facet_wrap(vars(country)) + labs(title = &quot;Percentage of vaccinated people&quot;, x = &quot;Date&quot;, y = &quot;%&quot;, color = &quot;Vac. type&quot;) + theme(legend.position = &quot;bottom&quot;) #&gt; Warning: Removed 2 rows containing missing values or values outside the scale range #&gt; (`geom_line()`). The plot showes that Denmark has the highest percentage of vaccinated people and the lowest gap between partly and full vaccinated. Close Solution × Hint dat |&gt; filter(___) |&gt; mutate(partly = ___, full = ___) |&gt; pivot_longer(cols = c(partly, full)) |&gt; ggplot() + geom_line(aes(x = ___, y = ___, color = ___)) + facet_wrap(vars(___)) + labs(title = &quot;Percentage of vaccinated people&quot;, x = &quot;Date&quot;, y = &quot;%&quot;, color = &quot;Vac. type&quot;) + theme(legend.position = &quot;bottom&quot;) Close Hint Create a visualization showing the percentage of persons vaccinated as a function of date with the following features: We consider 2021. Different colours are used to differ between vaccinated and fully vaccinated. The plot is divided using country (facet). Lines are used to visualize the data. Informative figure title and axis titles are given. Hint: If you calculated the two percentages in two new columns partly and full, then the values can be joined to one column using dat |&gt; pivot_longer(cols = c(partly, full)) Which country has the highest percentage of vaccinated people and the lowest gap between partly and fully vaccinated? × Solution dat |&gt; filter(country == &quot;Germany&quot;) |&gt; ggplot(aes(y = icu_patients)) + geom_boxplot() + facet_grid(month ~ year, scales = &quot;free_y&quot;) + labs(title = &quot;ICU patients given year and month&quot;, x = &quot;&quot;, y = &quot;Patients&quot;) + theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank(), legend.position = &quot;bottom&quot;) #&gt; Warning: Removed 63 rows containing non-finite outside the scale range (`stat_boxplot()`). In 2021 the mean value of the ICU patients was highest when considering October. Close Solution × Hint dat |&gt; filter(___) |&gt; ggplot(aes(y = ___)) + geom_boxplot() + facet_grid(___ ~ ___, scales = &quot;free_y&quot;) + labs(title = &quot;ICU patients given year and month&quot;, x = &quot;&quot;, y = &quot;Patients&quot;) + theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank(), legend.position = &quot;bottom&quot;) Close Hint Consider Germany. Create a visualization showing the variation in ICU patients with the following features: A sub-plot is given for each month and year (facet). Informative figure title and axis titles are given. In which year did the ICU have the most patients when considering October? × Solution dat |&gt; group_by(country, year) |&gt; summarise(deaths = sum(deaths/(population/100000) , na.rm = TRUE)) |&gt; ggplot(aes(y = deaths, x = country, fill = factor(year))) + geom_col(position = position_dodge()) + labs(title = &quot;Total number of deaths&quot;, x = &quot;&quot;, y = &quot;Deaths&quot;, fill = &quot;Year&quot;) + theme(legend.position = &quot;bottom&quot;) Norway had the lowest number of deaths in 2021. Close Solution × Hint dat |&gt; group_by(___) |&gt; summarise(deaths = sum(___ , na.rm = TRUE)) |&gt; ggplot(aes(y = ___, x = ___, fill = factor(___))) + geom_col(position = position_dodge()) + labs(title = &quot;Total number of deaths&quot;, x = &quot;&quot;, y = &quot;Deaths&quot;, fill = &quot;Year&quot;) + theme(legend.position = &quot;bottom&quot;) Close Hint Create a visualization showing the total number of deaths per 100000 capita for each country and year with the following features: The numbers are shown using columns for each country Different fill colours are used for year. Hint: columns for each year can be shown beside each other using position = position_dodge(). Informative figure title and axis titles are given. Which country had the lowest number of deaths in 2021? 14.6.8 Exercise (election) This exercise is a slightly modified version an exam assignment (reexam 2022-A3). Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). Answer this assignment using the ggplot2 package in tidyverse (you might need dplyr for preparing the datasets you want to plot). We work with the dataset from Assignment 2 which can be read using: # remotes::install_github(&quot;bss-osca/tfa-package&quot;, build = FALSE) # run if tfa not installed library(tidyverse) dat &lt;- read_csv(system.file(&quot;extdata/elections.csv&quot;, package = &quot;tfa&quot;)) Create a visualization showing the total number of votes for each election year with the following features: Number of votes is represented using columns. Columns are filled with colours for each party. Informative figure title and axis titles are given. × Solution dat |&gt; group_by(year, party) |&gt; summarise(votes = sum(validVotes)) |&gt; ggplot(aes(y = votes, x = factor(year), fill = party)) + geom_col() + labs(title = &quot;Total number of votes&quot;, x = &quot;Year&quot;, y = &quot;Votes&quot; ) The lowest number of votes was in 2009. Close Solution × Hint dat |&gt; group_by(___) |&gt; summarise(votes = ___) |&gt; ggplot(aes(y = ___, x = factor(year), fill = ___)) + geom_col() + labs(title = &quot;Total number of votes&quot;, x = &quot;Year&quot;, y = &quot;Votes&quot; ) Close Hint Which year had the lowest number of votes? Create a visualization showing the relative number of elected women in each municipality with the following features: The relative number of elected women is shown using columns. Municipalities are rotated 90 degrees on the x-axis. The columns are sorted increasing. Informative figure title and axis titles are given. × Solution dat |&gt; group_by(area) |&gt; summarize(electedWomen = sum(electedWomen), electedMen = sum(electedMen)) |&gt; mutate(electedWomenPct = electedWomen/(electedMen + electedWomen)) |&gt; filter(!is.na(electedWomenPct)) |&gt; ggplot(aes(x = reorder(area, electedWomenPct), y = electedWomenPct)) + geom_col() + labs(title = &quot;Relative number of elected women&quot;, x = &quot;Municipality&quot;, y = &quot;%&quot; ) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) The lowest number elected is in Ærø and the highest is in Gentofte. Close Solution × Hint dat |&gt; group_by(___) |&gt; summarize(___) |&gt; mutate(electedWomenPct = ___) |&gt; filter(!is.na(electedWomenPct)) |&gt; ggplot(aes(x = reorder(___), y = ___)) + geom_col() + labs(___) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Hint Which municipality has the lowest/highest percentage of women elected? Create a visualization showing the elected number of candidates as a function of election year with the following features: We consider only municipalities Herning, Copenhagen and Aarhus. We consider only the Social Democratic Party, Conservative Peoples Party and Liberal Democratic Party. The plot is divided using area (facet). Different colours are used for each party. Informative figure title and axis titles are given. Data points are given in the plot. A line for each party is added. × Solution dat |&gt; filter(area %in% c(&quot;Herning&quot;, &quot;Copenhagen&quot;, &quot;Aarhus&quot;), party %in% c(&quot;Social Democratic Party&quot;, &quot;Conservative Peoples Party&quot;, &quot;Liberal Democratic Party&quot;)) |&gt; mutate(elected = electedMen + electedWomen) |&gt; ggplot(aes(x = year, y = elected, color = party)) + geom_point() + geom_line() + scale_x_binned(n.breaks = 4, nice.breaks = TRUE) + facet_grid(. ~ area) + labs(title = &quot;Elected persons&quot;, x = &quot;Year&quot;, y = &quot;Elected&quot;, color = &quot;Party&quot;) + theme(legend.position = &quot;bottom&quot;) The trend for the Social Democratic Party in Copenhagen is decreasing over the years. Close Solution × Hint dat |&gt; filter(area %in% c(___), party %in% c(___)) |&gt; mutate(elected = electedMen + electedWomen) |&gt; ggplot(aes(___)) + geom_point() + geom_line() + scale_x_binned(n.breaks = 4, nice.breaks = TRUE) + facet_grid(. ~ ___) + labs(___) + theme(legend.position = &quot;bottom&quot;) Close Hint Consider the Social Democratic Party in Copenhagen. Based on the plot do the elected number of candidates increase or decrease over the election years? Create a visualization showing the relative number of women elected compared to listed (e.g. if listed is 12 and elected is 4 then the number is 4/12) with the following features: Columns are used for each party. Colours are used to identify the party. A sub-plot is given for each year. Informative figure title and axis titles are given. × Solution dat |&gt; mutate(electedW = electedWomen/listedWomen) |&gt; group_by(party, year) |&gt; summarize(electedW = mean(electedW, na.rm = T)) |&gt; ggplot(aes(x = reorder(party, electedW), y = electedW, fill = party)) + geom_col() + facet_grid(year ~ .) + labs(title = &quot;Releative number of women elected compared to listed.&quot;, x = &quot;Party&quot;, y = &quot;Percentage&quot;, fill = &quot;Party&quot;) + theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank(), legend.position = &quot;bottom&quot;) #&gt; Warning: Removed 7 rows containing missing values or values outside the scale range (`geom_col()`). For all years the Social Democratic Party has the highest number of the listed women elected. Close Solution × Hint dat |&gt; mutate(electedW = ___) |&gt; group_by(___) |&gt; summarize(___) |&gt; ggplot(aes(x = reorder(___), y = ___, fill = ___)) + ___ + theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank(), legend.position = &quot;bottom&quot;) Close Hint Which party seems to get the highest number of the listed women elected? Create a visualization showing the variance in the relative number of personal votes compared to valid votes (i.e. divide the two numbers) with the following features: We consider only municipalities Herning, Copenhagen and Aarhus. Variation is shown using a box-plot for each municipality. Informative figure title and axis titles are given. × Solution dat |&gt; filter(area %in% c(&quot;Herning&quot;, &quot;Copenhagen&quot;, &quot;Aarhus&quot;)) |&gt; mutate(personal = personalVotes/validVotes) |&gt; ggplot(aes(x = area, y = personal, fill = area)) + geom_boxplot() + labs(title = &quot;Releative number of personal votes over all the election years.&quot;, x = &quot;Municipality&quot;, y = &quot;Personal votes (pct)&quot;, fill = &quot;Municipality&quot;) + theme(legend.position = &quot;none&quot;) #&gt; Warning: Removed 34 rows containing non-finite outside the scale range (`stat_boxplot()`). Based on the plot Herning has the highest median of personal votes. Close Solution × Hint dat |&gt; filter(area %in% c(___)) |&gt; mutate(personal = ___) |&gt; ggplot(aes(___)) + geom_boxplot() + labs(title = &quot;Releative number of personal votes over all the election years.&quot;, x = &quot;Municipality&quot;, y = &quot;Personal votes (pct)&quot;, fill = &quot;Municipality&quot;) + theme(legend.position = &quot;none&quot;) Close Hint Which municipality has the highest median? 14.6.9 Exercise (orders) This exercise is a slightly modified version an exam assignment (reexam 2023-A2). Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). Answer this assignment using the ggplot2 package in tidyverse (you may need dplyr for preparing the datasets you want to plot). Consider the dataset in the file orders.csv with purchase orders for a group of ships. The dataset contains a row for each item used in an order. The columns/variables are: ship: The ship considered. order_id: Order id. An order is a group of items purchased in one batch from a single supplier. item_id: Item id. item_desc: Item description. quantity: Number of items ordered. price: Price per unit. order_date: Order date. delivery_date: Expected delivery date when order is made. delivery_place: Delivery place. recieved_date: Actual date the order is recieved. supplier: Supplier for the order. delivery_cost: Delivery cost. order_year: Year the order was placed. You can read the dataset file into the dataset dat using # remotes::install_github(&quot;bss-osca/tfa-package&quot;, build = FALSE) # run if tfa not installed library(tidyverse) dat &lt;- read_csv(system.file(&quot;extdata/orders.csv&quot;, package = &quot;tfa&quot;)) Create a visualization showing the number of purchase orders for each year with the following features: Bars are used for each year. Fill colors are used to identify the ship. Legends are put at the bottom of the plot. Informative figure title and axis titles are given. × Solution dat |&gt; group_by(order_year, order_id) |&gt; summarise(ship = first(ship)) |&gt; ggplot(aes(x = order_year, fill = ship)) + geom_bar() + labs(title = &quot;Number of orders&quot;, x = &quot;Year&quot;, y = &quot;Orders&quot;, fill = &quot;Ship&quot;) + theme(legend.position = &quot;bottom&quot;) # or # dat |&gt; # count(order_year, order_id, ship) |&gt; # ggplot(aes(x = order_year, fill = ship)) + # geom_bar() Most orders are in 2018. Close Solution × Hint dat |&gt; group_by(order_year, order_id) |&gt; summarise(ship = first(___)) |&gt; ggplot(aes(x = ___, fill = ___)) + geom_bar() + labs(title = ___, x = ___, y = ___, fill = ___) + theme(legend.position = &quot;bottom&quot;) Close Hint Which year had the most orders? Create a visualization showing the total number of items ordered for each ship with the following features: The numbers are shown using columns. Reorder the columns so they increase along the x-axis. Informative figure title and axis titles are given. × Solution res &lt;- dat |&gt; group_by(ship) |&gt; summarize(n = sum(quantity)) |&gt; arrange(desc(n)) res |&gt; ggplot(aes(x = reorder(ship, n), y = n)) + geom_col() + labs(title = &quot;Total number of items used&quot;, x = &quot;Ship&quot;, y = &quot;Items&quot;) + theme(legend.position = &quot;bottom&quot;) Most items are used for Ship-13. Close Solution × Hint res &lt;- dat |&gt; group_by(ship) |&gt; summarize(n = ___) |&gt; arrange(desc(n)) res |&gt; ggplot(aes(x = reorder(___)) + geom_col() + labs(___) + theme(legend.position = &quot;bottom&quot;) Close Hint Which ship uses most items? For each ship, create a visualization showing the number of items used as a function of done date with the following features: The numbers are shown using columns with a fixed line width of 1 and a blue color. The plot is divided using ship (facet). Hint: You may use scales = \"free_y\". Informative figure title and axis titles are given. × Solution res &lt;- dat |&gt; group_by(ship, order_date) |&gt; summarize(n = sum(quantity)) res |&gt; ggplot(aes(x = order_date, y = n)) + geom_col(linewidth = 1, color = &quot;blue&quot;) + facet_wrap(~ ship, scales = &quot;free_y&quot;) + labs(title = &quot;Number of items used&quot;, x = &quot;Date&quot;, y = &quot;Items used&quot;) On a specific date must items are used for Ship-13. Close Solution × Hint res &lt;- dat |&gt; group_by(___) |&gt; summarize(n = ___) res |&gt; ggplot(aes(___)) + geom_col(linewidth = 1, color = &quot;blue&quot;) + facet_wrap(~ ___, scales = &quot;free_y&quot;) + labs(___) Close Hint Which ship has most items used at a specific date? Consider items with id: items &lt;- c(&quot;601.003.004&quot; ,&quot;601.004.006&quot;, &quot;601.026.128&quot;, &quot;601.026.052&quot;) For each row in the dataset, calculate an index variable as price divided with the maximum item id price. Hint: Group by item id and use mutate to add the column. Create a visualization showing the index as a function of order year with the following features: The numbers are shown using points. The plot is divided using item id (facet). A trend line is added. Informative figure title and axis titles are given. × Solution res &lt;- dat |&gt; filter(item_id %in% items) |&gt; group_by(item_id) |&gt; mutate(idx = price/max(price)) res |&gt; ggplot(aes(y = idx, x = order_year)) + geom_point() + geom_smooth(se = F) + facet_wrap(~ item_id) + labs(title = &quot;Price index (index 1 = max price)&quot;, x = &quot;Order year&quot;, y = &quot;Index&quot;) #&gt; `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; #&gt; Warning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric, : pseudoinverse #&gt; used at 2019 #&gt; Warning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric, : neighborhood #&gt; radius 2.02 #&gt; Warning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric, : reciprocal #&gt; condition number 2.4348e-17 #&gt; Warning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric, : There are other #&gt; near singularities as well. 1 dat |&gt; filter(item_id %in% &quot;601.026.128&quot;) #&gt; # A tibble: 34 × 13 #&gt; ship order_id item_id item_desc quantity price order_date delivery_date delivery_place #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; &lt;date&gt; &lt;chr&gt; #&gt; 1 Ship-19 376315607101 601.026.1… Fuel val… 10 35083. 2015-05-12 2015-07-01 Delivery Plac… #&gt; 2 Ship-13 367515617501 601.026.1… O-ring, … 30 321. 2015-06-17 2015-06-23 Delivery Plac… #&gt; 3 Ship-20 376415614601 601.026.1… Spindle … 14 98589. 2015-06-26 2015-08-19 Delivery Plac… #&gt; 4 Ship-21 376515613801 601.026.1… Spindle … 4 98589. 2015-09-02 2015-09-20 Delivery Plac… #&gt; 5 Ship-14 367615627201 601.026.1… O-ring, … 12 321. 2016-01-07 2016-01-18 Delivery Plac… #&gt; 6 Ship-14 367616606902 601.026.1… O-Ring 12 321. 2016-03-30 2016-04-06 Delivery Plac… #&gt; 7 Ship-21 376516607201 601.026.1… Spindle … 7 98589. 2016-05-02 2016-07-07 Delivery Plac… #&gt; 8 Ship-20 376416611001 601.026.1… Spindle … 12 98589. 2016-05-06 2016-05-10 Delivery Plac… #&gt; 9 Ship-10 356516611701 601.026.1… O-Ring 20 321. 2016-05-17 2016-05-24 Delivery Plac… #&gt; 10 Ship-19 376316620601 601.026.1… Fuel val… 7 35083. 2016-09-09 2016-10-07 Delivery Plac… #&gt; # ℹ 24 more rows #&gt; # ℹ 4 more variables: received_date &lt;date&gt;, supplier &lt;chr&gt;, delivery_cost &lt;dbl&gt;, order_year &lt;dbl&gt; If consider item 601.026.128 it can be seen that prices are very different. By considering item description it can be seen that the item is in fact not a single product, i.e we have a misclassification of item id! Close Solution × Hint res &lt;- dat |&gt; filter(item_id %in% items) |&gt; group_by(item_id) |&gt; mutate(idx = price/max(price)) res |&gt; ggplot(___) + geom_point() + geom_smooth(se = F) + facet_wrap(~ ___) + labs(___) Close Hint Take a closer look at the item with most price fluctuations. Are the prices reasonable for a singe product? Make a summary table in the following way: Add a column val with the value of an item in a row equaling the price times quantity. Group each item id and set the total value total_value to the sum of val and calculate the total quantity purchased. Arrange the total value in descending order. Add columns: Relative total value equals total_val/sum(total_val). Relative item number equals row_number()/n(). Cumulative relative total value (cum_pct_val). Hint: You can use the cumsum function here. Class equals class = case_when(cum_pct_val &lt;= 0.8 ~ \"A\", cum_pct_val &lt;= 0.95 ~ \"B\", TRUE ~ \"C\") classifying items in A (high value items), B (middle), and C (low value items). Create a visualization showing the cumulative relative total value as a function of relative item number with the following features: Data points are given in the plot. Different colors are used for each class. Different sizes are used for each quantity. A line is added with black color and fixed size 0.3. Informative figure title and axis titles are given. × Solution res1 &lt;- dat |&gt; mutate(val = price * quantity) |&gt; group_by(item_id) |&gt; summarise(total_val = sum(val), item_desc = first(item_desc), quantity = sum(quantity)) |&gt; arrange(desc(total_val)) |&gt; mutate(pct_val = total_val/sum(total_val), pct_item = row_number()/n(), cum_pct_val = cumsum(pct_val), class = case_when( cum_pct_val &lt;= 0.8 ~ &quot;A&quot;, cum_pct_val &lt;= 0.95 ~ &quot;B&quot;, TRUE ~ &quot;C&quot; )) |&gt; # tail() |&gt; print() #&gt; # A tibble: 550 × 8 #&gt; item_id total_val item_desc quantity pct_val pct_item cum_pct_val class #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 601.003.004 20301030 Cylinder Liner IMO Number 1848… 42 0.104 0.00182 0.104 A #&gt; 2 601.026.139 16083341. Spindle Guide, Compl 169 0.0822 0.00364 0.186 A #&gt; 3 601.004.008 15029349. Piston Crown IMO Number 184826… 56 0.0768 0.00545 0.263 A #&gt; 4 601.002.078 12592313. DuraSpindle 62 0.0643 0.00727 0.327 A #&gt; 5 601.026.128 11675816. Fuel valve head 486 0.0596 0.00909 0.387 A #&gt; 6 601.004.010 8046002. Piston Rod IMO Effective Lengt… 11 0.0411 0.0109 0.428 A #&gt; 7 601.026.049 7654587. Pump barrel with plunger, comp… 46 0.0391 0.0127 0.467 A #&gt; 8 601.004.005 6631292. Piston ring, CPR-POP, H=9.5mm,… 154 0.0339 0.0145 0.501 A #&gt; 9 601.004.006 5946707. Piston Ring No. 2 &amp; 4 271 0.0304 0.0164 0.531 A #&gt; 10 601.026.052 5436342. Suction valve 135 0.0278 0.0182 0.559 A #&gt; # ℹ 540 more rows res1 |&gt; ggplot(aes(x = pct_item, y = cum_pct_val, col = class, size = quantity)) + geom_point() + geom_line(col = &quot;black&quot;, size = 0.3) + labs(title = &quot;Usage of items (one point per item)&quot;, x = &quot;Item percentage&quot;, y = &quot;Cumulative value&quot;, col = &quot;Class&quot;, size = &quot;Purchased&quot;) Items in the A class (80% of value) are approx. 7% of the total items. Close Solution × Hint res1 &lt;- dat |&gt; mutate(val = ___) |&gt; group_by(___) |&gt; summarise(total_val = ___, item_desc = first(___), quantity = ___) |&gt; arrange(desc(total_val)) |&gt; mutate(pct_val = total_val/sum(total_val), pct_item = row_number()/n(), cum_pct_val = cumsum(pct_val), class = case_when( cum_pct_val &lt;= 0.8 ~ &quot;A&quot;, cum_pct_val &lt;= 0.95 ~ &quot;B&quot;, TRUE ~ &quot;C&quot; )) |&gt; print() res1 |&gt; ggplot(aes(x = ___, y = ___, col = ___, size = ___)) + geom_point() + geom_line(col = &quot;black&quot;, size = 0.3) + labs(___) Close Hint How many items contribute to 80% of the total value? 14.6.10 Exercise (New York flights) This exercise is a larger assignment and is more extensive than the exam and is not a mandatory/part of curriculum. Do not expect such a large assignment at the exam. However, by doing this exercise you will improve your R skills which may be beneficial at the exam or when write your master thesis. A template file is given for this exercise, which should be used as a starting point (File &gt; New File &gt; R Markdown…, select From template and then TFA - New York flights template). You have as an analyst been asked to take over the analysis of the nycflights13 datasets from a former college. Your task is to finish the analysis started (see the TFA - New York flights template). We consider the datasets available from the package nycflights13 that contains information about every flight that departed from New York City in 2013. The datasets in the nycflights13 package are: #&gt; Warning in find.package(package, lib.loc, verbose = verbose): package &#39;nycflights13&#39; found more than once, using the first from #&gt; &quot;/home/runner/work/_temp/renv/cache/v5/linux-ubuntu-noble/R-4.5/x86_64-pc-linux-gnu/nycflights13/1.0.2/61eb941328b49a62d7f9816dfed7d959/nycflights13&quot;, #&gt; &quot;/home/runner/work/tfa/tfa/renv/library/linux-ubuntu-noble/R-4.5/x86_64-pc-linux-gnu/nycflights13&quot; Dataset Description airlines Airline names. airports Airport metadata flights Flights data planes Plane metadata. weather Hourly weather data Let us try to do some descriptive analytics on the different datasets. Flights Consider the flights data set, which lists all domestic flights out of the New York area in 2013. The variables are: year, month, day Date of departure dep_time,arr_time Actual departure and arrival times. sched_dep_time, sched_arr_time Scheduled departure and arrival times. dep_delay, arr_delay delays in minutes hour, minute Time of scheduled departure carrier carrier abbreviation tailnum Tail number of plane. flight flight number. origin, dest Origin and Destination air_time Time spent in air. distance Distance flown. time_hour scheduled date and hour of flight. For further details about the dataset see ?flights. Looking at the data set indicate that some flights are cancelled. We remove these observations from the dataset: dat &lt;- flights |&gt; filter(!is.na(dep_time)) Let us first try to do some mutating joins and combine variables from multiple tables. In flights we have flight information with an abbreviation for carrier (carrier), and in airlines we have a mapping between abbreviations and full names (name). You can use a join to add the carrier names to the flight data: dat &lt;- dat |&gt; left_join(airlines) |&gt; rename(carrier_name = name) |&gt; print() #&gt; Joining with `by = join_by(carrier)` #&gt; # A tibble: 328,521 × 20 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay carrier #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 2013 1 1 517 515 2 830 819 11 UA #&gt; 2 2013 1 1 533 529 4 850 830 20 UA #&gt; 3 2013 1 1 542 540 2 923 850 33 AA #&gt; 4 2013 1 1 544 545 -1 1004 1022 -18 B6 #&gt; 5 2013 1 1 554 600 -6 812 837 -25 DL #&gt; 6 2013 1 1 554 558 -4 740 728 12 UA #&gt; 7 2013 1 1 555 600 -5 913 854 19 B6 #&gt; 8 2013 1 1 557 600 -3 709 723 -14 EV #&gt; 9 2013 1 1 557 600 -3 838 846 -8 B6 #&gt; 10 2013 1 1 558 600 -2 753 745 8 AA #&gt; # ℹ 328,511 more rows #&gt; # ℹ 10 more variables: flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, #&gt; # distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, carrier_name &lt;chr&gt; Note we here join by the column carrier represented in both data frames. That is, the default argument by = c(\"carrier\" = \"carrier\") is used. If we want the full name of origin airport, we need to specify which one we want to join to since each flight has an origin and destination airport. Afterwards we do the same for the destination airport. dat &lt;- dat |&gt; left_join(airports |&gt; select(faa, name), by = c(&quot;origin&quot; = &quot;faa&quot;)) |&gt; rename(origin_name = name) |&gt; left_join(airports |&gt; select(faa, name), by = c(&quot;dest&quot; = &quot;faa&quot;)) |&gt; rename(dest_name = name) |&gt; select(month, carrier_name, origin_name, dest_name, sched_dep_time, dep_delay, arr_delay, distance, tailnum) |&gt; print() #&gt; # A tibble: 328,521 × 9 #&gt; month carrier_name origin_name dest_name sched_dep_time dep_delay arr_delay distance tailnum #&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 1 United Air Lines… Newark Lib… George B… 515 2 11 1400 N14228 #&gt; 2 1 United Air Lines… La Guardia George B… 529 4 20 1416 N24211 #&gt; 3 1 American Airline… John F Ken… Miami In… 540 2 33 1089 N619AA #&gt; 4 1 JetBlue Airways John F Ken… &lt;NA&gt; 545 -1 -18 1576 N804JB #&gt; 5 1 Delta Air Lines … La Guardia Hartsfie… 600 -6 -25 762 N668DN #&gt; 6 1 United Air Lines… Newark Lib… Chicago … 558 -4 12 719 N39463 #&gt; 7 1 JetBlue Airways Newark Lib… Fort Lau… 600 -5 19 1065 N516JB #&gt; 8 1 ExpressJet Airli… La Guardia Washingt… 600 -3 -14 229 N829AS #&gt; 9 1 JetBlue Airways John F Ken… Orlando … 600 -3 -8 944 N593JB #&gt; 10 1 American Airline… La Guardia Chicago … 600 -2 8 733 N3ALAA #&gt; # ℹ 328,511 more rows We now have the flights data we need stored in the data frame dat. Let us try to answer some questions. The questions are more open to interpretation than previous exercises. That is, you may answer them differently using data transformations and plots. How many flights leave each New York airport for each carrier? How many carrier flights per month? Which carriers/airlines have the delays? Consider Average delay Variation in delays Median values Delays of more than an hour What is the relationship between departure delay and arrival delay? Are flight delays worse at different New York airports? Are carrier flight delays different at New York airports? Does departure time affect flight delays? Does travel distance affect departure and arrival delay? Planes Let us do a mutation join so we have a bit more information about each airplane: dat &lt;- dat |&gt; left_join(planes |&gt; select(tailnum, plane_manufacturer = manufacturer, plane_model = model)) #&gt; Joining with `by = join_by(tailnum)` What is the monthly usage of all the aircrafts? Weather Consider the weather data set, which lists hourly meteorological data for LGA, JFK and EWR. We run skim to get an overview: skim(weather) Table 14.2: Data summary Name weather Number of rows 26115 Number of columns 15 _______________________ Column type frequency: character 1 numeric 13 POSIXct 1 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace origin 0 1 3 3 0 3 0 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist year 0 1.00 2013.00 0.00 2013.00 2013.0 2013.0 2013.0 2013.00 ▁▁▇▁▁ month 0 1.00 6.50 3.44 1.00 4.0 7.0 9.0 12.00 ▇▆▆▆▇ day 0 1.00 15.68 8.76 1.00 8.0 16.0 23.0 31.00 ▇▇▇▇▆ hour 0 1.00 11.49 6.91 0.00 6.0 11.0 17.0 23.00 ▇▇▆▇▇ temp 1 1.00 55.26 17.79 10.94 39.9 55.4 70.0 100.04 ▂▇▇▇▁ dewp 1 1.00 41.44 19.39 -9.94 26.1 42.1 57.9 78.08 ▁▆▇▇▆ humid 1 1.00 62.53 19.40 12.74 47.0 61.8 78.8 100.00 ▁▆▇▇▆ wind_dir 460 0.98 199.76 107.31 0.00 120.0 220.0 290.0 360.00 ▆▂▆▇▇ wind_speed 4 1.00 10.52 8.54 0.00 6.9 10.4 13.8 1048.36 ▇▁▁▁▁ wind_gust 20778 0.20 25.49 5.95 16.11 20.7 24.2 28.8 66.75 ▇▅▁▁▁ precip 0 1.00 0.00 0.03 0.00 0.0 0.0 0.0 1.21 ▇▁▁▁▁ pressure 2729 0.90 1017.90 7.42 983.80 1012.9 1017.6 1023.0 1042.10 ▁▁▇▆▁ visib 0 1.00 9.26 2.06 0.00 10.0 10.0 10.0 10.00 ▁▁▁▁▇ Variable type: POSIXct skim_variable n_missing complete_rate min max median n_unique time_hour 0 1 2013-01-01 01:00:00 2013-12-30 18:00:00 2013-07-01 14:00:00 8714 For further details see View(weather) or read the associated help file by running ?weather to bring up the help file. Observe that there is a variable called temp of hourly temperature recordings in Fahrenheit at weather stations near all three major airports in New York City: Newark (origin code EWR), John F. Kennedy International (JFK), and LaGuardia (LGA). Let us transform the temperature to Celsius: dat_w &lt;- weather |&gt; left_join(airports |&gt; select(faa, name), by = c(&quot;origin&quot; = &quot;faa&quot;)) |&gt; rename(origin_name = name) |&gt; mutate(temp = (temp - 32) * (5/9) ) |&gt; select(origin_name, time_hour, month, temp) How are the temperature fluctuating over the year? Are the temperatures different in the airports? Any insights on canceled flights? The cancelled flights are: dat_c &lt;- flights |&gt; filter(is.na(dep_time)) Do some analysis and add a few plots you think are important. Other insights? Include further analysis you think are important. 14.6.11 Exercise (jobs) This exercise is a slightly modified version an exam assignment (exam 2023-A2). Consider the dataset in the file jobs.csv with engine maintenance jobs for a group of ships. The dataset contains a row for each item used. The columns/variables are: ship: The ship considered. job_id: Maintenance job id. A job is a collection of items replaced. job_desc: Job description. item_id: Item id. item_name: Item name. item_quantity: Number of items used. item_manufaturer: Item manufacturer. component_id: Engine component id. component_desc: Engine component description. done_date: Date the job finished. year: Year of done date. days: Days since the item was last used for maintenance on the ship. You can load the data using # remotes::install_github(&quot;bss-osca/tfa-package&quot;, build = FALSE) # run if tfa not installed path &lt;- system.file(&quot;extdata/jobs.csv&quot;, package = &quot;tfa&quot;) dat &lt;- read_csv(path) Answer this assignment using the ggplot2 package in tidyverse (you may need dplyr for preparing the datasets you want to plot). × Solution dat |&gt; group_by(year, job_id) |&gt; summarise(ship = first(ship)) |&gt; ggplot(aes(x = year, fill = ship)) + geom_bar() + labs(title = &quot;Total number of jobs&quot;, x = &quot;Year&quot;, y = &quot;Jobs&quot;, fill = &quot;Ship&quot;) + theme(legend.position = &quot;bottom&quot;) Most jobs where done in 2018. Close Solution × Hint dat |&gt; group_by(___) |&gt; summarise(ship = first(___)) |&gt; ggplot(aes(x = ___, fill = ___)) + geom_bar() + labs(title = &quot;Total number of jobs&quot;, x = &quot;Year&quot;, y = &quot;Jobs&quot;, fill = &quot;Ship&quot;) + theme(legend.position = &quot;bottom&quot;) Close Hint For each year and job id, identify the ship the job was done on. Hint: The first function may be used to select the first item within a group. Use this to create a visualization showing the number of maintenance jobs for each year with the following features: Bars are used for each year. Fill colors are used to identify the ship. Legends are put at the bottom of the plot. Informative figure title and axis titles are given. Which year had the most jobs? × Solution res &lt;- dat |&gt; group_by(ship) |&gt; summarize(n = n_distinct(item_id)) |&gt; arrange(desc(n)) res |&gt; ggplot(aes(x = reorder(ship, n), y = n)) + geom_col() + labs(title = &quot;Number of unique items used&quot;, x = &quot;Ship&quot;, y = &quot;Items&quot;) + theme(legend.position = &quot;bottom&quot;) Most items are used for Ship-10. Close Solution × Hint res &lt;- dat |&gt; group_by(___) |&gt; summarize(n = n_distinct(___)) |&gt; arrange(___) res |&gt; ggplot(aes(x = reorder(___), y = ___)) + geom_col() + labs(title = &quot;Number of unique items used&quot;, x = &quot;Ship&quot;, y = &quot;Items&quot;) + theme(legend.position = &quot;bottom&quot;) Close Hint Create a visualization showing the number of different items used for each ship with the following features: The numbers are shown using columns. Reorder the columns so they increase along the x-axis. Informative figure title and axis titles are given. Which ship uses most items? × Solution res &lt;- dat |&gt; group_by(ship, done_date) |&gt; summarize(n = sum(item_quantity)) res |&gt; ggplot(aes(x = done_date, y = n)) + geom_col(linewidth = 1, color = &quot;blue&quot;) + facet_wrap(~ ship, scales = &quot;free_y&quot;) + labs(title = &quot;Number of items used&quot;, x = &quot;Date&quot;, y = &quot;Items used&quot;) On a specific date must items are used for Ship-12. Close Solution × Hint res &lt;- dat |&gt; group_by(___) |&gt; summarize(n = sum(___)) res |&gt; ggplot(aes(x = ___, y = ___)) + geom_col(linewidth = 1, color = &quot;blue&quot;) + facet_wrap(~ ship, scales = &quot;free_y&quot;) + labs(title = &quot;Number of items used&quot;, x = &quot;Date&quot;, y = &quot;Items used&quot;) Close Hint Create a visualization showing the number of items used as a function of done date with the following features: The numbers are shown using columns with a fixed line width of 1 and a blue color. The plot is divided using ship (facet). Hint: You may use scales = \"free_y\". Informative figure title and axis titles are given. Which ship has most items used at a specific date? × Solution res &lt;- dat |&gt; filter(item_id %in% items) res |&gt; ggplot(aes(item_quantity, fill = item_name)) + geom_density(bw = 1, alpha = 0.5) + facet_wrap(~ year) + labs(title = &quot;Demand density&quot;, x = &quot;Demand&quot;, y = &quot;&quot;, fill = &quot;Item&quot;) + theme(legend.position = &quot;bottom&quot;) #&gt; Warning: Groups with fewer than two data points have been dropped. #&gt; Groups with fewer than two data points have been dropped. #&gt; Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning -Inf #&gt; Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning -Inf It can be seen that over the years, the demand peak of the Piston Ring is higher that for the O-Ring, i.e. it seems to hold. Close Solution × Hint res &lt;- dat |&gt; filter(___) res |&gt; ggplot(aes(___, fill = ___)) + geom_density(bw = 1, alpha = 0.5) + facet_wrap(~ ___) + labs(title = &quot;Demand density&quot;, x = &quot;Demand&quot;, y = &quot;&quot;, fill = &quot;Item&quot;) + theme(legend.position = &quot;bottom&quot;) Close Hint Consider two items with id: items &lt;- c(&quot;601.004.006&quot;, &quot;601.026.128&quot;) Create a visualization showing the variation of demand (item quantity) of each item with the following features: A density is plotted for each item with a fixed bandwidth (bw) of 1 and transparency (alpha) of 0.5. Item name is used as fill. The plot is divided using year (facet). Informative figure title and axis titles are given. Over the years, is it consistent that on average the demand of one of the items is higher than the other? × Solution dat |&gt; filter(item_id %in% items) |&gt; ggplot(aes(y = days, x = item_id, fill = item_name)) + geom_violin() + labs(title = &quot;Violin density&quot;, x = &quot;Item id&quot;, y = &quot;Days&quot;, fill = &quot;Item&quot;) + theme(legend.position = &quot;bottom&quot;) #&gt; Warning: Removed 16 rows containing non-finite outside the scale range (`stat_ydensity()`). Most often there are less than 100 days between a repeated usage of the item, but there can be over 600 days. The Piston Ring have in general a lower number of days in between than the O-Ring on average. Close Solution × Hint dat |&gt; filter(___) |&gt; ggplot(aes(y = ___, x = ___, fill = ___)) + geom_violin() + labs(title = &quot;Violin density&quot;, x = &quot;Item id&quot;, y = &quot;Days&quot;, fill = &quot;Item&quot;) + theme(legend.position = &quot;bottom&quot;) Close Hint Consider two items with id: items &lt;- c(&quot;601.004.006&quot;, &quot;601.026.128&quot;) Create a visualization showing the variation of days since last used for maintenance given an item with the following features: A violin is used to plot days since last used given an item. Item name is used as fill. Informative figure title and axis titles are given. Comment on the plot. 14.6.12 Exercise (OneCom) Consider the case OneCom and read the introduction, Section 1 and Section 2. Next, read Section 5 and answer the questions. Data can be found at GitHub (download the raw files). When considering Question 4 assume that your forecast of demands for 2024 is found under assumptions: Sales equal demand except for the case mentioned in Question 3. The merger does not affect sales, i.e we can forecast demand for each company and the sum them. OneCom can increase sales next year since it has done it over the previous years. As a result, we assume that sales increase the same percentage for each region as from 2022 to 2023. Since there is no clear pattern for YFon, sales are assumed to be equal sales in 2023. Demand is rounded to millions. Moreover, give an answer to Question 5: Discuss how assumptions and data validation may affect how the numbers in Table 1 is estimated. May this affect the result in redesigning the supply chain network given the merger in ? How can the challenges be addressed? References Wilkinson, Leland. 2005. The Grammar of Graphics (Statistics and Computing). Springer-Verlag. "],["mod-r-dist-fit.html", "Module 15 Fitting probability distributions 15.1 Learning outcomes 15.2 Introduction 15.3 Fitting distributions to continuous data 15.4 Fitting distributions to discrete data 15.5 The Poisson process 15.6 Recap 15.7 Exercises", " Module 15 Fitting probability distributions Fitting distributions to data is a very common task in statistics and consists in choosing a probability distribution modelling the random variable, as well as finding parameter estimates for that distribution. This requires judgment and expertise and generally needs an iterative process of distribution choice, parameter estimation, and quality of fit assessment. In this module we will limit us to univariate data, i.e. univariate distributions such as normal, uniform, Poisson and exponential distributions. We will use the fitdistrplus package for fitting distributions. A template project for this module is given on Posit Cloud (open it and use it while reading the notes). 15.1 Learning outcomes By the end of this module, you are expected to: Have knowledge about different univariate distributions. Identify continuous and discrete data. Fit different distributions to data. The learning outcomes relate to the overall learning goals number 7 and 11-14 of the course. 15.2 Introduction Fitting distributions to data is a very common task in statistics and consists in choosing a probability distribution modelling the random variable, as well as finding parameter estimates for that distribution. This requires judgment and expertise and generally needs an iterative process of distribution choice, parameter estimation, and quality of fit assessment. In this module we will limit us to univariate data, i.e. univariate distributions such as a normal, uniform, Poisson and exponential distribution. Consider a dataset \\(x = (x_1, \\ldots, x_n)\\) with \\(n\\) observations which is assumed to be sample observations of a random variable \\(X\\). Our goal is to find a distribution that fit the data well and estimate the parameters of the distribution. For instance if the distribution is a normal distribution then the mean and variance should be estimated. Finding the distribution is an iterative process by considering distribution choice, parameter estimation, and quality of fit assessment repeatedly until you are satisfied. The first step is to decide if you data is should fit a discrete or continuous distribution. That is, should the random variable always take discrete values or could/are continuous values possible/okay? Note even though your sample only contain discrete values it is not necessarily samples from a discrete distribution. Consider for instance the dataset groundbeef which contains values of serving sizes in grams of ground beef patties consumed by children under 5 years old: library(fitdistrplus) #&gt; Loading required package: MASS #&gt; #&gt; Attaching package: &#39;MASS&#39; #&gt; The following object is masked from &#39;package:patchwork&#39;: #&gt; #&gt; area #&gt; The following object is masked from &#39;package:dplyr&#39;: #&gt; #&gt; select #&gt; Loading required package: survival library(tidyverse) data(&quot;groundbeef&quot;) # activate the dataset dat &lt;- as_tibble(groundbeef) str(dat) #&gt; tibble [254 × 1] (S3: tbl_df/tbl/data.frame) #&gt; $ serving: num [1:254] 30 10 20 24 20 24 40 20 50 30 ... Serving size in grams is only given using integers; however it is obvious that a continuous distribution should be fitted. We select the serving column so dat becomes a vector with the observations. dat &lt;- dat$serving 15.3 Fitting distributions to continuous data Before fitting one or more distributions to a data set, it is generally necessary to choose good candidates among a predefined set of distributions. This choice may be guided by the knowledge of stochastic processes governing the modeled variable, or, in the absence of knowledge regarding the underlying process, by the observation of its empirical distribution. We will use the fitdistrplus package for fitting distributions. Let us continue with the groundbeef dataset. First of all, it is common to start with plots of the empirical distribution function and the histogram (or density plot), which can be obtained with the plotdist function which provides two plots where the left-hand plot is by default the histogram on a density scale and the right-hand plot the empirical cumulative distribution function (CDF). plotdist(dat, histo = TRUE, demp = TRUE) Figure 15.1: Empirical density and distribution. The empirical plots of the density and the CDF may give you a hit about the distribution of \\(X\\). But often additional descriptive statistics may help to choose candidates to describe a distribution among a set of parametric distributions. Especially the skewness and kurtosis, linked to the third and fourth moments, are useful for this purpose. A non-zero skewness reveals a lack of symmetry of the empirical distribution, while the kurtosis value quantifies the weight of tails in comparison to the normal distribution for which the kurtosis equals 3. The skewness and kurtosis and their corresponding estimate are given by \\[\\begin{equation} \\label{skewness} sk(X) = \\frac{E[(X-E(X))^3]}{Var(X)^{\\frac{3}{2}}}~,~ \\widehat{sk}=\\frac{\\sqrt{n(n-1)}}{n-2}\\times\\frac{m_{3}}{m_{2}^{\\frac{3}{2}}}, \\end{equation}\\] \\[\\begin{equation} \\label{kurtosis} kr(X) = \\frac{E[(X-E(X))^4]}{Var(X)^{2}}~,~ \\widehat{kr}=\\frac{n-1}{(n-2)(n-3)}((n+1) \\times \\frac{m_{4}}{m_{2}^{2}}-3(n-1)) + 3, \\end{equation}\\] where \\(m_{2}\\), \\(m_{3}\\), \\(m_{4}\\) denote empirical moments defined by \\(m_{k}=\\frac{1}{n}\\sum_{i=1}^n(x_{i}-\\overline{x})^{k}\\), with mean value \\(\\overline{x}\\). The descdist function provides classical descriptive statistics (minimum, maximum, median, mean, standard deviation), skewness and kurtosis. A skewness-kurtosis plot such as the one proposed by Cullen and Frey (1999) is provided by the descdist function for the empirical distribution On this plot, values for common distributions are displayed in order to help the choice of distributions to fit to data. For some distributions (normal, uniform, logistic, exponential), there is only one possible value for the skewness and the kurtosis. Thus, the distribution is represented by a single point on the plot. For other distributions, areas of possible values are represented, consisting of lines (as for gamma and lognormal distributions), or areas (as for beta distribution). Nevertheless, the user needs to know that skewness and kurtosis, like all higher moments, have a very high variance. Hence the skewness-kurtosis plot should then be regarded as indicative only and the properties of the random variable should be considered, notably its expected value and its range, as a complement to the use of the plotdist and descdist functions. Below is a call to the descdist function to describe the distribution of the serving size from the groundbeef data set and to draw the corresponding skewness-kurtosis plot. Looking at the results notice that the observed skewness is positive and the kurtosis is not far from 3. Hence the fit of three common right-skewed distributions could be considered: Weibull, gamma and lognormal distributions. descdist(dat) #&gt; summary statistics #&gt; ------ #&gt; min: 10 max: 200 #&gt; median: 79 #&gt; mean: 73.6 #&gt; estimated sd: 35.9 #&gt; estimated skewness: 0.735 #&gt; estimated kurtosis: 3.55 Figure 15.2: Skewness-kurtosis plot for a continuous variable (groundbeef). Once one or more parametric distributions have been selected they are fitted to the data set using maximum likelihood. This is done using the fitdist function: fitW &lt;- fitdist(dat, distr = &quot;weibull&quot;) fitG &lt;- fitdist(dat, distr = &quot;gamma&quot;) fitL &lt;- fitdist(dat, distr = &quot;lnorm&quot;) The function returns a list with information about the fit such as the parameter estimates, the loglikelihood, the Akaike and Bayesian information criteria (the so-called AIC and BIC). An overview can be seen using the summary function: summary(fitW) #&gt; Fitting of the distribution &#39; weibull &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; shape 2.19 0.105 #&gt; scale 83.35 2.527 #&gt; Loglikelihood: -1255 AIC: 2514 BIC: 2522 #&gt; Correlation matrix: #&gt; shape scale #&gt; shape 1.000 0.322 #&gt; scale 0.322 1.000 summary(fitG) #&gt; Fitting of the distribution &#39; gamma &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; shape 4.0096 0.34145 #&gt; rate 0.0544 0.00494 #&gt; Loglikelihood: -1254 AIC: 2511 BIC: 2518 #&gt; Correlation matrix: #&gt; shape rate #&gt; shape 1.000 0.938 #&gt; rate 0.938 1.000 summary(fitL) #&gt; Fitting of the distribution &#39; lnorm &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; meanlog 4.169 0.0337 #&gt; sdlog 0.537 0.0238 #&gt; Loglikelihood: -1261 AIC: 2527 BIC: 2534 #&gt; Correlation matrix: #&gt; meanlog sdlog #&gt; meanlog 1 0 #&gt; sdlog 0 1 The fit to the data can be plotted using four classical goodness-of-fit plots (Cullen and Frey 1999): a density plot representing the density function of the fitted distribution along with the histogram of the empirical distribution, a CDF plot of both the empirical distribution and the fitted distribution, a Q-Q plot representing the empirical quantiles (y-axis) against the theoretical quantiles (x-axis), a P-P plot representing the empirical distribution function evaluated at each data point (y-axis) against the fitted distribution function (x-axis). par(mfrow = c(2, 2)) # 4 plots in one figure pLegend &lt;- c(&quot;Weibull&quot;, &quot;lognormal&quot;, &quot;gamma&quot;) lst &lt;- list(fitW, fitL, fitG) denscomp(lst, legendtext = pLegend) qqcomp(lst, legendtext = pLegend) cdfcomp(lst, legendtext = pLegend) ppcomp(lst, legendtext = pLegend) Figure 15.3: Four Goodness-of-fit plots for various distributions fitted to the serving size data. The density plot and the CDF plot may be considered as the basic classical goodness-of-fit plots. The two other plots are complementary and can be very informative in some cases. The Q-Q plot emphasizes the lack-of-fit at the distribution tails while the P-P plot emphasizes the lack-of-fit at the distribution center. In the present example, none of the three fitted distributions correctly describes the center of the distribution, but the Weibull and gamma distributions could be preferred for their better description of the right tail of the empirical distribution. Moreover, these distributions also have the lowest AIC values. Other methods can be used to fit distributions to the data instead of maximum likelihood. For details see Delignette-Muller and Dutang (2015). 15.3.1 Example: breakdown times We consider a dataset that contains the recorded breakdown times of a machine part in days. library(tfa) # update to latest version using remotes::install_github(&quot;bss-osca/tfa-package&quot;, upgrade = FALSE) dat &lt;- breakdown plotdist(dat, histo = TRUE, demp = TRUE) Since breakdown times may be seen as a continuous variable we try to fit a continuous variable. First we try to find distribution candidates: descdist(dat) #&gt; summary statistics #&gt; ------ #&gt; min: 91 max: 280 #&gt; median: 182 #&gt; mean: 183 #&gt; estimated sd: 30.7 #&gt; estimated skewness: 0.0503 #&gt; estimated kurtosis: 3.32 The observation is close to the normal and lognormal values and we try to fit these two distributions: fitN &lt;- fitdist(dat, distr = &quot;norm&quot;) fitL &lt;- fitdist(dat, distr = &quot;lnorm&quot;) summary(fitN) #&gt; Fitting of the distribution &#39; norm &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; mean 183.2 1.99 #&gt; sd 30.6 1.41 #&gt; Loglikelihood: -1142 AIC: 2288 BIC: 2295 #&gt; Correlation matrix: #&gt; mean sd #&gt; mean 1 0 #&gt; sd 0 1 summary(fitL) #&gt; Fitting of the distribution &#39; lnorm &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; meanlog 5.196 0.01130 #&gt; sdlog 0.174 0.00799 #&gt; Loglikelihood: -1148 AIC: 2300 BIC: 2306 #&gt; Correlation matrix: #&gt; meanlog sdlog #&gt; meanlog 1 0 #&gt; sdlog 0 1 par(mfrow = c(2, 2)) # 4 plots in one figure pLegend &lt;- c(&quot;normal&quot;, &quot;lognormal&quot;) lst &lt;- list(fitN, fitL) denscomp(lst, legendtext = pLegend) qqcomp(lst, legendtext = pLegend) cdfcomp(lst, legendtext = pLegend) ppcomp(lst, legendtext = pLegend) Figure 15.4: Four Goodness-of-fit plots for various distributions fitted to the breakdown data. Note it seems that the normal distribution has a better fit (AIC smallest). Also intuitively it makes sense that breakdown times are normal distributed around a mean value (however the probability of negative values should be low). 15.4 Fitting distributions to discrete data You may also need to fit discrete distributions such as: The Poisson distribution which is a discrete probability distribution that expresses the probability of a given number of events occurring in a fixed interval of time and/or space if these events occur with a known average rate and independently of the time since the last event. The Poisson distribution can be applied to systems with a large number of possible events, each of which is rare. How many such events will occur during a fixed time interval? Under the right circumstances, this is a random number following a Poisson distribution. The binomial distribution which is a probability distribution that is used to model the number of successes in a sequence of \\(n\\) independent experiments with probability \\(p\\) for success. The Bernoulli distribution is a special case of the Binomial distribution where \\(n=1\\) (one experiment). The negative binomial distribution which is a discrete probability distribution that models the number of failures in a sequence of independent and identically distributed Bernoulli trials before a specified number of successes occurs. The geometric distribution which is a special case of the negative binomial distribution where the specified number of successes are one. 15.4.1 Example: sales of lottery tickets Consider data of the number of houses that must be visited before selling 20 lottery tickets (assuming only one is sold at a time). dat &lt;- lottery plotdist(dat, discrete = TRUE) Since the number of houses that must be visited (trials) is unknown, a negative binomial distribution seems as a good choice (with 20 successes). The fit of a discrete distribution to discrete data requires the same procedure as for continuous data. fit &lt;- fitdist(dat, distr = &quot;nbinom&quot;, discrete = TRUE, fix.arg = list(size = 20)) summary(fit) #&gt; Fitting of the distribution &#39; nbinom &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; mu 37.2 1.38 #&gt; Fixed parameters: #&gt; value #&gt; size 20 #&gt; Loglikelihood: -200 AIC: 402 BIC: 404 par(mfrow = c(1, 2)) # 2 plots in one figure pLegend &lt;- c(&quot;negative binomial&quot;) lst &lt;- list(fit) denscomp(lst, legendtext = pLegend) cdfcomp(lst, legendtext = pLegend) Figure 15.5: Four Goodness-of-fit plots for various distributions fitted to the breakdown data. Note only the density and CDF is plotted for discrete data. Moreover, this is an example where some of the parameters of the negative binomial distribution are known in advance. The negative binomial distribution has two parameters (see ?pnbinom): the specified number of successes to occur (size argument) and the probability of success in each trial (prob argument). Given the information about the dataset, size equals 20 and we want to to try finding the probability of success in each trial. You fix a parameter by using the fix.arg argument in fitdist. Note that the summary only outputs the mean estimate mu but prob = size/(size+mu): prob &lt;- 20/(20 + fit$estimate) names(prob) &lt;- NULL prob #&gt; [1] 0.35 That is the probability of success when visiting each house is approx. 35% and e.g. the number of houses that must be visited before all lottery tickets are sold with 95% probability is: qnbinom(0.95, size = 20, prob) #&gt; [1] 55 15.5 The Poisson process A Poisson process models a series of discrete events. The average time between events is known, but the exact timing of events is random: the waiting time between events are exponential distributed. Since the exponential distribution is memoryless, the arrival time of an event is independent of what happend in the past (e.g. the arrival time of the last event). A Poisson process is often used in queueing theory to model random events, such as the arrival of customers at a store or phone calls arriving at a call center. More formally a Poisson process is defined as process counting the total number of events \\(N(t)\\) at time \\(t\\) given the average arrival rate \\(\\lambda\\). The process satisfy that: \\(N(0)=0\\); The waiting time between events is exponential distributed with rate \\(\\lambda\\); The number of arrivals in any interval of length \\(\\tau\\) is Poisson distributed with parameter \\(\\tau\\lambda\\) The arrivals in a Poisson process with on average 4 arrivals per time unit (\\(\\lambda=4\\)) may look like: Let us consider the data set demand_goods containing demand for two different goods/products: library(tfa) # update to latest version using remotes::install_github(&quot;bss-osca/tfa-package&quot;, upgrade = FALSE) demand_goods #&gt; # A tibble: 362 × 3 #&gt; date demand product #&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2016-01-01 00:00:00 8 1 #&gt; 2 2016-01-06 00:00:00 10 1 #&gt; 3 2016-01-08 00:00:00 10 1 #&gt; 4 2016-01-11 00:00:00 7 1 #&gt; 5 2016-01-22 00:00:00 9 1 #&gt; 6 2016-02-01 00:00:00 8 1 #&gt; 7 2016-02-05 00:00:00 8 1 #&gt; 8 2016-02-06 00:00:00 7 1 #&gt; 9 2016-02-13 00:00:00 9 1 #&gt; 10 2016-02-14 00:00:00 8 1 #&gt; # ℹ 352 more rows The arrival of demands and demand size may follow a compound Poisson process which differ from a Poisson process by allowing more than a demand of one given an arrival. That is, the inter arrival times should still follow an exponential distribution. Let us find the inter arrival times between each order and try to fit it: library(tidyverse) datDf &lt;- demand_goods |&gt; group_by(product) |&gt; mutate(between = as.numeric(date - lag(date), units=&quot;days&quot;)) |&gt; print() #&gt; # A tibble: 362 × 4 #&gt; # Groups: product [2] #&gt; date demand product between #&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2016-01-01 00:00:00 8 1 NA #&gt; 2 2016-01-06 00:00:00 10 1 5 #&gt; 3 2016-01-08 00:00:00 10 1 2 #&gt; 4 2016-01-11 00:00:00 7 1 3 #&gt; 5 2016-01-22 00:00:00 9 1 11 #&gt; 6 2016-02-01 00:00:00 8 1 10 #&gt; 7 2016-02-05 00:00:00 8 1 4 #&gt; 8 2016-02-06 00:00:00 7 1 1 #&gt; 9 2016-02-13 00:00:00 9 1 7 #&gt; 10 2016-02-14 00:00:00 8 1 1 #&gt; # ℹ 352 more rows dat &lt;- datDf |&gt; filter(product == 1, !is.na(between)) |&gt; pull(between) plotdist(dat, histo = TRUE, demp = TRUE) descdist(dat) #&gt; summary statistics #&gt; ------ #&gt; min: 0 max: 33 #&gt; median: 4 #&gt; mean: 5.08 #&gt; estimated sd: 4.72 #&gt; estimated skewness: 1.85 #&gt; estimated kurtosis: 8.86 The observation is close to the exponential and lognormal values. However, a lognormal distribution cannot equal zero values: fitE1 &lt;- fitdist(dat, distr = &quot;exp&quot;) summary(fitE1) #&gt; Fitting of the distribution &#39; exp &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; rate 0.197 0.0135 #&gt; Loglikelihood: -557 AIC: 1115 BIC: 1119 par(mfrow = c(2, 2)) # 4 plots in one figure pLegend &lt;- c(&quot;exp&quot;) lst &lt;- list(fitE1) denscomp(lst, legendtext = pLegend) qqcomp(lst, legendtext = pLegend) cdfcomp(lst, legendtext = pLegend) ppcomp(lst, legendtext = pLegend) Figure 15.6: Four Goodness-of-fit plots for various distributions fitted to the breakdown data. The fit seems okay. Note that the horizontal and vertical points in the Q-Q and P-P plot indicate that another scale on measuring the inter arrival times would have been better (such as hours or minutes). Using days may round the numbers to much. Let us do the analysis for product 2: dat &lt;- datDf |&gt; filter(product == 2, !is.na(between)) |&gt; pull(between) plotdist(dat, histo = TRUE, demp = TRUE) descdist(dat) #&gt; summary statistics #&gt; ------ #&gt; min: 0 max: 41 #&gt; median: 5 #&gt; mean: 7.36 #&gt; estimated sd: 7.26 #&gt; estimated skewness: 2 #&gt; estimated kurtosis: 8.4 The observation is close to the exponential values: fitE2 &lt;- fitdist(dat, distr = &quot;exp&quot;) summary(fitE2) #&gt; Fitting of the distribution &#39; exp &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; rate 0.136 0.0112 #&gt; Loglikelihood: -444 AIC: 889 BIC: 892 par(mfrow = c(2, 2)) # 4 plots in one figure pLegend &lt;- c(&quot;exp&quot;) lst &lt;- list(fitE2) denscomp(lst, legendtext = pLegend) qqcomp(lst, legendtext = pLegend) cdfcomp(lst, legendtext = pLegend) ppcomp(lst, legendtext = pLegend) Figure 15.7: Four Goodness-of-fit plots for various distributions fitted to the breakdown data. Again the fit seems okay. To summarize the demand rate for product 1 is estimated to be 0.2 per day and for product 2 to be 0.14 per day. Given a demand arrive the question is how much is the demand size? That is, we have to fit a distribution to the demand. Let us do the analysis for product 2: dat &lt;- datDf |&gt; filter(product == 2) |&gt; pull(demand) plotdist(dat, histo = TRUE, demp = TRUE, discrete = TRUE) Let us try to fit the negative binomial, Poisson and geometric distribution: fitN2 &lt;- fitdist(dat, distr = &quot;nbinom&quot;) fitP2 &lt;- fitdist(dat, distr = &quot;pois&quot;) fitG2 &lt;- fitdist(dat, distr = &quot;geom&quot;) summary(fitN2) #&gt; Fitting of the distribution &#39; nbinom &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; size 3.83 0.939 #&gt; mu 3.19 0.198 #&gt; Loglikelihood: -321 AIC: 645 BIC: 651 #&gt; Correlation matrix: #&gt; size mu #&gt; size 1.000000 -0.000436 #&gt; mu -0.000436 1.000000 summary(fitP2) #&gt; Fitting of the distribution &#39; pois &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; lambda 3.19 0.146 #&gt; Loglikelihood: -340 AIC: 683 BIC: 686 summary(fitG2) #&gt; Fitting of the distribution &#39; geom &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; prob 0.239 0.0171 #&gt; Loglikelihood: -343 AIC: 688 BIC: 691 par(mfrow = c(1, 2)) pLegend &lt;- c(&quot;neg binomial&quot;, &quot;Poisson&quot;, &quot;geometric&quot;) lst &lt;- list(fitN2, fitP2, fitG2) denscomp(lst, legendtext = pLegend) cdfcomp(lst, legendtext = pLegend) Figure 15.8: Four Goodness-of-fit plots for various distributions fitted to the breakdown data. The negative binomial seems to give the best fit and may be a good candidate. 15.6 Recap Fitting distributions to data is a very common task in statistics and consists in choosing a probability distribution modelling the random variable, as well as finding parameter estimates for that distribution. Fitting a univariate distribution requires judgment and expertise and generally needs an iterative process of distribution choice, parameter estimation, and quality of fit assessment. Steps may be: Examine data a decide on discrete vs continuous distribution. Find a set of candidate distributions. Fit the distributions using statistical methods and consider various plots. Decide on a distribution The AIC value may give you an indication about the best model fit. Other methods can be used to fit distributions to the data instead of maximum likelihood. For details see Delignette-Muller and Dutang (2015). This module have only considered uncensored data. See Delignette-Muller and Dutang (2015) on how to handle censored data. You may also have a look at the slides for this module . 15.7 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Some of the solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up too early. Put some effort into finding a solution! Always practice using shortcuts in RStudio (see Tools &gt; Keyboard Shortcuts Help). Go to the Tools for Analytics workspace and download/export the TM15 project. Open it on your laptop and have a look at the files in the exercises folder which can be used as a starting point. 15.7.1 Exercise - Call center Consider data from a call center: the Los Angeles 311 Call Center in 2014 from 8-17: library(tidyverse) library(tfa) library(skimr) skim(calls) Table 15.1: Data summary Name calls Number of rows 855077 Number of columns 6 _______________________ Column type frequency: character 3 difftime 1 numeric 1 POSIXct 1 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace department 79892 0.91 2 6 0 60 0 service 79892 0.91 4 70 0 1304 0 solved_how 0 1.00 3 30 0 17 0 Variable type: difftime skim_variable n_missing complete_rate min max median n_unique time 0 1 28800 secs 61200 secs 12:00:10 31964 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist zip 19512 0.98 91653 5420 0 90029 90094 91403 99999 ▁▁▁▁▇ Variable type: POSIXct skim_variable n_missing complete_rate min max median n_unique date 0 1 2014-01-01 2014-12-31 2014-07-04 363 We first transform the dataset a bit: library(lubridate) calls &lt;- calls |&gt; group_by(date) |&gt; arrange(date, time) |&gt; mutate( arrival = row_number(), wday = wday(date, label = TRUE), hour = hour(time), between = time - lag(time) ) × Solution arrival = number of arrivals on the given day, wday = weekday, hour = hour considered, between = time between calls in secs (inter arrival times). Close Solution Explain the new columns. The number of calls may follow a Poisson process with a fixed rate of calls per hour during the day. Let us try to plot the hourly rates: calls |&gt; count(date, hour, wday) |&gt; group_by(hour, wday) |&gt; summarize(rate = mean(n)) |&gt; ggplot(aes(x = hour, y = rate)) + geom_line() + facet_wrap(~wday) + ylab(&quot;calls/hour&quot;) × Solution As can be seen the rate is not constaint over the day (we don’t have a homogeneous Possion process). Moreover, in weekends the rate is much lower. Close Solution Is the rate constant during a day and is the rate the same for different weekdays (explain)? Since the rate is not fixed we may have a non-homogeneous Poisson process where the rate change during the day. Hence let us try to consider an specific hour and test if the rate here can be considered as fixed (i.e. we have a Poisson process with a fixed rate when considering a specific hour) × Solution library(fitdistrplus) dat &lt;- calls |&gt; filter( wday == &quot;Tue&quot;, hour == 10, !is.na(between)) |&gt; pull(between) |&gt; as.numeric() descdist(dat) #&gt; summary statistics #&gt; ------ #&gt; min: 1 max: 98 #&gt; median: 6 #&gt; mean: 9.01 #&gt; estimated sd: 8.35 #&gt; estimated skewness: 1.95 #&gt; estimated kurtosis: 8.73 fit1 &lt;- fitdist(dat, distr = &quot;exp&quot;) fit2 &lt;- fitdist(dat, distr = &quot;lnorm&quot;) fit3 &lt;- fitdist(dat, distr = &quot;gamma&quot;) summary(fit1) #&gt; Fitting of the distribution &#39; exp &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; rate 0.111 0.00077 #&gt; Loglikelihood: -66456 AIC: 132914 BIC: 132922 summary(fit2) #&gt; Fitting of the distribution &#39; lnorm &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; meanlog 1.779 0.00673 #&gt; sdlog 0.971 0.00476 #&gt; Loglikelihood: -65826 AIC: 131657 BIC: 131673 #&gt; Correlation matrix: #&gt; meanlog sdlog #&gt; meanlog 1.00e+00 -1.11e-10 #&gt; sdlog -1.11e-10 1.00e+00 summary(fit3) #&gt; Fitting of the distribution &#39; gamma &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; shape 1.333 0.01180 #&gt; rate 0.148 0.00158 #&gt; Loglikelihood: -65966 AIC: 131936 BIC: 131952 #&gt; Correlation matrix: #&gt; shape rate #&gt; shape 1.000 0.827 #&gt; rate 0.827 1.000 par(mfrow = c(2, 2)) # 4 plots in one figure pLegend &lt;- c(&quot;exp&quot;, &quot;lnorm&quot;, &quot;gamma&quot;) lst &lt;- list(fit1, fit2, fit3) denscomp(lst, legendtext = pLegend) qqcomp(lst, legendtext = pLegend) cdfcomp(lst, legendtext = pLegend) ppcomp(lst, legendtext = pLegend) For a Poisson process the inter arrival times should follow an exponential distribution. It seems to be a good fit here. Close Solution × Hint library(fitdistrplus) dat &lt;- calls |&gt; filter( wday == ___, hour == ___ !is.na(between)) |&gt; pull(between) |&gt; as.numeric() |&gt; print() descdist(dat) ___ # try to fit the exp, lnorm and gamma Close Hint Consider Tuesdays from 10-11 and fit the inter arrival times (between). If the data follow a Poisson process then the distribution should be? × Solution library(fitdistrplus) dat &lt;- calls |&gt; filter( wday == &quot;Tue&quot;, hour == 15, !is.na(between)) |&gt; pull(between) |&gt; as.numeric() descdist(dat) #&gt; summary statistics #&gt; ------ #&gt; min: 1 max: 103 #&gt; median: 7 #&gt; mean: 9.99 #&gt; estimated sd: 9.41 #&gt; estimated skewness: 2.01 #&gt; estimated kurtosis: 9.13 fit12 &lt;- fitdist(dat, distr = &quot;exp&quot;) fit22 &lt;- fitdist(dat, distr = &quot;lnorm&quot;) fit32 &lt;- fitdist(dat, distr = &quot;gamma&quot;) summary(fit12) #&gt; Fitting of the distribution &#39; exp &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; rate 0.1 0.000731 #&gt; Loglikelihood: -61883 AIC: 123768 BIC: 123776 summary(fit22) #&gt; Fitting of the distribution &#39; lnorm &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; meanlog 1.872 0.00719 #&gt; sdlog 0.985 0.00509 #&gt; Loglikelihood: -61398 AIC: 122800 BIC: 122816 #&gt; Correlation matrix: #&gt; meanlog sdlog #&gt; meanlog 1 0 #&gt; sdlog 0 1 summary(fit32) #&gt; Fitting of the distribution &#39; gamma &#39; by maximum likelihood #&gt; Parameters : #&gt; estimate Std. Error #&gt; shape 1.306 0.01215 #&gt; rate 0.131 0.00147 #&gt; Loglikelihood: -61501 AIC: 123007 BIC: 123022 #&gt; Correlation matrix: #&gt; shape rate #&gt; shape 1.000 0.824 #&gt; rate 0.824 1.000 par(mfrow = c(2, 2)) # 4 plots in one figure pLegend &lt;- c(&quot;exp&quot;, &quot;lnorm&quot;, &quot;gamma&quot;) lst &lt;- list(fit12, fit22, fit32) denscomp(lst, legendtext = pLegend) qqcomp(lst, legendtext = pLegend) cdfcomp(lst, legendtext = pLegend) ppcomp(lst, legendtext = pLegend) Close Solution Consider Tuesdays from 15-16 and fit the inter arrival times (between). × Solution fit1$estimate * 60 * 60 # 10-11 #&gt; rate #&gt; 400 fit12$estimate * 60 * 60 # 15-16 #&gt; rate #&gt; 360 The rate is higher (40 calls more per hour) in period 10-11. Close Solution × Hint You have to look at the estimates of the rate. Close Hint What is the estimated arrival rate per hour Tuesday 10-11 and 15-16? Is the arrival rate the same? References Cullen, A. C., and H. C. Frey. 1999. The Use of Probabilistic Techniques in Exposure Assessment. Plenum. Delignette-Muller, Marie Laure, and Christophe Dutang. 2015. “Fitdistrplus: An r Package for Fitting Distributions.” Journal of Statistical Software 64 (4): 1–34. https://doi.org/10.18637/jss.v064.i04. "],["mod-r-maps.html", "Module 16 Spatial data and maps 16.1 Learning outcomes 16.2 Services for obtatining spatial data 16.3 Calculating distances 16.4 Geocoding and reverse geocoding 16.5 Adding markers and routes to a map", " Module 16 Spatial data and maps Spatial data, also known as geospatial data, is a term used to describe any data related to or containing information about a specific location on a surface (often a map). We will consider distance matrix calculations for finding the shortest distance/travel time between a set of origins and destinations, geocoding which is the process of converting an address to geographic coordinates (latitude, longitude) and reverse geocoding which is the opposite process of converting a location as described by geographic coordinates (latitude, longitude) to a human-readable address or place name. Finally, we consider how to display spatial data on a map. 16.1 Learning outcomes By the end of this module, you are expected to be able to: Calculate euclidean, manhattan, etc. distances. Calculate a distance matrix, i.e. shortest paths between places using the Google and Bing API. Geocode an address using the Google and Bing API. Add markers and routes (lines) on a map. 16.2 Services for obtatining spatial data Often you need to connect to a service using an API for obtaining spatial data. The most common is Google and Bing (Microsoft) and to use the services you need an API key. Another service is also Here. If you use Google Maps you can obtain an API key here. Modest to light use is free; however, you need a valid credit card. Note you must enable the APIs you intend to use. Google in fact has several services for geo-related solutions. For example, the Maps Static API provides map images, while the Geocoding API provides geocoding and reverse geocoding services. You need to enable the APIs before you use them. You will only need to do that once, and then they will be ready for you to use. Enabling the APIs just means clicking a few radio buttons on the Google Maps Platform web interface. We will be using the ggmap package for Google services. You can add the API key using: library(ggmap) register_google(key = &quot;[your key]&quot;, write = TRUE) Sys.getenv(&quot;GGMAP_GOOGLE_API_KEY&quot;) Note the key is stored in the environment object GGMAP_GOOGLE_API_KEY. Moreover, it is saved in the file .Renviron so that it is automatically reloaded when you restart R. If you use Bing Maps you can obtain an API key here. No credit card is needed. You can add the API key using: usethis::edit_r_environ() # opens the .Renviron file Sys.setenv(BING_MAPS_API_KEY=[your key]) # so you don&#39;t have to restart R Add the line BING_MAPS_API_KEY=[your key] and save the file. Note your API keys is private and unique to you, so be careful not to share it online! 16.3 Calculating distances If you need to calculate euclidean, manhattan, etc. distances, you can use the dist R function: coord &lt;- matrix(c(0,0, 0,1, 1,0, 1,1), ncol = 2, byrow = TRUE) coord #&gt; [,1] [,2] #&gt; [1,] 0 0 #&gt; [2,] 0 1 #&gt; [3,] 1 0 #&gt; [4,] 1 1 dist(coord) #&gt; 1 2 3 #&gt; 2 1.00 #&gt; 3 1.00 1.41 #&gt; 4 1.41 1.00 1.00 as.matrix(dist(coord)) #&gt; 1 2 3 4 #&gt; 1 0.00 1.00 1.00 1.41 #&gt; 2 1.00 0.00 1.41 1.00 #&gt; 3 1.00 1.41 0.00 1.00 #&gt; 4 1.41 1.00 1.00 0.00 However, euclidean distances are often a poor approximation of shortest path lengths. 16.3.1 Using Google Maps Remember to have set your API key and activate the Distance Matrix API service on the Google Cloud Platform. We consider the following places: library(ggmap) #&gt; ℹ Google&#39;s Terms of Service: &lt;https://mapsplatform.google.com&gt; #&gt; Stadia Maps&#39; Terms of Service: &lt;https://stadiamaps.com/terms-of-service&gt; #&gt; OpenStreetMap&#39;s Tile Usage Policy: &lt;https://operations.osmfoundation.org/policies/tiles&gt; #&gt; ℹ Please cite ggmap if you use it! Use `citation(&quot;ggmap&quot;)` for details. library(tidyverse) dat &lt;- tibble::tribble( ~Id, ~Shop, ~Address, 1L, &quot;Bilka Esbjerg&quot;, &quot;Stormgade 157, 6715 Esbjerg, Denmark&quot;, 2L, &quot;Bilka Herning&quot;, &quot;Golfvej 5, 7400 Herning, Denmark&quot;, 3L, &quot;Bilka Hillerød&quot;, &quot;Slotsarkaderne 26, 3400 Hillerød, Denmark&quot;, 4L, &quot;Bilka Hjørring&quot;, &quot;A.F Heidemannsvej 20, 9800 Hjørring, Denmark&quot;, 5L, &quot;Bilka Holstebro&quot;, &quot;Nyholmvej 20, 7500 Holstebro, Denmark&quot;, ) dat #&gt; # A tibble: 5 × 3 #&gt; Id Shop Address #&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 1 Bilka Esbjerg Stormgade 157, 6715 Esbjerg, Denmark #&gt; 2 2 Bilka Herning Golfvej 5, 7400 Herning, Denmark #&gt; 3 3 Bilka Hillerød Slotsarkaderne 26, 3400 Hillerød, Denmark #&gt; 4 4 Bilka Hjørring A.F Heidemannsvej 20, 9800 Hjørring, Denmark #&gt; 5 5 Bilka Holstebro Nyholmvej 20, 7500 Holstebro, Denmark To calculate a distance matrix we use the mapdist function: mapdist(from = &quot;Stormgade 157, 6715 Esbjerg, Denmark&quot;, to = &quot;Golfvej 5, 7400 Herning, Denmark&quot;) #&gt; ℹ &lt;https://maps.googleapis.com/maps/api/distancematrix/json?origins=Stormgade+157,+6715+Esbjerg,+Denmark&amp;destinations=Golfvej+5,+7400+Herning,+Denmark&amp;key=xxx-RC0wa23c&amp;mode=driving&gt; #&gt; # A tibble: 1 × 9 #&gt; from to m km miles seconds minutes hours mode #&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 Stormgade 157, 6715 Esbjerg, Denmark Golfvej 5, 740… 90193 90.2 56.0 4502 75.0 1.25 driv… Note Google returns results for the fastest path between the two points. Let us try to define a function which calculate all the distances: #&#39; Calculate the distance matrix in long format. #&#39; #&#39; @param address A vector of addresses. #&#39; @param mode Driving, bicycling, walking, or transit. #&#39; @param symmetric Use symmetric distances (half the number of queries). #&#39; @return A data frame with the results #&#39; @note The API returns results for the fastest route. goo_calc_distances &lt;- function(address, mode = &quot;driving&quot;, symmetric = TRUE) { datDist &lt;- expand_grid(id_from = 1:length(address), id_to = 1:length(address)) datDist &lt;- datDist |&gt; filter(id_from != id_to) if (symmetric) datDist &lt;- datDist |&gt; filter(id_from &lt; id_to) datDist &lt;- datDist |&gt; mutate(from = address[id_from], to = address[id_to]) res &lt;- mapdist(from = datDist |&gt; pull(from), to = datDist |&gt; pull(to), mode = mode) return(left_join(datDist, res, by = c(&quot;from&quot;, &quot;to&quot;))) } datDistGoo &lt;- goo_calc_distances(dat$Address) #&gt; ℹ &lt;https://maps.googleapis.com/maps/api/distancematrix/json?origins=A.F+Heidemannsvej+20,+9800+Hj%C3%B8rring,+Denmark&amp;destinations=Nyholmvej+20,+7500+Holstebro,+Denmark&amp;key=xxx-RC0wa23c&amp;mode=driving&gt; #&gt; ℹ &lt;https://maps.googleapis.com/maps/api/distancematrix/json?origins=Golfvej+5,+7400+Herning,+Denmark&amp;destinations=Slotsarkaderne+26,+3400+Hiller%C3%B8d,+Denmark%7CA.F+Heidemannsvej+20,+9800+Hj%C3%B8rring,+Denmark%7CNyholmvej+20,+7500+Holstebro,+Denmark&amp;key=xxx-RC0wa23c&amp;mode=driving&gt; #&gt; ℹ &lt;https://maps.googleapis.com/maps/api/distancematrix/json?origins=Slotsarkaderne+26,+3400+Hiller%C3%B8d,+Denmark&amp;destinations=A.F+Heidemannsvej+20,+9800+Hj%C3%B8rring,+Denmark%7CNyholmvej+20,+7500+Holstebro,+Denmark&amp;key=xxx-RC0wa23c&amp;mode=driving&gt; #&gt; ℹ &lt;https://maps.googleapis.com/maps/api/distancematrix/json?origins=Stormgade+157,+6715+Esbjerg,+Denmark&amp;destinations=Golfvej+5,+7400+Herning,+Denmark%7CSlotsarkaderne+26,+3400+Hiller%C3%B8d,+Denmark%7CA.F+Heidemannsvej+20,+9800+Hj%C3%B8rring,+Denmark%7CNyholmvej+20,+7500+Holstebro,+Denmark&amp;key=xxx-RC0wa23c&amp;mode=driving&gt; datDistGoo #&gt; # A tibble: 10 × 11 #&gt; id_from id_to from to m km miles seconds minutes hours mode #&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 1 2 Stormgade 157, 6715 Esbjerg, … Golf… 90193 90.2 56.0 4502 75.0 1.25 driv… #&gt; 2 1 3 Stormgade 157, 6715 Esbjerg, … Slot… 321056 321. 200. 11857 198. 3.29 driv… #&gt; 3 1 4 Stormgade 157, 6715 Esbjerg, … A.F … 322085 322. 200. 12039 201. 3.34 driv… #&gt; 4 1 5 Stormgade 157, 6715 Esbjerg, … Nyho… 102506 103. 63.7 5414 90.2 1.50 driv… #&gt; 5 2 3 Golfvej 5, 7400 Herning, Denm… Slot… 332610 333. 207. 12275 205. 3.41 driv… #&gt; 6 2 4 Golfvej 5, 7400 Herning, Denm… A.F … 176051 176. 109. 7922 132. 2.20 driv… #&gt; 7 2 5 Golfvej 5, 7400 Herning, Denm… Nyho… 44262 44.3 27.5 1891 31.5 0.525 driv… #&gt; 8 3 4 Slotsarkaderne 26, 3400 Hille… A.F … 355446 355. 221. 18087 301. 5.02 driv… #&gt; 9 3 5 Slotsarkaderne 26, 3400 Hille… Nyho… 375164 375. 233. 13857 231. 3.85 driv… #&gt; 10 4 5 A.F Heidemannsvej 20, 9800 Hj… Nyho… 181389 181. 113. 7982 133. 2.22 driv… Note that only the calculated distances are returned. If you want to have the whole distance matrix we define function: #&#39; Convert the data frame returned from calling a `___calc_distances` function to a distance matrix. #&#39; #&#39; @param dat The data frame returned from calling `___calc_distances`. #&#39; @param value_col The column containing the distances. #&#39; @return The distance matrix as_dist_matrix &lt;- function(dat, value_col) { lgt &lt;- max(dat$id_from, dat$id_to) distanceMat&lt;-matrix(NA, nrow=lgt, ncol = lgt) diag(distanceMat) &lt;- 0 map(1:nrow(dat), function(r) { distanceMat[dat$id_from[r], dat$id_to[r]] &lt;&lt;- dat[[value_col]][r] }) idx &lt;- which(is.na(distanceMat), arr.ind = TRUE) map(1:nrow(idx), function(r) { distanceMat[idx[r, &quot;row&quot;], idx[r, &quot;col&quot;]] &lt;&lt;- distanceMat[idx[r, &quot;col&quot;], idx[r, &quot;row&quot;]] }) return(distanceMat) } as_dist_matrix(datDistGoo, &quot;km&quot;) # distances in km #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] 0.0 90.2 321 322 102.5 #&gt; [2,] 90.2 0.0 333 176 44.3 #&gt; [3,] 321.1 332.6 0 355 375.2 #&gt; [4,] 322.1 176.1 355 0 181.4 #&gt; [5,] 102.5 44.3 375 181 0.0 as_dist_matrix(datDistGoo, &quot;seconds&quot;) # travel time in seconds #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] 0 4502 11857 12039 5414 #&gt; [2,] 4502 0 12275 7922 1891 #&gt; [3,] 11857 12275 0 18087 13857 #&gt; [4,] 12039 7922 18087 0 7982 #&gt; [5,] 5414 1891 13857 7982 0 16.4 Geocoding and reverse geocoding 16.4.1 Using Google maps Remember to enable the Geocoding API. To get the coordinates of an address we use the geocode function: geocode(&quot;Stormgade 157, 6715 Esbjerg, Denmark&quot;) #&gt; ℹ &lt;https://maps.googleapis.com/maps/api/geocode/json?address=Stormgade+157,+6715+Esbjerg,+Denmark&amp;key=xxx-RC0wa23c&gt; #&gt; # A tibble: 1 × 2 #&gt; lon lat #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 8.46 55.5 We may use mutate_geocode to add the coordinates to a dataset: dat &lt;- dat |&gt; mutate_geocode(Address) #&gt; ℹ &lt;https://maps.googleapis.com/maps/api/geocode/json?address=Stormgade+157,+6715+Esbjerg,+Denmark&amp;key=xxx-RC0wa23c&gt; #&gt; ℹ &lt;https://maps.googleapis.com/maps/api/geocode/json?address=Golfvej+5,+7400+Herning,+Denmark&amp;key=xxx-RC0wa23c&gt; #&gt; ℹ &lt;https://maps.googleapis.com/maps/api/geocode/json?address=Slotsarkaderne+26,+3400+Hiller%C3%B8d,+Denmark&amp;key=xxx-RC0wa23c&gt; #&gt; ℹ &lt;https://maps.googleapis.com/maps/api/geocode/json?address=A.F+Heidemannsvej+20,+9800+Hj%C3%B8rring,+Denmark&amp;key=xxx-RC0wa23c&gt; #&gt; ℹ &lt;https://maps.googleapis.com/maps/api/geocode/json?address=Nyholmvej+20,+7500+Holstebro,+Denmark&amp;key=xxx-RC0wa23c&gt; dat #&gt; # A tibble: 5 × 5 #&gt; Id Shop Address lon lat #&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 Bilka Esbjerg Stormgade 157, 6715 Esbjerg, Denmark 8.46 55.5 #&gt; 2 2 Bilka Herning Golfvej 5, 7400 Herning, Denmark 9.01 56.1 #&gt; 3 3 Bilka Hillerød Slotsarkaderne 26, 3400 Hillerød, Denmark 12.3 55.9 #&gt; 4 4 Bilka Hjørring A.F Heidemannsvej 20, 9800 Hjørring, Denmark 10.0 57.4 #&gt; 5 5 Bilka Holstebro Nyholmvej 20, 7500 Holstebro, Denmark 8.62 56.4 To reverse geocode use the revgeocode function: revgeocode(c(dat$lon[1], dat$lat[1])) #&gt; ℹ &lt;https://maps.googleapis.com/maps/api/geocode/json?latlng=55.510949,8.4562446&amp;key=xxx-RC0wa23c&gt; #&gt; Warning: Multiple addresses found, the first will be returned: #&gt; ! Stormgade 157, 6715 Esbjerg, Denmark #&gt; ! Stormgade 157, 6715 Esbjerg N, Denmark #&gt; ! Stormgade 155, 6715 Esbjerg, Denmark #&gt; ! GF64+9F Esbjerg, Denmark #&gt; ! Stormgade 158-155, 6715 Esbjerg, Denmark #&gt; ! 6715 Esbjerg N, Denmark #&gt; ! Esbjerg N, 6715 Esbjerg N, Denmark #&gt; ! Esbjerg N, 6715 Esbjerg, Denmark #&gt; ! Esbjerg, Denmark #&gt; ! Esbjerg Municipality, Denmark #&gt; ! Region of Southern Denmark, Denmark #&gt; ! Denmark #&gt; [1] &quot;Stormgade 157, 6715 Esbjerg, Denmark&quot; To apply it to the dataset use: dat &lt;- dat |&gt; mutate(AddressGeoGoo = map_chr(1:n(), function(i) { revgeocode(c(lon = lon[i], lat = lat[i])) })) #&gt; ! Stormgade 157, 6715 Esbjerg, Denmark #&gt; ! Stormgade 157, 6715 Esbjerg N, Denmark #&gt; ! Stormgade 155, 6715 Esbjerg, Denmark #&gt; ! GF64+9F Esbjerg, Denmark #&gt; ! Stormgade 158-155, 6715 Esbjerg, Denmark #&gt; ! 6715 Esbjerg N, Denmark #&gt; ! Esbjerg N, 6715 Esbjerg N, Denmark #&gt; ! Esbjerg N, 6715 Esbjerg, Denmark #&gt; ! Esbjerg, Denmark #&gt; ! Esbjerg Municipality, Denmark #&gt; ! Region of Southern Denmark, Denmark #&gt; ! Denmark #&gt; ℹ &lt;https://maps.googleapis.com/maps/api/geocode/json?latlng=56.1357174,9.0053714&amp;key=xxx-RC0wa23c&gt; #&gt; ! Golfvej 5, 7400 Herning, Denmark #&gt; ! 42P4+74 Herning, Denmark #&gt; ! Engdahlsvej, 7400 Herning, Denmark #&gt; ! 7400 Herning, Denmark #&gt; ! Herning, 7400 Herning, Denmark #&gt; ! Herning Municipality, Denmark #&gt; ! Central Denmark Region, Denmark #&gt; ! Denmark #&gt; ℹ &lt;https://maps.googleapis.com/maps/api/geocode/json?latlng=55.9288332,12.2978145&amp;key=xxx-RC0wa23c&gt; #&gt; ! Slotsarkaderne 30, 3400 Hillerød, Denmark #&gt; ! Christians Torv 210, 3400 Hillerød, Denmark #&gt; ! Slotsarkaderne 26, 3400 Hillerød, Denmark #&gt; ! W7HX+G4 Hillerød, Denmark #&gt; ! Hillerød, 3400 Hillerød, Denmark #&gt; ! 3400 Hillerød, Denmark #&gt; ! Hillerød Municipality, Denmark #&gt; ! Capital Region of Denmark, Denmark #&gt; ! Denmark #&gt; ℹ &lt;https://maps.googleapis.com/maps/api/geocode/json?latlng=57.4441555,10.0034928&amp;key=xxx-RC0wa23c&gt; #&gt; ! A F Heidemanns Vej 20, 9800 Hjørring, Denmark #&gt; ! A F Heidemanns Vej 21, 9800 Hjørring, Denmark #&gt; ! A F Heidemanns Vej 21C, 9800 Hjørring, Denmark #&gt; ! C2V3+M9 Hjørring, Denmark #&gt; ! 9800 Hjørring, Denmark #&gt; ! Hjørring, 9800 Hjørring, Denmark #&gt; ! Hjørring Municipality, Denmark #&gt; ! North Denmark Region, Denmark #&gt; ! Denmark #&gt; ℹ &lt;https://maps.googleapis.com/maps/api/geocode/json?latlng=56.377168,8.621638&amp;key=xxx-RC0wa23c&gt; #&gt; ! Nyholmvej 20, 7500 Holstebro, Denmark #&gt; ! o Bilka, Nyholmvej 20 C, 7500 Holstebro, Denmark #&gt; ! Nyholmvej 5, 7500 Holstebro, Denmark #&gt; ! 9JGC+VM Holstebro, Denmark #&gt; ! Nyholmvej 7-5, 7500 Holstebro, Denmark #&gt; ! 7500 Holstebro, Denmark #&gt; ! Holstebro, 7500 Holstebro, Denmark #&gt; ! Holstebro Municipality, Denmark #&gt; ! Central Denmark Region, Denmark #&gt; ! Denmark #&gt; Warning: There were 5 warnings in `mutate()`. #&gt; The first warning was: #&gt; ℹ In argument: `AddressGeoGoo = map_chr(...)`. #&gt; Caused by warning: #&gt; ! Multiple addresses found, the first will be returned: #&gt; ℹ Run `dplyr::last_dplyr_warnings()` to see the 4 remaining warnings. dat #&gt; # A tibble: 5 × 6 #&gt; Id Shop Address lon lat AddressGeoGoo #&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 1 Bilka Esbjerg Stormgade 157, 6715 Esbjerg, Denmark 8.46 55.5 Stormgade 157, 671… #&gt; 2 2 Bilka Herning Golfvej 5, 7400 Herning, Denmark 9.01 56.1 Golfvej 5, 7400 He… #&gt; 3 3 Bilka Hillerød Slotsarkaderne 26, 3400 Hillerød, Denmark 12.3 55.9 Slotsarkaderne 30,… #&gt; 4 4 Bilka Hjørring A.F Heidemannsvej 20, 9800 Hjørring, Denmark 10.0 57.4 A F Heidemanns Vej… #&gt; 5 5 Bilka Holstebro Nyholmvej 20, 7500 Holstebro, Denmark 8.62 56.4 Nyholmvej 20, 7500… 16.5 Adding markers and routes to a map Leaflet is an open-source JavaScript library for interactive maps. It’s used by websites ranging from The New York Times and The Washington Post to GitHub and Flickr, as well as GIS specialists like OpenStreetMap, Mapbox, and CartoDB. The leaflet package makes it easy to create Leaflet maps from R. Note Leaflet is open-source and free so you do not need an API key for making maps. If you would like to use Google maps instead then have a look at the googleway package instead. First let us create a map with two base layers library(leaflet) library(htmlwidgets) m &lt;- leaflet() |&gt; # Base maps addTiles(group = &quot;Map&quot;) |&gt; addProviderTiles(&#39;Esri.WorldImagery&#39;, group = &quot;Satelite&quot;) |&gt; addProviderTiles(&quot;CartoDB.PositronOnlyLabels&quot;, group = &quot;Map&quot;) |&gt; # Center and zoom setView(10.2, 56.2, zoom = 7) |&gt; # Layer control addLayersControl( baseGroups = c(&quot;Map&quot;, &quot;Satelite&quot;), options = layersControlOptions(collapsed = TRUE) ) m Next, let us add the places: dat &lt;- tibble::tribble( ~Id, ~Shop, ~Address, 1L, &quot;Bilka Esbjerg&quot;, &quot;Stormgade 157, 6715 Esbjerg, Denmark&quot;, 2L, &quot;Bilka Herning&quot;, &quot;Golfvej 5, 7400 Herning, Denmark&quot;, 3L, &quot;Bilka Hillerød&quot;, &quot;Slotsarkaderne 26, 3400 Hillerød, Denmark&quot;, 4L, &quot;Bilka Hjørring&quot;, &quot;A.F Heidemannsvej 20, 9800 Hjørring, Denmark&quot;, 5L, &quot;Bilka Holstebro&quot;, &quot;Nyholmvej 20, 7500 Holstebro, Denmark&quot;, ) dat &lt;- dat |&gt; mutate_geocode(Address) #&gt; ℹ &lt;https://maps.googleapis.com/maps/api/geocode/json?address=Stormgade+157,+6715+Esbjerg,+Denmark&amp;key=xxx-RC0wa23c&gt; #&gt; ℹ &lt;https://maps.googleapis.com/maps/api/geocode/json?address=Golfvej+5,+7400+Herning,+Denmark&amp;key=xxx-RC0wa23c&gt; #&gt; ℹ &lt;https://maps.googleapis.com/maps/api/geocode/json?address=Slotsarkaderne+26,+3400+Hiller%C3%B8d,+Denmark&amp;key=xxx-RC0wa23c&gt; #&gt; ℹ &lt;https://maps.googleapis.com/maps/api/geocode/json?address=A.F+Heidemannsvej+20,+9800+Hj%C3%B8rring,+Denmark&amp;key=xxx-RC0wa23c&gt; #&gt; ℹ &lt;https://maps.googleapis.com/maps/api/geocode/json?address=Nyholmvej+20,+7500+Holstebro,+Denmark&amp;key=xxx-RC0wa23c&gt; m &lt;- m |&gt; addMarkers(~lon, ~lat, popup = ~Address, label = ~str_c(Id, &quot; - &quot;, Shop), data = dat) m To add a line between a set of points use the addPolylines function: routeIds &lt;- c(2, 5, 1, 2) route &lt;- dat[routeIds,] m |&gt; addPolylines(lng = ~lon, lat = ~lat, data = route, weight = 2, label = &quot;Route 1&quot;) A more advanced setup is to use the addFlows function from the leaflet.minicharts package. First let us define some lines: datLines &lt;- tibble(FromId = c(2, 5, 1, 2, 4, 3), ToId = c(5, 1, 2, 4, 3, 2)) datLines &lt;- left_join(datLines, dat |&gt; select(-Shop, -Address), by = c(&quot;FromId&quot; = &quot;Id&quot;)) |&gt; rename(&quot;FromLat&quot; = &quot;lat&quot;, &quot;FromLon&quot; = &quot;lon&quot;) |&gt; left_join(dat |&gt; select(-Shop, -Address), by = c(&quot;ToId&quot; = &quot;Id&quot;)) |&gt; rename(&quot;ToLat&quot; = &quot;lat&quot;, &quot;ToLon&quot; = &quot;lon&quot;) datLines #&gt; # A tibble: 6 × 6 #&gt; FromId ToId FromLon FromLat ToLon ToLat #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2 5 9.01 56.1 8.62 56.4 #&gt; 2 5 1 8.62 56.4 8.46 55.5 #&gt; 3 1 2 8.46 55.5 9.01 56.1 #&gt; 4 2 4 9.01 56.1 10.0 57.4 #&gt; 5 4 3 10.0 57.4 12.3 55.9 #&gt; 6 3 2 12.3 55.9 9.01 56.1 Note we have a from/to pair in each row. We add the lines to the map: library(leaflet.minicharts) m |&gt; addFlows(datLines$FromLon, datLines$FromLat, datLines$ToLon, datLines$ToLat, flow = 1, maxFlow = 20, opacity = 0.5, popup = popupArgs(noPopup = TRUE)) Let us define a function for adding routes: add_route &lt;- function(dat = NULL, route, solution = 1) { route_id = if_else(is.null(dat), 1, max(dat$RouteId) + 1) tmp &lt;- tibble(From = route[1:(length(route)-1)], To = route[2:length(route)]) tmp &lt;- tmp |&gt; mutate(Sol = solution, RouteId = route_id) dat &lt;- bind_rows(dat, tmp) } datLines &lt;- add_route(route = c(2, 5, 1, 2)) |&gt; add_route(route = c(2, 4, 3, 2)) |&gt; add_route(route = c(2, 3, 1, 2), solution = 2) |&gt; add_route(route = c(2, 5, 4, 2), solution = 2) #&gt; Warning in max(dat$RouteId): no non-missing arguments to max; returning -Inf datLines &lt;- left_join(datLines, dat |&gt; select(-Shop, -Address), by = c(&quot;From&quot; = &quot;Id&quot;)) |&gt; rename(&quot;FromLat&quot; = &quot;lat&quot;, &quot;FromLon&quot; = &quot;lon&quot;) |&gt; left_join(dat |&gt; select(-Shop, -Address), by = c(&quot;To&quot; = &quot;Id&quot;)) |&gt; rename(&quot;ToLat&quot; = &quot;lat&quot;, &quot;ToLon&quot; = &quot;lon&quot;) |&gt; mutate(group = str_c(&quot;Solution &quot;, Sol)) datLines #&gt; # A tibble: 12 × 9 #&gt; From To Sol RouteId FromLon FromLat ToLon ToLat group #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 2 5 1 1 9.01 56.1 8.62 56.4 Solution 1 #&gt; 2 5 1 1 1 8.62 56.4 8.46 55.5 Solution 1 #&gt; 3 1 2 1 1 8.46 55.5 9.01 56.1 Solution 1 #&gt; 4 2 4 1 2 9.01 56.1 10.0 57.4 Solution 1 #&gt; 5 4 3 1 2 10.0 57.4 12.3 55.9 Solution 1 #&gt; 6 3 2 1 2 12.3 55.9 9.01 56.1 Solution 1 #&gt; 7 2 3 2 3 9.01 56.1 12.3 55.9 Solution 2 #&gt; 8 3 1 2 3 12.3 55.9 8.46 55.5 Solution 2 #&gt; 9 1 2 2 3 8.46 55.5 9.01 56.1 Solution 2 #&gt; 10 2 5 2 4 9.01 56.1 8.62 56.4 Solution 2 #&gt; 11 5 4 2 4 8.62 56.4 10.0 57.4 Solution 2 #&gt; 12 4 2 2 4 10.0 57.4 9.01 56.1 Solution 2 A map with Solution 1: col_pal &lt;- rainbow(max(datLines$RouteId)) datP &lt;- datLines |&gt; filter(Sol == 1) m |&gt; addFlows(datP$FromLon, datP$FromLat, datP$ToLon, datP$ToLat, flow = datP$RouteId, maxThickness = 2, color = col_pal[datP$RouteId], opacity = 0.5, popup = popupArgs(labels = &quot;Route&quot;)) A map with Solution 2: col_pal &lt;- rainbow(max(datLines$RouteId)) datP &lt;- datLines |&gt; filter(Sol == 2) m |&gt; addFlows(datP$FromLon, datP$FromLat, datP$ToLon, datP$ToLat, flow = datP$RouteId, maxThickness = 2, color = col_pal[datP$RouteId], opacity = 0.5, popup = popupArgs(labels = &quot;Route&quot;)) An interactive map with both solutions: mm &lt;- m res &lt;- map(1:nrow(datLines), function(i) { tmp &lt;- tibble(lat = c(datLines$FromLat[i], datLines$ToLat[i]), lon = c(datLines$FromLon[i], datLines$ToLon[i])) mm &lt;&lt;- mm |&gt; addPolylines(lng = ~lon, lat = ~lat, color = col_pal[datLines$Sol[i]], group = datLines$group[i], data = tmp, weight = 2, label = datLines$group[i]) return(invisible(NULL)) }) mm &lt;- mm |&gt; # Layer control addLayersControl( baseGroups = c(&quot;Map&quot;, &quot;Satelite&quot;), overlayGroups = unique(datLines$group), options = layersControlOptions(collapsed = FALSE) ) |&gt; hideGroup(unique(datLines$group)) |&gt; showGroup(&quot;Solution 1&quot;) mm Note unfortunately arrows cannot be shown in this case. "],["groups.html", "A Working in groups Using Git together with GitHub", " A Working in groups During the course you have been allocated into groups. You are expected to solve the exercises and write the project reports in these groups. Before you start, it is a good idea to agree on a set of group rules. First, agree on a coding convention. Most people in the R community use snake case but camel case is also okay. Next, setup rules on when to meet and how you will organize the work. For instance, it is a good idea that all try to solve some of the exercises before you meet and you then discuss the answers, problems etc. Finally, it is a good idea to have a common place for your code. You have different options: Use a cloud storage services such as Dropbox, OneDrive or Google Drive. Use a version control system such as Git together with GitHub. GitHub is a code sharing and publishing service and may be seen as a social networking site for programmers. If you use Posit Cloud then one person in the group can create a shared workspace with projects: First create a new workspace named e.g. Shared. Press Members and add the group members as moderators. Now go back to Projects in the Tools for Analytics workspace and move one project to the shared workspace. Rename it to e.g. Group Project. Members will now have access to this project where you can share code. NOTE you can not work collectively on a file simultaneously. That is, only one member can change a file at a time! Hence it is a good idea to have your own private project to work on and use this project as a place where you can share code. If you want to download a project to your laptop then press the export button. The benefit of a cloud storage service is that it is well known to you and easy to setup. Cons are that you cannot work on the same file simultaneously. The benefit of Git and GitHub is that it manages the evolution of a set of files – called a repository – in a sane, highly structured way. If you have no idea what I’m talking about, think of it as the “Track Changes” features from Microsoft Word on steroids. Here you can work on files simultaneously. Moreover, it can be used from within RStudio. Cons are that it is harder to setup and learn. For a detailed description see Why Git? Why GitHub?. The Using Git together with GitHub section gives a tutorial on how to setup Git and GitHub. Skip it if you use a cloud storage service. Using Git together with GitHub Git is a version control system. Git manages the evolution of a set of files – called a repository – in a sane, highly structured way. If you have no idea what I’m talking about, think of it as the “Track Changes” features from Microsoft Word on steroids. GitHub provide a home for your Git-based projects on the internet. If you have no idea what I’m talking about, think of it as DropBox but much, much better. It allows other people to see your stuff, sync up with you, and perhaps even make changes. Even for private solo projects, it’s a good idea to push your work to a remote location for peace of mind. To configure your computer go though the following steps: Register a free GitHub account Sign-up at GitHub. Some thoughts about your username: Incorporate your actual name! People like to know who they’re dealing with. Also makes your username easier for people to guess or remember. Reuse your username from other contexts, e.g., Twitter or Slack. But, of course, someone with no GitHub activity will probably be squatting on that. Pick a username you will be comfortable revealing to your future boss. Shorter is better than longer. Be as unique as possible in as few characters as possible. In some settings GitHub auto-completes or suggests usernames. Make it timeless. Don’t highlight your current university, employer, or place of residence, e.g. JennyFromTheBlock. Avoid the use of upper vs. lower case to separate words. We highly recommend all lowercase. GitHub treats usernames in a case insensitive way, but using all lowercase is kinder to people doing downstream regular expression work with usernames, in various languages. A better strategy for word separation is to use a hyphen - or underscore _. Install Git Find installation instructions below for your operating system. Windows Install Git from the web. Windows prefers for Git to be installed below C:/Program Files and this appears to be the default. This implies, for example, that the Git executable on my Windows system is found at C:/Program Files/Git/bin/git.exe. Unless you have specific reasons to otherwise, follow this convention. If asked about “Adjusting your PATH environment”, make sure to select “Git from the command line and also from 3rd-party software”. macOS Option 1 (highly recommended): Install the Xcode command line tools (not all of Xcode), which includes Git. Go to the shell and enter one of these commands to elicit an offer to install developer command line tools: git --version git config Accept the offer! Click on “Install”. Here’s another way to request this installation, more directly: xcode-select --install We just happen to find this Git-based trigger apropos. Note also that, after upgrading macOS, you might need to re-do the above and/or re-agree to the Xcode license agreement. We have seen this cause the RStudio Git pane to disappear on a system where it was previously working. Use commands like those above to tickle Xcode into prompting you for what it needs, then restart RStudio. Option 2 (recommended): Install Git from here: http://git-scm.com/downloads. This arguably sets you up the best for the future. It will certainly get you the latest version of Git of all approaches described here. The GitHub home for the macOS installer is here: https://github.com/timcharper/git_osx_installer. At that link, you can find more info if something goes wrong or you are working on an old version of macOS. Option 3 (recommended): If you anticipate getting heavily into scientific computing, you’re going to be installing and updating lots of software. You should check out Homebrew, “the missing package manager for OS X”. Among many other things, it can install Git for you. Once you have Homebrew installed, do this in the shell: brew install git Linux Install Git via your distro’s package manager. Ubuntu or Debian Linux: sudo apt-get install git Fedora or RedHat Linux: sudo yum install git A comprehensive list for various Linux and Unix package managers: https://git-scm.com/download/linux Check your installation Quit and re-launch RStudio if there’s any doubt in your mind about whether you opened RStudio before or after installing Git. You can set your Git user name and email from within R using the usethis package: ## install if needed (do this exactly once): ## install.packages(&quot;usethis&quot;) library(usethis) use_git_config(user.name = &quot;Jane Doe&quot;, user.email = &quot;jane@example.org&quot;) What user name should you give to Git? This does not have to be your GitHub user name, although it can be. Another good option is your actual first name and last name. If you commit from different machines, sometimes people work that info into the user name. Your commits will be labelled with this user name, so make it informative to potential collaborators and future you. What email should you give to Git? This must be the email associated with your GitHub account. These commands return nothing. You can check that Git understood what you typed by looking at the output of git config --global --list from a shell. An easy way to get into a shell from RStudio is **Tools &gt; Terminal* or *Tools &gt; Shell**. If you have any problems go though Chapters 4-14 on the Happy Git site. Setup projects using Git and GitHub You have different options depending on how you start you project. I will only highlight the prefererd one. New project, GitHub first Here we create a project with “GitHub first, then RStudio” sequence: Step 1: Go to GitHub and make sure you are logged in. Click green “New repository” button. Or, if you are on your own profile page, click on “Repositories”, then click the green “New” button. Repository name: test (or whatever you wish) Public YES Initialize this repository with a README Click the big green button “Create repository.” Copy the HTTPS clone URL to your clipboard via the green “Clone or Download” button. Step 2: In RStudio, start a new Project: File &gt; New Project &gt; Version Control &gt; Git. In the “repository URL” paste the URL of your new GitHub repository. It will be something like this https://github.com/[you-username]/test.git. Be intentional about where you create this Project. Suggest you “Open in new session”. Click “Create Project” to create a new directory, which will be all of these things: a directory or “folder” on your computer a Git repository, linked to a remote GitHub repository an RStudio Project In the absence of other constraints, I suggest that all of your R projects have exactly this set-up. This should download the README.md file that we created on GitHub in the previous step. Look in RStudio’s file browser pane for the README.md file. There’s a big advantage to the “GitHub first, then RStudio” workflow: the remote GitHub repo is added as a remote for your local repo and your local master branch is now tracking master on GitHub. This is a technical but important point about Git. The practical implication is that you are now set up to push and pull. No need to fanny around setting up Git remotes and tracking branches on the command line. Step 3: Make local changes, save, commit. Do this every time you finish a valuable chunk of work, probably many times a day. From RStudio, modify the README.md file, e.g., by adding the line “This is a line from RStudio”. Save your changes. Commit these changes to your local repo. How? Click the “Git” tab in upper right pane Check “Staged” box for any files whose existence or modifications you want to commit. To see more detail on what’s changed in file since the last commit, click on “Diff” for a Git pop-up If you’re not already in the Git pop-up, click “Commit” Type a message in “Commit message”, such as “Commit from RStudio”. Click “Commit” Step 4: Push your local changes to GitHub Do this a few times a day, but possibly less often than you commit. You have new work in your local Git repository, but the changes are not online yet. This will seem counterintuitive, but first let’s stop and pull from GitHub. Why? Establish this habit for the future! If you make changes to the repo in the browser or from another machine or (one day) a collaborator has pushed, you will be happier if you pull those changes in before you attempt to push. Click the blue “Pull” button in the “Git” tab in RStudio. I doubt anything will happen, i.e. you’ll get the message “Already up-to-date.” This is just to establish a habit. Click the green “Push” button to send your local changes to GitHub. You should see some message along these lines. [master dc671f0] blah 3 files changed, 22 insertions(+) create mode 100644 .gitignore create mode 100644 myrepo.Rproj Step 5: Confirm the local change propagated to the GitHub remote Go back to the browser. I assume we’re still viewing your new GitHub repo. Refresh. You should see the new “This is a line from RStudio” in the README. If you click on “commits,” you should see one with the message “Commit from RStudio”. Step 6: Make a change on GitHub Click on README.md in the file listing on GitHub. In the upper right corner, click on the pencil for “Edit this file”. Add a line to this file, such as “Line added from GitHub.” Edit the commit message in “Commit changes” or accept the default. Click the big green button “Commit changes.” Step 7: Pull from GitHub Back in RStudio locally … Inspect your README.md. It should NOT have the line “Line added from GitHub”. It should be as you left it. Verify that. Click the blue Pull button. Look at README.md again. You should now see the new line there. The end Now just repeat these operations when you do group work. Do work somewhere. Commit it. Push it or pull it depending on where you did it, but get local and remote “synced up”. Repeat. Note that in general (and especially in future when collaborating with other developers) you will usually need to pull changes from the remote (GitHub) before pushing the local changes you have made. For this reason, it’s a good idea to try and get into the habit of pulling before you attempt to push. If you have to type in your password over and over again, this can be avoided. Have a look at Chapter 10 of Happy Git. Existing project, GitHub first See details in Chapter 16 of Happy Git. Existing project, GitHub last See details in Chapter 17 of Happy Git. "],["annotate.html", "B Annotate the course notes", " B Annotate the course notes I recommend using hypothes.is to annotate the online course notes. You can create both private and public annotations. Collaborative annotation helps people connect to each other and what they’re reading, even when they’re keeping their distance. You may also use public notes to help me indicate spell errors, unclear content etc. in the notes. "],["help.html", "C Getting help", " C Getting help We all get stuck sometimes and need some help. Below are some advises on how to help yourself and ask for help: First try to understand the error message and solve the problem. You may try to debug your code by inserting break points in VBA or use browser() in your R code. See Chapter 11 in Bryan and H (n.d.) for further details. Google is your friend. This is always the first step. Try searches like “vba range”, “r dplyr filter”, “r tidyverse”, “r subset vector”, etc. Do you need help for a specific function in R then try ?[function-name] such as ?geom_line, ?mutate, etc. Mostly, focus on the last section with examples. Moreover, some packages may have written vignettes try browseVignettes(package = \"package_name\") to check. Have a look at Help &gt; Cheatsheets in RStudio. If you can’t find an answer then it is time to ask on-line. I recommend asking a question at stackoverflow. To make your question effective, the idea is to make things as easy as possible for someone to answer. This stack overflow thread How to make a great R reproducible example? give you some good hints. The process of providing a good minimal reproducible example (reprex) often causes you to answer your own question! See also Stack Exchange’s ‘How to ask’ and How to make a reprex at tidyverse. Another option is to use i.e. ChatGPT as a mentor for you. It is in general good at giving hints for programming tasks. Note use it as a mentor and not as a giving you the solution. For instance, ask “Given me an example on a Hello world procedure in VBA. Explain careful the code since I want to learn.”. If you have a more course related question then ask it at our course forum and we will try to answer your question asap. Students are also welcome in helping each other. You can also try to annotate the online course notes if something is unclear. I will try to answer asap. You can get help from our TAs at study cafés. Note help using mail correspondence is not supported! References Bryan, J., and J. H. n.d. What They Forgot to Teach You about r. https://rstats.wtf/. "],["coding-convention.html", "D Coding/naming convention D.1 Commenting your code", " D Coding/naming convention The main reason for using a consistent set of coding conventions is to standardize the structure and coding style of an application so that you and others can easily read and understand the code. Good coding conventions result in precise, readable, and unambiguous source code that is consistent with other language conventions and as intuitive as possible. Different ways of naming you variables exists. You are advised to adopt a naming convention; some use snake case others use camel case. The Leszynski naming convention define variables with a consistent prefix that makes it easy to identify its data type. It is common to use Leszynski convention within the VBA community. The R community use snake case but camel case is also okay. Some common prefixes used for the Leszynski naming convention are: Type Prefix Example Boolean bln blnFound Currency cur curRevenue Date (Time) dtm dtmStart Double dbl dblTolerance Integer int intQuantity Long lng lngDistance String str strFName Variant vnt vntCheckSum Array ary aryNumbers (optional) User form frm frmProcess Worksheet wst wstDistances Workbook wbk wbkData Many other prefixes can be used also. Choose the naming convention you like best in your study group. But stick only to one of them. A few examples: this_is_snake_case # note you do not use capital letters here thisIsCamelCase # you start each word with a capital letter (except the first) dblTolerance # Lezynski convention naming a double (dbl) variable strFullName # Lezynski naming a string (str) variable When defining variables and functions, it is in general good practice to use nouns for variables and verbs for functions. D.1 Commenting your code It is always good practice to comment your code. Such that others can get a fast overview and understand your code easier. You can add comments at the lines of code you think is difficult to understand. Moreover, you should document the whole procedure too. We will use roxygen documentation comments which are widely known. A few examples in VBA are The top of a module file: &#39;&#39;&#39; Module description. &#39; Can be more than one line. &#39; @remarks Put your remarks on the module implementation here &#39; @author Lars Relund &lt;junk@relund.dk&gt; &#39; @date 2016-08-26 Before each sub, function etc. write: &#39;&#39; Procedure description &#39; &#39; @param strA Explanation of input parameter strA &#39; @param intB Explanation of input parameter intB &#39; @return Return value (if a function) &#39; @remarks Further remarks Public Function MyFunc(strA As String, intB As Integer) As Integer { ... } Further tags (i.e. keywords starting with @) can be seen here. In R we use a ‘hash’ (#’) to comment functions: #&#39; Subtract two vectors #&#39; #&#39; @param x First vector. #&#39; @param y Vector to be subtracted. #&#39; #&#39; @return The difference. #&#39; @export #&#39; #&#39; @examples #&#39; subtract(x = c(5,5), y = c(2,3)) subtract &lt;- function(x, y) { return(x-y) } "],["apdx-vba.html", "E VBA specific topics E.1 Debugging your code E.2 Error handling E.3 Course procedures", " E VBA specific topics E.1 Debugging your code You debug you code to find errors and correct bugs in your program. VBA has a built-in debugger that you may use to step though you code and check if the values in memory are correct. You start and use the debugger using the debugger buttons in the VBA editor, e.g. set the cursor in the top of a sub and press the Step Into button ( F8, ⇧⌘I). You can now repeatedly press the button to step though the code. In the Locals window you can see the values of the variables as you run you code. Finally, if you want to run the program until a specific line or code then insert a break-point by clicking the margin of that line in the VBA editor. Next, run you sub and the debugger will stop at that line. For more details you may have a look at Chapter 9 in Wøhlk (2010) or the videos Debug toolbar, Locals window and Breakpoints. E.2 Error handling See https://excelmacromastery.com/vba-error-handling/ E.3 Course procedures The course have a set of course procedures that you may use ‘as is’ during the course and at the exam without any warranty. I will explicitly state if you are not allowed to use them. An overview is given in Table E.1. All procedures within a topic start with the same suffix so you easy can find them using auto complete in the VBA editor (Ctrl + Space). On a mac you may have to disable the default shortcut (Ctrl + Space) for switching input sources. You can go to the System Preferences -&gt; Keyboard -&gt; Shortcuts -&gt; Input Sources and disable it. For instance all procedures related to arrays start with suffix Ary. Similar the procedures are stored in module ModAry. The modules are stored in the Excel files we use during the course and all course procedures can also be found as text files. If you want to use a course procedure in your own file copy/import the whole module containing the procedure to the Excel file. Table E.1: Course procedures. See the modules named ModRng, ModAry, ModWst, ModCol, ModTm, and ModRand for further info. Procedure Type Description AryCopyColumn sub Create a 1D array by copying it from a column in a 2D array AryCopyRow sub Create a 1D array by copying it from a row in a 2D array AryDim function Array dimension AryEmpty function Check if an array empty AryFromCSV sub Read a csv file to and array AryPaste sub Paste a 1D or 2D array to a sheet AryPasteColumn sub Paste a column of a 2D array to a sheet AryPasteRow sub Paste a row of a 2D array to a sheet AryQuickSort sub Sort a 2-Dimensional array using a quicksort algorithm AryRead sub Read a range into a 2D array AryReadLong sub Read a range (long format) into an array (up to a 5D array is supported) AryToSeq sub Set all array elements to a sequence AryToStr function Convert an array to a string AryToVal sub Set all array elements to a specific value Col2Str function Convert a collection to a string ColCopy function Copy a collection RandGenBinomial sub Generate random numbers from a binomial distribution RandGenDiscrete sub Generate random numbers from a custom discrete distribution RandGenNormal sub Generate random numbers from a normal distribution RandGenPoisson sub Generate random numbers from a poisson distribution RandGenUniformCont sub Generate random numbers from a continuous uniform distribution RandGenUniformDisc sub Generate random numbers from a discrete uniform distribution RandInvBinomial function Generate a random number from a binomial distribution RandInvDiscrete function Generate a random number from a custom discrete distribution RandInvNormal function Generate a random number from a normal distribution RandInvPoisson function Generate a random number from a Poisson distribution RandInvUniformCont function Generate a random number from a continuous uniform distribution RandInvUniformDisc function Generate a random number from a discrete uniform distribution RngClear sub Clear a range RngCurRegion function Return the current region of a range RngFormat sub Format a range RngFromCSV function Read a csv file and output it to cells RngGetAddress function Return the address of a range. RngGetColLetter function Convert column number to letter RngGetCols function Columns in range RngGetCurRegionAddress function Return the address of the current region of a range RngGetCurRegionCols function Columns in current region RngGetCurRegionFirstCol function First column in current region RngGetCurRegionFirstRow function First row in current region RngGetCurRegionLastCol function Last column in current region RngGetCurRegionLastRow function Last row in current region RngGetCurRegionLowerLeft function Return the lower left cell of the current region RngGetCurRegionLowerRight function Return the lower right cell of the current region RngGetCurRegionRange function Return the part of the current region starting with upper right cell in row and col number (counting within the current range) and lower right corner of the current range. RngGetCurRegionRows function Rows in current region RngGetCurRegionUpperLeft function Return the upper left cell of the current region RngGetCurRegionUpperRight function Return the upper right cell of the current region RngGetFirstCol function First column in range RngGetFirstRow function First row in range RngGetLastCol function Last column in range RngGetLastRow function Last row in range RngGetLowerLeft function Return the lower left cell of the range RngGetLowerRight function Return the lower right cell of the range RngGetRange function Return the part of the range starting with upper right cell in row and col RngGetRows function Rows in range RngGetUpperLeft function Return the upper left cell of the range RngGetUpperRight function Return the upper right cell of the range RngJoin function Join two ranges RngPaste function Paste a range on a sheet. RngRemoveInterior sub Remove fill colors in cell range RngToCSV sub Write a range to a csv file TmElapsed function Time since timer has be started. TmRestoreAfterSpeedOptimize sub Restore properties for the Application object after have called ApplicationSpeedOptimize TmSpeedOptimize sub Set some properties for the Application object to optimize excecution of vba TmStart function Start timer (unit seconds) WstClear function Clear a worksheet if it exists WstCreate function Create a worksheet WstDelete function Delete a worksheet if it exists WstExists function Check if a worksheet exists WstRename function Rename a worksheet if it exists and no sheet with the new name E.3.1 Detailed descriptions of course procedures #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; • `` -&gt; `...1` #&gt; • `` -&gt; `...2` #&gt; Warning in stri_sub(string, from = start, to = end): argument is not an atomic vector; coercing #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; • `` -&gt; `...1` #&gt; • `` -&gt; `...2` E.3.1.1 RngRemoveInterior: Remove fill colors in cell range Usage Sub RngRemoveInterior( rng As Range ) Argument Description rng Range to clear. E.3.1.2 RngFormat: Format a range Usage Sub RngFormat( rng As Range, Optional color As String = &quot;none&quot;, Optional fit As Boolean = False, Optional vertical As Boolean = False, Optional merge As Boolean = False, Optional wrap As Boolean = False ) Argument Description rng Range to format. color A string equal “normal”, “yellow”, “orange” or “green” (otherwise leave background as is). fit Autofit width? vertical Make orientation vertical? merge Merge range? wrap Wrap text? Only works if you use an english version of Excel since e.g. .Style=“Good” must be replaced with .Style = “God” in DK. Examples Dim rng As Range Dim rngNew As Range Set rng = RngCurRegion(Range(&quot;D7&quot;)) &#39; get current region MsgBox (&quot;Copy to H14 (upper left corner).&quot;) Set rngNew = RngPaste(rng, Range(&quot;H14&quot;)) &#39; rngNew is now the new range MsgBox (&quot;Make yellow.&quot;) Call RngFormat(rngNew, &quot;yellow&quot;) MsgBox (&quot;Remove format.&quot;) Call RngClear(rngNew, blnCells:=False, blnFormat:=True) MsgBox (&quot;Clear range.&quot;) Call RngClear(rngNew) E.3.1.3 RngGetCurRegionRows: Rows in current region Usage Function RngGetCurRegionRows( rng As Range ) As Long Argument Description rng A range within the currentregion Currentregion is the 2-dim range exapanded until empty cells Examples Dim rng As Range ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Set rng = Range(&quot;D7&quot;) &#39; assume we know that data contains cell D7 MsgBox (&quot;Address: &quot; &amp; RngGetCurRegionAddress(rng)) MsgBox (&quot;Rows = &quot; &amp; RngGetCurRegionRows(rng) &amp; &quot; cols = &quot; &amp; RngGetCurRegionCols(rng)) MsgBox (&quot;First row number = &quot; &amp; RngGetCurRegionFirstRow(rng) &amp; &quot;. Last row number = &quot; &amp; RngGetCurRegionLastRow(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col number = &quot; &amp; RngGetCurRegionFirstCol(rng) &amp; &quot;. Last col number = &quot; &amp; RngGetCurRegionLastCol(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col letter = &quot; &amp; RngGetCurRegionFirstCol(rng, True) &amp; &quot;. Last col letter = &quot; &amp; RngGetCurRegionLastCol(rng, True) &amp; &quot;.&quot;) E.3.1.4 RngGetCurRegionCols: Columns in current region Usage Function RngGetCurRegionCols( rng As Range ) As Long Argument Description rng A range within the currentregion Currentregion is the 2-dim range exapanded until empty cells Examples Dim rng As Range ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Set rng = Range(&quot;D7&quot;) &#39; assume we know that data contains cell D7 MsgBox (&quot;Address: &quot; &amp; RngGetCurRegionAddress(rng)) MsgBox (&quot;Rows = &quot; &amp; RngGetCurRegionRows(rng) &amp; &quot; cols = &quot; &amp; RngGetCurRegionCols(rng)) MsgBox (&quot;First row number = &quot; &amp; RngGetCurRegionFirstRow(rng) &amp; &quot;. Last row number = &quot; &amp; RngGetCurRegionLastRow(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col number = &quot; &amp; RngGetCurRegionFirstCol(rng) &amp; &quot;. Last col number = &quot; &amp; RngGetCurRegionLastCol(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col letter = &quot; &amp; RngGetCurRegionFirstCol(rng, True) &amp; &quot;. Last col letter = &quot; &amp; RngGetCurRegionLastCol(rng, True) &amp; &quot;.&quot;) E.3.1.5 RngGetColLetter: Convert column number to letter Usage Function RngGetColLetter( lngCol As Long ) As String Argument Description lngCol Column number. E.3.1.6 RngGetCurRegionFirstRow: First row in current region Usage Function RngGetCurRegionFirstRow( rng As Range ) As Long Argument Description rng A range within the currentregion Current region is the 2-dim range expanded until empty cells Examples Dim rng As Range ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Set rng = Range(&quot;D7&quot;) &#39; assume we know that data contains cell D7 MsgBox (&quot;Address: &quot; &amp; RngGetCurRegionAddress(rng)) MsgBox (&quot;Rows = &quot; &amp; RngGetCurRegionRows(rng) &amp; &quot; cols = &quot; &amp; RngGetCurRegionCols(rng)) MsgBox (&quot;First row number = &quot; &amp; RngGetCurRegionFirstRow(rng) &amp; &quot;. Last row number = &quot; &amp; RngGetCurRegionLastRow(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col number = &quot; &amp; RngGetCurRegionFirstCol(rng) &amp; &quot;. Last col number = &quot; &amp; RngGetCurRegionLastCol(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col letter = &quot; &amp; RngGetCurRegionFirstCol(rng, True) &amp; &quot;. Last col letter = &quot; &amp; RngGetCurRegionLastCol(rng, True) &amp; &quot;.&quot;) E.3.1.7 RngGetCurRegionFirstCol: First column in current region Usage Function RngGetCurRegionFirstCol( rng As Range, Optional asLetter As Boolean = False ) As Variant Argument Description rng A range within the currentregion Currentregion is the 2-dim range expanded until empty cells Examples Dim rng As Range ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Set rng = Range(&quot;D7&quot;) &#39; assume we know that data contains cell D7 MsgBox (&quot;Address: &quot; &amp; RngGetCurRegionAddress(rng)) MsgBox (&quot;Rows = &quot; &amp; RngGetCurRegionRows(rng) &amp; &quot; cols = &quot; &amp; RngGetCurRegionCols(rng)) MsgBox (&quot;First row number = &quot; &amp; RngGetCurRegionFirstRow(rng) &amp; &quot;. Last row number = &quot; &amp; RngGetCurRegionLastRow(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col number = &quot; &amp; RngGetCurRegionFirstCol(rng) &amp; &quot;. Last col number = &quot; &amp; RngGetCurRegionLastCol(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col letter = &quot; &amp; RngGetCurRegionFirstCol(rng, True) &amp; &quot;. Last col letter = &quot; &amp; RngGetCurRegionLastCol(rng, True) &amp; &quot;.&quot;) E.3.1.8 RngGetCurRegionLastRow: Last row in current region Usage Function RngGetCurRegionLastRow( rng As Range ) As Long Argument Description rng A range within the currentregion Currentregion is the 2-dim range expanded until empty cells Examples Dim rng As Range ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Set rng = Range(&quot;D7&quot;) &#39; assume we know that data contains cell D7 MsgBox (&quot;Address: &quot; &amp; RngGetCurRegionAddress(rng)) MsgBox (&quot;Rows = &quot; &amp; RngGetCurRegionRows(rng) &amp; &quot; cols = &quot; &amp; RngGetCurRegionCols(rng)) MsgBox (&quot;First row number = &quot; &amp; RngGetCurRegionFirstRow(rng) &amp; &quot;. Last row number = &quot; &amp; RngGetCurRegionLastRow(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col number = &quot; &amp; RngGetCurRegionFirstCol(rng) &amp; &quot;. Last col number = &quot; &amp; RngGetCurRegionLastCol(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col letter = &quot; &amp; RngGetCurRegionFirstCol(rng, True) &amp; &quot;. Last col letter = &quot; &amp; RngGetCurRegionLastCol(rng, True) &amp; &quot;.&quot;) E.3.1.9 RngGetCurRegionLastCol: Last column in current region Usage Function RngGetCurRegionLastCol( rng As Range, Optional asLetter As Boolean = False ) As Variant Argument Description rng A range within the currentregion Currentregion is the 2-dim range expanded until empty cells Examples Dim rng As Range ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Set rng = Range(&quot;D7&quot;) &#39; assume we know that data contains cell D7 MsgBox (&quot;Address: &quot; &amp; RngGetCurRegionAddress(rng)) MsgBox (&quot;Rows = &quot; &amp; RngGetCurRegionRows(rng) &amp; &quot; cols = &quot; &amp; RngGetCurRegionCols(rng)) MsgBox (&quot;First row number = &quot; &amp; RngGetCurRegionFirstRow(rng) &amp; &quot;. Last row number = &quot; &amp; RngGetCurRegionLastRow(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col number = &quot; &amp; RngGetCurRegionFirstCol(rng) &amp; &quot;. Last col number = &quot; &amp; RngGetCurRegionLastCol(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col letter = &quot; &amp; RngGetCurRegionFirstCol(rng, True) &amp; &quot;. Last col letter = &quot; &amp; RngGetCurRegionLastCol(rng, True) &amp; &quot;.&quot;) E.3.1.10 RngGetCurRegionRange: Return the part of the current region starting with upper right cell in row and col number (counting within the current range) and lower right corner of the current range. Usage Function RngGetCurRegionRange( rng As Range, Optional row As Integer = 1, Optional col As Integer = 1 ) As Range Argument Description rng A range within the currentregion row First row number in the current range. col First column number in the current range. Examples RngGetCurRegionRange(rng, 2, 3) &#39; return the range of the current region starting in row number 2 and column number 3. E.3.1.11 RngGetCurRegionUpperLeft: Return the upper left cell of the current region Usage Function RngGetCurRegionUpperLeft( rng As Range, Optional asString As Boolean = False ) As Variant Argument Description rng A range within the currentregion asString Return as R1C1 string; otherwise return a Range to the cell. Examples Dim rng As Range Set rng = ThisWorkbook.Worksheets(&quot;TM5&quot;).Range(&quot;C5&quot;) MsgBox (&quot;Address: &quot; &amp; RngGetCurRegionAddress(rng)) MsgBox (&quot;Number of rows: &quot; &amp; RngGetCurRegionRows(rng)) MsgBox (&quot;Number of cols: &quot; &amp; RngGetCurRegionCols(rng)) MsgBox (&quot;First column number: &quot; &amp; RngGetCurRegionFirstCol(rng)) MsgBox (&quot;First column letter: &quot; &amp; RngGetCurRegionFirstCol(rng, asLetter:=True)) MsgBox (&quot;Lower left cell: &quot; &amp; RngGetCurRegionLowerLeft(rng, asString:=True)) MsgBox (&quot;Upper left cell: &quot; &amp; RngGetCurRegionUpperLeft(rng, asString:=True)) MsgBox (&quot;Lower right cell: &quot; &amp; RngGetCurRegionLowerRight(rng, asString:=True)) MsgBox (&quot;Upper right cell: &quot; &amp; RngGetCurRegionUpperRight(rng, asString:=True)) E.3.1.12 RngGetCurRegionLowerLeft: Return the lower left cell of the current region Usage Function RngGetCurRegionLowerLeft( rng As Range, Optional asString As Boolean = False ) As Variant Argument Description rng A range within the currentregion asString Return as R1C1 string; otherwise return a Range to the cell. Examples Dim rng As Range Set rng = ThisWorkbook.Worksheets(&quot;TM5&quot;).Range(&quot;C5&quot;) MsgBox (&quot;Address: &quot; &amp; RngGetCurRegionAddress(rng)) MsgBox (&quot;Number of rows: &quot; &amp; RngGetCurRegionRows(rng)) MsgBox (&quot;Number of cols: &quot; &amp; RngGetCurRegionCols(rng)) MsgBox (&quot;First column number: &quot; &amp; RngGetCurRegionFirstCol(rng)) MsgBox (&quot;First column letter: &quot; &amp; RngGetCurRegionFirstCol(rng, asLetter:=True)) MsgBox (&quot;Lower left cell: &quot; &amp; RngGetCurRegionLowerLeft(rng, asString:=True)) MsgBox (&quot;Upper left cell: &quot; &amp; RngGetCurRegionUpperLeft(rng, asString:=True)) MsgBox (&quot;Lower right cell: &quot; &amp; RngGetCurRegionLowerRight(rng, asString:=True)) MsgBox (&quot;Upper right cell: &quot; &amp; RngGetCurRegionUpperRight(rng, asString:=True)) E.3.1.13 RngGetCurRegionUpperRight: Return the upper right cell of the current region Usage Function RngGetCurRegionUpperRight( rng As Range, Optional asString As Boolean = False ) As Variant Argument Description rng A range within the currentregion asString Return as R1C1 string; otherwise return a Range to the cell. Examples Dim rng As Range Set rng = ThisWorkbook.Worksheets(&quot;TM5&quot;).Range(&quot;C5&quot;) MsgBox (&quot;Address: &quot; &amp; RngGetCurRegionAddress(rng)) MsgBox (&quot;Number of rows: &quot; &amp; RngGetCurRegionRows(rng)) MsgBox (&quot;Number of cols: &quot; &amp; RngGetCurRegionCols(rng)) MsgBox (&quot;First column number: &quot; &amp; RngGetCurRegionFirstCol(rng)) MsgBox (&quot;First column letter: &quot; &amp; RngGetCurRegionFirstCol(rng, asLetter:=True)) MsgBox (&quot;Lower left cell: &quot; &amp; RngGetCurRegionLowerLeft(rng, asString:=True)) MsgBox (&quot;Upper left cell: &quot; &amp; RngGetCurRegionUpperLeft(rng, asString:=True)) MsgBox (&quot;Lower right cell: &quot; &amp; RngGetCurRegionLowerRight(rng, asString:=True)) MsgBox (&quot;Upper right cell: &quot; &amp; RngGetCurRegionUpperRight(rng, asString:=True)) E.3.1.14 RngGetCurRegionLowerRight: Return the lower right cell of the current region Usage Function RngGetCurRegionLowerRight( rng As Range, Optional asString As Boolean = False ) As Variant Argument Description rng A range within the currentregion asString Return as R1C1 string; otherwise return a Range to the cell. Examples Dim rng As Range Set rng = ThisWorkbook.Worksheets(&quot;TM5&quot;).Range(&quot;C5&quot;) MsgBox (&quot;Address: &quot; &amp; RngGetCurRegionAddress(rng)) MsgBox (&quot;Number of rows: &quot; &amp; RngGetCurRegionRows(rng)) MsgBox (&quot;Number of cols: &quot; &amp; RngGetCurRegionCols(rng)) MsgBox (&quot;First column number: &quot; &amp; RngGetCurRegionFirstCol(rng)) MsgBox (&quot;First column letter: &quot; &amp; RngGetCurRegionFirstCol(rng, asLetter:=True)) MsgBox (&quot;Lower left cell: &quot; &amp; RngGetCurRegionLowerLeft(rng, asString:=True)) MsgBox (&quot;Upper left cell: &quot; &amp; RngGetCurRegionUpperLeft(rng, asString:=True)) MsgBox (&quot;Lower right cell: &quot; &amp; RngGetCurRegionLowerRight(rng, asString:=True)) MsgBox (&quot;Upper right cell: &quot; &amp; RngGetCurRegionUpperRight(rng, asString:=True)) E.3.1.15 RngJoin: Join two ranges Usage Function RngJoin( rng1 As Range, rng2 As Range ) As Range Argument Description character( Examples Dim rng As Range ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Set rng = RngJoin(Range(&quot;A35:B38&quot;), Range(&quot;A49:D56&quot;)) MsgBox (RngGetAddress(rng)) &#39; note rng is two seperate blocks of cells E.3.1.16 RngPaste: Paste a range on a sheet. Usage Function RngPaste( rng As Range, rngUL As Range, Optional withFormat As Boolean = False ) As Range Argument Description rng The range to paste rngUL The upper left cell to paste to. withFormat If true also copy cell format too. Examples Dim rng As Range Dim rngNew As Range Set rng = RngCurRegion(Range(&quot;D7&quot;)) &#39; get current region MsgBox (&quot;Copy to H14 (upper left corner).&quot;) Set rngNew = RngPaste(rng, Range(&quot;H14&quot;)) &#39; rngNew is now the new range MsgBox (&quot;Make yellow.&quot;) Call RngFormat(rngNew, &quot;yellow&quot;) MsgBox (&quot;Remove format.&quot;) Call RngClear(rngNew, blnCells:=False, blnFormat:=True) MsgBox (&quot;Clear range.&quot;) Call RngClear(rngNew) E.3.1.17 RngClear: Clear a range Usage Sub RngClear( rng As Range, Optional blnCells As Boolean = True, Optional blnContents As Boolean = False, Optional blnFormat As Boolean = False ) Argument Description rng Range to clear. blnCells Delete cell contents, formats, comments, etc. (default). blnContents Delete cell contents. blnFormat Delete cell format. Examples Dim rng As Range Dim rngNew As Range Set rng = RngCurRegion(Range(&quot;D7&quot;)) &#39; get current region MsgBox (&quot;Copy to H14 (upper left corner).&quot;) Set rngNew = RngPaste(rng, Range(&quot;H14&quot;)) &#39; rngNew is now the new range MsgBox (&quot;Make yellow.&quot;) Call RngFormat(rngNew, &quot;yellow&quot;) MsgBox (&quot;Remove format.&quot;) Call RngClear(rngNew, blnCells:=False, blnFormat:=True) MsgBox (&quot;Clear range.&quot;) Call RngClear(rngNew) E.3.1.18 RngCurRegion: Return the current region of a range Usage Function RngCurRegion( rng As Range ) As Range Argument Description rng The range to get the current region from. Examples Dim rng As Range ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Set rng = RngCurRegion(Range(&quot;D7&quot;)) &#39; rng now is the current region MsgBox (&quot;Address: &quot; &amp; RngGetAddress(rng)) MsgBox (&quot;Rows = &quot; &amp; RngGetRows(rng) &amp; &quot; cols = &quot; &amp; RngGetCols(rng)) MsgBox (&quot;First row number = &quot; &amp; RngGetFirstRow(rng) &amp; &quot;. Last row number = &quot; &amp; RngGetLastRow(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col number = &quot; &amp; RngGetFirstCol(rng) &amp; &quot;. Last col number = &quot; &amp; RngGetLastCol(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col letter = &quot; &amp; RngGetFirstCol(rng, True) &amp; &quot;. Last col letter = &quot; &amp; RngGetLastCol(rng, True) &amp; &quot;.&quot;) E.3.1.19 RngGetCurRegionAddress: Return the address of the current region of a range Usage Function RngGetCurRegionAddress( rng As Range ) As String Argument Description rng The range to get the current region from. Examples Dim rng As Range ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Set rng = Range(&quot;D7&quot;) &#39; assume we know that data contains cell D7 MsgBox (&quot;Address: &quot; &amp; RngGetCurRegionAddress(rng)) MsgBox (&quot;Rows = &quot; &amp; RngGetCurRegionRows(rng) &amp; &quot; cols = &quot; &amp; RngGetCurRegionCols(rng)) MsgBox (&quot;First row number = &quot; &amp; RngGetCurRegionFirstRow(rng) &amp; &quot;. Last row number = &quot; &amp; RngGetCurRegionLastRow(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col number = &quot; &amp; RngGetCurRegionFirstCol(rng) &amp; &quot;. Last col number = &quot; &amp; RngGetCurRegionLastCol(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col letter = &quot; &amp; RngGetCurRegionFirstCol(rng, True) &amp; &quot;. Last col letter = &quot; &amp; RngGetCurRegionLastCol(rng, True) &amp; &quot;.&quot;) E.3.1.20 RngGetAddress: Return the address of a range. Usage Function RngGetAddress( rng As Range ) As String Argument Description rng The range to get the current region from Examples Dim rng As Range ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Set rng = RngCurRegion(Range(&quot;D7&quot;)) &#39; rng now is the current region MsgBox (&quot;Address: &quot; &amp; RngGetAddress(rng)) MsgBox (&quot;Rows = &quot; &amp; RngGetRows(rng) &amp; &quot; cols = &quot; &amp; RngGetCols(rng)) MsgBox (&quot;First row number = &quot; &amp; RngGetFirstRow(rng) &amp; &quot;. Last row number = &quot; &amp; RngGetLastRow(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col number = &quot; &amp; RngGetFirstCol(rng) &amp; &quot;. Last col number = &quot; &amp; RngGetLastCol(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col letter = &quot; &amp; RngGetFirstCol(rng, True) &amp; &quot;. Last col letter = &quot; &amp; RngGetLastCol(rng, True) &amp; &quot;.&quot;) E.3.1.21 RngGetRows: Rows in range Usage Function RngGetRows( rng As Range ) As Long Argument Description rng A range. Examples Dim rng As Range Set rng = ThisWorkbook.Worksheets(&quot;TM5&quot;).Range(&quot;C4:E19&quot;) MsgBox (&quot;Number of rows: &quot; &amp; RngGetRows(rng)) MsgBox (&quot;Number of cols: &quot; &amp; RngGetCols(rng)) MsgBox (&quot;First column number: &quot; &amp; RngGetFirstCol(rng)) MsgBox (&quot;First column letter: &quot; &amp; RngGetFirstCol(rng, asLetter:=True)) MsgBox (&quot;Lower right cell: &quot; &amp; RngGetLowerRight(rng, asString:=True)) MsgBox (&quot;Upper right cell: &quot; &amp; RngGetUpperRight(rng, asString:=True)) E.3.1.22 RngGetCols: Columns in range Usage Function RngGetCols( rng As Range ) As Long Argument Description rng A range. Examples Dim rng As Range Set rng = ThisWorkbook.Worksheets(&quot;TM5&quot;).Range(&quot;C4:E19&quot;) MsgBox (&quot;Number of rows: &quot; &amp; RngGetRows(rng)) MsgBox (&quot;Number of cols: &quot; &amp; RngGetCols(rng)) MsgBox (&quot;First column number: &quot; &amp; RngGetFirstCol(rng)) MsgBox (&quot;First column letter: &quot; &amp; RngGetFirstCol(rng, asLetter:=True)) MsgBox (&quot;Lower right cell: &quot; &amp; RngGetLowerRight(rng, asString:=True)) MsgBox (&quot;Upper right cell: &quot; &amp; RngGetUpperRight(rng, asString:=True)) E.3.1.23 RngGetFirstRow: First row in range Usage Function RngGetFirstRow( rng As Range ) As Long Argument Description rng A range. Examples Dim rng As Range ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Set rng = RngCurRegion(Range(&quot;D7&quot;)) &#39; rng now is the current region MsgBox (&quot;Address: &quot; &amp; RngGetAddress(rng)) MsgBox (&quot;Rows = &quot; &amp; RngGetRows(rng) &amp; &quot; cols = &quot; &amp; RngGetCols(rng)) MsgBox (&quot;First row number = &quot; &amp; RngGetFirstRow(rng) &amp; &quot;. Last row number = &quot; &amp; RngGetLastRow(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col number = &quot; &amp; RngGetFirstCol(rng) &amp; &quot;. Last col number = &quot; &amp; RngGetLastCol(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col letter = &quot; &amp; RngGetFirstCol(rng, True) &amp; &quot;. Last col letter = &quot; &amp; RngGetLastCol(rng, True) &amp; &quot;.&quot;) E.3.1.24 RngGetFirstCol: First column in range Usage Function RngGetFirstCol( rng As Range, Optional asLetter As Boolean = False ) As Variant Argument Description rng A range. Examples Dim rng As Range Set rng = ThisWorkbook.Worksheets(&quot;TM5&quot;).Range(&quot;C4:E19&quot;) MsgBox (&quot;Number of rows: &quot; &amp; RngGetRows(rng)) MsgBox (&quot;Number of cols: &quot; &amp; RngGetCols(rng)) MsgBox (&quot;First column number: &quot; &amp; RngGetFirstCol(rng)) MsgBox (&quot;First column letter: &quot; &amp; RngGetFirstCol(rng, asLetter:=True)) MsgBox (&quot;Lower right cell: &quot; &amp; RngGetLowerRight(rng, asString:=True)) MsgBox (&quot;Upper right cell: &quot; &amp; RngGetUpperRight(rng, asString:=True)) E.3.1.25 RngGetLastRow: Last row in range Usage Function RngGetLastRow( rng As Range ) As Long Argument Description rng A range. Examples Dim rng As Range ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Set rng = RngCurRegion(Range(&quot;D7&quot;)) &#39; rng now is the current region MsgBox (&quot;Address: &quot; &amp; RngGetAddress(rng)) MsgBox (&quot;Rows = &quot; &amp; RngGetRows(rng) &amp; &quot; cols = &quot; &amp; RngGetCols(rng)) MsgBox (&quot;First row number = &quot; &amp; RngGetFirstRow(rng) &amp; &quot;. Last row number = &quot; &amp; RngGetLastRow(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col number = &quot; &amp; RngGetFirstCol(rng) &amp; &quot;. Last col number = &quot; &amp; RngGetLastCol(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col letter = &quot; &amp; RngGetFirstCol(rng, True) &amp; &quot;. Last col letter = &quot; &amp; RngGetLastCol(rng, True) &amp; &quot;.&quot;) E.3.1.26 RngGetLastCol: Last column in range Usage Function RngGetLastCol( rng As Range, Optional asLetter As Boolean = False ) As Variant Argument Description rng A range. Examples Dim rng As Range ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Set rng = RngCurRegion(Range(&quot;D7&quot;)) &#39; rng now is the current region MsgBox (&quot;Address: &quot; &amp; RngGetAddress(rng)) MsgBox (&quot;Rows = &quot; &amp; RngGetRows(rng) &amp; &quot; cols = &quot; &amp; RngGetCols(rng)) MsgBox (&quot;First row number = &quot; &amp; RngGetFirstRow(rng) &amp; &quot;. Last row number = &quot; &amp; RngGetLastRow(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col number = &quot; &amp; RngGetFirstCol(rng) &amp; &quot;. Last col number = &quot; &amp; RngGetLastCol(rng) &amp; &quot;.&quot;) MsgBox (&quot;First col letter = &quot; &amp; RngGetFirstCol(rng, True) &amp; &quot;. Last col letter = &quot; &amp; RngGetLastCol(rng, True) &amp; &quot;.&quot;) E.3.1.27 RngGetRange: Return the part of the range starting with upper right cell in row and col Usage Function RngGetRange( rng As Range, Optional row As Integer = 1, Optional col As Integer = 1 ) As Range Argument Description rng A range. row Row number in the current range. col Column number in the current range. Examples RngGetRange(rng, 2, 3) &#39; return the range of the range starting in row number 2 and column number 3. E.3.1.28 RngGetUpperLeft: Return the upper left cell of the range Usage Function RngGetUpperLeft( rng As Range, Optional asString As Boolean = False ) As Variant Argument Description rng A range. Examples MsgBox (&quot;Address: &quot; &amp; RngGetAddress(rng) &amp; vbLf &amp; _ &quot;Rows: &quot; &amp; RngGetRows(rng) &amp; &quot; &quot; &amp; &quot;Cols: &quot; &amp; RngGetCols(rng) &amp; vbLf &amp; _ &quot;UL: &quot; &amp; RngGetUpperLeft(rng, asString:=True) &amp; &quot; &quot; &amp; _ &quot;UR: &quot; &amp; RngGetUpperRight(rng, asString:=True) &amp; vbLf &amp; _ &quot;LL: &quot; &amp; RngGetLowerLeft(rng, asString:=True) &amp; &quot; &quot; &amp; _ &quot;LR: &quot; &amp; RngGetLowerRight(rng, asString:=True)) E.3.1.29 RngGetLowerLeft: Return the lower left cell of the range Usage Function RngGetLowerLeft( rng As Range, Optional asString As Boolean = False ) As Variant Argument Description rng A range. asString Return as address string; otherwise return a Range to the cell. Examples MsgBox (&quot;Address: &quot; &amp; RngGetAddress(rng) &amp; vbLf &amp; _ &quot;Rows: &quot; &amp; RngGetRows(rng) &amp; &quot; &quot; &amp; &quot;Cols: &quot; &amp; RngGetCols(rng) &amp; vbLf &amp; _ &quot;UL: &quot; &amp; RngGetUpperLeft(rng, asString:=True) &amp; &quot; &quot; &amp; _ &quot;UR: &quot; &amp; RngGetUpperRight(rng, asString:=True) &amp; vbLf &amp; _ &quot;LL: &quot; &amp; RngGetLowerLeft(rng, asString:=True) &amp; &quot; &quot; &amp; _ &quot;LR: &quot; &amp; RngGetLowerRight(rng, asString:=True)) E.3.1.30 RngGetUpperRight: Return the upper right cell of the range Usage Function RngGetUpperRight( rng As Range, Optional asString As Boolean = False ) As Variant Argument Description rng A range. asString Return as R1C1 string; otherwise return a Range to the cell. Examples Dim rng As Range Set rng = ThisWorkbook.Worksheets(&quot;TM5&quot;).Range(&quot;C4:E19&quot;) MsgBox (&quot;Number of rows: &quot; &amp; RngGetRows(rng)) MsgBox (&quot;Number of cols: &quot; &amp; RngGetCols(rng)) MsgBox (&quot;First column number: &quot; &amp; RngGetFirstCol(rng)) MsgBox (&quot;First column letter: &quot; &amp; RngGetFirstCol(rng, asLetter:=True)) MsgBox (&quot;Lower right cell: &quot; &amp; RngGetLowerRight(rng, asString:=True)) MsgBox (&quot;Upper right cell: &quot; &amp; RngGetUpperRight(rng, asString:=True)) E.3.1.31 RngGetLowerRight: Return the lower right cell of the range Usage Function RngGetLowerRight( rng As Range, Optional asString As Boolean = False ) As Variant Argument Description rng A range. asString Return as R1C1 string; otherwise return a Range to the cell. Examples Dim rng As Range Set rng = ThisWorkbook.Worksheets(&quot;TM5&quot;).Range(&quot;C4:E19&quot;) MsgBox (&quot;Number of rows: &quot; &amp; RngGetRows(rng)) MsgBox (&quot;Number of cols: &quot; &amp; RngGetCols(rng)) MsgBox (&quot;First column number: &quot; &amp; RngGetFirstCol(rng)) MsgBox (&quot;First column letter: &quot; &amp; RngGetFirstCol(rng, asLetter:=True)) MsgBox (&quot;Lower right cell: &quot; &amp; RngGetLowerRight(rng, asString:=True)) MsgBox (&quot;Upper right cell: &quot; &amp; RngGetUpperRight(rng, asString:=True)) E.3.1.32 RngToCSV: Write a range to a csv file Usage Sub RngToCSV( strFileName As String, rng As Range, Optional strDelim As String = &quot;;&quot;, Optional blnAddCharacter As Boolean = False, Optional blnAbsPath As Boolean = False ) Argument Description strFileName File name. rng Range given the upper left cell of where to place the data. strDelim Delimiter, e.g. “,” in a comma delimited file. blnAddCharacter Add quotes around values. blnAbsPath If true strName specify the absolute path otherwise create the folder as a subfolder to the current file placement. Examples Dim rng As Range ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Call TM5_ClearTestTM5 &#39; clear test cells so have empty cells &#39;&#39; Write to csv file Set rng = Range(&quot;C4:E19&quot;) Call RngToCSV(&quot;test.csv&quot;, rng, &quot;;&quot;) &#39; semicolon (;) separated file &#39;&#39; Read test.csv file to check Range(&quot;G3&quot;) = &quot;Content of test.csv:&quot; Set rng = RngFromCSV(&quot;test.csv&quot;, Range(&quot;G4&quot;), &quot;;&quot;) E.3.1.33 RngFromCSV: Read a csv file and output it to cells Usage Function RngFromCSV( strFileName As String, rngUL As Range, Optional strDelim As String = &quot;;&quot;, Optional strExcludeCharacter As String = &quot;&quot;, Optional blnAbsPath As Boolean = False ) As Range Argument Description strFileName File name. rngUL The upper left cell of where to place the data. strDelim Delimiter, e.g. “,” in a comma delimited file. strExcludeCharacter Sometimes csv files have quotes around strings (“value”). If strExcludeCharacter = “““” then removes the quotes. blnAbsPath If true strName specify the absolute path otherwise create the folder as a subfolder to the current file placement. Examples Dim rng As Range ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Call TM5_ClearTestTM5 &#39; clear test cells so have empty cells &#39;&#39; Read data1.csv file (NOTE you must know the separator in the csv file beforehand!) Range(&quot;G3&quot;) = &quot;Content of data1.csv:&quot; Set rng = RngFromCSV(&quot;data1.csv&quot;, Range(&quot;G4&quot;), &quot;;&quot;) &#39; paste file in range with upper left cell G4 MsgBox (RngGetAddress(rng)) &#39;&#39; Read data2.csv file (NOTE you must know the separator in the csv file beforehand!) Range(&quot;G8&quot;) = &quot;Content of data2.csv:&quot; Set rng = RngFromCSV(&quot;data2.csv&quot;, Range(&quot;G9&quot;), &quot;,&quot;) &#39; paste file in range with upper left cell G9 MsgBox (RngGetAddress(rng)) #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; • `` -&gt; `...1` #&gt; • `` -&gt; `...2` E.3.1.34 AryDim: Array dimension Usage Function AryDim( ary As Variant ) As Integer Argument Description ary The array. E.3.1.35 AryToStr: Convert an array to a string Usage Function AryToStr( ary As Variant, Optional strSep As String = &quot;, &quot; ) As String Argument Description ary A 1D or 2D array. strSep Seperator used to seperate the values. Examples Dim intAry(4) As Integer &#39; define array of integers with index 0-4 &#39; Set values intAry(0) = 9 intAry(1) = 12 intAry(2) = 222 intAry(3) = 4 intAry(4) = 100 &#39; Information about the array MsgBox (&quot;Lowest index: &quot; &amp; LBound(intAry)) MsgBox (&quot;Largest index: &quot; &amp; UBound(intAry)) MsgBox (&quot;Number of elements : &quot; &amp; UBound(intAry) - LBound(intAry) + 1) MsgBox (&quot;Array as a string: &quot; &amp; AryToStr(intAry)) E.3.1.36 AryPaste: Paste a 1D or 2D array to a sheet Usage Sub AryPaste( ary As Variant, rngUL As Range, Optional blnRowwise As Boolean = True ) Argument Description ary The array. rng The upper left cell of the printed cells. blnRowwise Paste the 1D array as a column or row (default). Examples Dim ary() As Integer Dim strAry() As String ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Call TM5_ClearTestTM5 &#39;&#39; Set to value single value ReDim ary(2) Call AryToVal(ary, 5) Range(&quot;G4&quot;) = &quot;A fixed value:&quot; Call AryPaste(ary, Range(&quot;G5&quot;)) &#39; the upper left cell is G5 &#39;&#39; Paste vertical Range(&quot;K4&quot;) = &quot;Paste vertical:&quot; Call AryPaste(ary, Range(&quot;K5&quot;), False) &#39;&#39; Set to sequence Call AryToSeq(ary, 1, 6) Range(&quot;G10&quot;) = &quot;A sequence:&quot; Call AryPaste(ary, Range(&quot;G11&quot;)) &#39;&#39; Read strings from a range Call AryRead(strAry, Range(&quot;C31:D33&quot;)) &#39; read a 2D array Range(&quot;G31&quot;) = &quot;Names in the &quot; &amp; AryDim(strAry) &amp; &quot;D array:&quot; Call AryPaste(strAry, Range(&quot;G32&quot;)) E.3.1.37 AryPasteRow: Paste a row of a 2D array to a sheet Usage Sub AryPasteRow( ary As Variant, intRowIdx As Integer, rngUL As Range, Optional blnRowwise As Boolean = True ) Argument Description ary The 2D array. intRowIdx The index of the row to paste. rngUL The upper left cell of the paste area. blnRowwise Paste the row horizontal (default). Examples Dim ary(2 To 3, 2 To 5) As Integer Call AryToVal(ary, 5) &#39; set all entries to 5 &#39; Paste rows Call AryPasteRow(ary, 2, Range(&quot;B2&quot;)) &#39; paste row with index 2 Call AryPasteRow(ary, 0, Range(&quot;B4&quot;)) &#39; nothing happens since index is not valid Call AryPasteRow(ary, 3, Range(&quot;B4&quot;), blnRowwise:=False) &#39; print horizontial &#39; Paste columns Call AryPasteColumn(ary, 2, Range(&quot;A9&quot;)) &#39; paste column with index 2 Call AryPasteColumn(ary, 1, Range(&quot;B12&quot;)) &#39; nothing happens since index is not valid Call AryPasteColumn(ary, 5, Range(&quot;B12&quot;), blnColwise:=False) &#39; print vertical E.3.1.38 AryPasteColumn: Paste a column of a 2D array to a sheet Usage Sub AryPasteColumn( ary As Variant, intColumnIdx As Integer, rngUL As Range, Optional blnColwise As Boolean = True ) Argument Description ary The 2D array. intColumnIdx The index of the row to paste. rngUL The upper left cell of the paste area. blnColwise Paste the column vertical (default). Examples Dim ary(2 To 3, 2 To 5) As Integer Call AryToVal(ary, 5) &#39; set all entries to 5 &#39; Paste rows Call AryPasteRow(ary, 2, Range(&quot;B2&quot;)) &#39; paste row with index 2 Call AryPasteRow(ary, 0, Range(&quot;B4&quot;)) &#39; nothing happens since index is not valid Call AryPasteRow(ary, 3, Range(&quot;B4&quot;), blnRowwise:=False) &#39; print horizontial &#39; Paste columns Call AryPasteColumn(ary, 2, Range(&quot;A9&quot;)) &#39; paste column with index 2 Call AryPasteColumn(ary, 1, Range(&quot;B12&quot;)) &#39; nothing happens since index is not valid Call AryPasteColumn(ary, 5, Range(&quot;B12&quot;), blnColwise:=False) &#39; print vertical E.3.1.39 AryCopyRow: Create a 1D array by copying it from a row in a 2D array Usage Sub AryCopyRow( ary As Variant, intRowIdx As Integer, aryRes As Variant ) Argument Description ary The 2D array. intRowIdx The index of the row. aryRes The 1D array to return (dynamic, ByRef). The array will use the same start and end index as the 2D array! Examples Dim ary(2 To 3, 2 To 5) As Integer Dim aryRes() As Integer &#39; Copy row Call AryToVal(ary, 5) &#39; set all entries to 5 Call AryCopyRow(ary, 2, aryRes) &#39; copy row with index 2 Call AryCopyRow(ary, 1, aryRes) &#39; nothing happens since index is not valid &#39; Copy column Call AryCopyColumn(ary, 3, aryRes) &#39; copy column with index 2 Call AryCopyColumn(ary, 0, aryRes) &#39; nothing happens since index is not valid E.3.1.40 AryCopyColumn: Create a 1D array by copying it from a column in a 2D array Usage Sub AryCopyColumn( ary As Variant, intColumnIdx As Integer, aryRes As Variant ) Argument Description ary The 2D array. intColumnIdx The index of the column. aryRes The 1D array to return (dynamic, ByRef). The array will use the same start and end index as the 2D array! Examples Dim ary(2 To 3, 2 To 5) As Integer Dim aryRes() As Integer &#39; Copy row Call AryToVal(ary, 5) &#39; set all entries to 5 Call AryCopyRow(ary, 2, aryRes) &#39; copy row with index 2 Call AryCopyRow(ary, 1, aryRes) &#39; nothing happens since index is not valid &#39; Copy column Call AryCopyColumn(ary, 3, aryRes) &#39; copy column with index 2 Call AryCopyColumn(ary, 0, aryRes) &#39; nothing happens since index is not valid E.3.1.41 AryRead: Read a range into a 2D array Usage Sub AryRead( ByRef ary As Variant, ByRef rng As Range, Optional intStartIdx1 As Integer = 1, Optional intStartIdx2 As Integer = 1, Optional blnReduceDim As Boolean = True ) Argument Description ary Dynamic array. rng Range to be copied. intStartIdx1 Starting index for first dimension (default 1). intStartIdx2 Starting index for second dimension (default 1). blnReduceDim If true then reduce a range with 1 row or column to a 1D array. (post?) The array contains the range values Examples Dim ary() As Integer ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Call TM5_ClearTestTM5 &#39;&#39; Read values from a range with only 1 column Call AryRead(ary, Range(&quot;C5:C9&quot;)) Range(&quot;G4&quot;) = AryDim(ary) &amp; &quot;D array:&quot; Call AryPaste(ary, Range(&quot;G5&quot;), False) &#39;&#39; Read values from a range with only 1 row Call AryRead(ary, Range(&quot;C5:E5&quot;)) Range(&quot;I4&quot;) = AryDim(ary) &amp; &quot;D array:&quot; Call AryPaste(ary, Range(&quot;I5&quot;)) &#39;&#39; Read values from a range with only 1 column/row but use 2D array Call AryRead(ary, Range(&quot;C11:C14&quot;), blnReduceDim:=False) Range(&quot;G10&quot;) = AryDim(ary) &amp; &quot;D array:&quot; Call AryPaste(ary, Range(&quot;G11&quot;), False) &#39;&#39; Use other start and end index Call AryRead(ary, Range(&quot;C17:E19&quot;), intStartIdx1:=2, intStartIdx2:=5) Range(&quot;G16&quot;) = AryDim(ary) &amp; &quot;D array with start index &quot; &amp; LBound(ary, 1) &amp; &quot; and &quot; &amp; LBound(ary, 2) &amp; &quot;:&quot; Call AryPaste(ary, Range(&quot;G17&quot;)) E.3.1.42 AryReadLong: Read a range (long format) into an array (up to a 5D array is supported) Usage Sub AryReadLong( ByRef ary As Variant, ByRef rng As Range, Optional vntDefalult As Variant = 0 ) Argument Description ary Dynamic array. rng Range to be copied in long format, i.e. index in all columns except the last which contains the values. (post?) The array contains the range values Examples Dim ary() As Integer ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Call TM5_ClearTestTM5 &#39;&#39; Read 1D array Call AryReadLong(ary, Range(&quot;A36:B38&quot;), 3) &#39; default value = 3 Range(&quot;G35&quot;) = &quot;Values in the &quot; &amp; AryDim(ary) &amp; &quot;D array:&quot; Call AryPaste(ary, Range(&quot;G36&quot;)) &#39;&#39; Read 2D array Call AryReadLong(ary, Range(&quot;A41:C47&quot;), 4) &#39; default value = 4 Range(&quot;G40&quot;) = &quot;Values in the &quot; &amp; AryDim(ary) &amp; &quot;D array:&quot; Call AryPaste(ary, Range(&quot;G41&quot;)) &#39;&#39; Read 3D array (cannot be pasted to the sheet, have a look at it using the debugger) Call AryReadLong(ary, Range(&quot;A50:D56&quot;), 5) &#39; default value = 5 E.3.1.43 AryEmpty: Check if an array empty Usage Function AryEmpty( ary As Variant ) As Boolean Argument Description ary The variable to check. E.3.1.44 AryToVal: Set all array elements to a specific value Usage Sub AryToVal( ByRef ary As Variant, value As Variant ) Argument Description ary A 1D to 5D array. value The value. Examples Dim ary() As Integer Dim strAry() As String ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Call TM5_ClearTestTM5 &#39;&#39; Set to value single value ReDim ary(2) Call AryToVal(ary, 5) Range(&quot;G4&quot;) = &quot;A fixed value:&quot; Call AryPaste(ary, Range(&quot;G5&quot;)) &#39; the upper left cell is G5 E.3.1.45 AryToSeq: Set all array elements to a sequence Usage Sub AryToSeq( ByRef ary As Variant, lngFrom As Long, lngTo As Long, Optional lngIdx As Long = 1 ) Argument Description ary A dynamic array (use redim to resize it) lngFrom From value. lngTo To value. lngIdx Start index in the array. Examples Dim ary() As Integer Dim strAry() As String ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Call TM5_ClearTestTM5 &#39;&#39; Set to sequence Call AryToSeq(ary, 1, 6) Range(&quot;G10&quot;) = &quot;A sequence:&quot; Call AryPaste(ary, Range(&quot;G11&quot;)) E.3.1.46 AryQuickSort: Sort a 2-Dimensional array using a quicksort algorithm Usage Sub AryQuickSort( ByRef ary As Variant, Optional lngColumn As Long = 0, Optional lngStartIdx As Long = -1, Optional lngEndIdx As Long = -1 ) Argument Description ary Array to sort and return. lngColumn Column to sort lngStartIdx Start index to sort from lngEndIdx End index to sort from https://stackoverflow.com/questions/4873182/sorting-a-multidimensionnal-array-in-vba Posted by Jim Rech 10/20/98 Excel.Programming. Modifications by Nigel Heffernan: Escape failed comparison with empty variant and defensive coding: check inputs Examples Dim ary() As Integer ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Call TM5_ClearTestTM5 &#39;&#39; Read from a range and sort Call AryRead(ary, Range(&quot;C5:E19&quot;)) Call AryQuickSort(ary, 1) Range(&quot;G3&quot;) = &quot;Sort w.r.t. 1. column:&quot; Call RngPaste(Range(&quot;C4:E4&quot;), Range(&quot;G4&quot;)) Call AryPaste(ary, Range(&quot;G5&quot;)) E.3.1.47 AryFromCSV: Read a csv file to and array Usage Sub AryFromCSV( ary As Variant, strFileName As String, Optional strDelim As String = &quot;;&quot;, Optional strExcludeCharacter As String = &quot;&quot;, Optional blnAbsPath As Boolean = False, Optional lngReadFrom As Long = 1 ) Argument Description strFileName File name. strDelim Delimiter, e.g. “,” in a comma delimited file. strExcludeCharacter Sometimes csv files have quotes around strings (“value”). If strExcludeCharacter = “““” then removes the quotes. blnAbsPath If true strName specify the absolute path otherwise create the folder as a subfolder to the current file placement. lngReadFrom The line to read from. Inspired by http://stackoverflow.com/questions/9564908/open-csv-file-via-vba-performance Will not work if the cell values contain the delimeter. You MUST use blnAbsPath = True if the files are stored at a network folder (e.g. OneDrive) and specify the full path. Examples Dim rng As Range Dim ary() As Integer ThisWorkbook.Worksheets(&quot;TM5&quot;).Activate Call TM5_ClearTestTM5 &#39;&#39; Read csv file (NOTE you must know the separator in the csv file beforehand!) Range(&quot;G3&quot;) = &quot;Array values:&quot; Call AryFromCSV(ary, &quot;data2.csv&quot;, &quot;,&quot;) &#39; know that it contains integers (otherwise use variant) Call AryPaste(ary, Range(&quot;G4&quot;)) #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; • `` -&gt; `...1` #&gt; • `` -&gt; `...2` E.3.1.48 WstExists: Check if a worksheet exists Usage Function WstExists( strName As String ) As Boolean Argument Description strName Name of worksheet. Examples If WstExists(&quot;Test&quot;) Then MsgBox (&quot;Found it!&quot;) E.3.1.49 WstDelete: Delete a worksheet if it exists Usage Function WstDelete( strName As String ) As Boolean Argument Description strName Name of worksheet. Examples If WstDelete(&quot;Test1&quot;) Then MsgBox (&quot;Deleted Test1&quot;) E.3.1.50 WstCreate: Create a worksheet Usage Function WstCreate( strName As String, Optional blnForce As Boolean = False ) As Boolean Argument Description strName Name of worksheet. blnForce Force deletion of worksheet if exists. Examples If WstCreate(&quot;Test&quot;, blnForce:=True) Then MsgBox (&quot;Created Test&quot;) &#39; create Test sheet E.3.1.51 WstRename: Rename a worksheet if it exists and no sheet with the new name Usage Function WstRename( strName As String, strNewName As String ) As Boolean Argument Description strName Name of worksheet. strNewName New name of worksheet. Examples If WstRename(&quot;Test&quot;, &quot;Test1&quot;) Then MsgBox (&quot;Renamed the Test to Test1&quot;) &#39; only work if no Test1 sheet E.3.1.52 WstClear: Clear a worksheet if it exists Usage Function WstClear( strName As String, Optional blnCells As Boolean = True, Optional blnContents As Boolean = False, Optional blnFormat As Boolean = False, Optional blnObjects As Boolean = False ) As Boolean Argument Description strName Name of worksheet. blnCells Delete cell contents, formats, comments, etc. (default). blnContents Delete only cell contents. blnFormat Delete only cell format. blnObjects Delete cell buttons and charts too. Examples If WstClear(&quot;Test8&quot;) Then MsgBox (&quot;Cleared Test8&quot;) &#39; no clearing since if no sheet with that name #&gt; New names: #&gt; New names: #&gt; • `` -&gt; `...1` #&gt; • `` -&gt; `...2` E.3.1.53 Col2Str: Convert a collection to a string Usage Function Col2Str( col As Collection, Optional strSep As String = &quot;, &quot; ) As String Argument Description col A collection. strSep Seperator used to seperate the values. E.3.1.54 ColCopy: Copy a collection Usage Function ColCopy( colFrom As Collection ) As Collection Argument Description colFrom The collection to copy. #&gt; Warning in stri_sub(string, from = start, to = end): argument is not an atomic vector; coercing #&gt; New names: #&gt; New names: #&gt; • `` -&gt; `...1` #&gt; • `` -&gt; `...2` #&gt; Warning in stri_sub(string, from = start, to = end): argument is not an atomic vector; coercing #&gt; New names: #&gt; • `` -&gt; `...1` #&gt; • `` -&gt; `...2` #&gt; Warning in stri_sub(string, from = start, to = end): argument is not an atomic vector; coercing #&gt; New names: #&gt; • `` -&gt; `...1` #&gt; • `` -&gt; `...2` E.3.1.55 TmStart: Start timer (unit seconds) Usage Function TmStart() As Double Argument Description character( Examples dblTimer = TmStart() Application.Wait (Now() + TimeValue(&quot;0:00:02&quot;)) &#39; wait for approx 2 sec MsgBox (TmElapsed(dblTimer, &quot;sec&quot;)) E.3.1.56 TmElapsed: Time since timer has be started. Usage Function TmElapsed( dblTimer As Double, Optional strUnit As String = &quot;sec&quot; ) Argument Description dblTimer Timer when started the timer using timer = StartTimer(). strUnit Return unit must be either ms, sec, min or hour otherwise return -1 Examples dblTimer = TmStart() Application.Wait (Now() + TimeValue(&quot;0:00:02&quot;)) &#39; wait for approx 2 sec MsgBox (TmElapsed(dblTimer, &quot;sec&quot;)) E.3.1.57 TmSpeedOptimize: Set some properties for the Application object to optimize excecution of vba Usage Sub TmSpeedOptimize() Argument Description character( Examples Dim dbltimer As Double Dim i As Integer Dim dblT1 As Double, dblT2 As Double &#39; Measure cpu time dbltimer = TmStart() Application.Wait (Now() + TimeValue(&quot;0:00:02&quot;)) &#39; wait for approx 2 sec MsgBox (&quot;Time used: &quot; &amp; TmElapsed(dbltimer, &quot;sec&quot;) &amp; &quot; sec&quot;) &#39; Impact of disabling application updates Call TmSpeedOptimize dbltimer = TmStart() For i = 1 To 10000 Cells(200, 500) = 56 Next dblT1 = TmElapsed(dbltimer, &quot;sec&quot;) Call TmRestoreAfterSpeedOptimize dbltimer = TmStart() For i = 1 To 10000 Cells(200, 500) = 56 Next dblT2 = TmElapsed(dbltimer, &quot;sec&quot;) MsgBox (&quot;Time without updates: &quot; &amp; dblT1 &amp; vbCr &amp; &quot;Time with updates: &quot; &amp; dblT2) Cells(200, 500).Clear E.3.1.58 TmRestoreAfterSpeedOptimize: Restore properties for the Application object after have called ApplicationSpeedOptimize Usage Sub TmRestoreAfterSpeedOptimize() Argument Description character( Examples Dim dbltimer As Double Dim i As Integer Dim dblT1 As Double, dblT2 As Double &#39; Measure cpu time dbltimer = TmStart() Application.Wait (Now() + TimeValue(&quot;0:00:02&quot;)) &#39; wait for approx 2 sec MsgBox (&quot;Time used: &quot; &amp; TmElapsed(dbltimer, &quot;sec&quot;) &amp; &quot; sec&quot;) &#39; Impact of disabling application updates Call TmSpeedOptimize dbltimer = TmStart() For i = 1 To 10000 Cells(200, 500) = 56 Next dblT1 = TmElapsed(dbltimer, &quot;sec&quot;) Call TmRestoreAfterSpeedOptimize dbltimer = TmStart() For i = 1 To 10000 Cells(200, 500) = 56 Next dblT2 = TmElapsed(dbltimer, &quot;sec&quot;) MsgBox (&quot;Time without updates: &quot; &amp; dblT1 &amp; vbCr &amp; &quot;Time with updates: &quot; &amp; dblT2) Cells(200, 500).Clear #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; New names: #&gt; • `` -&gt; `...1` #&gt; • `` -&gt; `...2` E.3.1.59 RandGenNormal: Generate random numbers from a normal distribution Usage Sub RandGenNormal( intSize As Integer, dblMean As Double, dblSD As Double, ary() As Double ) Argument Description intSize Random numbers generated dblMean Mean. dblSD Standard deviation. ary Array to store the values in. Examples Dim ary() As Double Dim aryDens() As Double Dim intSize As Integer ThisWorkbook.Worksheets(&quot;TM6&quot;).Activate Randomize &#39; initialize random-number generator intSize = 20 &#39; generate 20 numbers for each distribution &#39; Normal Call RandGenNormal(intSize, 100, 20, ary) Range(&quot;A1&quot;) = &quot;Normal&quot; Call AryPaste(ary, Range(&quot;A2&quot;), False) &#39; Cont. uniform [10,500[ Call RandGenUniformCont(intSize, 10, 500, ary) Range(&quot;B1&quot;) = &quot;Uniform&quot; Call AryPaste(ary, Range(&quot;B2&quot;), False) &#39; Discrete uniform 10,...,500 Call RandGenUniformDisc(intSize, 10, 500, ary) Range(&quot;B1&quot;) = &quot;Uniform&quot; Call AryPaste(ary, Range(&quot;B2&quot;), False) &#39; Binomial 100 trials, pr = 0.2 Call RandGenBinomial(intSize, 100, 0.2, ary) Range(&quot;C1&quot;) = &quot;Binomial&quot; Call AryPaste(ary, Range(&quot;C2&quot;), False) &#39; Poisson lambda = 5 Call RandGenPoisson(intSize, 5, ary) Range(&quot;D1&quot;) = &quot;Poisson&quot; Call AryPaste(ary, Range(&quot;D2&quot;), False) &#39; Custom discrete ReDim aryDens(1 To 4, 1 To 2) aryDens(1, 1) = 3 aryDens(2, 1) = 4 aryDens(3, 1) = 5 aryDens(4, 1) = 6 aryDens(1, 2) = 0.1 aryDens(2, 2) = 0.3 aryDens(3, 2) = 0.5 aryDens(4, 2) = 0.1 Call RandGenDiscrete(intSize, aryDens, ary) Range(&quot;E1&quot;) = &quot;Custom&quot; Call AryPaste(ary, Range(&quot;E2&quot;), False) Range(&quot;G3&quot;) = &quot;Custom distribution:&quot; Range(&quot;G4&quot;) = &quot;Value&quot; Range(&quot;H4&quot;) = &quot;Prob.&quot; Call AryPaste(aryDens, Range(&quot;G5&quot;)) E.3.1.60 RandInvNormal: Generate a random number from a normal distribution Usage Function RandInvNormal( dblMean As Double, dblSD As Double ) As Double Argument Description dblMean Mean. dblSD Standard deviation. Examples MsgBox (&quot;Normal: &quot; &amp; RandInvNormal(100, 20)) E.3.1.61 RandGenUniformCont: Generate random numbers from a continuous uniform distribution Usage Sub RandGenUniformCont( intSize As Integer, dblMin As Double, dblMax As Double, ary() As Double ) Argument Description intSize Random numbers generated dblMin Minimum number. dblMax Maximum number (not included). ary Array to store the values in. Examples Dim ary() As Double Dim aryDens() As Double Dim intSize As Integer ThisWorkbook.Worksheets(&quot;TM6&quot;).Activate Randomize &#39; initialize random-number generator intSize = 20 &#39; generate 20 numbers for each distribution &#39; Normal Call RandGenNormal(intSize, 100, 20, ary) Range(&quot;A1&quot;) = &quot;Normal&quot; Call AryPaste(ary, Range(&quot;A2&quot;), False) &#39; Cont. uniform [10,500[ Call RandGenUniformCont(intSize, 10, 500, ary) Range(&quot;B1&quot;) = &quot;Uniform&quot; Call AryPaste(ary, Range(&quot;B2&quot;), False) &#39; Discrete uniform 10,...,500 Call RandGenUniformDisc(intSize, 10, 500, ary) Range(&quot;B1&quot;) = &quot;Uniform&quot; Call AryPaste(ary, Range(&quot;B2&quot;), False) &#39; Binomial 100 trials, pr = 0.2 Call RandGenBinomial(intSize, 100, 0.2, ary) Range(&quot;C1&quot;) = &quot;Binomial&quot; Call AryPaste(ary, Range(&quot;C2&quot;), False) &#39; Poisson lambda = 5 Call RandGenPoisson(intSize, 5, ary) Range(&quot;D1&quot;) = &quot;Poisson&quot; Call AryPaste(ary, Range(&quot;D2&quot;), False) &#39; Custom discrete ReDim aryDens(1 To 4, 1 To 2) aryDens(1, 1) = 3 aryDens(2, 1) = 4 aryDens(3, 1) = 5 aryDens(4, 1) = 6 aryDens(1, 2) = 0.1 aryDens(2, 2) = 0.3 aryDens(3, 2) = 0.5 aryDens(4, 2) = 0.1 Call RandGenDiscrete(intSize, aryDens, ary) Range(&quot;E1&quot;) = &quot;Custom&quot; Call AryPaste(ary, Range(&quot;E2&quot;), False) Range(&quot;G3&quot;) = &quot;Custom distribution:&quot; Range(&quot;G4&quot;) = &quot;Value&quot; Range(&quot;H4&quot;) = &quot;Prob.&quot; Call AryPaste(aryDens, Range(&quot;G5&quot;)) E.3.1.62 RandInvUniformCont: Generate a random number from a continuous uniform distribution Usage Function RandInvUniformCont( dblMin As Double, dblMax As Double ) As Double Argument Description dblMin Minimum number. dblMax Maximum number (not included). Examples &#39; Cont. uniform [10,500[ MsgBox (&quot;Uniform (continuous): &quot; &amp; RandInvUniformCont(10, 500)) E.3.1.63 RandGenUniformDisc: Generate random numbers from a discrete uniform distribution Usage Sub RandGenUniformDisc( intSize As Integer, vntMin As Variant, vntMax As Variant, ary As Variant ) Argument Description intSize Random numbers generated vntMin Minimum number. vntMax Maximum number. ary Array to store the values in. Examples Dim ary() As Double Dim aryDens() As Double Dim intSize As Integer ThisWorkbook.Worksheets(&quot;TM6&quot;).Activate Randomize &#39; initialize random-number generator intSize = 20 &#39; generate 20 numbers for each distribution &#39; Normal Call RandGenNormal(intSize, 100, 20, ary) Range(&quot;A1&quot;) = &quot;Normal&quot; Call AryPaste(ary, Range(&quot;A2&quot;), False) &#39; Cont. uniform [10,500[ Call RandGenUniformCont(intSize, 10, 500, ary) Range(&quot;B1&quot;) = &quot;Uniform&quot; Call AryPaste(ary, Range(&quot;B2&quot;), False) &#39; Discrete uniform 10,...,500 Call RandGenUniformDisc(intSize, 10, 500, ary) Range(&quot;B1&quot;) = &quot;Uniform&quot; Call AryPaste(ary, Range(&quot;B2&quot;), False) &#39; Binomial 100 trials, pr = 0.2 Call RandGenBinomial(intSize, 100, 0.2, ary) Range(&quot;C1&quot;) = &quot;Binomial&quot; Call AryPaste(ary, Range(&quot;C2&quot;), False) &#39; Poisson lambda = 5 Call RandGenPoisson(intSize, 5, ary) Range(&quot;D1&quot;) = &quot;Poisson&quot; Call AryPaste(ary, Range(&quot;D2&quot;), False) &#39; Custom discrete ReDim aryDens(1 To 4, 1 To 2) aryDens(1, 1) = 3 aryDens(2, 1) = 4 aryDens(3, 1) = 5 aryDens(4, 1) = 6 aryDens(1, 2) = 0.1 aryDens(2, 2) = 0.3 aryDens(3, 2) = 0.5 aryDens(4, 2) = 0.1 Call RandGenDiscrete(intSize, aryDens, ary) Range(&quot;E1&quot;) = &quot;Custom&quot; Call AryPaste(ary, Range(&quot;E2&quot;), False) Range(&quot;G3&quot;) = &quot;Custom distribution:&quot; Range(&quot;G4&quot;) = &quot;Value&quot; Range(&quot;H4&quot;) = &quot;Prob.&quot; Call AryPaste(aryDens, Range(&quot;G5&quot;)) E.3.1.64 RandInvUniformDisc: Generate a random number from a discrete uniform distribution Usage Function RandInvUniformDisc( vntMin As Variant, vntMax As Variant ) As Variant Argument Description vntMin Minimum number. vntMax Maximum number. Examples &#39; Discrete uniform 10,...,500 MsgBox (&quot;Uniform (discrete): &quot; &amp; RandInvUniformDisc(10, 500)) E.3.1.65 RandGenBinomial: Generate random numbers from a binomial distribution Usage Sub RandGenBinomial( intSize As Integer, intTrials As Integer, dblPr As Double, ary() As Double ) Argument Description intSize Random numbers generated intTrials Number of trials. dblPr Probability of success. ary Array to store the values in. Examples Dim ary() As Double Dim aryDens() As Double Dim intSize As Integer ThisWorkbook.Worksheets(&quot;TM6&quot;).Activate Randomize &#39; initialize random-number generator intSize = 20 &#39; generate 20 numbers for each distribution &#39; Normal Call RandGenNormal(intSize, 100, 20, ary) Range(&quot;A1&quot;) = &quot;Normal&quot; Call AryPaste(ary, Range(&quot;A2&quot;), False) &#39; Cont. uniform [10,500[ Call RandGenUniformCont(intSize, 10, 500, ary) Range(&quot;B1&quot;) = &quot;Uniform&quot; Call AryPaste(ary, Range(&quot;B2&quot;), False) &#39; Discrete uniform 10,...,500 Call RandGenUniformDisc(intSize, 10, 500, ary) Range(&quot;B1&quot;) = &quot;Uniform&quot; Call AryPaste(ary, Range(&quot;B2&quot;), False) &#39; Binomial 100 trials, pr = 0.2 Call RandGenBinomial(intSize, 100, 0.2, ary) Range(&quot;C1&quot;) = &quot;Binomial&quot; Call AryPaste(ary, Range(&quot;C2&quot;), False) &#39; Poisson lambda = 5 Call RandGenPoisson(intSize, 5, ary) Range(&quot;D1&quot;) = &quot;Poisson&quot; Call AryPaste(ary, Range(&quot;D2&quot;), False) &#39; Custom discrete ReDim aryDens(1 To 4, 1 To 2) aryDens(1, 1) = 3 aryDens(2, 1) = 4 aryDens(3, 1) = 5 aryDens(4, 1) = 6 aryDens(1, 2) = 0.1 aryDens(2, 2) = 0.3 aryDens(3, 2) = 0.5 aryDens(4, 2) = 0.1 Call RandGenDiscrete(intSize, aryDens, ary) Range(&quot;E1&quot;) = &quot;Custom&quot; Call AryPaste(ary, Range(&quot;E2&quot;), False) Range(&quot;G3&quot;) = &quot;Custom distribution:&quot; Range(&quot;G4&quot;) = &quot;Value&quot; Range(&quot;H4&quot;) = &quot;Prob.&quot; Call AryPaste(aryDens, Range(&quot;G5&quot;)) E.3.1.66 RandInvBinomial: Generate a random number from a binomial distribution Usage Function RandInvBinomial( intTrials As Integer, dblPr As Double ) As Double Argument Description intTrials Number of trials. dblPr Probability of success. Examples &#39; Binomial 100 trials, pr = 0.2 MsgBox (&quot;Binomial: &quot; &amp; RandInvBinomial(100, 0.2)) E.3.1.67 RandGenPoisson: Generate random numbers from a poisson distribution Usage Sub RandGenPoisson( intSize As Integer, dblLambda As Double, ary() As Double ) Argument Description intSize Random numbers generated dblLambda Mean. ary Array to store the values in. Algorithm suggested by D. Knuth. Examples Dim ary() As Double Dim aryDens() As Double Dim intSize As Integer ThisWorkbook.Worksheets(&quot;TM6&quot;).Activate Randomize &#39; initialize random-number generator intSize = 20 &#39; generate 20 numbers for each distribution &#39; Normal Call RandGenNormal(intSize, 100, 20, ary) Range(&quot;A1&quot;) = &quot;Normal&quot; Call AryPaste(ary, Range(&quot;A2&quot;), False) &#39; Cont. uniform [10,500[ Call RandGenUniformCont(intSize, 10, 500, ary) Range(&quot;B1&quot;) = &quot;Uniform&quot; Call AryPaste(ary, Range(&quot;B2&quot;), False) &#39; Discrete uniform 10,...,500 Call RandGenUniformDisc(intSize, 10, 500, ary) Range(&quot;B1&quot;) = &quot;Uniform&quot; Call AryPaste(ary, Range(&quot;B2&quot;), False) &#39; Binomial 100 trials, pr = 0.2 Call RandGenBinomial(intSize, 100, 0.2, ary) Range(&quot;C1&quot;) = &quot;Binomial&quot; Call AryPaste(ary, Range(&quot;C2&quot;), False) &#39; Poisson lambda = 5 Call RandGenPoisson(intSize, 5, ary) Range(&quot;D1&quot;) = &quot;Poisson&quot; Call AryPaste(ary, Range(&quot;D2&quot;), False) &#39; Custom discrete ReDim aryDens(1 To 4, 1 To 2) aryDens(1, 1) = 3 aryDens(2, 1) = 4 aryDens(3, 1) = 5 aryDens(4, 1) = 6 aryDens(1, 2) = 0.1 aryDens(2, 2) = 0.3 aryDens(3, 2) = 0.5 aryDens(4, 2) = 0.1 Call RandGenDiscrete(intSize, aryDens, ary) Range(&quot;E1&quot;) = &quot;Custom&quot; Call AryPaste(ary, Range(&quot;E2&quot;), False) Range(&quot;G3&quot;) = &quot;Custom distribution:&quot; Range(&quot;G4&quot;) = &quot;Value&quot; Range(&quot;H4&quot;) = &quot;Prob.&quot; Call AryPaste(aryDens, Range(&quot;G5&quot;)) E.3.1.68 RandInvPoisson: Generate a random number from a Poisson distribution Usage Function RandInvPoisson( dblLambda As Double ) As Long Argument Description dblLambda Mean. Algorithm suggested by D. Knuth. Examples &#39; Poisson lambda = 5 MsgBox (&quot;Poisson: &quot; &amp; RandInvPoisson(5)) E.3.1.69 RandGenDiscrete: Generate random numbers from a custom discrete distribution Usage Sub RandGenDiscrete( intSize As Integer, dblDens As Variant, ary As Variant ) Argument Description intSize Random numbers generated dblDens The probability density. First column contains the outcome and the second the probability. ary Array to store the values in. Assume that the second column in aryDens sums to one. Examples Dim ary() As Double Dim aryDens() As Double Dim intSize As Integer ThisWorkbook.Worksheets(&quot;TM6&quot;).Activate Randomize &#39; initialize random-number generator intSize = 20 &#39; generate 20 numbers for each distribution &#39; Normal Call RandGenNormal(intSize, 100, 20, ary) Range(&quot;A1&quot;) = &quot;Normal&quot; Call AryPaste(ary, Range(&quot;A2&quot;), False) &#39; Cont. uniform [10,500[ Call RandGenUniformCont(intSize, 10, 500, ary) Range(&quot;B1&quot;) = &quot;Uniform&quot; Call AryPaste(ary, Range(&quot;B2&quot;), False) &#39; Discrete uniform 10,...,500 Call RandGenUniformDisc(intSize, 10, 500, ary) Range(&quot;B1&quot;) = &quot;Uniform&quot; Call AryPaste(ary, Range(&quot;B2&quot;), False) &#39; Binomial 100 trials, pr = 0.2 Call RandGenBinomial(intSize, 100, 0.2, ary) Range(&quot;C1&quot;) = &quot;Binomial&quot; Call AryPaste(ary, Range(&quot;C2&quot;), False) &#39; Poisson lambda = 5 Call RandGenPoisson(intSize, 5, ary) Range(&quot;D1&quot;) = &quot;Poisson&quot; Call AryPaste(ary, Range(&quot;D2&quot;), False) &#39; Custom discrete ReDim aryDens(1 To 4, 1 To 2) aryDens(1, 1) = 3 aryDens(2, 1) = 4 aryDens(3, 1) = 5 aryDens(4, 1) = 6 aryDens(1, 2) = 0.1 aryDens(2, 2) = 0.3 aryDens(3, 2) = 0.5 aryDens(4, 2) = 0.1 Call RandGenDiscrete(intSize, aryDens, ary) Range(&quot;E1&quot;) = &quot;Custom&quot; Call AryPaste(ary, Range(&quot;E2&quot;), False) Range(&quot;G3&quot;) = &quot;Custom distribution:&quot; Range(&quot;G4&quot;) = &quot;Value&quot; Range(&quot;H4&quot;) = &quot;Prob.&quot; Call AryPaste(aryDens, Range(&quot;G5&quot;)) E.3.1.70 RandInvDiscrete: Generate a random number from a custom discrete distribution Usage Function RandInvDiscrete( aryDens As Variant ) As Variant Argument Description aryDens The probability density. First column contains the outcome and the second the probability. Assume that the second column in aryDens sums to one. Examples Dim aryDens() As Double &#39; Custom discrete ReDim aryDens(1 To 4, 1 To 2) aryDens(1, 1) = 3 aryDens(2, 1) = 4 aryDens(3, 1) = 5 aryDens(4, 1) = 6 aryDens(1, 2) = 0.1 aryDens(2, 2) = 0.3 aryDens(3, 2) = 0.5 aryDens(4, 2) = 0.1 MsgBox (&quot;Custom (discrete): &quot; &amp; RandInvDiscrete(aryDens)) References Wøhlk, S. 2010. VBA Programming in Business Economics. DJØF Publishing. "],["lg-course.html", "F Learning goals", " F Learning goals The purpose of this course is to give students a knowledge about IT tools for Analytics which requires the analyst to be qualified in handling tools beyond e.g. basic Excel. After having participated in the course, the student must, in addition to achieving general academic skills, demonstrate: Knowledge of how a computer works at a basic level. basic programming such as variables, arrays, loops, functions and procedures. what an algorithm is. how to implement an algorithm based on a description. different programming languages. how to manage a code in a collaborative working environment. Skills to handle data such as import, tidy, transform, visualize and export. develop well-structured code. perform testing and debugging. implement/code selected algorithms. apply analytical techniques on data. apply relevant methods, algorithms and techniques from this course in order to solve a specific problem. Competences to independently handle data given a problem. independently analyze data given a relevant research question. compare different programming languages. compare different algorithms solving a problem and discuss their advantages and disadvantages. interpret and discuss results based on a data analysis in relation to the relevant academic literature. communicate results from applied research in a scientific way, e.g. using literate programming. "],["ba.html", "G Business Analytics", " G Business Analytics Business Analytics (BA) refers to the scientific process of transforming data into insight for making better decisions in business. BA can both be seen as the complete decision making process for solving a business problem or as a set of methodologies that enable the creation of business value. As a process it can be characterized by descriptive, predictive, and prescriptive model building using “big” data sources. Descriptive Analytics: A set of technologies and processes that use data to understand and analyze business performance. Descriptive analytics are the most commonly used and most well understood type of analytics. Descriptive analytics categorizes, characterizes, consolidates, and classifies data. Examples are standard reporting and dashboards (KPIs, what happened or is happening now?) and ad-hoc reporting (how many/often?). Descriptive analytics often serves as a first step in the successful application of predictive or prescriptive analytics. Predictive Analytics: The use of data and statistical techniques to make predictions about future outputs/outcomes, identify patterns or opportunities for business performance. Examples of techniques are data mining (what data is correlated with other data?), pattern recognition and alerts (when should I take action to correct/adjust a spare part?), Monte-Carlo simulation (what could happen?), neural networks (which customer group are best?) and forecasting (what if these trends continue?). Prescriptive Analytics: The use of optimization and other decision modelling techniques using the results of descriptive and predictive analytics to suggest decision options with the goal of improving business performance. Prescriptive analytics attempt to quantify the effect of future decisions in order to advise on possible outcomes before the decisions are actually made. Prescriptive analytics predicts not only what will happen, but also why it will happen and provides recommendations regarding actions that will take advantage of the predictions. Prescriptive analytics are relatively complex to administer, and most companies are not yet using it in their daily course of business. However, when implemented correctly, it can have a huge impact on business performance and how businesses make decisions. Examples on prescriptive analytics are optimization in production planning and scheduling, inventory management, the supply chain and transportation planning. Companies who use BA focus on fact-based management to drive decision making and treats data and information as a strategic asset that is shared within the company. This enterprise approach generates a companywide respect for applying descriptive, predictive and prescriptive analytics in areas such as supply chain, marketing and human resources. Related areas: In the past Business Intelligence traditionally focuses on querying, reporting, online analytical processing, i.e. descriptive analytics. However, a more modern definition of Business Intelligence is the union of descriptive and predictive analytics. Operations Research or Management Science deals with the application of advanced analytical methods to help make better decisions and can hence be seen as prescriptive analytics. However, traditionally it has been taking a more theoretical approach and focusing on problem-driven research while BA takes a more data-driven approach. Logistics is a cross-functional area focusing on the effective and efficient flows of goods and services, and the related flows of information and cash. Supply Chain Management adds a process-oriented and cross-company perspective. Both can be seen as prescriptive analytics with a more problem-driven research focus. Advanced Analytics is often used as a classification of both predictive and prescriptive analytics. Data science is an interdisciplinary field about scientific methods, processes, and systems to extract knowledge or insights from data in various forms, either structured or unstructured and can be seen as Business analytics applied to a wider range of data. Resources http://analytics-magazine.org/the-analytics-journey/ https://en.wikipedia.org/wiki/Business_analytics http://connect.informs.org/analytics/home https://www.or-exchange.org/questions/5645/informs-analytics-definition https://en.wikipedia.org/wiki/Prescriptive_analytics https://en.wikipedia.org/wiki/Predictive_analytics "],["colophon.html", "H Colophon", " H Colophon These notes were written in bookdown inside RStudio. This version of the book was built with: #&gt; Finding R package dependencies ... Done! #&gt; setting value #&gt; version R version 4.5.1 (2025-06-13) #&gt; os Ubuntu 24.04.2 LTS #&gt; system x86_64, linux-gnu #&gt; ui X11 #&gt; language (EN) #&gt; collate C.UTF-8 #&gt; ctype C.UTF-8 #&gt; tz UTC #&gt; date 2025-08-05 #&gt; pandoc 3.1.11 @ /opt/hostedtoolcache/pandoc/3.1.11/x64/ (via rmarkdown) #&gt; quarto NA Along with these packages: Boyar, J., and K. S. Larsen. 1999. “The Seat Reservation Problem.” Algorithmica 25 (4): 403–17. https://doi.org/10.1007/pl00009286. Boyar, Joan, Susan Krarup, and Morten N Nielsen. 2004. “Seat Reservation Allowing Seat Changes.” Journal of Algorithms 52 (2): 169–92. https://doi.org/10.1016/j.jalgor.2004.02.002. Bryan, J. 2017. STAT 545 - Data Wrangling, Exploration, and Analysis with r. https://stat545.com/. Bryan, J., and J. H. n.d. What They Forgot to Teach You about r. https://rstats.wtf/. Bryan, J., the STAT 545 TAs, and J. Hester. 2020. Happy Git and GitHub for the useR. https://happygitwithr.com/. Cullen, A. C., and H. C. Frey. 1999. The Use of Probabilistic Techniques in Exposure Assessment. Plenum. Delignette-Muller, Marie Laure, and Christophe Dutang. 2015. “Fitdistrplus: An r Package for Fitting Distributions.” Journal of Statistical Software 64 (4): 1–34. https://doi.org/10.18637/jss.v064.i04. Irizarry, R. A. 2020. Introduction to Data Science - Data Analysis and Prediction Algorithms with r. https://rafalab.github.io/dsbook/. Ismay, C., and A. Y. Kim. 2020. Statistical Inference via Data Science. ModernDrive. https://moderndive.netlify.app/. Nielsen, L. R. 2024. Tools for Analytics - Course Notes. https://bss-osca.github.io/tfa/. Peng, R. D. 2018. R Programming for Data Science. https://bookdown.org/rdpeng/rprogdatascience/. Wickham, H. 2017. R for Data Science. O’Reilly. https://r4ds.had.co.nz/. Wickham, Hadley. 2015. R Packages: Organize, Test, Document, and Share Your Code. O’Reilly Media. http://r-pkgs.had.co.nz/. Wilkinson, Leland. 2005. The Grammar of Graphics (Statistics and Computing). Springer-Verlag. Wøhlk, S. 2010. VBA Programming in Business Economics. DJØF Publishing. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
